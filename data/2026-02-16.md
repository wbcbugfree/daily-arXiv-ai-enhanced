<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 32]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.IR](#cs.IR) [Total: 13]
- [cs.LG](#cs.LG) [Total: 66]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Lightweight LLM Framework for Disaster Humanitarian Information Classification](https://arxiv.org/abs/2602.12284)
*Han Jinzhen,Kim Jisung,Yang Jong Soo,Yun Hong Sik*

Main category: cs.CL

TL;DR: 针对资源受限应急场景下LLM部署难题，提出基于LoRA/QLoRA参数高效微调的轻量化灾害推文分类框架，在HumAID数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体人道主义信息及时分类对灾害响应至关重要，但LLM在资源受限应急环境中的部署面临计算成本高、内存占用大等挑战。

Method: 整合HumAID数据集（76,484条推文，19个灾害事件）构建双任务基准（人道主义信息分类+事件类型识别），在Llama 3.1 8B上系统评估提示工程、LoRA微调、QLoRA及检索增强生成（RAG）策略。

Result: 1) LoRA仅训练约2%参数即实现79.62%分类准确率（较零样本提升37.79%）；2) QLoRA以50%内存成本保持99.4%的LoRA性能；3) RAG因检索示例的标签噪声反而降低微调模型效果。

Conclusion: 验证了参数高效微调在应急场景的可行性，为构建低成本、可复现的危机情报系统提供了实践路径。

Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper develops a lightweight, cost-effective framework for disaster tweet classification using parameter-efficient fine-tuning. We construct a unified experimental corpus by integrating and normalizing the HumAID dataset (76,484 tweets across 19 disaster events) into a dual-task benchmark: humanitarian information categorization and event type identification. Through systematic evaluation of prompting strategies, LoRA fine-tuning, and retrieval-augmented generation (RAG) on Llama 3.1 8B, we demonstrate that: (1) LoRA achieves 79.62% humanitarian classification accuracy (+37.79% over zero-shot) while training only ~2% of parameters; (2) QLoRA enables efficient deployment with 99.4% of LoRA performance at 50% memory cost; (3) contrary to common assumptions, RAG strategies degrade fine-tuned model performance due to label noise from retrieved examples. These findings establish a practical, reproducible pipeline for building reliable crisis intelligence systems with limited computational resources.

</details>


### [2] [From Biased Chatbots to Biased Agents: Examining Role Assignment Effects on LLM Agent Robustness](https://arxiv.org/abs/2602.12285)
*Linbo Cao,Lihao Sun,Yang Yue*

Main category: cs.CL

TL;DR: 该研究首次系统性地证明，基于人口统计特征的角色设定会显著影响大语言模型智能体的行为并导致性能下降（最高达26.2%），揭示当前系统在安全部署方面的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注文本生成中的角色偏见，但忽略了这种偏见对具有现实世界影响的智能体任务性能的直接操作风险，这是亟待探索的安全隐患。

Method: 对广泛部署的大语言模型在涵盖策略推理、规划和运维操作的智能体基准测试中进行评估，系统分析无关角色线索对性能的影响。

Result: 发现无关角色设定会导致显著的性能差异（最高下降26.2%），且这种影响跨越任务类型和模型架构，表明简单的角色设定和提示注入即可扭曲决策可靠性。

Conclusion: 角色分配会引入隐性偏见并增加行为不稳定性，这是当前大语言模型智能体系统中被忽视的脆弱性，对安全鲁棒的部署构成挑战。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents capable of actions with real-world impacts beyond text generation. While persona-induced biases in text generation are well documented, their effects on agent task performance remain largely unexplored, even though such effects pose more direct operational risks. In this work, we present the first systematic case study showing that demographic-based persona assignments can alter LLM agents' behavior and degrade performance across diverse domains. Evaluating widely deployed models on agentic benchmarks spanning strategic reasoning, planning, and technical operations, we uncover substantial performance variations - up to 26.2% degradation, driven by task-irrelevant persona cues. These shifts appear across task types and model architectures, indicating that persona conditioning and simple prompt injections can distort an agent's decision-making reliability. Our findings reveal an overlooked vulnerability in current LLM agentic systems: persona assignments can introduce implicit biases and increase behavioral volatility, raising concerns for the safe and robust deployment of LLM agents.

</details>


### [3] [Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction](https://arxiv.org/abs/2602.12287)
*Junjie An,Jingguang Tian,Tianyi Wang,Yu Gao,Xiaofeng Mou,Yi Xu*

Main category: cs.CL

TL;DR: 针对端到端自动语音识别系统命名实体误识别问题，本文提出基于大语言模型的检索增强生成框架。该框架包含重述语言模型进行实体识别与音素级候选检索，以及可根据任务难度动态调整推理深度的自适应思维链模型。在AISHELL-1和Homophone数据集上，命名实体字错误率相对基线分别降低17.96%和34.42%。


<details>
  <summary>Details</summary>
Motivation: 端到端语音识别系统对命名实体等专域短语识别错误率高，易导致下游任务灾难性失败。现有基于大语言模型的纠正方法未充分利用其复杂推理能力，需探索更有效的推理机制以提升纠正性能。

Method: 提出双组件检索增强框架：1) 重述语言模型完成命名实体识别后，采用音素级编辑距离检索候选实体；2) 自适应思维链推理模型根据任务难度动态调节推理深度。通过检索与推理的协同优化实现精准纠正。

Result: 实验表明，该方法在AISHELL-1和Homophone数据集上均取得显著改进，命名实体字错误率相对强基线分别降低17.96%和34.42%，验证了所提框架的有效性。

Conclusion: 本研究提出的检索增强框架结合自适应推理机制，有效利用大语言模型能力，显著提升了语音识别中命名实体的纠正准确率，为语音识别后处理提供了有效解决方案。

Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large language models (LLMs) has recently emerged. However, these approaches have yet to fully exploit the sophisticated reasoning capabilities inherent to LLMs. To bridge this gap, we propose a novel retrieval-augmented generation framework for correcting named entity errors in ASR. Our approach consists of two key components: (1) a rephrasing language model (RLM) for named entity recognition, followed by candidate retrieval using a phonetic-level edit distance; and (2) a novel self-taught reasoning model with adaptive chain-of-thought (A-STAR) that dynamically adjusts the depth of its reasoning based on task difficulty. Experiments on the AISHELL-1 and Homophone datasets demonstrate the effectiveness of our method, which achieves relative reductions in the named entity character error rate of 17.96\% and 34.42\%, respectively, compared to a strong baseline.

</details>


### [4] [Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria à Prática](https://arxiv.org/abs/2602.12302)
*Neemias da Silva,Júlio C. W. Scholz,John Harrison,Marina Borges,Paulo Ávila,Frances A Santos,Myriam Delgado,Rodrigo Minetto,Thiago H Silva*

Main category: cs.CL

TL;DR: 本章系统介绍了多模态大语言模型（MLLMs）的基础理论、代表性模型、实践技术（包括预处理、提示工程和基于LangChain/LangGraph的管道构建），并探讨了其挑战与未来趋势。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型将大语言模型的自然语言理解生成能力与图像、音频等多模态感知技能相结合，代表了当代人工智能的关键性进步，需要系统性的理论梳理与实践指导。

Method: 本章通过介绍MLLMs的核心基础理论与代表性模型，并探索预处理、提示工程以及使用LangChain和LangGraph构建多模态管道等实践技术来展开，同时提供在线补充材料供实践研究。

Result: 深入探讨了多项实践技术，并提供了在线补充学习材料（https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica），供进一步实践研究。

Conclusion: 本章最后分析了MLLMs当前面临的挑战，并指出了该领域富有前景的发展趋势，为后续研究和应用提供了方向性指导。

Abstract: Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI. This chapter presents the main fundamentals of MLLMs and emblematic models. Practical techniques for preprocessing, prompt engineering, and building multimodal pipelines with LangChain and LangGraph are also explored. For further practical study, supplementary material is publicly available online: https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica. Finally, the chapter discusses the challenges and highlights promising trends.

</details>


### [5] [RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty](https://arxiv.org/abs/2602.12424)
*Ziqian Zhang,Xingjian Hu,Yue Huang,Kai Zhang,Ruoxi Chen,Yixin Liu,Qingsong Wen,Kaidi Xu,Xiangliang Zhang,Neil Zhenqiang Gong,Lichao Sun*

Main category: cs.CL

TL;DR: 针对现有LLM基准测试无法区分问题难度的局限性，本文提出RankLLM框架，通过双向分数传播机制同时量化模型能力和问题难度，实现更细粒度的模型评估。


<details>
  <summary>Details</summary>
Motivation: 标准基准测试虽能系统评估LLM性能，但现有方法缺乏问题难度区分度，难以有效鉴别模型能力差异，限制了该领域的进步。

Method: RankLLM采用双向评分传播机制：模型正确答题获得能力分数，问题成功挑战模型则提升难度分数，以此同时评估30个模型在35,550个跨领域问题的表现。

Result: 实验表明RankLLM与人类判断一致性达90%，持续优于IRT等强基线，且具备强稳定性、快速收敛和高计算效率。

Conclusion: RankLLM为大规模、难度感知的LLM评估提供了实用解决方案，能够更精细地区分模型能力。

Abstract: Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively distinguish models' capabilities. To address this limitation, we propose RankLLM, a novel framework designed to quantify both question difficulty and model competency. RankLLM introduces difficulty as the primary criterion for differentiation, enabling a more fine-grained evaluation of LLM capabilities. RankLLM's core mechanism facilitates bidirectional score propagation between models and questions. The core intuition of RankLLM is that a model earns a competency score when it correctly answers a question, while a question's difficulty score increases when it challenges a model. Using this framework, we evaluate 30 models on 35,550 questions across multiple domains. RankLLM achieves 90% agreement with human judgments and consistently outperforms strong baselines such as IRT. It also exhibits strong stability, fast convergence, and high computational efficiency, making it a practical solution for large-scale, difficulty-aware LLM evaluation.

</details>


### [6] [RBCorr: Response Bias Correction in Language Models](https://arxiv.org/abs/2602.12445)
*Om Bhatt,Anna A. Ivanova*

Main category: cs.CL

TL;DR: 本文提出RBCorr——一种简易的语言模型响应偏置校正策略。实验在12个开放权重模型上进行，涵盖是非题、蕴含判断题和选择题，证实预训练模型普遍存在响应偏置，而RBCorr能有效消除偏置并提升性能。研究发现，基于LogProbs的校正效果高度依赖于模型、数据集和提示格式三大因素。


<details>
  <summary>Details</summary>
Motivation: 语言模型在固定答案问题中存在选项偏好偏置，这种响应偏置会扭曲模型性能评估，影响基准测试的准确性。因此，亟需开发低成本、高效偏置校正方法来提升模型表现，使其基准测试成绩更真实反映模型能力。

Method: 提出简单响应偏置校正策略RBCorr，在12个开放权重语言模型上测试其在是非题、蕴含判断题和选择题上的效果，并系统探索基于LogProbs的校正方法在模型、数据集和提示格式三个维度上的泛化特性。

Result: 1) 校正前语言模型普遍存在显著响应偏置；2) RBCorr能有效消除偏置并提升模型性能；3) 基于LogProbs的校正效果对模型类型、数据集和提示格式三个因素具有高度依赖性。

Conclusion: RBCorr是一种易于使用的偏置校正方法，可提升小型语言模型性能，并确保闭卷响应基准测试成绩更准确地反映模型真实能力。

Abstract: Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM performance and enable more accurate evaluations of model abilities. Here, we propose a simple response bias correction strategy ($\texttt{RBCorr}$) and test it on 12 open-weight language models using yes-no, entailment, and multiple choice questions. We show that response bias is prevalent in LMs pre-correction and that $\texttt{RBCorr}$ effectively eliminates bias and boosts model performance. We also explore the generalizability of bias behavior across models, datasets, and prompt formats, showing that LogProbs-based correction is highly dependent on all three of these aspects. Overall, $\texttt{RBCorr}$ is an easy-to-use method that can boost the performance of smaller LMs and ensure that LM performance on closed-response benchmarks aligns more closely with their true capabilities.

</details>


### [7] [Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification](https://arxiv.org/abs/2602.12575)
*Bo Wang,Yuxuan Zhang,Yueqin Hu,Hanchao Hou,Kaiping Peng,Shiguang Ni*

Main category: cs.CL

TL;DR: 本文提出一种基于自然语言处理的量表精简框架，通过主题建模与语义聚类，在不依赖被试反应数据的情况下实现项目约简。在DASS、IPIP和EPOCH量表上验证表明，该方法可平均缩短60.5%题量，同时保持心理测量学特性。


<details>
  <summary>Details</summary>
Motivation: 传统量表精简方法（如因子分析、项目反应理论）依赖大样本反应数据，受数据可用性和跨文化可比性限制。本研究探索利用项目语义结构作为不依赖反应数据的补充视角。

Method: 该框架使用上下文句子嵌入对项目编码，通过密度聚类自动发现潜在语义因子（无需预设因子数），采用类别术语加权生成可解释的主题表征，并基于成员资格标准选择代表性项目。

Result: 跨DASS、IPIP和EPOCH量表的评估显示：方法恢复了与既有构念一致的高内聚因子分组；平均缩减60.5%题量；简化后量表与原始因子结构高度一致，保持了因子间相关关系，证明语义结构可无反应数据近似测量结构。

Conclusion: 语义潜在组织可作为量表构建与约简的可检查前端，为不依赖反应数据的量表优化提供了系统化框架，并开发了可视化工具促进应用。

Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultural comparability. Recent advances in natural language processing suggest that the semantic structure of questionnaire items may encode latent construct organization, offering a complementary response-free perspective. We introduce a topic-modeling framework that operationalizes semantic latent structure for scale simplification. Items are encoded using contextual sentence embeddings and grouped via density-based clustering to discover latent semantic factors without predefining their number. Class-based term weighting derives interpretable topic representations that approximate constructs and enable merging of semantically adjacent clusters. Representative items are selected using membership criteria within an integrated reduction pipeline. We benchmarked the framework across DASS, IPIP, and EPOCH, evaluating structural recovery, internal consistency, factor congruence, correlation preservation, and reduction efficiency. The proposed method recovered coherent factor-like groupings aligned with established constructs. Selected items reduced scale length by 60.5% on average while maintaining psychometric adequacy. Simplified scales showed high concordance with original factor structures and preserved inter-factor correlations, indicating that semantic latent organization provides a response-free approximation of measurement structure. Our framework formalizes semantic structure as an inspectable front-end for scale construction and reduction. To facilitate adoption, we provide a visualization-supported tool enabling one-click semantic analysis and structured simplification.

</details>


### [8] [Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats](https://arxiv.org/abs/2602.12635)
*Pengxiang Zhao,Hui-Ling Zhen,Xing Li,Han Bao,Weizhe Lin,Zhiyuan Yang,Ziwei Yu,Xin Wang,Mingxuan Yuan,Xianzhi Yu,Zhenhua Dong*

Main category: cs.CL

TL;DR: 本文评估了专为华为昇腾NPU设计的HiFloat（HiF8和HiF4）浮点格式系列，通过与INT8等整数格式在权重-激活和KV缓存任务上的严格对比，发现HiFloat在4-bit精度下通过分层缩放避免了整数格式的精度崩溃问题，且与最新训练后量化框架完全兼容，为NPU上的高效大模型推理提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模不断扩大，低比特浮点格式（如MXFP和NVFP4）为精度和效率带来了新机遇。然而，现有整数格式在处理高方差数据时存在局限，且4-bit精度下容易出现精度崩溃。本研究旨在评估专为华为昇腾NPU定制的HiFloat浮点格式家族，探索其在LLM推理中的优势，为高效NPU推理提供解决方案。

Method: 研究通过严格的实验对比，在权重-激活量化和KV缓存两个关键任务上评估HiFloat（HiF8和HiF4）格式。与INT8等整数格式进行系统性比较，重点分析不同数据分布（窄范围vs高方差）下的表现差异，以及4-bit精度下的精度保持能力。

Result: 得出三个关键发现：（1）INT8适用于窄范围数据，而浮点格式在高方差数据上表现更优；（2）在4-bit精度下，HiF4通过分层缩放机制有效防止了整数格式常见的精度崩溃问题；（3）HiFloat格式与现有最先进的训练后量化框架完全兼容。

Conclusion: HiFloat格式为昇腾NPU上的高效大语言模型推理提供了可行的解决方案，在保持精度的同时提升计算效率，特别适用于高方差数据和低比特场景。

Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.

</details>


### [9] [CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation](https://arxiv.org/abs/2602.12639)
*Yiran Rex Ma,Yuxiao Ye,Huiyuan Xie*

Main category: cs.CL

TL;DR: 该论文提出CLASE（中文法律文体评估），一种用于评价大型语言模型生成法律文本风格质量的混合评估方法。该方法融合语言特征评分与经验引导的LLM评分，通过对比真实法律文档与LLM恢复版本进行学习。在200篇中文法律文档上的实验表明，CLASE与人类判断的吻合度显著优于传统指标和纯LLM评估，并提供可解释的评分细分和改进建议，为专业法律文本生成提供了可扩展的评估方案。


<details>
  <summary>Details</summary>
Motivation: LLM生成的法律文本虽事实准确，但常违反专业文体规范与语言惯例。然而，法律写作的隐性文体要求难以形式化，专家手动制定标准不切实际。现有自动评估方法存在缺陷：基于参考的指标混淆语义准确性与风格保真度，LLM-as-a-judge评估则缺乏透明度与一致性。因此，亟需一种可靠的自动文体评估方法。

Method: 提出CLASE混合评估方法，采用双轨评分机制：1）基于语言特征的量化评分；2）经验引导的LLM-as-a-judge评分。通过从真实法律文档与其LLM恢复版本的对比对中学习特征系数与评分经验，实现无需参考文本的透明化评估。该方法能同时捕捉表层语言特征与隐性文体规范。

Result: 在200篇中文法律文档上的实验显示，CLASE与人类判断的一致性显著高于传统评估指标和纯LLM-as-a-judge方法。此外，CLASE提供可解释的评分细分与针对性改进建议，为法律文本生成提供了实用的文体评估解决方案。

Conclusion: CLASE为法律文本生成的专业文体评估提供了可扩展且实用的解决方案。该方法不仅提升了与人类判断的对齐度，还通过透明的评分机制与可操作建议，为法律领域的文本生成质量评估设立了新的实践基准。

Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic quality, a crucial first step is to establish a reliable evaluation method. However, having legal experts manually develop such a metric is impractical, as the implicit stylistic requirements in legal writing practice are difficult to formalise into explicit rubrics. Meanwhile, existing automatic evaluation methods also fall short: reference-based metrics conflate semantic accuracy with stylistic fidelity, and LLM-as-a-judge evaluations suffer from opacity and inconsistency. To address these challenges, we introduce CLASE (Chinese LegAlese Stylistic Evaluation), a hybrid evaluation method that focuses on the stylistic performance of legal text. The method incorporates a hybrid scoring mechanism that combines 1) linguistic feature-based scores and 2) experience-guided LLM-as-a-judge scores. Both the feature coefficients and the LLM scoring experiences are learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts. This hybrid design captures both surface-level features and implicit stylistic norms in a transparent, reference-free manner. Experiments on 200 Chinese legal documents show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods. Beyond improved alignment, CLASE provides interpretable score breakdowns and suggestions for improvements, offering a scalable and practical solution for professional stylistic evaluation in legal text generation (Code and data for CLASE is available at: https://github.com/rexera/CLASE).

</details>


### [10] [Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR](https://arxiv.org/abs/2602.12642)
*Dohyung Kim,Minbeom Kim,Jeonghye Kim,Sangmook Lee,Sojeong Rhee,Kyomin Jung*

Main category: cs.CL

TL;DR: 本文提出 PACED-RL，一种基于 GFlowNet 的 LLM 后训练框架。通过将配分函数重新解释为每个提示的期望奖励信号，利用准确性估计优先选择信息性提示并实现误差优先的重放，从而提升样本效率。该方法摊销计算开销，在多个基准测试中显著优于 GRPO 和现有 GFlowNet 方法。


<details>
  <summary>Details</summary>
Motivation: 奖励最大化的强化学习方法虽然提升了 LLM 的推理性能，但会损害输出多样性。尽管 GFlowNets 通过匹配目标分布缓解了该问题，但现有工作仅将配分函数视为归一化常数，未充分利用其潜在信息。

Method: 首先建立配分函数与每个提示准确率估计之间的理论关系，提出配分函数引导的强化学习框架 PACED-RL。该框架包含两个组件：(1) 利用准确性估计在训练过程中优先选择信息更丰富的提示；(2) 通过准确性估计误差优先的重放机制进一步提升样本效率。两个组件均重用 GFlowNet 训练中已产生的信息，将额外计算开销摊销到现有优化过程中。

Result: 在多个基准测试上的广泛实验表明，PACED-RL 在性能上显著优于 GRPO 和现有 GFlowNet 方法，验证了其作为更样本高效的分布匹配训练框架的有效性。

Conclusion: PACED-RL 通过重新诠释 GFlowNet 配分函数的语义，将其转化为在线准确性信号，实现了样本效率的提升，为 LLM 的后训练提供了一种有前景的新方向。

Abstract: Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly learning its partition function. In contrast to prior works that treat this partition function solely as a normalizer, we reinterpret it as a per-prompt expected-reward (i.e., online accuracy) signal, leveraging this unused information to improve sample efficiency. Specifically, we first establish a theoretical relationship between the partition function and per-prompt accuracy estimates. Building on this key insight, we propose Partition Function-Guided RL (PACED-RL), a post-training framework that leverages accuracy estimates to prioritize informative question prompts during training, and further improves sample efficiency through an accuracy estimate error-prioritized replay. Crucially, both components reuse information already produced during GFlowNet training, effectively amortizing the compute overhead into the existing optimization process. Extensive experiments across diverse benchmarks demonstrate strong performance improvements over GRPO and prior GFlowNet approaches, highlighting PACED-RL as a promising direction for a more sample efficient distribution-matching training for LLMs.

</details>


### [11] [Learning Ordinal Probabilistic Reward from Preferences](https://arxiv.org/abs/2602.12660)
*Longze Chen,Lu Wang,Renke Shan,Ze Gong,Run Luo,Jiaming Li,Jing Luo,Qiyao Wang,Min Yang*

Main category: cs.CL

TL;DR: 针对现有奖励模型（生成式需高成本点监督，判别式产生未校准相对分数）的局限性，本文提出概率奖励模型（PRM）将奖励视为随机变量并学习完整概率分布，其实践形式为序数概率奖励模型（OPRM），并设计区域泛洪微调（RgFT）策略提升数据效率，在基准测试中准确率提升2.9-7.4%，同时捕捉相对排序与绝对质量。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型存在两大局限：生成式范式（GRMs）需要昂贵的逐点监督，判别式范式（DRMs）产生未校准的相对分数且缺乏概率解释性，这限制了它们在LLM对齐中的应用效果。

Method: 1) 提出概率奖励模型（PRM）范式，将奖励视为随机变量；2) 设计其离散实现序数概率奖励模型（OPRM），将质量分数离散化为序数评级；3) 开发区域泛洪微调（RgFT）训练策略，通过质量级别标注引导模型将概率质量集中在对应评级子区域。

Result: 在各类奖励模型基准测试中，所提方法比先前模型准确率提升2.9%-7.4%，表现出强性能和数据效率；分数分布分析证明该方法不仅捕获相对排序，还能反映绝对质量。

Conclusion: 概率奖励模型（特别是OPRM结合RgFT）有效解决了现有奖励模型的局限性，通过概率框架同时建模响应质量的相对排序和绝对水平，为LLM对齐提供了更可靠且数据高效的奖励建模新范式。

Abstract: Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs typically demand costly point-wise supervision, while DRMs produce uncalibrated relative scores that lack probabilistic interpretation. To address these challenges, we introduce a novel reward modeling paradigm: Probabilistic Reward Model (PRM). Instead of modeling reward as a deterministic scalar, our approach treats it as a random variable, learning a full probability distribution for the quality of each response. To make this paradigm practical, we present its closed-form, discrete realization: the Ordinal Probabilistic Reward Model (OPRM), which discretizes the quality score into a finite set of ordinal ratings. Building on OPRM, we propose a data-efficient training strategy called Region Flooding Tuning (RgFT). It enables rewards to better reflect absolute text quality by incorporating quality-level annotations, which guide the model to concentrate the probability mass within corresponding rating sub-regions. Experiments on various reward model benchmarks show that our method improves accuracy by $\textbf{2.9%}\sim\textbf{7.4%}$ compared to prior reward models, demonstrating strong performance and data efficiency. Analysis of the score distribution provides evidence that our method captures not only relative rankings but also absolute quality.

</details>


### [12] [$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2602.12674)
*Yuang Cai,Yuyu Yuan*

Main category: cs.CL

TL;DR: 现有大语言模型知识蒸馏方法忽视教师模型的原始学习环境，仅模仿其行为。为此，本文受经验学习理论和逆强化学习启发，提出经验知识蒸馏框架（X-KD），通过近似变分奖励模仿学习（AVRIL）联合建模教师原始奖励函数并进行策略蒸馏。X-KD在摘要生成、机器翻译和算术推理任务上超越基线方法，并展现出更优的性能-多样性平衡与数据效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型规模的增长使知识蒸馏成为关键技术。然而，现有方法仅关注行为模仿，忽略了塑造教师知识的原始学习环境，导致知识迁移不充分。本文从经验学习理论和逆强化学习中获得启示，旨在通过重建教师的学习环境来提升蒸馏效果。

Method: 本文提出的X-KD框架采用AVRIL（近似变分奖励模仿学习）算法，核心是联合建模教师模型的原始奖励函数并执行策略蒸馏，促使学生策略与原始奖励保持一致。理论推导证明X-KD符合监督学习范式，并可适配序列级和散度-based蒸馏，体现了框架的简洁性与通用性。

Result: 实证评估涵盖抽象摘要生成、机器翻译和算术推理三项任务。结果表明，X-KD性能显著优于广义KD和MiniLLM基线；同时，在性能-多样性权衡和数据利用效率方面，X-KD也优于现有基线方法。

Conclusion: X-KD通过模拟教师原始学习环境，为知识蒸馏提供了简单、灵活且有效的通用框架。其优越性能表明，重建学习环境是知识迁移的有效途径，为大模型压缩与能力继承开辟了新方向。

Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning environment that shaped the teacher's knowledge. Inspired by the experiential learning theory and inverse reinforcement learning, we propose Experiential Knowledge Distillation ($\mathcal{X}$-KD), a novel and general framework that enables student models to learn in the teacher's original learning environment. $\mathcal{X}$-KD adopts the Approximated Variational Reward Imitation Learning (AVRIL) framework to jointly model the teacher's original reward function and perform policy distillation, encouraging consistency between the student policy and the original reward function. Our derivation demonstrates that $\mathcal{X}$-KD follows the supervised learning framework and applies to both sequence-level and divergence-based distillation methods, underlining the simplicity and flexibility of our approach. Empirical results show that $\mathcal{X}$-KD outperforms the generalized KD and MiniLLM baselines on abstractive summarization, machine translation, and arithmetic reasoning tasks. Additionally, $\mathcal{X}$-KD achieves better performance-diversity trade-off and data efficiency than baseline KD approaches.

</details>


### [13] [ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter](https://arxiv.org/abs/2602.12709)
*Yixin Chen,Ying Xiong,Shangyu Wu,Xiangrui Ke,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: 针对检索增强生成(RAG)中现有融合方法随检索数量k增加而扩展性不足的问题，本文提出ReFilter框架，通过token级过滤和融合机制，在通用域和生物医学域问答基准测试中均实现最优性能，且在零样本迁移下无需领域微调即可达到70.01%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 现有RAG内部融合方法（基于查询、参数化和潜在融合）在检索规模k增大时表现不佳，因为top-k检索不可避免地引入无关或冗余内容，同时增加推理成本，导致覆盖率和效率之间的矛盾。

Method: 提出ReFilter，一种新颖的基于潜在融合的框架，包含三个核心组件：1）上下文编码器，用于编码检索内容特征；2）门控过滤器，对每个token进行加权过滤；3）token融合模块，将加权后的token特征集成到LLM隐藏状态中。

Result: 在四个通用域问答基准测试中，ReFilter在域内适应和域外迁移下均取得最佳平均性能；在零样本迁移至五个生物医学问答基准时，无需领域微调即可达到70.01%的平均准确率（使用Qwen2.5-14B-Instruct模型）。

Conclusion: ReFilter通过token级过滤和融合机制有效解决了RAG融合的可扩展性瓶颈，在保持推理效率的同时显著提升大规模检索下的性能，展现出强大的跨领域泛化能力。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples into the LLMs, where existing internal fusion approaches broadly fall into query-based fusion, parametric fusion, and latent-based fusion. Despite their effectiveness at modest retrieval scales, these methods often fail to scale gracefully as the number of retrieved candidates k increases: Larger k improves evidence coverage, yet realistic top-k retrieval inevitably contains irrelevant or redundant content and increases the inference cost.
  To address these limitations, we propose ReFilter, a novel latent-based fusion framework that performs token-level filtering and fusion. ReFilter consists of three key components: a context encoder for encoding context features, a gated filter for weighting each token, and a token fusion module for integrating the weighted token feature into the LLM's hidden states. Our experiments across four general-domain QA benchmarks show that ReFilter consistently achieves the best average performance under both in-domain adaptation and out-of-domain transfer. ReFilter further generalizes to five biomedical QA benchmarks in zero-shot transfer without domain fine-tuning, reaching 70.01% average accuracy with Qwen2.5-14B-Instruct.

</details>


### [14] [Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting](https://arxiv.org/abs/2602.12746)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: 针对自监督语音模型在新语言泛化及持续学习遗忘问题，本文提出Lamer-SSL框架，通过层感知LoRA专家混合模块与重放策略，仅训练2.14%参数即可有效扩展新语言并维持旧语言性能。


<details>
  <summary>Details</summary>
Motivation: 自监督语音模型虽性能卓越，但面临两大瓶颈：难以泛化至新语言，以及持续训练时易遗忘已习得的知识，这限制了其在多语言场景下的实际应用与持续进化能力。

Method: 提出Lamer-SSL参数高效框架：(1) 设计Layer-Aware MixturE of LoRA Experts (Lamer)模块，平衡共享与语言特定表示；(2) 采用层感知专家分配，在语义丰富的深层部署更多专家；(3) 结合重放策略，利用极少量数据保留先验知识，缓解持续学习中的灾难性遗忘。

Result: 在自动语音识别(ASR)与语言识别(LID)任务上的实验表明，Lamer-SSL能高效扩展模型至新语言，同时对已学习语言保持强劲性能，仅需训练2.14%的参数即可实现。

Conclusion: Lamer-SSL通过创新的参数高效架构，成功攻克自监督语音模型在多语言持续学习中的泛化与遗忘难题，为构建可扩展、可持续进化的多语言语音系统提供了有效解决方案。

Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient framework that integrates a Layer-Aware MixturE of LoRA Experts (Lamer) module with a replay strategy. The Lamer module enables flexible balancing between shared and language-specific representations, while layer-aware expert allocation assigns more experts to deeper layers where semantic information is richer. Meanwhile, the replay strategy retains prior knowledge using minimal data, mitigating forgetting during continual training. Experiments on automatic speech recognition (ASR) and language identification (LID) demonstrate that Lamer-SSL extends self-supervised models to new languages effectively while maintaining strong performance on previously learned languages with only 2.14% parameters being trainable.

</details>


### [15] [Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks](https://arxiv.org/abs/2602.12759)
*Elena Alvarez-Mellado,Julio Gonzalo*

Main category: cs.CL

TL;DR: 该论文针对自然语言处理中的标准评估方法缺乏改进指导和泛化预测能力的问题，提出了一种基于错误分析、面向序列标注任务的评估方法。该方法通过人工构建覆盖多种语言特征的少量测试样例，替代传统的真实世界分布数据，能有效诊断模型弱点、指导模型选择，并预测模型在外部数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 标准NLP评估仅能判断系统A的平均性能优于系统B，但无法指导如何提升性能，且存在在新数据上B反超A的风险。现有方法缺乏对模型系统性弱点的诊断能力，也难以预测模型在不同分布数据上的表现，限制了实际应用中的模型选择和改进。

Method: 提出一种基于错误分析的评估方法论，核心是人工构建小型测试集。该测试集不依赖大量真实分布数据，而是由语言学驱动的样例组成， exhaustive覆盖序列标注中可能遇到的各种跨度属性（如形状、长度、大小写、句子位置等）。通过在西班牙语外来语识别基准上验证该方法。

Result: 该方法具有三大优势：1）诊断性，能识别模型性能的系统性弱点；2）可操作性，能指导特定场景下的模型选择；3）预测性，其预测的模型在外部数据集上的表现与实际表现的中位数相关性达0.85。

Conclusion: 所提评估方法有效解决了标准评估的局限性，通过精心设计的语言学测试集，为模型改进和跨分布性能预测提供了实用工具，为NLP评估范式提供了新思路。

Abstract: Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being better than A on outside data. We propose an evaluation methodology for sequence labeling tasks grounded on error analysis that provides both quantitative and qualitative information on where systems must be improved and predicts how models will perform on a different distribution. The key is to create test sets that, contrary to common practice, do not rely on gathering large amounts of real-world in-distribution scraped data, but consists in handcrafting a small set of linguistically motivated examples that exhaustively cover the range of span attributes (such as shape, length, casing, sentence position, etc.) a system may encounter in the wild. We demonstrate this methodology on a benchmark for anglicism identification in Spanish. Our methodology provides results that are diagnostic (because they help identify systematic weaknesses in performance), actionable (because they can inform which model is better suited for a given scenario) and predictive: our method predicts model performance on external datasets with a median correlation of 0.85.

</details>


### [16] [RAT-Bench: A Comprehensive Benchmark for Text Anonymization](https://arxiv.org/abs/2602.12806)
*Nataša Krčo,Zexi Yao,Matthieu Meeus,Yves-Alexandre de Montjoye*

Main category: cs.CL

TL;DR: 本文提出RAT-Bench，一个基于再识别风险的文本匿名化工具基准测试。通过生成含多种标识符的合成文本评估发现，现有工具在防止再识别上远非完美，尤其当直接标识符非标准或间接标识符存在时。基于大语言模型(LLM)的匿名化工具虽计算成本更高，但在隐私-效用权衡和多语言性能上表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着个人信息数据被广泛用于大语言模型训练、微调和查询，现有文本匿名化工具（如微软Presidio）的评估主要关注特定标识符移除能力，但其在防止再识别方面的有效性仍不明确，存在隐私泄露风险。

Method: 基于美国人口统计数据构建RAT-Bench基准，生成跨领域、跨语言、多难度级别的合成文本，包含直接和间接标识符。通过评估多种命名实体识别(NER)和LLM-based匿名化工具，基于LLM攻击者从匿名化文本中可推断的正确属性，计算美国人口中的再识别风险，并考虑标识符的差异化影响。

Result: 工具性能差异显著：即使最佳工具在防止再识别方面也远非完美，尤其在直接标识符非标准写法或间接标识符导致再识别时。LLM-based匿名化工具（含新迭代式方法）提供更优的隐私-效用权衡，虽计算成本更高，但跨语言性能良好。

Conclusion: 提出未来匿名化工具改进建议，将公开发布RAT-Bench基准并鼓励社区扩展至其他地理区域，以促进更有效的隐私保护技术发展。

Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio or Anthropic's PII purifier. These tools have traditionally been evaluated on their ability to remove specific identifiers (e.g., names), yet their effectiveness at preventing re-identification remains unclear. We introduce RAT-Bench, a comprehensive benchmark for text anonymization tools based on re-identification risk. Using U.S. demographic statistics, we generate synthetic text containing various direct and indirect identifiers across domains, languages, and difficulty levels. We evaluate a range of NER- and LLM-based text anonymization tools and, based on the attributes an LLM-based attacker is able to correctly infer from the anonymized text, we report the risk of re-identification in the U.S. population, while properly accounting for the disparate impact of identifiers. We find that, while capabilities vary widely, even the best tools are far from perfect in particular when direct identifiers are not written in standard ways and when indirect identifiers enable re-identification. Overall we find LLM-based anonymizers, including new iterative anonymizers, to provide a better privacy-utility trade-off albeit at a higher computational cost. Importantly, we also find them to work well across languages. We conclude with recommendations for future anonymization tools and will release the benchmark and encourage community efforts to expand it, in particular to other geographies.

</details>


### [17] [Left-right asymmetry in predicting brain activity from LLMs' representations emerges with their formal linguistic competence](https://arxiv.org/abs/2602.12811)
*Laurent Bonnasse-Gahot,Christophe Pallier*

Main category: cs.CL

TL;DR: 本研究通过分析OLMo-2等大语言模型在不同训练阶段的激活与人类大脑fMRI数据的相关性，发现左半球预测准确性的提升不对称性与模型的形式语言学能力（如语法判断和文本生成）同步发展，而与算术、Dyck语言或世界知识推理任务表现无关。该结论在Pythia模型和法语数据上得到验证，表明大脑可预测性的左右不对称性反映的是模型对语言模式的掌握程度。


<details>
  <summary>Details</summary>
Motivation: 已有研究表明，随着大语言模型训练进行，其内部激活预测大脑活动的能力在左半球比右半球提升更显著。然而，驱动这种左右不对称性出现的能力机制尚不明确——究竟是与语言相关的形式语法能力，还是更通用的认知能力（如推理或世界知识）。本研究旨在揭示这种不对称性背后对应的具体模型能力类型。

Method: 研究采用OLMo-2 7B模型在不同训练步的检查点，以及英语受试者的fMRI数据。通过对比模型脑区预测得分（brain scores）的左右不对称性演变趋势与多项基准测试表现的相关性，系统分析其关联性。实验涵盖语法可接受性判断、文本生成、算术、Dyck语言解析以及世界知识推理等多种任务类型，并在Pythia模型和法语数据上进行了跨模型、跨语言的泛化验证。

Result: 结果显示，左半球预测准确性的不对称性提升与模型的形式语言学能力同步涌现，包括：（1）对最小对比句对中合法句赋予更高概率的语法判断能力；（2）生成合乎语法文本的能力。相反，该不对称性与算术任务、Dyck语言解析任务以及涉及世界知识和推理的文本任务表现均无显著相关性。这些发现在Pythia模型家族和法语fMRI数据中得到复现，证实了结果的稳健性。

Conclusion: 本研究得出结论：大语言模型预测大脑活动时的左半球优势不对称性，特异性地对应于模型形式语言学能力的发展，即对语言统计模式和语法结构的掌握程度，而非通用认知或世界知识能力。这一发现为理解语言模型与人类大脑表征对齐的机制提供了关键证据。

Abstract: When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the training of an LLM progresses, the performance in predicting brain activity from its internal activations improves more in the left hemisphere than in the right one. The aim of the present work is to understand which kind of competence acquired by the LLMs underlies the emergence of this left-right asymmetry. Using the OLMo-2 7B language model at various training checkpoints and fMRI data from English participants, we compare the evolution of the left-right asymmetry in brain scores alongside performance on several benchmarks. We observe that the asymmetry co-emerges with the formal linguistic abilities of the LLM. These abilities are demonstrated in two ways: by the model's capacity to assign a higher probability to an acceptable sentence than to a grammatically unacceptable one within a minimal contrasting pair, or its ability to produce well-formed text. On the opposite, the left-right asymmetry does not correlate with the performance on arithmetic or Dyck language tasks; nor with text-based tasks involving world knowledge and reasoning. We generalize these results to another family of LLMs (Pythia) and another language, namely French. Our observations indicate that the left-right asymmetry in brain predictivity matches the progress in formal linguistic competence (knowledge of linguistic patterns).

</details>


### [18] [BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.12889)
*Jiangxi Chen,Qian Liu*

Main category: cs.CL

TL;DR: 本文提出BaziQA-Benchmark，一个评估大语言模型符号性和时间组合性推理的标准化基准，源自200道专业命理学竞赛题。研究表明模型虽优于随机基线，但在时间组合推理和符号判断上存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型推理评估依赖轶事性或提示驱动方法，缺乏客观评分和可控比较。在符号性与时间组合性推理这一复杂认知领域，亟需标准化基准以系统评估模型能力边界。

Method: 从全球算命师竞赛（2021-2025）精选200道多选题构建基准，采用多轮对话评估当代语言模型。提出轻量级结构化推理协议（SRP），在不增加领域知识前提下约束推理顺序，探究模型推理行为。

Result: 实验表明所有模型均显著优于随机但远未饱和。模型对时间组合和推理顺序高度敏感，在精确时间定位与多条件符号判断上存在系统性失败。

Conclusion: BaziQA-Benchmark为符号性与时间组合性推理提供了客观评估工具，揭示了当前大语言模型在该复杂认知领域的性能边界与关键缺陷，为未来模型改进指明方向。

Abstract: We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global Fortune-teller Competition (2021--2025), where each instance requires structured inference over a fixed symbolic chart and interacting temporal conditions. Unlike anecdotal or prompt-driven evaluations, BaziQA-Benchmark enables objective scoring and controlled comparison across years, domains, and model families. We evaluate contemporary language models under a multi-turn setting and analyze performance variation across temporal difficulty, reasoning domains, and inference protocols.To further probe reasoning behavior, we introduce a lightweight Structured Reasoning Protocol that constrains inference order without adding domain knowledge. Results show that models consistently outperform chance but remain far from saturation, exhibiting pronounced sensitivity to temporal composition and reasoning order, as well as systematic failures on precise temporal localization and multi-condition symbolic judgments.

</details>


### [19] [ViMedCSS: A Vietnamese Medical Code-Switching Speech Dataset & Benchmark](https://arxiv.org/abs/2602.12911)
*Tung X. Nguyen,Nhu Vo,Giang-Son Nguyen,Duy Mai Hoang,Chien Dinh Huynh,Inigo Jauregi Unanue,Massimo Piccardi,Wray Buntine,Dung D. Le*

Main category: cs.CL

TL;DR: 本文针对越南语医疗对话中夹杂英文术语的语码转换现象，构建了首个越南语医疗语码转换语音数据集ViMedCSS（34小时），评估了多种先进ASR模型及微调策略，发现越南语优化模型与多语言预训练相结合的方法在整体准确率和语码转换识别上达到最佳平衡，为低资源多语言ASR系统提供了重要基准和研究启示。


<details>
  <summary>Details</summary>
Motivation: 越南语医疗交流中普遍存在使用英文药品名或医疗程序的语码转换现象，这对自动语音识别（ASR）系统构成严峻挑战，尤其是对越南语这类低资源语言。现有ASR系统难以准确识别越南语句中的英文医学术语，且缺乏专门针对此挑战的基准数据集。

Method: 构建了包含16,576条语句、总计34小时的越南语医疗语码转换语音数据集ViMedCSS，每条语句至少包含一个来自涵盖五个医疗主题的双语词典的英文医学术语。在此基础上，评估了多种先进ASR模型，并探索了不同的针对性微调策略以改进医疗术语识别效果。

Result: 实验结果表明，越南语优化模型在常规语段上表现更优，而多语言预训练有助于捕捉英文插入成分；将两种方法结合能够在整体识别准确率和语码转换准确率之间取得最佳平衡。

Conclusion: 本研究提供了首个越南语医疗语码转换识别基准，并为低资源、多语言ASR系统的有效领域自适应提供了重要见解。

Abstract: Code-switching (CS), which is when Vietnamese speech uses English words like drug names or procedures, is a common phenomenon in Vietnamese medical communication. This creates challenges for Automatic Speech Recognition (ASR) systems, especially in low-resource languages like Vietnamese. Current most ASR systems struggle to recognize correctly English medical terms within Vietnamese sentences, and no benchmark addresses this challenge. In this paper, we construct a 34-hour \textbf{Vi}etnamese \textbf{Med}ical \textbf{C}ode-\textbf{S}witching \textbf{S}peech dataset (ViMedCSS) containing 16,576 utterances. Each utterance includes at least one English medical term drawn from a curated bilingual lexicon covering five medical topics. Using this dataset, we evaluate several state-of-the-art ASR models and examine different specific fine-tuning strategies for improving medical term recognition to investigate the best approach to solve in the dataset. Experimental results show that Vietnamese-optimized models perform better on general segments, while multilingual pretraining helps capture English insertions. The combination of both approaches yields the best balance between overall and code-switched accuracy. This work provides the first benchmark for Vietnamese medical code-switching and offers insights into effective domain adaptation for low-resource, multilingual ASR systems.

</details>


### [20] [When Words Don't Mean What They Say: Figurative Understanding in Bengali Idioms](https://arxiv.org/abs/2602.12921)
*Adib Sakhawat,Shamim Ara Parveen,Md Ruhul Amin,Shamim Al Mahmud,Md Saiful Islam,Tahera Khatun*

Main category: cs.CL

TL;DR: 本研究针对低资源语言习语理解难题，构建了包含10,361个孟加拉语习语的大规模文化标注数据集，采用19字段专家共识模式，并对30个先进大模型进行习语推理评估，发现所有模型准确率均未超过50%，与83.4%的人类表现形成巨大差距，揭示了当前模型在跨文化推理方面的根本缺陷。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在理解比喻性语言方面面临重大挑战，尤其是低资源语言。孟加拉语作为全球使用人数众多但计算资源匮乏的语言，其丰富的文化特异性习语为检验模型的跨文化推理能力提供了理想测试场景，现有研究缺乏系统性的标注资源和基准评估。

Method: 通过专家审议共识流程，建立了涵盖语义、句法、文化和宗教维度的19字段标注体系；构建了包含10,361个孟加拉语习语的大规模文化接地语料库；对30个先进多语言及指令微调大模型进行习语含义推理任务的系统性评估。

Result: 评估结果显示，所有被测模型在孟加拉语习语理解任务上的准确率均未超过50%，最佳模型表现远逊于人类基准（83.4%准确率），暴露出当前大模型在低资源语言文化语境下进行隐喻和推理的根本性能力缺陷。

Conclusion: 研究揭示了现有大模型在跨文化语言理解中的显著局限性，通过开源该数据集和基准，为推进孟加拉语及其他低资源语言的比喻性语言理解、文化接地模型研发提供了关键基础设施，强调了文化语境在语言模型中的必要性。

Abstract: Figurative language understanding remains a significant challenge for Large Language Models (LLMs), especially for low-resource languages. To address this, we introduce a new idiom dataset, a large-scale, culturally-grounded corpus of 10,361 Bengali idioms. Each idiom is annotated under a comprehensive 19-field schema, established and refined through a deliberative expert consensus process, that captures its semantic, syntactic, cultural, and religious dimensions, providing a rich, structured resource for computational linguistics. To establish a robust benchmark for Bangla figurative language understanding, we evaluate 30 state-of-the-art multilingual and instruction-tuned LLMs on the task of inferring figurative meaning. Our results reveal a critical performance gap, with no model surpassing 50% accuracy, a stark contrast to significantly higher human performance (83.4%). This underscores the limitations of existing models in cross-linguistic and cultural reasoning. By releasing the new idiom dataset and benchmark, we provide foundational infrastructure for advancing figurative language understanding and cultural grounding in LLMs for Bengali and other low-resource languages.

</details>


### [21] [Curriculum Learning and Pseudo-Labeling Improve the Generalization of Multi-Label Arabic Dialect Identification Models](https://arxiv.org/abs/2602.12937)
*Ali Mekky,Mohamed El Zeftawy,Lara Hassan,Amr Keleg,Preslav Nakov*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语方言识别缺乏多标签数据的问题，提出利用GPT-4o和二元方言可接受性分类器自动生成多标签标注，结合课程学习训练BERT模型，在MLADI榜单上达到0.69宏F1，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言识别长期被建模为单标签分类任务，但近期研究认为应转为多标签分类。然而，该领域缺乏大规模多标签训练资源，且现有单标签数据集在转用为多标签时面临核心挑战：负样本选择不当，因为许多被标记为负的句子实际上可在多种方言中接受。

Method: 1) 数据构建：利用GPT-4o生成自动多标签标注，结合二元方言可接受性分类器，并以阿拉伯语方言程度(ALDi)为指导进行标签聚合，构建高质量多标签数据集；2) 模型训练：采用BERT-based多标签分类器，并应用基于方言复杂度和标签基数的课程学习策略，逐步提升学习难度。

Result: 在MLADI评测榜单上，本研究的最佳模型LAHJATBERT取得了0.69的宏F1分数，相比此前最强系统(0.55)有显著提升，验证了所提方法的有效性。

Conclusion: 本研究通过自动生成多标签数据和课程学习策略，成功解决了阿拉伯语多标签方言识别的数据瓶颈问题，性能显著提升。该方法为资源稀缺的语言任务提供了可行的技术路径。

Abstract: Being modeled as a single-label classification task for a long time, recent work has argued that Arabic Dialect Identification (ADI) should be framed as a multi-label classification task. However, ADI remains constrained by the availability of single-label datasets, with no large-scale multi-label resources available for training. By analyzing models trained on single-label ADI data, we show that the main difficulty in repurposing such datasets for Multi-Label Arabic Dialect Identification (MLADI) lies in the selection of negative samples, as many sentences treated as negative could be acceptable in multiple dialects. To address these issues, we construct a multi-label dataset by generating automatic multi-label annotations using GPT-4o and binary dialect acceptability classifiers, with aggregation guided by the Arabic Level of Dialectness (ALDi). Afterward, we train a BERT-based multi-label classifier using curriculum learning strategies aligned with dialectal complexity and label cardinality. On the MLADI leaderboard, our best-performing LAHJATBERT model achieves a macro F1 of 0.69, compared to 0.55 for the strongest previously reported system. Code and data are available at https://mohamedalaa9.github.io/lahjatbert/.

</details>


### [22] [ProbeLLM: Automating Principled Diagnosis of LLM Failures](https://arxiv.org/abs/2602.12966)
*Yue Huang,Zhengzhe Jiang,Yuchen Ma,Yu Jiang,Xiangqi Wang,Yujun Zhou,Yuexing Hao,Kehan Guo,Pin-Yu Chen,Stefan Feuerriegel,Xiangliang Zhang*

Main category: cs.CL

TL;DR: ProbeLLM是一个基准无关的自动化探测框架，通过分层蒙特卡洛树搜索来发现大语言模型的失败模式，从孤立的失败案例提升到结构化的失败模式分析。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型快速演进和静态评估落后，理解模型失败的原因和方式成为核心挑战。现有动态测试生成方法存在三个局限：发现孤立的失败案例、缺乏探索的原则性控制、对模型弱点底层结构的洞察有限。

Method: ProbeLLM采用分层蒙特卡洛树搜索，在全局探索新失败区域和局部精化重复错误模式之间分配探测预算；通过工具增强生成和验证将失败发现建立在可靠证据基础上；使用失败感知嵌入和边界感知归纳将发现的失败整合为可解释的失败模式。

Result: 在不同基准和模型上，ProbeLLM揭示了比静态基准和先前自动化方法更广泛、更清晰、更细粒度的失败图谱。

Conclusion: 该框架支持从以案例为中心的评估向原则性弱点发现的转变。

Abstract: Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled control over exploration, and provide limited insight into the underlying structure of model weaknesses. We propose ProbeLLM, a benchmark-agnostic automated probing framework that elevates weakness discovery from individual failures to structured failure modes. ProbeLLM formulates probing as a hierarchical Monte Carlo Tree Search, explicitly allocating limited probing budgets between global exploration of new failure regions and local refinement of recurring error patterns. By restricting probing to verifiable test cases and leveraging tool-augmented generation and verification, ProbeLLM grounds failure discovery in reliable evidence. Discovered failures are further consolidated into interpretable failure modes via failure-aware embeddings and boundary-aware induction. Across diverse benchmarks and LLMs, ProbeLLM reveals substantially broader, cleaner, and more fine-grained failure landscapes than static benchmarks and prior automated methods, supporting a shift from case-centric evaluation toward principled weakness discovery.

</details>


### [23] [SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents](https://arxiv.org/abs/2602.12984)
*Yujiong Shen,Yajie Yang,Zhiheng Xi,Binze Hu,Huayu Sha,Jiazheng Zhang,Qiyuan Peng,Junlin Shang,Jixuan Huang,Yutao Fan,Jingqi Tong,Shihan Dou,Ming Zhang,Lei Bai,Zhenfei Yin,Tao Gui,Xingjun Ma,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 本文针对科学推理中工具编排能力的评估缺失，提出SciAgentGym环境和SciAgentBench基准，揭示当前模型在多步工作流中的瓶颈，并通过SciForge数据合成方法训练出性能优越的SciAgent-8B模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视智能体在科学领域中编排复杂工具进行多步工作流的能力，无法满足科学推理的实际需求，存在显著的评估空白。

Method: 1) 构建SciAgentGym：包含1780个跨四个自然科学领域的工具集和可执行基础设施；2) 创建SciAgentBench：分层评估套件，从基础动作到长时工作流测试智能体能力；3) 提出SciForge：将工具动作空间建模为依赖图，生成逻辑感知的训练轨迹；4) 在合成轨迹上微调得到SciAgent-8B。

Result: 评估显示，先进模型如GPT-5在复杂科学工具使用上存在严重瓶颈，随着交互步数增加，成功率从60.6%急剧下降至30.9%，主要失败于多步工作流执行；而基于SciForge微调的SciAgent-8B模型性能超越参数量更大的Qwen3-VL-235B-Instruct，并展现出跨领域科学工具使用能力的正向迁移。

Conclusion: 该研究验证了通过数据合成和依赖图建模方法提升科学智能体能力的有效性，为下一代自主科学智能体的发展提供了重要方向。

Abstract: Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.

</details>


### [24] [Evaluating the Homogeneity of Keyphrase Prediction Models](https://arxiv.org/abs/2602.12989)
*Maël Houbre,Florian Boudin,Beatrice Daille*

Main category: cs.CL

TL;DR: 本研究探讨关键词预测模型在文档索引中的一致性表现。传统观点认为，生成模型因能预测文档中未显式出现的"缺失关键词"，在处理相同主题文档时比提取模型更具一致性。然而，作者提出的评估方法显示，提取模型与生成模型表现相当，且生成缺失关键词的能力反而可能降低一致性，这一发现挑战了现有认知。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试缺乏对关键词预测模型一致性的评估指标。理论上，生成模型通过关联未提及概念应为同主题文档提供更一致的索引，但这一假设缺乏实证验证。本研究旨在填补这一研究空白，系统检验生成模型在一致性方面的实际表现。

Method: 作者创新性地提出一种评估关键词预测模型一致性的方法，通过对比模型对同主题文档的预测结果，量化分析生成能力与一致性的关系，实证研究缺失关键词生成是否真正提升模型一致性。

Result: 实验结果表明，关键词提取方法在一致性方面与生成模型具有显著竞争力。更令人意外的是，模型生成缺失关键词的能力可能对一致性产生负面影响，这与直觉预期完全相反。

Conclusion: 研究结论颠覆了对关键词生成模型的传统理解，揭示其生成能力与一致性之间存在复杂关系。该发现为未来模型优化提供了新方向，同时强调了开发更全面评估指标的必要性。所有数据和代码已开源。

Abstract: Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.

</details>


### [25] [Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models](https://arxiv.org/abs/2602.12996)
*Hao Chen,Ye He,Yuchun Fan,Yukun Yan,Zhenghao Liu,Qingfu Zhu,Maosong Sun,Wanxiang Che*

Main category: cs.CL

TL;DR: 针对大语言模型知识增强中知识-置信度不匹配问题，本文提出元认知框架，通过差异化干预和对齐将知识空间划分为掌握、混淆、缺失三区，利用认知一致性机制校准边界，实验证实能有效提升知识能力并区分已知未知。


<details>
  <summary>Details</summary>
Motivation: 现有知识增强方法存在知识-置信度差距问题，导致模型产生过度自信错误或不确定真实判断。为此，需要开发能够识别模型内部认知状态并校准知识边界的可靠增强框架。

Method: 该框架利用模型内部认知信号将知识空间划分为掌握、混淆和缺失三个区域，针对不同区域实施差异化知识扩展策略；同时引入认知一致性机制，使模型的主观确定性与客观准确性同步，实现知识边界的校准。

Result: 在多个知识密集型任务上的实验表明，该框架显著优于现有强基线方法，不仅提升了知识能力，更重要的是培养了模型更好区分已知与未知的认知行为。

Conclusion: 通过差异化干预和认知对齐，该框架有效解决了知识-置信度不匹配问题，为构建更可靠的大语言模型知识增强系统提供了有效方案，验证了其理论合理性和实践有效性。

Abstract: Knowledge augmentation has significantly enhanced the performance of Large Language Models (LLMs) in knowledge-intensive tasks. However, existing methods typically operate on the simplistic premise that model performance equates with internal knowledge, overlooking the knowledge-confidence gaps that lead to overconfident errors or uncertain truths. To bridge this gap, we propose a novel meta-cognitive framework for reliable knowledge augmentation via differentiated intervention and alignment. Our approach leverages internal cognitive signals to partition the knowledge space into mastered, confused, and missing regions, guiding targeted knowledge expansion. Furthermore, we introduce a cognitive consistency mechanism to synchronize subjective certainty with objective accuracy, ensuring calibrated knowledge boundaries. Extensive experiments demonstrate the our framework consistently outperforms strong baselines, validating its rationality in not only enhancing knowledge capabilities but also fostering cognitive behaviors that better distinguish knowns from unknowns.

</details>


### [26] [Can we trust AI to detect healthy multilingual English speakers among the cognitively impaired cohort in the UK? An investigation using real-world conversational speech](https://arxiv.org/abs/2602.13047)
*Madhurananda Pahar,Caitlin Illingworth,Dorota Braun,Bahman Mirheidari,Lise Sproson,Daniel Blackburn,Heidi Christensen*

Main category: cs.CL

TL;DR: 该研究首次发现，AI模型在检测英国少数族裔多语言者认知衰退时存在偏见：ASR系统无偏见，但分类模型对多语言者（尤其南约克郡口音）表现出偏见，易将其误判为认知衰退。现有工具尚不适合临床诊断。


<details>
  <summary>Details</summary>
Motivation: 英国四分之一人口属少数族裔，黑人及亚裔社区痴呆症患病率上升最快。本研究旨在探究AI认知衰退检测工具对多语言英语使用者的可信度与偏见，确保其临床适用性。

Method: 研究招募英国全国单语者，以及谢菲尔德与布拉德福德四个社区中心的多语言者（说索马里语、中文或南亚语言），并按西/南约克郡口音分组。评估自动语音识别(ASR)系统和使用声学/语言特征的分类/回归模型在记忆、流利度、阅读任务上的表现，对比公开DementiaBank数据集训练效果。

Result: ASR系统在各组间无显著偏见。但分类和回归模型对多语言者存在明显偏见，尤其在记忆、流利度和阅读任务中，使用DementiaBank数据集训练时偏见更严重。多语言者更易被误判为认知衰退，南约克郡口音者被误诊为更严重认知障碍的比例更高。

Conclusion: 尽管AI模型整体性能良好，但针对英国少数族裔多语言者存在偏见，现有工具尚不可靠用于临床诊断。未来需开发更具泛化性、能缓解偏见的新模型。

Abstract: Conversational speech often reveals early signs of cognitive decline, such as dementia and MCI. In the UK, one in four people belongs to an ethnic minority, and dementia prevalence is expected to rise most rapidly among Black and Asian communities. This study examines the trustworthiness of AI models, specifically the presence of bias, in detecting healthy multilingual English speakers among the cognitively impaired cohort, to make these tools clinically beneficial. For experiments, monolingual participants were recruited nationally (UK), and multilingual speakers were enrolled from four community centres in Sheffield and Bradford. In addition to a non-native English accent, multilinguals spoke Somali, Chinese, or South Asian languages, who were further divided into two Yorkshire accents (West and South) to challenge the efficiency of the AI tools thoroughly. Although ASR systems showed no significant bias across groups, classification and regression models using acoustic and linguistic features exhibited bias against multilingual speakers, particularly in memory, fluency, and reading tasks. This bias was more pronounced when models were trained on the publicly available DementiaBank dataset. Moreover, multilinguals were more likely to be misclassified as having cognitive decline. This study is the first of its kind to discover that, despite their strong overall performance, current AI models show bias against multilingual individuals from ethnic minority backgrounds in the UK, and they are also more likely to misclassify speakers with a certain accent (South Yorkshire) as living with a more severe cognitive decline. In this pilot study, we conclude that the existing AI tools are therefore not yet reliable for diagnostic use in these populations, and we aim to address this in future work by developing more generalisable, bias-mitigated models.

</details>


### [27] [TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution](https://arxiv.org/abs/2602.13059)
*Tejas Anvekar,Junha Park,Rajat Jha,Devanshu Gupta,Poojah Ganesan,Puneeth Mathur,Vivek Gupta*

Main category: cs.CL

TL;DR: TraceBack是一个用于表格问答的可扩展多智能体框架，通过单元格级归因提供可验证的证据支持，解决现有系统在关键场景中缺乏透明度的问题。


<details>
  <summary>Details</summary>
Motivation: 现有表格问答系统很少提供细粒度的答案归因，即使答案正确也缺乏可验证的事实依据，这限制了在高风险场景中的可信度。需要能够追踪每个答案来源的透明化方法。

Method: TraceBack采用模块化多智能体架构：1)剪枝表格至相关行列；2)将问题分解为语义一致的子问题；3)将答案片段与支持单元格对齐，捕获中间推理步骤中的显式和隐式证据；4)提出无需人工标注的FairScore评估指标。

Result: 在CITEBench基准测试上，TraceBack在多个数据集和粒度上显著优于强基线；FairScore指标与人工判断高度相关，能有效保持方法排名顺序。

Conclusion: TraceBack为单表问答提供了可扩展的单元格级归因能力，结合CITEBench基准和FairScore指标，实现了可解释且可扩展的表格问答评估，增强了高风险场景下的系统可信度。

Abstract: Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable grounding, limiting trust in high-stakes settings. We address this with TraceBack, a modular multi-agent framework for scalable, cell-level attribution in single-table QA. TraceBack prunes tables to relevant rows and columns, decomposes questions into semantically coherent sub-questions, and aligns each answer span with its supporting cells, capturing both explicit and implicit evidence used in intermediate reasoning steps. To enable systematic evaluation, we release CITEBench, a benchmark with phrase-to-cell annotations drawn from ToTTo, FetaQA, and AITQA. We further propose FairScore, a reference-less metric that compares atomic facts derived from predicted cells and answers to estimate attribution precision and recall without human cell labels. Experiments show that TraceBack substantially outperforms strong baselines across datasets and granularities, while FairScore closely tracks human judgments and preserves relative method rankings, supporting interpretable and scalable evaluation of table-based QA.

</details>


### [28] [Exploring a New Competency Modeling Process with Large Language Models](https://arxiv.org/abs/2602.13084)
*Silin Du,Manqing Xin,Raymond Jia Wang*

Main category: cs.CL

TL;DR: 提出一种基于大语言模型的胜任力建模新流程，通过解构专家实践为结构化计算组件，实现文本中行为心理描述到胜任力库的智能映射，并引入可学习参数自适应融合多源信息，同时开发离线评估方法，实证显示具有良好预测效度、跨库一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统专家驱动方法依赖人工分析大量访谈文本，成本高且存在随机性、模糊性和可复现性差等问题。

Method: 利用LLM提取文本中的行为与心理描述；通过嵌入相似度映射至胜任力库；引入可学习参数自适应加权行为与心理信号；开发无需额外大规模数据收集的离线评估流程。

Result: 软件外包公司实证结果表明该方法具有强预测效度、跨库一致性和结构鲁棒性。

Conclusion: 将胜任力建模从定性、专家依赖的实践转变为透明、数据驱动且可评估的分析过程。

Abstract: Competency modeling is widely used in human resource management to select, develop, and evaluate talent. However, traditional expert-driven approaches rely heavily on manual analysis of large volumes of interview transcripts, making them costly and prone to randomness, ambiguity, and limited reproducibility. This study proposes a new competency modeling process built on large language models (LLMs). Instead of merely automating isolated steps, we reconstruct the workflow by decomposing expert practices into structured computational components. Specifically, we leverage LLMs to extract behavioral and psychological descriptions from raw textual data and map them to predefined competency libraries through embedding-based similarity. We further introduce a learnable parameter that adaptively integrates different information sources, enabling the model to determine the relative importance of behavioral and psychological signals. To address the long-standing challenge of validation, we develop an offline evaluation procedure that allows systematic model selection without requiring additional large-scale data collection. Empirical results from a real-world implementation in a software outsourcing company demonstrate strong predictive validity, cross-library consistency, and structural robustness. Overall, our framework transforms competency modeling from a largely qualitative and expert-dependent practice into a transparent, data-driven, and evaluable analytical process.

</details>


### [29] [Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts](https://arxiv.org/abs/2602.13102)
*Kais Allkivi*

Main category: cs.CL

TL;DR: 本研究结合NLP与二语习得研究，通过精选词汇、形态、表层和错误特征构建爱沙尼亚语A2-C1水平作文分类模型，准确率达90%，揭示学习者写作复杂度7-10年间显著提升，成果已应用于开源语言学习平台。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏将真实学习者语言分析用于自动化评估工具构建与二语产出发展洞察的有机结合，尤其在爱沙尼亚语测试领域。本研究旨在填补这一空白，通过精细特征选择构建可解释且泛化性强的语言测试机器学习模型。

Method: 研究以爱沙尼亚语水平考试作文为对象（A2-C1级），系统分析训练数据的语言学属性，筛选与复杂度、正确性相关而非写作任务本身的预测特征。采用词汇、形态、表层和错误特征训练分类器，并与包含其他特征的模型对比。额外在7-10年前的历史样本上评估模型性能。

Result: 精选特征模型在测试集上准确率与全特征模型相当，但对不同文本类型的分类稳定性显著提升。最优分类器准确率约0.9。历史样本评估显示考生写作复杂度随时间显著增加，部分特征集在旧样本上仍保持0.8的准确率。该成果已集成至爱沙尼亚语开源学习环境的写作评估模块。

Conclusion: 研究表明，针对性的特征选择能增强语言测试ML模型的可解释性与泛化能力，有效捕捉学习者语言能力发展轨迹。该方法论适用于语言评估工具开发，并为二语习得研究提供量化证据，具有实践与理论双重价值。

Abstract: Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly combining these aspects. This study aimed to classify Estonian proficiency examination writings (levels A2-C1), assuming that careful feature selection can lead to more explainable and generalizable machine learning models for language testing. Various linguistic properties of the training data were analyzed to identify relevant proficiency predictors associated with increasing complexity and correctness, rather than the writing task. Such lexical, morphological, surface, and error features were used to train classification models, which were compared to models that also allowed for other features. The pre-selected features yielded a similar test accuracy but reduced variation in the classification of different text types. The best classifiers achieved an accuracy of around 0.9. Additional evaluation on an earlier exam sample revealed that the writings have become more complex over a 7-10-year period, while accuracy still reached 0.8 with some feature sets. The results have been implemented in the writing evaluation module of an Estonian open-source language learning environment.

</details>


### [30] [From sunblock to softblock: Analyzing the correlates of neology in published writing and on social media](https://arxiv.org/abs/2602.13123)
*Maria Ryskina,Matthew R. Gormley,Kyle Mahowald,David R. Mortensen,Taylor Berg-Kirkpatrick,Vivek Kulkarni*

Main category: cs.CL

TL;DR: 本研究将先前基于历史出版文本的英语新词发现方法扩展到Twitter社交媒体领域，通过融合静态与上下文词嵌入分析，验证了两个领域新词形成机制的共通性，但发现主题流行度增长因素在Twitter上贡献较弱，推测源于不同领域对新词生成机制的偏好差异。


<details>
  <summary>Details</summary>
Motivation: 先前英语新词研究主要依赖历史出版文本语料库，而不同交际语境（如报纸与社交媒体）对语言使用施加不同约束。鉴于社交媒体语言演化的独特性，本研究旨在验证已有发现是否适用于Twitter语境，并探究领域差异对新词形成机制的调节作用。

Method: 扩展Ryskina等人(2020)的分布语义方法，构建Twitter帖子语料库，同时采用静态词嵌入与上下文嵌入技术，识别并分析新词形成模式。通过对比Twitter与出版文本两个领域中主题流行度增长等因素对新词形成的贡献度差异。

Result: 实验表明，先前在出版文本中识别的两个新词形成关键因素同样适用于Twitter领域，但主题流行度增长在Twitter上的贡献显著低于出版写作领域。

Conclusion: 研究假设Twitter与出版写作领域的差异可归因于二者偏好不同的新词形成机制。这一发现揭示了语言演化对交际语境的依赖性，为理解不同媒介下的词汇创新提供了新的理论视角。

Abstract: Living languages are shaped by a host of conflicting internal and external evolutionary pressures. While some of these pressures are universal across languages and cultures, others differ depending on the social and conversational context: language use in newspapers is subject to very different constraints than language use on social media. Prior distributional semantic work on English word emergence (neology) identified two factors correlated with creation of new words by analyzing a corpus consisting primarily of historical published texts (Ryskina et al., 2020, arXiv:2001.07740). Extending this methodology to contextual embeddings in addition to static ones and applying it to a new corpus of Twitter posts, we show that the same findings hold for both domains, though the topic popularity growth factor may contribute less to neology on Twitter than in published writing. We hypothesize that this difference can be explained by the two domains favouring different neologism formation mechanisms.

</details>


### [31] [OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report](https://arxiv.org/abs/2602.13139)
*Mariia Fedorova,Nikolay Arefyev,Maja Buljan,Jindřich Helcl,Stephan Oepen,Egil Rønningstad,Yves Scherrer*

Main category: cs.CL

TL;DR: 该论文针对网页多语种数据清洗中的语言识别难题，提出OpenLID-v3系统。通过扩展训练数据、合并易混淆语言变体簇、引入噪声标签，并构建新的评测数据集，显著提升了低资源语言和相近语言对的识别能力，但发现集成方法在提高精度的同时会牺牲覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别工具（如OpenLID和GlotLID）在识别相近语言及区分自然语言与噪声方面存在不足，导致语种子集数据污染，尤其对低资源语言影响严重。这限制了高质量多语种数据集的构建。

Method: 在OpenLID基础上扩展训练数据量；合并有问题的语言变体聚类；引入专门标记噪声的特殊标签；针对波斯尼亚语/克罗地亚语/塞尔维亚语、北意大利/南法罗曼语族、斯堪的纳维亚语三组相近语言，构建新的评测数据集以弥补现有不足；与GlotLID在多个基准上进行对比评估。

Result: 实验发现集成方法虽然提升了识别精度，但对低资源语言会大幅降低覆盖率。OpenLID-v3在相近语言区分和噪声过滤方面表现优于基线系统。

Conclusion: OpenLID-v3通过数据扩展和结构优化有效改善了低资源语言和易混淆语言的识别质量，揭示了精度与覆盖率间的固有权衡。该系统已开源发布，为多语种数据清洗提供了更可靠的工具。

Abstract: Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages. In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters, and introducing a special label for marking noise. We call this extended system OpenLID-v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages. OpenLID-v3 is available on https://huggingface.co/HPLT/OpenLID-v3.

</details>


### [32] [Semantic Chunking and the Entropy of Natural Language](https://arxiv.org/abs/2602.13194)
*Weishun Zhong,Doron Sivan,Tankut Can,Mikhail Katkov,Misha Tsodyks*

Main category: cs.CL

TL;DR: 本文提出一种统计模型，通过自相似地将文本分割为语义连贯的块并构建层次化结构，从第一性原理出发解释了英文约80%的冗余度。模型预测的熵率（约1比特/字符）与现代大语言模型测得的结果一致，并揭示语言熵率随语义复杂度系统增加而非固定不变的规律。


<details>
  <summary>Details</summary>
Motivation: 英文印刷文本的熵率约为1比特/字符，意味着近80%的冗余度，而现代大语言模型直到最近才接近该基准。现有研究缺乏对自然语言多尺度结构的定量描述和第一性原理解释。本研究旨在建立一个能够捕捉语言内在层次结构、从基本原理出发解释这种高冗余度的统计模型。

Method: 研究引入一个统计模型，该模型自相似地将文本分割成从单词到更大单元的语义连贯块，形成层次化的语义结构。通过这种层次化分解实现解析处理。利用现代大语言模型和开放数据集进行数值实验，验证模型在不同语义层级上定量捕捉真实文本结构的能力。

Result: 数值实验表明，该模型能定量捕捉真实文本在不同语义层级上的结构特征。模型预测的熵率与印刷英文的估计熵率（约1比特/字符）相符。更重要的是，理论揭示自然语言熵率并非固定，而是随语料库语义复杂度系统性地增加，这一规律由模型唯一的自由参数所捕获。

Conclusion: 自然语言的熵率并非恒定值，而是随语义复杂度系统增加。该研究通过自相似层次化语义模型，首次从第一性原理成功解释了英文的高冗余度特征，为理解大语言模型的性能提供了新的理论框架，并揭示了语言复杂性的内在规律。

Abstract: The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316)
*Pepijn Cobben,Xuanqiang Angelo Huang,Thao Amelia Pham,Isabel Dahlgren,Terry Jingchen Zhang,Zhijing Jin*

Main category: cs.AI

TL;DR: 提出GT-HarmBench多智能体安全基准测试，包含2,009个博弈论场景。15个前沿模型仅62%选择社会有益行动，博弈论干预可提升有益结果达18%，揭示多智能体交互存在严重可靠性缺陷。


<details>
  <summary>Details</summary>
Motivation: 前沿AI系统日益部署于高风险多智能体环境，但现有安全基准主要评估单智能体，导致协调失败和冲突等多智能体风险缺乏充分理解，亟需专门评估工具。

Method: 构建涵盖囚徒困境、猎鹿博弈、斗鸡博弈等结构的2,009个高风险场景基准，源自MIT AI风险库。测试15个前沿模型，分析其对博弈论提示框架与排序的敏感性、失败推理模式，并评估博弈论干预措施效果。

Result: 实证表明，智能体仅62%的情况下采取社会有益行动，频繁导致有害结果。模型决策显著受提示框架和排序影响。博弈论干预可使社会有益结果提升最高18个百分点。

Conclusion: 研究揭示了当前AI在多智能体交互中存在重大对齐可靠性差距，GT-HarmBench为标准化研究多智能体环境中的对齐问题提供了全面测试平台。

Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.

</details>


### [34] [To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.12566)
*Haoqing Wang,Xiang Long,Ziheng Li,Yilong Xu,Tingguang Li,Yehui Tang*

Main category: cs.AI

TL;DR: 本文通过多领域实验系统比较了混合多任务强化学习与分离训练后模型合并两种范式，发现跨领域RLVR干扰有限且推理密集型任务存在协同增益，并从多角度揭示其内在机制。


<details>
  <summary>Details</summary>
Motivation: 当前最优的多领域RLVR模型主要采用混合训练或分离后合并两种范式，但相关研究缺乏对这两种范式的深入比较分析，无法满足构建通用多领域专家级大语言模型的理论需求。

Method: 选取数学、代码、科学和指令遵循等高阶认知任务作为目标领域，基于开源数据集设计广泛的定性与定量实验，并从权重空间几何结构、模型预测行为特征及信息约束三个维度剖析协同效应的内在机制。

Result: 实验表明跨领域RLVR之间相互干扰较少，且推理密集型领域（如数学、代码）呈现显著的协同增强效应。

Conclusion: M2RL项目首次系统性地揭示了多领域RLVR训练范式的特性与优势，为开发通用型专家级大语言模型提供了重要的理论依据和实践指导。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL

</details>


### [35] [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)
*Joshua Ong Jun Leang,Yu Zhao,Mihaela Cătălina Stoian,Wenda Li,Shay B. Cohen,Eleonora Giunchiglia*

Main category: cs.AI

TL;DR: 针对Masked Diffusion Models中槽位填充顺序敏感性导致的输出方差问题，本文提出McDiffuSE框架，通过蒙特卡洛树搜索优化填充顺序，在MBPP和MATH500基准上分别取得19.5%和4.9%的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: Masked Diffusion Models的计划-填充解码策略在数学与代码推理任务中表现潜力，但其性能严重受制于槽位填充顺序的选择，产生显著的输出方差，亟需系统性优化方法。

Method: 将槽位选择建模为序贯决策问题，采用蒙特卡洛树搜索框架进行填充顺序优化。通过前向模拟评估部分解的质量，系统探索生成顺序的组合空间，并利用较大的探索常数来克服模型置信度偏好。

Result: 在多个基准测试中，McDiffuSE相比自回归基线平均提升3.2%，相比基线计划-填充方法平均提升8.0%。具体而言，在MBPP代码生成任务上提升19.5%，在MATH500数学推理任务上提升4.9%。

Conclusion: 研究表明，基于蒙特卡洛树搜索的规划策略能有效提升MDMs的生成质量。关键发现包括：非顺序生成对性能最大化至关重要；采用较大探索常数比增加模拟次数更能有效克服模型置信度偏差，为生成顺序优化提供了新方向。

Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.

</details>


### [36] [GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics](https://arxiv.org/abs/2602.12617)
*Modi Jin,Yiming Zhang,Boyuan Sun,Dingwen Zhang,MingMing Cheng,Qibin Hou*

Main category: cs.AI

TL;DR: 提出GeoAgent地理定位模型，通过专家标注的GeoSeek数据集和地理相似性奖励机制，解决现有RL方法依赖AI生成数据且不符合地理特性的问题，实现细粒度地址推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法依赖AI生成的思维链数据，训练策略与地理任务特性存在冲突，导致模型推理过程缺乏地理合理性，难以生成符合人类认知的精确地址结论。

Method: 1) 构建GeoSeek数据集：由地理专家和职业玩家人工标注高质量的思维链数据；2) 设计地理相似性奖励和一致性奖励机制，通过一致性智能体评估，引导模型从地理视角收敛到正确答案，同时确保推理过程的完整性和逻辑一致性。

Result: 实验结果表明，GeoAgent在多个粒度上均优于现有方法和通用视觉大语言模型，生成的推理过程与人类思维高度一致，显著提升了地理定位的准确性和可解释性。

Conclusion: GeoAgent通过引入专家知识和领域自适应奖励机制，成功解决了地理任务中AI生成数据的可靠性问题，为构建更符合人类认知的地理智能体提供了有效方案。

Abstract: This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose a geo-similarity reward and a consistency reward assessed by a consistency agent to assist training. This encourages the model to converge towards correct answers from a geographic perspective while ensuring the integrity and consistency of its reasoning process. Experimental results show that GeoAgent outperforms existing methods and a series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans.

</details>


### [37] [AI Agents for Inventory Control: Human-LLM-OR Complementarity](https://arxiv.org/abs/2602.12631)
*Jackie Baek,Yaopeng Fu,Will Ma,Tianyi Peng*

Main category: cs.AI

TL;DR: 本研究考察运筹学算法、大语言模型与人在多周期库存控制中的交互机制。通过构建InventoryBench基准测试集，发现OR增强的LLM方法性能优于单一方法；课堂实验表明人机协作团队利润显著高于单独决策者，且大多数个体能从AI协作中受益。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学算法因刚性假设在需求变化时表现不佳，而LLM的灵活推理能力尚未明确如何有效融入传统决策流程，亟需探索人机协同的互补机制。

Method: 创建InventoryBench基准（1000+实例，含合成与真实需求数据），测试不同决策规则在需求漂移、季节性和不确定提前期下的表现；设计课堂实验，研究人在回路中采纳LLM推荐的协作效果。

Result: OR增强的LLM方法实现性能互补；人机协作团队平均利润显著优于单独人类或AI；形式化个体互补效应，推导出受益比例的分布无关下界，实证显示该比例具有统计显著性。

Conclusion: OR算法与LLM具有互补性而非替代性；人机协作可系统性提升决策绩效，为AI在运营管理中的有效集成提供了理论和实证基础。

Abstract: Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.
  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.
  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.

</details>


### [38] [Evaluating Robustness of Reasoning Models on Parameterized Logical Problems](https://arxiv.org/abs/2602.12665)
*Naïm Es-sebbani,Esteban Marquer,Yakoub Salhi,Zied Bouraoui*

Main category: cs.AI

TL;DR: 提出参数化2-SAT诊断基准，通过结构化公式族分离表面难度与结构现象，揭示LLM推理器在结构干预下的脆弱性


<details>
  <summary>Details</summary>
Motivation: 标准SAT基准混淆表面难度（长度、措辞、子句顺序）与决定可满足性的结构现象，缺乏解耦能力，无法精准评估LLM推理器的真实推理机制

Method: 构建参数化2-CNF公式族，其可满足性由蕴含图决定并可沿可解释轴调节；设计五类生成器隔离不同能力：(i)可控矛盾环UNSAT核心，(ii)自由变量比例控制解的多重性，(iii)植入骨干调节传播，(iv)桥接子句探测对排序的敏感性，(v)对称/重复结构测试抽象能力；评估决策准确性与赋值有效性，并测试在子句重排、填充子句、变量重命名等保语义扰动下的鲁棒性

Result: 跨模型实验显示，即使在表面统计特征固定的情况下，针对性的结构干预也会导致性能的急剧转变，揭示了传统SAT准确率无法检测的脆弱性机制

Conclusion: 该诊断基准有效揭示了大语言模型推理器在结构层面的性能缺陷，超越了传统SAT基准的评估能力，为理解模型推理失败模式提供了精细化分析工具

Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.

</details>


### [39] [X-SYS: A Reference Architecture for Interactive Explanation Systems](https://arxiv.org/abs/2602.12748)
*Tobias Labarta,Nhi Hoang,Maximilian Dreyer,Jim Berend,Oleg Hein,Jackie Ma,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.AI

TL;DR: 本文提出X-SYS参考架构，通过STAR质量属性（可扩展性、可追溯性、响应性、适应性）和五组件分解，解决交互式解释系统部署难题。该系统在SemanticLens中实现，验证了契约化服务边界、离在线分离和持久状态管理等机制，为可操作化XAI提供可重用蓝图。


<details>
  <summary>Details</summary>
Motivation: 尽管XAI技术方法丰富，但部署交互式解释系统仍面临算法与系统能力双重挑战：需应对重复查询、模型数据演进和治理约束，缺乏将用户交互需求转化为系统要求的系统性框架。

Method: 将可解释性视为信息系统问题，提出X-SYS参考架构：1)定义STAR质量属性；2)五组件分解(XUI服务、解释服务、模型服务、数据服务、编排与治理)；3)映射交互模式到系统能力，实现前后端解耦。

Result: 通过SemanticLens系统（视觉语言模型的语义搜索与激活引导）实现X-SYS，验证了契约化服务边界支持独立演进、离在线分离保障响应性、持久状态管理实现可追溯性的有效性。

Conclusion: 研究为可操作化XAI提供了系统性参考架构和可重用设计蓝图，通过X-SYS与SemanticLens实践，证明了交互需求向系统能力转化、前后端解耦对端到端设计的重要性。

Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

</details>


### [40] [WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning](https://arxiv.org/abs/2602.12852)
*Junjie Wang,Zequn Xie,Dan Yang,Jie Feng,Yue Shen,Duolin Sun,Meixiu Long,Yihan Jiao,Zhehao Tan,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: 针对网页智能体搜索效率低下的问题，本文提出 WebClipper 框架，通过将搜索轨迹建模为状态图并求解最小必要有向无环图挖掘问题来实现轨迹压缩。该方法在保留关键推理的同时消除冗余步骤，使工具调用轮次减少约 20% 且准确率提升，并引入 F-AE Score 平衡评估效果与效率。


<details>
  <summary>Details</summary>
Motivation: 基于网页智能体的深度研究系统虽具强大潜力，但搜索效率尚未充分探索。现有先进开源智能体存在工具调用轨迹冗长、循环推理及无效分支探索等问题，导致搜索效率低下，亟需优化。

Method: WebClipper 框架将智能体搜索过程建模为状态图，将轨迹优化形式化为最小必要有向无环图（DAG）挖掘问题。通过图剪枝技术去除冗余步骤，保留必要推理路径。进一步在精炼轨迹上继续训练，使智能体演化出更高效搜索模式。

Result: 实验表明，WebClipper 可在保持优异性能前提下，将工具调用轮次压缩约 20%，同时提升准确率。此外，论文提出 F-AE Score 新指标，用于综合衡量模型在准确性与效率间的平衡表现。

Conclusion: WebClipper 有效解决了网页智能体的效率问题，为平衡搜索效果与效率提供了实用洞见，证明通过轨迹压缩与优化训练可显著提升智能体性能，为未来高效智能体设计指明方向。

Abstract: Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rely on long tool-call trajectories with cyclic reasoning loops and exploration of unproductive branches. To address this, we propose WebClipper, a framework that compresses web agent trajectories via graph-based pruning. Concretely, we model the agent's search process as a state graph and cast trajectory optimization as a minimum-necessary Directed Acyclic Graph (DAG) mining problem, yielding pruned trajectories that preserve essential reasoning while eliminating redundant steps. Continued training on these refined trajectories enables the agent to evolve toward more efficient search patterns and reduces tool-call rounds by about 20% while improving accuracy. Furthermore, we introduce a new metric called F-AE Score to measure the model's overall performance in balancing accuracy and efficiency. Experiments demonstrate that WebClipper compresses tool-call rounds under excellent performance, providing practical insight into balancing effectiveness and efficiency in web agent design.

</details>


### [41] [Information-theoretic analysis of world models in optimal reward maximizers](https://arxiv.org/abs/2602.12963)
*Alfred Harwood,Jose Faustino,Alex Altair*

Main category: cs.AI

TL;DR: 这篇论文研究了在AI中，成功行为需要多少关于世界的内部表示。通过分析控制马尔可夫过程，作者证明了对于任意非恒定奖励函数，一个确定性最优策略恰好能揭示n log m比特关于环境的信息，这为最优策略所需的最小"隐式世界模型"提供了精确的信息论下界。


<details>
  <summary>Details</summary>
Motivation: 该研究的核心动机是量化成功AI行为所需的环境内部表示程度。在AI领域，一个基本问题是理解智能体在多大程度上需要通过内部世界模型来指导其行为。现有研究缺乏对这一问题的精确量化分析，特别是在信息论框架下的严格界定。本研究旨在填补这一空白，为智能体最优决策所需的最小环境信息提供理论依据。

Method: 作者采用控制马尔可夫过程(Controlled Markov Process, CMP)作为理论框架，假设系统包含n个状态和m个动作，并对可能的转移动态设定均匀先验分布。通过信息论分析，特别是互信息(mutual information)的计算，研究最优策略与环境之间的信息传递量。分析方法涵盖有限时域、无限时域折扣奖励以及时间平均奖励最大化等多种目标函数类别。

Result: 研究结果表明，在给定均匀先验条件下，观察一个针对任意非恒定奖励函数的确定性最优策略，能够恰好传达n log m比特关于底层环境的信息。这一结果在所有考虑的目标函数类别中均成立。具体而言，环境与最优策略之间的互信息精确等于n log m比特，这构成了最优策略所需"隐式世界模型"的信息论下界。

Conclusion: 该结论为理解智能体最优决策所需的环境表示提供了精确的量化框架。n log m比特的信息量揭示了实现最优策略所必须的最小信息处理需求，表明即使在隐式表示的情况下，智能体也必须编码至少如此多的环境信息。这一发现深化了对AI系统中世界模型必要性的认识，并为未来研究智能体表征学习的信息论基础提供了重要参考。

Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the "implicit world model'' necessary for optimality.

</details>


### [42] [Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093)
*Yubo Li,Ramayya Krishnan,Rema Padman*

Main category: cs.AI

TL;DR: 本研究评估九个前沿推理模型在多轮对抗性攻击下的鲁棒性，发现推理能力虽能提升性能但仍存在显著漏洞。识别出五种失败模式（自我怀疑、社会趋同、建议劫持、情感易感性和推理疲劳），其中前两者占故障的50%。针对标准大语言模型有效的置信度感知响应生成策略在推理模型上因过度自信而失效，随机置信度嵌入反而更有效。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务上表现优异，但其面临多轮对抗性压力时的鲁棒性尚未得到充分探索。理解这些模型的脆弱性特征并开发有效防御机制具有重要研究价值和现实意义。

Method: 研究团队对九个前沿推理模型进行对抗性攻击实验，通过轨迹分析系统识别失败模式，并评估置信度感知响应生成（CARG）策略在推理模型上的适用性，对比了针对性提取与随机置信度嵌入的效果。

Result: 推理模型相比指令微调基线展现出显著但非完全的鲁棒性提升；所有模型均呈现独特脆弱性，其中误导性建议普遍有效，社会压力则具模型特异性。轨迹分析揭示五种主要失败模式，自我怀疑与社会趋同合计占比达50%。CARG策略因扩展推理轨迹导致的过度自信而失效，随机置信度嵌入效果优于针对性提取方法。

Conclusion: 推理能力无法自动赋予对抗性鲁棒性，现有基于置信度的防御机制需针对推理模型进行根本性重新设计。该发现为提升推理模型安全性和可靠性提供了重要研究方向。

Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.

</details>


### [43] [Constrained Assumption-Based Argumentation Frameworks](https://arxiv.org/abs/2602.13135)
*Emanuele De Angelis,Fabio Fioravanti,Maria Chiara Meo,Alberto Pettorossi,Maurizio Proietti,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出约束假设论证(CABA)框架，通过引入约束变量扩展传统ABA的表达能力，使其能够处理非接地论证和无限域上的攻击，同时保持对标准ABA语义的保守推广性。


<details>
  <summary>Details</summary>
Motivation: 传统假设论证(ABA)框架受限于只能处理接地(变量无关)的命题原子构建的论证和攻击，这一表示性限制约束了其实际应用场景。为突破此局限，需要构建支持变量和无限域的扩展框架。

Method: 提出约束假设论证(CABA)新范式，允许框架组件和论证包含约束变量；定义基于非接地攻击的多种非接地语义；通过形式化方法证明新语义对标准ABA语义的保守推广关系。

Result: 成功构建了CABA框架的理论体系，明确各类非接地攻击的形式化定义，并验证新语义在变量实例化下与传统接地语义的一致性。

Conclusion: CABA框架有效克服了ABA的表示性限制，显著增强了结构化论证的表达能力，为处理含变量的复杂推理场景提供了理论基础，同时保持了与传统理论的兼容性。

Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.

</details>


### [44] [Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation](https://arxiv.org/abs/2602.11799)
*Pingjun Pan,Tingting Zhou,Peiyao Lu,Tingting Fei,Hongxiang Chen,Chuanjiang Luo*

Main category: cs.AI

TL;DR: 本文针对多模态推荐系统提出Hi-SAM框架，通过解耦语义令牌器(DST)和分层记忆锚定Transformer(HMAT)解决令牌化不优与架构-数据失配问题。DST实现跨模态语义解耦，HMAT恢复交互层次结构，在真实数据集上显著优于SOTA，工业部署实现6.55%核心指标提升。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐虽可利用文本、图像等丰富属性，但基于语义ID的离散化方法面临两大挑战：1) 令牌化质量不佳：现有RQ-VAE等方法未能有效解耦跨模态共享语义与模态特定细节，导致信息冗余或模式崩溃；2) 架构与数据结构失配：标准Transformer将语义ID视为扁平序列，忽视了用户-项目-令牌的三级层次关系，多令牌扩展项目会引入长度膨胀和噪声干扰，使注意力机制偏向局部细节而忽略全局语义。

Method: Hi-SAM框架包含两大核心设计：1) 解耦语义令牌器(DST)：采用几何感知对齐统一多模态表示，通过粗到细量化策略，利用共享码本提取共识语义，模态专属码本重构残差细节，并以互信息最小化强制解耦；2) 分层记忆锚定Transformer(HMAT)：通过分层旋转位置编码(Hierarchical RoPE)分离项间与项内位置信息，维护层次结构；引入锚定令牌压缩项目表示，在保留当前项目细节的同时，仅通过压缩记忆访问历史交互。

Result: 在多个真实世界数据集上的实验表明，Hi-SAM相对于现有SOTA方法取得一致且显著的性能提升，尤其在冷启动场景下优势明显。该框架已部署于某大型社交平台服务数百万用户，核心在线指标相对提升6.55%。

Conclusion: Hi-SAM通过创新的解耦令牌化机制和层次化Transformer架构，有效解决了多模态推荐中语义表示与结构建模的关键问题，兼具学术价值与工业实用性，为下一代推荐系统提供了新范式。

Abstract: Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.

</details>


### [45] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 本文提出了一种混合障碍规避架构，将基于 clearance 的最优控制与模糊规则系统结合，通过三层 Takagi-Sugeno-Kang 模糊层自适应调整约束参数，在遵守 FAA/EASA 航空法规的同时减少不必要的重计算。概念验证显示该方法在 MATLAB 中达到每迭代 2.3 秒的计算速度，具备近实时应用可行性，但发现 FALCON 与 IPOPT 最新版本存在严重软件兼容性问题，导致拉格朗日惩罚项恒为零，约束执行失效。


<details>
  <summary>Details</summary>
Motivation: 经典最优控制在处理不确定性时存在局限，而安全关键航空系统需要可解释的决策机制。因此，需要一种既能适应动态障碍环境，又能符合 FAA/EASA 监管分离最小值与适航指南的障碍规避方法，同时降低计算负担，实现选择性激活更新以保持合规性。

Method: 设计三层 Takagi-Sugeno-Kang 模糊推理系统，根据航空法规动态调制约束半径、紧急程度和激活决策。将模糊系统导出的 clearance 作为软约束集成到最优控制问题中，使用 FALCON 工具箱建模并调用 IPOPT 求解器进行数值求解，通过简化飞机模型实现概念验证。

Result: 仿真实验表明该框架能生成满足航空程序的最优轨迹，单次迭代计算时间为 2.3 秒（单线程 MATLAB），具备近实时应用潜力。但发现 FALCON 与 IPOPT 最新版本存在严重软件不兼容，拉格朗日惩罚项始终为零，导致约束 enforcement 完全失效，此问题为求解器工具箱回归而非建模缺陷。

Conclusion: 该混合架构在理论上能有效平衡法规合规性与计算效率，但软件兼容性是实际部署的主要障碍。未来工作包括：回退至早期稳定软件版本验证问题根源、采用进化算法优化模糊隶属函数、扩展至高保真飞机模型及随机障碍环境，以推进该方法的工程实用化。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [46] [An Industrial-Scale Sequential Recommender for LinkedIn Feed Ranking](https://arxiv.org/abs/2602.12354)
*Lars Hertel,Gaurav Srivastava,Syed Ali Naqvi,Satyam Kumar,Yue Zhang,Borja Ocejo,Benjamin Zelditch,Adrian Englhardt,Hailing Cheng,Andy Hu,Antonio Alonso,Daming Li,Siddharth Dangi,Chen Zhu,Mingzhou Zhou,Wanning Li,Tao Huang,Fedor Borisyuk,Ganesh Parameswaran,Birjodh Singh Tiwana,Sriram Sankar,Qing Lan,Julie Choi,Souvik Ghosh*

Main category: cs.IR

TL;DR: LinkedIn Feed推出基于Transformer的序列推荐模型Feed-SR，替代DCNv2排序器，在A/B测试中用户停留时间提升2.10%，并满足严格的生产约束条件。


<details>
  <summary>Details</summary>
Motivation: LinkedIn Feed需要满足严格的生产约束并提升会员参与度，现有DCNv2-based排名系统无法满足需求，因此开发新的序列推荐模型。

Method: 提出Feed Sequential Recommender (Feed-SR)，一种基于Transformer的序列排序模型，通过特定的建模选择、训练技术和推理优化实现LinkedIn规模级部署。

Result: Feed-SR已成为LinkedIn Feed的主要会员体验，在线A/B测试显示用户停留时间相比原生产模型显著提升+2.10%。

Conclusion: 对比其他序列模型和LLM-based架构，Feed-SR在在线指标与生产效率方面达到最佳平衡，是当前最合适的解决方案。

Abstract: LinkedIn Feed enables professionals worldwide to discover relevant content, build connections, and share knowledge at scale. We present Feed Sequential Recommender (Feed-SR), a transformer-based sequential ranking model for LinkedIn Feed that replaces a DCNv2-based ranker and meets strict production constraints. We detail the modeling choices, training techniques, and serving optimizations that enable deployment at LinkedIn scale. Feed-SR is currently the primary member experience on LinkedIn's Feed and shows significant improvements in member engagement (+2.10% time spent) in online A/B tests compared to the existing production model. We also describe our deployment experience with alternative sequential and LLM-based ranking architectures and why Feed-SR provided the best combination of online metrics and production efficiency.

</details>


### [47] [Visual RAG Toolkit: Scaling Multi-Vector Visual Retrieval with Training-Free Pooling and Multi-Stage Search](https://arxiv.org/abs/2602.12510)
*Ara Yeroyan*

Main category: cs.IR

TL;DR: 该论文提出Visual RAG Toolkit，一种无需训练的模型感知池化与多阶段检索系统，通过静态空间池化将每页数千个向量压缩至几十个，在保持NDCG和Recall@5/10性能的同时实现约4倍吞吐量提升，显著降低了视觉多向量检索的硬件门槛。


<details>
  <summary>Details</summary>
Motivation: 多向量视觉检索器（如ColPali）虽准确率高，但每页产生数千个向量导致索引和搜索成本高昂，扩展性差，亟需一种既能保持性能又能提升效率的轻量级解决方案。

Method: 受Matryoshka Embeddings启发，采用静态空间池化（含轻量级滑动窗口平均）对patch嵌入进行压缩，生成紧凑的tile级和全局表示用于快速候选生成，再使用完整多向量嵌入进行精确MaxSim重排序，实现训练免费、模型感知的两阶段检索。

Result: 在ViDoRe v2基准测试中，两阶段检索在k≤10时基本保持NDCG和Recall@5/10性能，仅在大k值时敏感；向量对比次数呈二次方减少，吞吐量提升约4倍QPS；并提供稳健的预处理和可复现评估流程。

Conclusion: 该工具包通过强调常见截断点（k≤10）的效率，无需额外训练即可显著降低硬件要求，使先进视觉检索技术更易落地应用，为工业级部署提供了实用且高效的工程方案。

Abstract: Multi-vector visual retrievers (e.g., ColPali-style late interaction models) deliver strong accuracy, but scale poorly because each page yields thousands of vectors, making indexing and search increasingly expensive. We present Visual RAG Toolkit, a practical system for scaling visual multi-vector retrieval with training-free, model-aware pooling and multi-stage retrieval. Motivated by Matryoshka Embeddings, our method performs static spatial pooling - including a lightweight sliding-window averaging variant - over patch embeddings to produce compact tile-level and global representations for fast candidate generation, followed by exact MaxSim reranking using full multi-vector embeddings.
  Our design yields a quadratic reduction in vector-to-vector comparisons by reducing stored vectors per page from thousands to dozens, notably without requiring post-training, adapters, or distillation. Across experiments with interaction-style models such as ColPali and ColSmol-500M, we observe that over the limited ViDoRe v2 benchmark corpus 2-stage retrieval typically preserves NDCG and Recall @ 5/10 with minimal degradation, while substantially improving throughput (approximately 4x QPS); with sensitivity mainly at very large k. The toolkit additionally provides robust preprocessing - high resolution PDF to image conversion, optional margin/empty-region cropping and token hygiene (indexing only visual tokens) - and a reproducible evaluation pipeline, enabling rapid exploration of two-, three-, and cascaded retrieval variants. By emphasizing efficiency at common cutoffs (e.g., k <= 10), the toolkit lowers hardware barriers and makes state-of-the-art visual retrieval more accessible in practice.

</details>


### [48] [DiffuRank: Effective Document Reranking with Diffusion Language Models](https://arxiv.org/abs/2602.12528)
*Qi Liu,Kun Ai,Jiaxin Mao,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Fengbin Zhu,Ji-Rong Wen*

Main category: cs.IR

TL;DR: 本文提出DiffuRank，一种基于扩散语言模型(dLLM)的文档重排序框架，旨在解决传统自回归LLM重排序器解码延迟高、左到右生成顺序导致错误传播等问题。通过三种策略（逐点、基于logits的逐列表和基于排列的逐列表）的系统探索，在多个基准测试上验证表明，dLLM性能可与同等规模自回归LLM相媲美甚至超越，为重排序任务提供了新的架构选择。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在文档重排序中展现出强大能力，但现有方法严重依赖自回归生成机制，存在两大核心限制：token-by-token解码导致高延迟；固定的从左到右生成顺序使早期预测错误持续传播且难以修正，限制了效率与灵活性。为此，研究者探索扩散语言模型(dLLM)在重排序中的应用潜力，以克服这些瓶颈。

Method: 提出三种基于dLLM的重排序策略：1）逐点方法，独立估计查询-文档对的相关性；2）基于logits的逐列表方法，提示dLLM联合评估多个文档并直接从logits推导排序；3）基于排列的逐列表方法，将dLLM标准解码过程适配到重排序任务。针对每种策略设计相应训练方法，充分利用dLLM并行解码和非自回归生成的优势。

Result: 在多个基准测试上的零样本与微调实验表明，扩散语言模型性能达到甚至超越了同等规模自回归LLM的水平。结果验证了dLLM在重排序任务中的有效性，其并行解码特性展现出更高的效率潜力和可控性优势。

Conclusion: 本研究证实扩散语言模型作为自回归架构替代方案在文档重排序中具有巨大潜力。DiffuRank框架成功克服了效率瓶颈与错误传播问题，性能表现优异，为重排序系统设计提供了新方向，推动了生成式语言模型在信息检索领域的多元化应用。

Abstract: Recent advances in large language models (LLMs) have inspired new paradigms for document reranking. While this paradigm better exploits the reasoning and contextual understanding capabilities of LLMs, most existing LLM-based rerankers rely on autoregressive generation, which limits their efficiency and flexibility. In particular, token-by-token decoding incurs high latency, while the fixed left-to-right generation order causes early prediction errors to propagate and is difficult to revise. To address these limitations, we explore the use of diffusion language models (dLLMs) for document reranking and propose DiffuRank, a reranking framework built upon dLLMs. Unlike autoregressive models, dLLMs support more flexible decoding and generation processes that are not constrained to a left-to-right order, and enable parallel decoding, which may lead to improved efficiency and controllability. Specifically, we investigate three reranking strategies based on dLLMs: (1) a pointwise approach that uses dLLMs to estimate the relevance of each query-document pair; (2) a logit-based listwise approach that prompts dLLMs to jointly assess the relevance of multiple documents and derives ranking lists directly from model logits; and (3) a permutation-based listwise approach that adapts the canonical decoding process of dLLMs to the reranking tasks. For each approach, we design corresponding training methods to fully exploit the advantages of dLLMs. We evaluate both zero-shot and fine-tuned reranking performance on multiple benchmarks. Experimental results show that dLLMs achieve performance comparable to, and in some cases exceeding, that of autoregressive LLMs with similar model sizes. These findings demonstrate the promise of diffusion-based language models as a compelling alternative to autoregressive architectures for document reranking.

</details>


### [49] [Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation](https://arxiv.org/abs/2602.12530)
*Kehan Zheng,Deyao Hong,Qian Li,Jun Zhang,Huan Yu,Jie Jiang,Hongning Wang*

Main category: cs.IR

TL;DR: 本文提出"推理排序"框架，通过强化学习实现端到端训练，将推荐效用优化内化到LLM的逐步推理学习中，在避免位置偏差的同时提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 推荐系统需要深度推理用户偏好，现有LLM推荐方法缺乏对推荐效用的有效优化，模式匹配式评分不足以捕捉用户动态意图。

Method: 提出Reasoning to Rank端到端训练框架：在用户-物品级别进行推理，通过强化学习直接优化推理过程，将推荐效用目标内化到LLM的逐步推理学习中，避免位置偏差。

Result: 在三个Amazon数据集和工业级数据集上均取得显著提升，超越传统方法和现有LLM推荐方案，验证了框架有效性。

Conclusion: 该框架成功将推荐优化融入推理学习，关键组件不可或缺，为LLM推荐系统的未来发展提供了重要方向。

Abstract: Recommender systems are tasked to infer users' evolving preferences and rank items aligned with their intents, which calls for in-depth reasoning beyond pattern-based scoring. Recent efforts start to leverage large language models (LLMs) for recommendation, but how to effectively optimize the model for improved recommendation utility is still under explored. In this work, we propose Reasoning to Rank, an end-to-end training framework that internalizes recommendation utility optimization into the learning of step-by-step reasoning in LLMs. To avoid position bias in LLM reasoning and enable direct optimization of the reasoning process, our framework performs reasoning at the user-item level and employs reinforcement learning for end-to-end training of the LLM. Experiments on three Amazon datasets and a large-scale industrial dataset showed consistent gains over strong conventional and LLM-based solutions. Extensive in-depth analyses validate the necessity of the key components in the proposed framework and shed lights on the future developments of this line of work.

</details>


### [50] [CAPTS: Channel-Aware, Preference-Aligned Trigger Selection for Multi-Channel Item-to-Item Retrieval](https://arxiv.org/abs/2602.12564)
*Xiaoyou Zhou,Yuqi Liu,Zhao Liu,Xiao Lv,Bo Chen,Ruiming Tang,Guorui Zhou*

Main category: cs.IR

TL;DR: 针对工业级推荐系统多通道检索中价值归因偏差与路由不协调问题，本文提出CAPTS框架。该框架通过价值归因模块(VAM)提供展望未来监督，并通过通道自适应触发器路由模块(CATR)协调分配，在Kwai平台验证可提升召回率并带来+0.351%的用户使用时长增益。


<details>
  <summary>Details</summary>
Motivation: 工业级推荐系统中多通道检索存在两个核心问题：(1) 价值归因偏差——现有方法根据触发器直接反馈而非其作为检索种子的下游效用来评估触发器价值；(2) 多通道路由不协调——各通道独立选择触发器，在共享配额下导致跨通道重叠，降低了整体效率。

Method: 提出CAPTS框架，将多通道触发器选择建模为可学习的路由问题。包含两个模块：价值归因模块(VAM)通过展望未来监督，将每个触发器在每个I2I通道上检索项目所产生的后续参与度归功于该触发器；通道自适应触发器路由模块(CATR)协调触发器到通道的分配以最大化多通道检索的整体价值。

Result: 在Kwai平台的广泛离线实验和大规模在线A/B测试表明，CAPTS持续改进了多通道召回率，在线上实现了平均每设备使用时长+0.351%的提升。

Conclusion: CAPTS是一个统一且灵活的框架，通过解耦价值归因与路由决策，有效解决了工业推荐系统中多通道检索的固有挑战，为提升推荐系统整体效率提供了新的解决方案。

Abstract: Large-scale industrial recommender systems commonly adopt multi-channel retrieval for candidate generation, combining direct user-to-item (U2I) retrieval with two-hop user-to-item-to-item (U2I2I) pipelines. In U2I2I, the system selects a small set of historical interactions as triggers to seed downstream item-to-item (I2I) retrieval across multiple channels. In production, triggers are often selected using rule-based policies or learned scorers and tuned in a channel-by-channel manner. However, these practices face two persistent challenges: biased value attribution that values triggers by on-trigger feedback rather than their downstream utility as retrieval seeds, and uncoordinated multi-channel routing where channels select triggers independently under a shared quota, increasing cross-channel overlap. To address these challenges, we propose Channel-Aware, Preference-Aligned Trigger Selection (CAPTS), a unified and flexible framework that treats multi-channel trigger selection as a learnable routing problem. CAPTS introduces a Value Attribution Module (VAM) that provides look-ahead supervision by crediting each trigger with the subsequent engagement generated by items retrieved from it on each I2I channel, and a Channel-Adaptive Trigger Routing (CATR) module that coordinates trigger-to-channel assignment to maximize the overall value of multi-channel retrieval. Extensive offline experiments and large-scale online A/B tests on Kwai, Kuaishou's international short-video platform, show that CAPTS consistently improves multi-channel recall offline and delivers a +0.351% lift in average time spent per device online.

</details>


### [51] [RQ-GMM: Residual Quantized Gaussian Mixture Model for Multimodal Semantic Discretization in CTR Prediction](https://arxiv.org/abs/2602.12593)
*Ziye Tong,Jiahao Liu,Weimin Zhang,Hongji Ruan,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: RQ-GMM通过概率建模和高斯混合模型结合残量量化，改进多模态嵌入的离散化，提升CTR预测效果，已在亿级用户平台部署，带来1.502%的广告主价值提升。


<details>
  <summary>Details</summary>
Motivation: 多模态内容对点击率预测至关重要，但直接引入预训练模型的连续嵌入因优化目标不一致和收敛速度不匹配导致效果不佳。离散化虽有效，但现有方法存在码本利用率低、重构精度差和语义区分度不足的问题。

Method: 提出RQ-GMM（残量量化高斯混合模型），引入概率建模更好地捕捉多模态嵌入空间的统计结构，结合高斯混合模型与残量量化技术。

Result: 实现了更优的码本利用率和重构精度，在公开数据集和亿级用户短视频平台的在线A/B测试中，相比强基线提升广告主价值1.502%，并已全面部署服务每日推荐。

Conclusion: RQ-GMM有效解决了多模态离散化的核心挑战，显著提升CTR预测性能，具备大规模工业应用价值。

Abstract: Multimodal content is crucial for click-through rate (CTR) prediction. However, directly incorporating continuous embeddings from pre-trained models into CTR models yields suboptimal results due to misaligned optimization objectives and convergence speed inconsistency during joint training. Discretizing embeddings into semantic IDs before feeding them into CTR models offers a more effective solution, yet existing methods suffer from limited codebook utilization, reconstruction accuracy, and semantic discriminability. We propose RQ-GMM (Residual Quantized Gaussian Mixture Model), which introduces probabilistic modeling to better capture the statistical structure of multimodal embedding spaces. Through Gaussian Mixture Models combined with residual quantization, RQ-GMM achieves superior codebook utilization and reconstruction accuracy. Experiments on public datasets and online A/B tests on a large-scale short-video platform serving hundreds of millions of users demonstrate substantial improvements: RQ-GMM yields a 1.502% gain in Advertiser Value over strong baselines. The method has been fully deployed, serving daily recommendations for hundreds of millions of users.

</details>


### [52] [Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback](https://arxiv.org/abs/2602.12612)
*Sein Kim,Sangwu Park,Hongseok Kang,Wonjoong Kim,Jimin Seo,Yeonjun In,Kanghoon Yoon,Chanyoung Park*

Main category: cs.IR

TL;DR: 本文提出Self-EvolveRec框架，通过集成用户模拟器（定性批评）和模型诊断工具（定量验证）建立方向性反馈循环，并引入诊断工具-模型协同进化策略，使评估标准随推荐架构演化而动态调整。实验表明该框架在推荐性能和用户满意度上显著优于现有神经架构搜索和LLM驱动的代码演化基线。


<details>
  <summary>Details</summary>
Motivation: 传统神经架构搜索（NAS）受限于人工先验定义的固定搜索空间，仅能在预定义操作符内创新。近期LLM驱动的代码演化框架虽转向开放程序空间，但过度依赖NDCG、命中率等标量指标，无法提供模型失败的定性洞察和改进的方向性指导，亟需能够动态适应评估标准并提供定性反馈的解决方案。

Method: 提出Self-EvolveRec框架：1）建立方向性反馈循环，整合用户模拟器生成定性批评和模型诊断工具进行定量内部验证；2）引入诊断工具-模型协同进化策略，确保评估标准随推荐架构演化而动态适应。

Result: 大量实验验证，Self-EvolveRec在推荐性能和用户满意度方面均显著超越当前最先进的NAS和LLM驱动的代码演化基线方法。

Conclusion: Self-EvolveRec通过创新的定性-定量反馈机制和协同进化策略，有效解决了自动化推荐系统设计中评估标准僵化和缺乏方向性指导的问题，为构建更优推荐系统提供了新范式。代码已开源。

Abstract: Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec.

</details>


### [53] [Training Dense Retrievers with Multiple Positive Passages](https://arxiv.org/abs/2602.12727)
*Benben Wang,Minghao Tang,Hengran Zhang,Jiafeng Guo,Keping Bi*

Main category: cs.IR

TL;DR: 本文系统研究了检索器训练中的多正样本优化目标问题。通过将联合似然、求和边缘似然和Log-Sum-Exp成对损失统一到对比学习框架下，从理论和实证两方面分析了不同目标的梯度行为与概率分配机制。在Natural Questions、MS MARCO和BEIR基准上的实验表明，LSEPair损失具有最强的鲁棒性，而联合似然和求和边缘似然对正样本质量高度敏感，简单的随机采样基线同样表现可靠，为利用大语言模型生成的稠密监督信号提供了实践指导原则。


<details>
  <summary>Details</summary>
Motivation: 现代知识密集型系统（如检索增强生成RAG）的性能上限取决于检索器的效果，但传统检索器训练受限于稀疏的单正样本标注，导致假阴性噪声和次优监督。尽管大语言模型(LLM)使得大规模收集全面的多正样本相关性标签成为可能，但如何将这些稠密信号最优地融入训练仍缺乏系统理解，亟需对不同优化目标进行比较研究。

Method: 作者对多正样本优化目标进行了系统性研究，将联合似然(JointLH)、求和边缘似然(SumMargLH)和Log-Sum-Exp成对损失(LSEPair)统一到共享的对比学习框架下。通过理论分析揭示了各目标在梯度行为和正样本集上的概率质量分配差异，并在Natural Questions、MS MARCO和BEIR基准上，针对LLM同质标注数据和人工/LLM异构混合标签两种真实场景进行了广泛实证评估。

Result: 实验结果表明：1) LSEPair损失在所有设定下均表现出持续优越的鲁棒性和性能；2) JointLH和SumMargLH对正样本质量高度敏感，性能波动较大；3) 简单的随机采样策略(Rand1LH)可作为可靠的基线方法；4) 不同目标确实存在显著的概率质量分配机制差异。这些发现为检索器训练提供了可复现的实证依据。

Conclusion: 本研究通过理论分析与实证验证相结合的方式，为利用稠密LLM增强监督提升检索器效果提供了实用的设计原则：推荐采用LSEPair损失以获得鲁棒性能，同时需注意简单基线的有效性。研究揭示了多正样本优化目标的核心机制，为知识密集型系统中的检索器训练奠定了更坚实的理论基础，并指导未来在异构标注数据环境下的实践应用。

Abstract: Modern knowledge-intensive systems, such as retrieval-augmented generation (RAG), rely on effective retrievers to establish the performance ceiling for downstream modules. However, retriever training has been bottlenecked by sparse, single-positive annotations, which lead to false-negative noise and suboptimal supervision. While the advent of large language models (LLMs) makes it feasible to collect comprehensive multi-positive relevance labels at scale, the optimal strategy for incorporating these dense signals into training remains poorly understood. In this paper, we present a systematic study of multi-positive optimization objectives for retriever training. We unify representative objectives, including Joint Likelihood (JointLH), Summed Marginal Likelihood (SumMargLH), and Log-Sum-Exp Pairwise (LSEPair) loss, under a shared contrastive learning framework. Our theoretical analysis characterizes their distinct gradient behaviors, revealing how each allocates probability mass across positive document sets. Empirically, we conduct extensive evaluations on Natural Questions, MS MARCO, and the BEIR benchmark across two realistic regimes: homogeneous LLM-annotated data and heterogeneous mixtures of human and LLM labels. Our results show that LSEPair consistently achieves superior robustness and performance across settings, while JointLH and SumMargLH exhibit high sensitivity to the quality of positives. Furthermore, we find that the simple strategy of random sampling (Rand1LH) serves as a reliable baseline. By aligning theoretical insights with empirical findings, we provide practical design principles for leveraging dense, LLM-augmented supervision to enhance retriever effectiveness.

</details>


### [54] [SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise](https://arxiv.org/abs/2602.12783)
*Yuejie Li,Ke Yang,Yueying Hua,Berlin Chen,Jianhao Nie,Yueping He,Caixin Kang*

Main category: cs.IR

TL;DR: SQuTR是一个用于语音查询检索鲁棒性评估的基准测试，包含大规模数据集和统一评估协议。该基准从6个常用文本检索数据集聚合了37,317个唯一查询，使用200位真实说话人的语音特征合成语音，并混合了17类真实环境噪声。实验表明，噪声增加会导致检索性能下降，即使在极端噪声下大规模模型也表现不佳，鲁棒性仍是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有语音查询检索评估数据集通常局限于简单查询和受限的噪声条件，无法充分评估系统在复杂声学扰动下的鲁棒性，这限制了相关技术的发展。

Method: 构建SQuTR基准，包含大规模数据集和统一评估协议。数据集从6个英文和中文文本检索数据集中聚合37,317个唯一查询，覆盖多领域和多样化查询类型。使用200位真实说话人的语音特征合成语音，并在可控信噪比下混合17类真实环境噪声，实现从安静到高噪声条件的可重复鲁棒性评估。

Result: 对级联式和端到端检索系统的大规模评估显示，检索性能随噪声增加而下降，不同系统的性能下降程度差异显著。即使在极端噪声条件下，大规模检索模型仍表现不佳，表明鲁棒性是亟待解决的关键瓶颈。

Conclusion: SQuTR为语音查询检索的基准测试和诊断分析提供了可重复的测试平台，促进了该领域未来研究的发展。

Abstract: Spoken query retrieval is an important interaction mode in modern information retrieval. However, existing evaluation datasets are often limited to simple queries under constrained noise conditions, making them inadequate for assessing the robustness of spoken query retrieval systems under complex acoustic perturbations. To address this limitation, we present SQuTR, a robustness benchmark for spoken query retrieval that includes a large-scale dataset and a unified evaluation protocol. SQuTR aggregates 37,317 unique queries from six commonly used English and Chinese text retrieval datasets, spanning multiple domains and diverse query types. We synthesize speech using voice profiles from 200 real speakers and mix 17 categories of real-world environmental noise under controlled SNR levels, enabling reproducible robustness evaluation from quiet to highly noisy conditions. Under the unified protocol, we conduct large-scale evaluations on representative cascaded and end-to-end retrieval systems. Experimental results show that retrieval performance decreases as noise increases, with substantially different drops across systems. Even large-scale retrieval models struggle under extreme noise, indicating that robustness remains a critical bottleneck. Overall, SQuTR provides a reproducible testbed for benchmarking and diagnostic analysis, and facilitates future research on robustness in spoken query to text retrieval.

</details>


### [55] [WISE: A Multimodal Search Engine for Visual Scenes, Audio, Objects, Faces, Speech, and Metadata](https://arxiv.org/abs/2602.12819)
*Prasanna Sridhar,Horace Lee,David M. S. Pinto,Andrew Zisserman,Abhishek Dutta*

Main category: cs.IR

TL;DR: 本文提出 WISE，一个开源视听搜索引擎，集成多模态检索能力于统一工具，支持自然语言/反向图像查询、人脸识别、音频检索、语音转录搜索及元数据过滤。采用向量搜索技术可扩展至数百万图像/数千小时视频，模块化架构便于集成新模型，支持本地部署，面向无机器学习背景用户。


<details>
  <summary>Details</summary>
Motivation: 现有视听检索工具需机器学习专业知识且功能孤立，无法灵活处理跨模态组合查询。领域专家（如档案管理员、研究人员）需要易用、可扩展的开源解决方案，以支持大规模私有敏感数据的多模态检索需求。

Method: 开发统一框架 WISE，融合多种检索模型（场景/对象识别、人脸识别、音频事件检测、语音识别）于单一接口；利用向量搜索技术实现高效近似最近邻检索；采用模块化设计解耦各功能组件；支持本地部署保障数据安全。

Result: 系统支持百万级图像和千小时级视频检索；实现文本、图像、音频、人脸、元数据五类查询及其任意组合；在历史档案（如德国火车检索）等真实场景中验证有效性；提供开源代码。

Conclusion: WISE 成功构建了低门槛、高扩展性的开源视听检索引擎，实现了多媒体检索技术的民主化，为非专家用户提供了处理复杂多模态查询的实用工具，特别适用于敏感数据环境。

Abstract: In this paper, we present WISE, an open-source audiovisual search engine which integrates a range of multimodal retrieval capabilities into a single, practical tool accessible to users without machine learning expertise. WISE supports natural-language and reverse-image queries at both the scene level (e.g. empty street) and object level (e.g. horse) across images and videos; face-based search for specific individuals; audio retrieval of acoustic events using text (e.g. wood creak) or an audio file; search over automatically transcribed speech; and filtering by user-provided metadata. Rich insights can be obtained by combining queries across modalities -- for example, retrieving German trains from a historical archive by applying the object query "train" and the metadata query "Germany", or searching for a face in a place. By employing vector search techniques, WISE can scale to support efficient retrieval over millions of images or thousands of hours of video. Its modular architecture facilitates the integration of new models. WISE can be deployed locally for private or sensitive collections, and has been applied to various real-world use cases. Our code is open-source and available at https://gitlab.com/vgg/wise/wise.

</details>


### [56] [JARVIS: An Evidence-Grounded Retrieval System for Interpretable Deceptive Reviews Adjudication](https://arxiv.org/abs/2602.12941)
*Nan Lu,Leyang Li,Yurong Hu,Rui Lin,Shaoyi Xu*

Main category: cs.IR

TL;DR: 针对电商虚假评论检测中存在泛化性不足和可解释性差的问题，本文提出JARVIS框架，通过混合稠密-稀疏多模态检索获取相似证据，构建异构证据图，并利用大语言模型进行基于证据的判决，实现了高精度和可解释的风险评估。离线实验和线上部署均显示显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现代电商生态系统中，虚假评论治理是严峻挑战。现有评论级和基于图的检测方法存在两个关键局限：泛化能力不足、缺乏可解释性，导致模型在实际应用中效果受限且难以获得信任。

Method: JARVIS框架采用"增强检索+证据图"的双路径架构：从待检测评论出发，通过混合稠密-稀疏多模态检索获取语义相似的证据，利用共享实体扩展关系信号并构建异构证据图，最后通过大语言模型进行基于证据的可解释风险判决。

Result: 离线实验表明，JARVIS在自建数据集上将精确率从0.953提升至0.988，召回率从0.830提升至0.901。生产环境中，召回量增加27%，人工审核时间降低75%，模型分析采纳率高达96.4%。

Conclusion: JARVIS通过检索增强和证据图结构有效解决了虚假评论检测的泛化性和可解释性问题，显著提升了检测性能与运营效率，在实际应用中获得了高度认可，为电商平台治理提供了有效的技术解决方案。

Abstract: Deceptive reviews, refer to fabricated feedback designed to artificially manipulate the perceived quality of products. Within modern e-commerce ecosystems, these reviews remain a critical governance challenge. Despite advances in review-level and graph-based detection methods, two pivotal limitations remain: inadequate generalization and lack of interpretability. To address these challenges, we propose JARVIS, a framework providing Judgment via Augmented Retrieval and eVIdence graph Structures. Starting from the review to be evaluated, it retrieves semantically similar evidence via hybrid dense-sparse multimodal retrieval, expands relational signals through shared entities, and constructs a heterogeneous evidence graph. Large language model then performs evidence-grounded adjudication to produce interpretable risk assessments. Offline experiments demonstrate that JARVIS enhances performance on our constructed review dataset, achieving a precision increase from 0.953 to 0.988 and a recall boost from 0.830 to 0.901. In the production environment, our framework achieves a 27% increase in the recall volume and reduces manual inspection time by 75%. Furthermore, the adoption rate of the model-generated analysis reaches 96.4%.

</details>


### [57] [RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems](https://arxiv.org/abs/2602.12968)
*Junhua Liu,Yang Jihao,Cheng Chang,Kunrong LI,Bin Fu,Kwan Hui Lim*

Main category: cs.IR

TL;DR: 本文针对电商聊天机器人中的主动意图预测问题，提出RGAlign-Rec框架，通过融合LLM语义推理器与查询增强排序模型，并引入排序引导对齐(RGA)多阶段训练范式，解决了用户特征与语义意图间的语义鸿沟以及LLM输出与排序目标不一致的问题。在Shopee工业级数据集上验证了该方法在GAUC、召回率和在线CTR方面的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有工业系统在主动意图预测中面临两个根本挑战：一是离散用户特征与聊天机器人知识库中语义意图之间存在语义鸿沟；二是通用大语言模型的输出与特定任务排序效用之间存在目标错位，导致零查询推荐效果受限。

Method: 提出RGAlign-Rec闭环比对齐框架，集成基于LLM的语义推理器与查询增强(QE)排序模型；引入排序引导对齐(RGA)多阶段训练范式，利用下游排序信号作为反馈来细化LLM的潜在推理过程，实现语义推理与排序目标的同步。

Result: 在Shopee大规模工业数据集上，RGAlign-Rec实现GAUC提升0.12%、相对错误率降低3.52%、Recall@3提升0.56%。在线A/B测试显示，QE-Rec阶段带来0.98%的CTR提升，RGA阶段进一步增加0.13%的CTR增益。

Conclusion: 排序感知的对齐策略有效同步了语义推理与排序目标，显著提升了预测准确性和服务质量，验证了闭环框架在真实世界主动推荐系统中的累积有效性。

Abstract: Proactive intent prediction is a critical capability in modern e-commerce chatbots, enabling "zero-query" recommendations by anticipating user needs from behavioral and contextual signals. However, existing industrial systems face two fundamental challenges: (1) the semantic gap between discrete user features and the semantic intents within the chatbot's Knowledge Base, and (2) the objective misalignment between general-purpose LLM outputs and task-specific ranking utilities. To address these issues, we propose RGAlign-Rec, a closed-loop alignment framework that integrates an LLM-based semantic reasoner with a Query-Enhanced (QE) ranking model. We also introduce Ranking-Guided Alignment (RGA), a multi-stage training paradigm that utilizes downstream ranking signals as feedback to refine the LLM's latent reasoning. Extensive experiments on a large-scale industrial dataset from Shopee demonstrate that RGAlign-Rec achieves a 0.12% gain in GAUC, leading to a significant 3.52% relative reduction in error rate, and a 0.56% improvement in Recall@3. Online A/B testing further validates the cumulative effectiveness of our framework: the Query-Enhanced model (QE-Rec) initially yields a 0.98% improvement in CTR, while the subsequent Ranking-Guided Alignment stage contributes an additional 0.13% gain. These results indicate that ranking-aware alignment effectively synchronizes semantic reasoning with ranking objectives, significantly enhancing both prediction accuracy and service quality in real-world proactive recommendation systems.

</details>


### [58] [Asynchronous Verified Semantic Caching for Tiered LLM Architectures](https://arxiv.org/abs/2602.13165)
*Asmit Kumar Singh,Haozhe Wang,Laxmi Naga Santosh Attaluri,Tak Chiam,Weihua Zhu*

Main category: cs.IR

TL;DR: Krites是一种异步的、由LLM判定的缓存策略，用于在不改变服务决策的前提下扩展静态缓存覆盖范围。当查询与静态缓存的最近邻相似度略低于阈值时，它会异步调用LLM判断器验证响应可接受性，验证通过后提升至动态缓存。在对话和搜索工作负载上，该方案将使用静态答案的请求比例提升最高3.9倍，且不增加关键路径延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已深度融入搜索、辅助和智能体工作流，语义缓存对降低推理成本与延迟至关重要。生产环境采用静态-动态分层缓存，但两层共享单一嵌入相似度阈值，导致固有权衡：保守阈值错失安全重用机会，激进阈值则可能返回语义错误响应，亟需更精细的缓存决策机制。

Method: Krites采用异步LLM验证机制：在关键路径上保持标准静态阈值策略；当查询的最近静态邻居相似度略低于阈值时，异步触发LLM判断器验证静态响应对新查询的可接受性；验证通过的匹配项被提升至动态缓存，供未来重复查询和改写查询重用，从而渐进式扩展静态缓存的有效覆盖范围。

Result: 基于真实追踪的对话与搜索工作负载模拟表明，相较于调优后的基线策略，Krites将使用精选静态答案的请求比例（直接静态命中+验证提升）提升了最高达3.9倍，同时完全保持关键路径延迟不变。

Conclusion: Krites通过异步LLM验证机制，在不影响关键路径性能的前提下，有效解决了单一阈值策略的硬权衡问题，显著扩展了静态缓存覆盖范围，为生产环境中LLM缓存管理提供了可扩展的解决方案。

Abstract: Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [59] [Abstractive Red-Teaming of Language Model Character](https://arxiv.org/abs/2602.12318)
*Nate Rahn,Allison Qi,Avery Griffin,Jonathan Michala,Henry Sleight,Erik Jones*

Main category: cs.LG

TL;DR: 本文提出抽象红队测试方法，通过搜索能诱发语言模型违反角色规范的自然语言查询类别，实现部署前高效风险识别。基于角色特质奖励模型，提出强化学习驱动的类别生成与高分查询迭代合成两种算法。在12项原则规范和7个模型上的实验显示，该方法持续优于基线，发现了如未来预测导致AI统治人类、监狱生存建议推荐非法武器等典型违规类别，为预部署审计提供了关键进展。


<details>
  <summary>Details</summary>
Motivation: 语言模型需遵循预设角色规范，但大规模部署时偶有违规现象。传统部署后监测计算成本高昂，且难以覆盖所有潜在风险。本研究旨在以远低于部署级别的计算开销，主动识别易引发角色违规的查询类别，实现预部署阶段的风险前瞻性审计，提升模型部署安全性。

Method: 引入抽象红队测试框架，通过自然语言描述的类别（如"查询为中文且涉及家庭角色"）概括多样化查询变体。设计两种高效搜索算法：1）强化学习算法，训练类别生成LLM直接输出高风险类别；2）迭代合成算法，利用强LLM从奖励模型筛选的高分查询中提炼类别。两种方法均通过角色特质特定奖励模型评估查询违规程度。

Result: 实验涵盖12项角色原则和7个主流模型，结果表明所提算法在违规类别发现效率上显著优于基线。生成的类别揭示系统性风险：例如Llama-3.1-8B-Instruct在预测未来场景中声称AI将统治人类；GPT-4.1-Mini在监狱生存咨询中积极推荐非法武器。这些发现证明了抽象类别对隐蔽违规模式的捕捉能力。

Conclusion: 抽象红队测试为语言模型角色审计提供了可扩展的预部署解决方案，通过高效识别高风险查询类别，显著降低实际部署风险。该方法在计算效率和发现质量间取得平衡，是构建更安全AI助手的重要技术路径，推动了角色规范遵守的可验证性研究。

Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally violate them in large-scale deployments. In this work, we aim to identify types of queries that are likely to produce such character violations at deployment, using much less than deployment-level compute. To do this, we introduce abstractive red-teaming, where we search for natural-language query categories, e.g. "The query is in Chinese. The query asks about family roles," that routinely elicit violations. These categories abstract over the many possible variants of a query which could appear in the wild. We introduce two algorithms for efficient category search against a character-trait-specific reward model: one based on reinforcement learning on a category generator LLM, and another which leverages a strong LLM to iteratively synthesize categories from high-scoring queries. Across a 12-principle character specification and 7 target models, we find that our algorithms consistently outperform baselines, and generate qualitatively interesting categories; for example, queries which ask Llama-3.1-8B-Instruct to predict the future lead to responses saying that AI will dominate humanity, and queries that ask GPT-4.1-Mini for essential prison survival items lead to enthusiastic recommendation of illegal weapons. Overall, we believe our results represent an important step towards realistic pre-deployment auditing of language model character.

</details>


### [60] [The Appeal and Reality of Recycling LoRAs with Adaptive Merging](https://arxiv.org/abs/2602.12323)
*Haokun Liu,Gyung Hyun Je,Marco Ciccone,Zhenlin Xu,Prasanth YSS,Colin Raffel*

Main category: cs.LG

TL;DR: 本文通过实证研究近1000个来自Hugging Face Hub的用户贡献LoRA模块，发现自适应合并方法相比基础模型能提升性能，但相比在相同数据上训练新LoRA优势有限；关键在于合并哪些LoRA并不重要，甚至使用随机初始化的LoRA也能获得相似效果，这表明自适应合并主要通过正则化效应而非正向跨任务迁移起作用。


<details>
  <summary>Details</summary>
Motivation: 尽管自适应LoRA合并方法已在某些场景下展现改进效果，但现有研究均未尝试从Hugging Face Hub等模型仓库中"回收"公开的LoRA模块进行合并，存在一个重要的研究空白。

Method: 研究基于从Llama 3.1 8B-Instruct模型微调产生的近1000个用户贡献LoRA池，系统评估了多种自适应和非自适应合并方法，并包含通过广泛设计空间搜索得到的新方法。

Result: 自适应合并方法相比基础模型确有提升，但在设置合并系数的相同数据上训练新LoRA可取得更好效果；更重要的是，具体选择哪些LoRA合并影响甚微，随机初始化的LoRA参数亦能达到相近性能，仅在存在高度相关LoRA时才会出现正向迁移。

Conclusion: 实验结果表明自适应LoRA合并可能主要依赖正则化效应而非正向跨任务迁移；尽管针对特定任务训练新LoRA仍是更优选择，但合并高度相关的LoRA模块确实可实现正向迁移。

Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting LoRAs from a pool and tune merging coefficients based on a task-specific dataset. While adaptive merging methods have demonstrated improvements in some settings, no past work has attempted to recycle LoRAs found "in the wild" on model repositories like the Hugging Face Hub. To address this gap, we consider recycling from a pool of nearly 1,000 user-contributed LoRAs trained from the Llama 3.1 8B-Instruct language model. Our empirical study includes a range of adaptive and non-adaptive merging methods in addition to a new method designed via a wide search over the methodological design space. We demonstrate that adaptive merging methods can improve performance over the base model but provide limited benefit over training a new LoRA on the same data used to set merging coefficients. We additionally find not only that the specific choice of LoRAs to merge has little importance, but that using LoRAs with randomly initialized parameter values yields similar performance. This raises the possibility that adaptive merging from recycled LoRAs primarily works via some kind of regularization effect, rather than by enabling positive cross-task transfer. To better understand why past work has proven successful, we confirm that positive transfer is indeed possible when there are highly relevant LoRAs in the pool. We release the model checkpoints and code online.

</details>


### [61] [Intrinsic Credit Assignment for Long Horizon Interaction](https://arxiv.org/abs/2602.12342)
*Ilze Amanda Auzina,Joschka Strüber,Sergio Hernández-Gutiérrez,Shashwat Goel,Ameya Prabhu,Matthias Bethge*

Main category: cs.LG

TL;DR: 本文提出ΔBelief-RL，一种利用语言模型内在信念变化奖励中间进展的强化学习方法。通过计算智能体对目标方案概率赋值的变化（ΔBelief）实现信用分配，在合成数据上训练信息寻求能力，在长期不确定性任务上持续优于纯结果奖励，并在客户服务和个性化等分布外应用中展现良好泛化性，且测试时交互增加仍能持续提升性能。


<details>
  <summary>Details</summary>
Motivation: 训练智能体在长期时间跨度中有效应对不确定性是强化学习的核心挑战。传统稀疏结果奖励导致长期信用分配困难，样本效率低下，尤其在目标遥远或反馈延迟的场景下难以激励智能体进行有效的信息探索。

Method: ΔBelief-RL利用语言模型自身对目标解决方案概率信念的内在变化作为中间奖励信号。核心机制是计算智能体在交互过程中对目标方案概率赋值的前后差异（ΔBelief），通过该差异进行信用分配，从而在合成交互数据上训练具备主动信息寻求能力的策略。

Result: 实验表明：1）在多种长期不确定性任务上持续优于纯结果奖励基线；2）在客户服务和个性化等分布外场景中具有良好泛化能力；3）测试时交互规模超越训练horizon仍能带来性能提升；4）在Pass@k指标上交互效率显著提高，显示其具备持续改进的扩展性。

Conclusion: 该工作提出了一种可扩展的长期不确定性导航训练框架，通过内在ΔBelief奖励机制实现了对中间动作的有效信用分配，突破了传统结果奖励的局限性，为构建更高效的长时程决策智能体提供了新范式，展现了在真实世界复杂场景中的应用潜力。

Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose ΔBelief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the change in the probability an agent assigns to the target solution for credit assignment. By training on synthetic interaction data, ΔBelief-RL teaches information-seeking capabilities that consistently outperform purely outcome-based rewards for Reinforcement Learning, with improvements generalizing to out-of-distribution applications ranging from customer service to personalization. Notably, the performance continues to improve as we scale test-time interactions beyond the training horizon, with interaction-efficiency increasing even on Pass@k metrics. Overall, our work introduces a scalable training strategy for navigating uncertainty over a long-horizon, by enabling credit assignment to intermediate actions via intrinsic ΔBelief rewards.

</details>


### [62] [Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis](https://arxiv.org/abs/2602.12373)
*Yijun Ma,Zehong Wang,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Nitesh Chawla,Yanfang Ye*

Main category: cs.LG

TL;DR: 本文提出Policy4OOD，一个知识引导的时空世界模型，用于评估阿片类药物政策。该模型通过统一政策知识图谱、州级空间依赖和社会经济时间序列，实现政策条件下的阿片类药物结果预测、反事实分析和政策优化，为美国阿片类药物危机提供数据驱动的决策支持。


<details>
  <summary>Details</summary>
Motivation: 美国阿片类药物危机是最严重的公共卫生危机之一。由于多个政策在动态系统中相互作用，实施前评估政策干预效果十分困难。有效评估需要三种能力：预测现行政策下的未来结果、对替代性过去决策进行反事实推理，以及对候选干预措施进行优化。

Method: 提出Policy4OOD世界模型，采用政策条件Transformer架构，联合编码政策知识图谱、州级空间依赖和社会经济时间序列。训练后作为模拟器：预测只需前向传播，反事实分析通过替换历史政策编码实现，政策优化采用蒙特卡洛树搜索。构建2019-2024年月度州级数据集整合死亡率、社会经济指标和结构化政策编码。

Result: 实验表明空间依赖和结构化政策知识显著提升预测准确性，验证了每个架构组件的有效性。世界模型在阿片类药物政策评估中展现出潜力。

Conclusion: 世界建模方法为数据驱动的公共卫生决策支持提供了有效框架，Policy4OOD能够整合多源数据，在复杂政策交互环境中实现准确预测、反事实分析和优化，具有实际应用价值。

Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where targeting one risk pathway may inadvertently amplify another. We argue that effective opioid policy evaluation requires three capabilities -- forecasting future outcomes under current policies, counterfactual reasoning about alternative past decisions, and optimization over candidate interventions -- and propose to unify them through world modeling. We introduce Policy4OOD, a knowledge-guided spatio-temporal world model that addresses three core challenges: what policies prescribe, where effects manifest, and when effects unfold.Policy4OOD jointly encodes policy knowledge graphs, state-level spatial dependencies, and socioeconomic time series into a policy-conditioned Transformer that forecasts future opioid outcomes.Once trained, the world model serves as a simulator: forecasting requires only a forward pass, counterfactual analysis substitutes alternative policy encodings in the historical sequence, and policy optimization employs Monte Carlo Tree Search over the learned simulator. To support this framework, we construct a state-level monthly dataset (2019--2024) integrating opioid mortality, socioeconomic indicators, and structured policy encodings. Experiments demonstrate that spatial dependencies and structured policy knowledge significantly improve forecasting accuracy, validating each architectural component and the potential of world modeling for data-driven public health decision support.

</details>


### [63] [Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning](https://arxiv.org/abs/2602.12375)
*Abdul Wahab,Raksha Kumaraswamy,Martha White*

Main category: cs.LG

TL;DR: 本文提出VBE算法，通过集成随机价值函数并利用其估计误差设计价值奖励，实现首次访问乐观探索，在经典环境和Atari游戏中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于乐观价值估计的有向探索方法存在局限：价值奖励仅能在观察到更高奖励后追溯性增加，无法激励智能体首次访问新的状态-动作对，导致探索效率不足。

Method: 提出Value Bonuses with Ensemble errors (VBE)算法，核心是维护一组随机动作价值函数(RQF)的集成，利用这些函数的估计误差设计价值奖励机制。关键创新在于为RQF设计奖励，使价值奖励能够随时间衰减至零，从而实现首次访问乐观性和深度探索。

Result: 在多个经典探索测试环境中，VBE性能优于Bootstrap DQN以及RND和ACB两种奖励奖励方法；演示实验表明该算法可轻松扩展到Atari等更复杂环境。

Conclusion: VBE算法有效解决了强化学习中的首次访问探索难题，通过集成学习实现有向探索，在简单和复杂环境中均展现出优越的可扩展性和性能。

Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can be learned by estimating a value function on reward bonuses, propagating local uncertainties around rewards. However, this approach only increases the value bonus for an action retroactively, after seeing a higher reward bonus from that state and action. Such an approach does not encourage the agent to visit a state and action for the first time. In this work, we introduce an algorithm for exploration called Value Bonuses with Ensemble errors (VBE), that maintains an ensemble of random action-value functions (RQFs). VBE uses the errors in the estimation of these RQFs to design value bonuses that provide first-visit optimism and deep exploration. The key idea is to design the rewards for these RQFs in such a way that the value bonus can decrease to zero. We show that VBE outperforms Bootstrap DQN and two reward bonus approaches (RND and ACB) on several classic environments used to test exploration and provide demonstrative experiments that it can scale easily to more complex environments like Atari.

</details>


### [64] [High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions](https://arxiv.org/abs/2602.12391)
*Giang Ngo,Dat Phan Trong,Dang Nguyen,Sunil Gupta*

Main category: cs.LG

TL;DR: 提出TRLSE算法，通过全局和局部双重采集函数在高维水平集估计中实现高效主动学习，样本效率显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水平集估计是实际应用中的基础问题，但在高维空间面临维度灾难挑战——搜索空间随维度指数级增长。尽管主动学习可通过迭代获取信息点来缓解数据稀缺，但现有方法在高维场景下样本效率不足，亟需专门算法。

Method: 提出TRLSE算法，采用全局和局部双重采集函数策略：首先在全局层面识别可能包含阈值边界的区域，然后在局部层面精细化搜索边界邻近点，通过迭代主动获取信息量最大的样本构建分类器。

Result: 理论分析证明了TRLSE的准确性保证，在多个合成和真实水平集估计问题的广泛评估中，该算法展现出比现有方法更优的样本效率，能显著减少标注成本。

Conclusion: TRLSE通过双重采集函数有效解决了高维水平集估计的维度灾难问题，理论和实验验证了其优越性，为高维主动学习提供了可扩展的解决方案。

Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data, we aim to iteratively acquire informative points to construct an accurate classifier for this task. In high-dimensional spaces, this becomes challenging where the search volume grows exponentially with increasing dimensionality. We propose TRLSE, an algorithm for high-dimensional LSE, which identifies and refines regions near the threshold boundary with dual acquisition functions operating at both global and local levels. We provide a theoretical analysis of TRLSE's accuracy and show its superior sample efficiency against existing methods through extensive evaluations on multiple synthetic and real-world LSE problems.

</details>


### [65] [AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning](https://arxiv.org/abs/2602.12402)
*Felicia B. Guo,Ken T. Ho,Andrei Vladimirescu,Borivoje Nikolic*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度强化学习的模拟混合信号电路自动生成方法AstRL，将电路设计建模为图生成问题，通过策略梯度方法在模拟器环境中直接优化用户指定目标，实现了100%结构正确性和超过90%功能性的电路设计，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号集成电路设计复杂度高但自动化进展缓慢，主要挑战在于电路设计空间多样、约束严格且不可微，难以开发通用优化方法。传统自动化工具难以在晶体管层面实现细粒度拓扑生成。

Method: 提出AstRL框架，将电路设计视为图生成问题。采用策略梯度强化学习方法，在嵌入模拟器的环境中进行训练，获得真实反馈。引入行为克隆和基于判别器的相似性奖励，实现专家对齐的电路生成范式。通过动作空间和环境中的强归纳偏置确保结构一致性和有效性。

Result: 在三个实际设计任务上的实验表明，该方法在所有设计指标上显著优于最先进基线。生成的电路100%结构正确，超过90%满足功能要求，首次在晶体管层面实现了通用且高质量的AMS电路自动生成。

Conclusion: 该工作成功证明了深度强化学习在模拟混合信号电路设计中的有效性，为复杂电路自动化设计提供了新范式，有望推动AMS设计自动化领域的发展。

Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of AMS synthesis driven by deep reinforcement learning (AstRL). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation. Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100% of generated designs being structurally correct and over 90% demonstrating required functionality.

</details>


### [66] [Soft Contamination Means Benchmarks Test Shallow Generalization](https://arxiv.org/abs/2602.12413)
*Ari Spiesberger,Juan J. Vazquez,Nicky Pochinkov,Tomáš Gavenčiak,Peli Grietzer,Gavin Leech,Nandi Schoots*

Main category: cs.LG

TL;DR: 本文研究发现大语言模型训练数据中存在严重的"软污染"问题：基准测试数据通过语义重复（而非仅是字符串重复）污染训练集。通过嵌入分析Olmo3语料库，发现78%的CodeForces问题和50%的ZebraLogic问题存在重复。这种污染会虚假提升基准性能，导致近期性能提升部分源于测试数据泄露，而非模型真实泛化能力改善。


<details>
  <summary>Details</summary>
Motivation: 传统去污染方法使用n-gram匹配，无法检测语义重复的基准测试数据。当训练数据包含基准测试数据的语义等价版本时，基准性能会高估模型真实泛化能力。本文旨在研究这种"软污染"现象的普遍性及其对基准性能的影响，以揭示当前基准性能提升是否真实反映能力进步。

Method: 研究采用嵌入技术对Olmo3训练语料库进行语义相似性分析，检测与CodeForces和ZebraLogic基准数据集的语义重复。通过对比实验，评估包含语义重复数据对训练效果的影响，并进一步研究在基准数据重复点上进行微调时，对真实保留测试点性能的影响。

Result: 实验发现：1) 污染现象普遍存在，CodeForces数据集78%存在语义重复，ZebraLogic中50%存在完全重复；2) 训练数据中包含基准数据的语义重复版本会显著提升基准性能；3) 在基准数据重复点上进行微调，还能提升同一基准内真实保留测试点的性能。

Conclusion: 近期基准性能的提升存在严重混杂因素：由于软污染广泛存在，性能提升既反映模型真实能力改进，也源于训练语料中测试数据的累积。这导致基准性能高估了大语言模型的分布外泛化能力，研究呼吁更严格的去污染标准和更稳健的基准评估方法。

Abstract: If LLM training data is polluted with benchmark test data, then benchmark performance gives biased estimates of out-of-distribution (OOD) generalization. Typical decontamination filters use n-gram matching which fail to detect semantic duplicates: sentences with equivalent (or near-equivalent) content that are not close in string space. We study this soft contamination of training data by semantic duplicates. Among other experiments, we embed the Olmo3 training corpus and find that: 1) contamination remains widespread, e.g. we find semantic duplicates for 78% of CodeForces and exact duplicates for 50% of ZebraLogic problems; 2) including semantic duplicates of benchmark data in training does improve benchmark performance; and 3) when finetuning on duplicates of benchmark datapoints, performance also improves on truly-held-out datapoints from the same benchmark. We argue that recent benchmark gains are thus confounded: the prevalence of soft contamination means gains reflect both genuine capability improvements and the accumulation of test data and effective test data in growing training corpora.

</details>


### [67] [Stabilizing Native Low-Rank LLM Pretraining](https://arxiv.org/abs/2602.12429)
*Paul Janson,Edouard Oyallon,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出Spectron（谱归一化与正交化）方法，通过动态约束权重更新的谱范数，首次实现了从初始阶段完全使用低秩因子化权重训练大型语言模型，解决了训练不稳定性和损失峰值问题，并建立了原生低秩Transformer的计算最优缩放定律。


<details>
  <summary>Details</summary>
Motivation: 大模型参数量增长带来显著的计算与内存挑战，低秩分解虽能降低训练和推理成本，但现有方法需要额外的全秩指导，缺乏从训练初期就完全采用低秩权重且性能匹配稠密模型的稳定方案。

Method: 研究发现低秩训练不稳定的主导因素是权重更新过程中谱范数（最大奇异值）的失控增长。提出的Spectron方法基于因子矩阵的当前谱范数，动态约束权重更新，结合谱归一化与正交化技术实现稳定训练。

Result: 成功实现了端到端的原生低秩训练，所有非嵌入矩阵均使用低秩分解权重即可匹配稠密模型性能，训练过程稳定且开销可忽略，建立了低秩Transformer的计算最优缩放定律，显示出可预测的幂律行为及相对于稠密模型的推理效率优势。

Conclusion: 本研究为大规模模型的高效训练提供了新范式，证明了从0开始原生低秩训练的可行性，Spectron方法为资源受限场景提供了实用解决方案，低秩模型在扩展性和推理效率方面具有理论优势。

Abstract: Foundation models have achieved remarkable success, yet their growing parameter counts pose significant computational and memory challenges. Low-rank factorization offers a promising route to reduce training and inference costs, but the community lacks a stable recipe for training models from scratch using exclusively low-rank weights while matching the performance of the dense model. We demonstrate that Large Language Models (LLMs) can be trained from scratch using exclusively low-rank factorized weights for all non-embedding matrices without auxiliary "full-rank" guidance required by prior methods. While native low-rank training often suffers from instability and loss spikes, we identify uncontrolled growth in the spectral norm (largest singular value) of the weight matrix update as the dominant factor. To address this, we introduce Spectron: Spectral renormalization with orthogonalization, which dynamically bounds the resultant weight updates based on the current spectral norms of the factors. Our method enables stable, end-to-end factorized training with negligible overhead. Finally, we establish compute-optimal scaling laws for natively low-rank transformers, demonstrating predictable power-law behavior and improved inference efficiency relative to dense models.

</details>


### [68] [Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models](https://arxiv.org/abs/2602.12444)
*Alexander W. Goodall,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 本文提出了一种用于未知非线性连续动力系统的安全强化学习框架，通过集成基于高斯过程不确定性量化的备份策略，实现可证明的安全保证与高效探索的平衡。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键应用中缺乏可证明的安全保证，特别是面对未知和非线性连续系统时。现有方法要么过于保守限制探索，要么无法提供严格安全边界，制约了其在实际安全敏感场景中的部署。

Method: 提出恢复型屏蔽框架，将备份策略（shield）与RL智能体动态集成。利用高斯过程量化模型不确定性以预测安全约束违反，仅在必要时触发安全轨迹恢复。通过内部模型采样优化策略，使用被屏蔽智能体的经验构建GP模型，实现无限制探索与样本高效学习。

Result: 在连续控制环境测试中，该方法展现出严格的安全合规性和强大性能，验证了其在保证安全的同时维持高学习效率的有效性。

Conclusion: 该框架成功实现了可证明安全保证与高效强化学习的统一，为安全关键应用提供了可扩展的解决方案，在维持安全边界的同时不牺牲探索自由度。

Abstract: Reinforcement learning (RL) is a powerful framework for optimal decision-making and control but often lacks provable guarantees for safety-critical applications. In this paper, we introduce a novel recovery-based shielding framework that enables safe RL with a provable safety lower bound for unknown and non-linear continuous dynamical systems. The proposed approach integrates a backup policy (shield) with the RL agent, leveraging Gaussian process (GP) based uncertainty quantification to predict potential violations of safety constraints, dynamically recovering to safe trajectories only when necessary. Experience gathered by the 'shielded' agent is used to construct the GP models, with policy optimization via internal model-based sampling - enabling unrestricted exploration and sample efficient learning, without compromising safety. Empirically our approach demonstrates strong performance and strict safety-compliance on a suite of continuous control environments.

</details>


### [69] [Computationally sufficient statistics for Ising models](https://arxiv.org/abs/2602.12449)
*Abhijith Jayakumar,Shreya Shukla,Marc Vuffray,Andrey Y. Lokhov,Sidhant Misra*

Main category: cs.LG

TL;DR: 该论文研究了在仅能获取有限统计量的条件下高效学习吉布斯分布的问题，以伊辛模型为例，证明通过观察O(γ)阶统计量即可重建ℓ₁宽度为γ的模型参数，实现结构推断与参数学习。


<details>
  <summary>Details</summary>
Motivation: 传统学习吉布斯分布的方法要么仅依赖充分统计量但计算困难，要么需要完整的样本配置但不切实际；许多物理系统无法获得完整观测，因此需要在有限统计量下寻求计算高效的学习方法。

Method: 以伊辛模型为范例，分析计算能力与观测能力之间的权衡关系；通过ℓ₁宽度γ表征模型复杂度，设计仅观测至O(γ)阶统计量的学习算法，并探讨先验结构信息对降低观测需求的增强作用。

Result: 证明对于ℓ₁宽度为γ的模型，仅需观测O(γ)阶统计量即可重建模型参数，同时实现结构推断、耦合强度与磁场学习；当存在先验结构信息时，观测需求可进一步降低。

Conclusion: 该工作表明在有限观测条件下高效学习吉布斯分布是可行的，为物理系统中参数估计提供了理论保证和实践指导，先验信息能显著提升学习效率。

Abstract: Learning Gibbs distributions using only sufficient statistics has long been recognized as a computationally hard problem. On the other hand, computationally efficient algorithms for learning Gibbs distributions rely on access to full sample configurations generated from the model. For many systems of interest that arise in physical contexts, expecting a full sample to be observed is not practical, and hence it is important to look for computationally efficient methods that solve the learning problem with access to only a limited set of statistics. We examine the trade-offs between the power of computation and observation within this scenario, employing the Ising model as a paradigmatic example. We demonstrate that it is feasible to reconstruct the model parameters for a model with $\ell_1$ width $γ$ by observing statistics up to an order of $O(γ)$. This approach allows us to infer the model's structure and also learn its couplings and magnetic fields. We also discuss a setting where prior information about structure of the model is available and show that the learning problem can be solved efficiently with even more limited observational power.

</details>


### [70] [Regularized Meta-Learning for Improved Generalization](https://arxiv.org/abs/2602.12469)
*Noor Islam S. Mohammad,Md Muntaqim Meherab*

Main category: cs.LG

TL;DR: 本文提出四阶段正则化元学习框架，通过冗余感知投影、统计元特征增强和交叉验证正则化元模型，解决深度集成中的冗余性、多重共线性和过拟合问题，在基准测试上RMSE提升至8.582且条件数降低53.7%。


<details>
  <summary>Details</summary>
Motivation: 深度集成方法存在基模型冗余导致计算成本高和条件数恶化、多重共线性下权重不稳定、元学习过拟合三大实际限制。

Method: 四阶段框架：1）用相关性/MSE阈值（τ_corr=0.95）去重；2）冗余投影降低条件数；3）统计元特征和交互项增强；4）交叉验证正则化元模型（Ridge/Lasso/ElasticNet）加逆RMSE融合。

Result: 在10万样本、72基模型的Playground Series S6E1上，袋外RMSE达8.582，优于简单平均（8.894）和Ridge堆叠（8.627），与贪心爬山法（8.603）相当但快4倍，条件数降低53.7%。

Conclusion: 该框架为高维集成系统提供了稳定且部署高效的堆叠策略。

Abstract: Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a regularized meta-learning framework that addresses these challenges through a four-stage pipeline combining redundancy-aware projection, statistical meta-feature augmentation, and cross-validated regularized meta-models (Ridge, Lasso, and ElasticNet). Our multi-metric de-duplication strategy removes near-collinear predictors using correlation and MSE thresholds ($τ_{\text{corr}}=0.95$), reducing the effective condition number of the meta-design matrix while preserving predictive diversity. Engineered ensemble statistics and interaction terms recover higher-order structure unavailable to raw prediction columns. A final inverse-RMSE blending stage mitigates regularizer-selection variance. On the Playground Series S6E1 benchmark (100K samples, 72 base models), the proposed framework achieves an out-of-fold RMSE of 8.582, improving over simple averaging (8.894) and conventional Ridge stacking (8.627), while matching greedy hill climbing (8.603) with substantially lower runtime (4 times faster). Conditioning analysis shows a 53.7\% reduction in effective matrix condition number after redundancy projection. Comprehensive ablations demonstrate consistent contributions from de-duplication, statistical meta-features, and meta-ensemble blending. These results position regularized meta-learning as a stable and deployment-efficient stacking strategy for high-dimensional ensemble systems.

</details>


### [71] [Designing RNAs with Language Models](https://arxiv.org/abs/2602.12470)
*Milan Gautam,Ning Dai,Tianshuo Zhou,Bowen Xie,David Mathews,Liang Huang*

Main category: cs.LG

TL;DR: 该论文将RNA设计重构为条件序列生成问题，提出基于自回归语言模型的神经逼近器，通过监督学习加强化学习的两阶段训练，在四个数据集上超越现有最优方法，速度提升1.7倍，为RNA设计提供了可扩展的任务无关解决方案。


<details>
  <summary>Details</summary>
Motivation: RNA设计具有广泛的生物和生物医学应用价值，但计算上面临指数级序列空间和多种竞争折叠的挑战。传统方法将其视为优化问题，依赖实例级启发式算法或约束搜索，在效率和泛化性方面存在局限，亟需开发更通用、可扩展的解决方案。

Method: 研究将RNA设计重新定义为条件序列生成任务，引入自回归语言模型作为可复用的神经逼近器，直接实现目标结构到序列的映射。首先使用随机诱导的结构-序列对进行监督训练，然后采用强化学习优化端到端指标。提出创新性的小规模子集选择策略，显著提升强化学习的效率和质量。

Result: 在四个基准数据集上的实验表明，该方法在玻尔兹曼概率等关键指标上全面超越现有最优系统，同时实现1.7倍的加速。模型展现出良好的可扩展性和任务无关特性，为计算生物学中的序列设计提供了新范式。

Conclusion: 条件语言模型生成被证明是RNA设计领域可扩展、任务无关的有效替代方案，突破了传统实例级优化方法的瓶颈。该方法不仅提高了设计质量和效率，还为其他生物序列设计任务提供了可迁移的技术框架。

Abstract: RNA design, the task of finding a sequence that folds into a target secondary structure, has broad biological and biomedical impact but remains computationally challenging due to the exponentially large sequence space and exponentially many competing folds. Traditional approaches treat it as an optimization problem, relying on per-instance heuristics or constraint-based search. We instead reframe RNA design as conditional sequence generation and introduce a reusable neural approximator, instantiated as an autoregressive language model (LM), that maps target structures directly to sequences. We first train our model in a supervised setting on random-induced structure-sequence pairs, and then use reinforcement learning (RL) to optimize end-to-end metrics. We also propose methods to select a small subset for RL that greatly improves RL efficiency and quality. Across four datasets, our approach outperforms state-of-the-art systems on key metrics such as Boltzmann probability while being 1.7x faster, establishing conditional LM generation as a scalable, task-agnostic alternative to per-instance optimization for RNA design. Our code and data are available at https://github.com/KuNyaa/RNA-Design-LM.

</details>


### [72] [Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension](https://arxiv.org/abs/2602.12471)
*Michael Crawshaw,Mingrui Liu*

Main category: cs.LG

TL;DR: ...


<details>
  <summary>Details</summary>
Motivation: ...

Method: ...

Result: ...

Conclusion: ...

Abstract: We consider the optimization problem of minimizing the logistic loss with gradient descent to train a linear model for binary classification with separable data. With a budget of $T$ iterations, it was recently shown that an accelerated $1/T^2$ rate is possible by choosing a large step size $η= Θ(γ^2 T)$ (where $γ$ is the dataset's margin) despite the resulting non-monotonicity of the loss. In this paper, we provide a tighter analysis of gradient descent for this problem when the data is two-dimensional: we show that GD with a sufficiently large learning rate $η$ finds a point with loss smaller than $\mathcal{O}(1/(ηT))$, as long as $T \geq Ω(n/γ+ 1/γ^2)$, where $n$ is the dataset size. Our improved rate comes from a tighter bound on the time $τ$ that it takes for GD to transition from unstable (non-monotonic loss) to stable (monotonic loss), via a fine-grained analysis of the oscillatory dynamics of GD in the subspace orthogonal to the max-margin classifier. We also provide a lower bound of $τ$ matching our upper bound up to logarithmic factors, showing that our analysis is tight.

</details>


### [73] [On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs](https://arxiv.org/abs/2602.12506)
*Rosie Zhao,Anshul Shah,Xiaoyu Zhu,Xinke Deng,Zhongyu Jiang,Yang Yang,Joerg Liebelt,Arnab Mondal*

Main category: cs.LG

TL;DR: 研究发现RL微调的视觉语言模型存在准确性与忠实性权衡问题：虽然基准准确率提升，但思维链可靠性下降且对文本扰动脆弱。仅靠对抗增强不足，需综合评估正确性、鲁棒性和忠实性。


<details>
  <summary>Details</summary>
Motivation: 将强化学习微调从大语言模型扩展到视觉语言模型时，发现RL调优后的VLMs在视觉推理基准测试上表现改善，但仍存在视觉 grounding 弱、幻觉和过度依赖文本线索等脆弱性，亟需系统分析其鲁棒性缺陷及改进方法。

Method: 通过控制性文本扰动（误导性标题或错误思维链）测试模型鲁棒性，使用熵基指标分析模型不确定性变化，并探究RL微调动态过程、对抗增强和忠实性感知奖励的效果。

Result: 发现简单文本扰动导致鲁棒性和置信度大幅下降；存在准确性与忠实性权衡（微调提升准确率但损害思维链可靠性）；对抗增强改善鲁棒性但不能防止忠实性漂移；结合忠实性奖励虽能恢复对齐，但与增强结合时训练易崩溃到捷径策略。

Conclusion: 仅基于准确率的评估存在根本局限，未来训练与评估协议必须联合强调答案正确性、上下文鲁棒性和视觉 grounded 推理的忠实性，这些发现为构建更可靠的VLM安全微调框架提供了关键方向。

Abstract: Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.

</details>


### [74] [Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games](https://arxiv.org/abs/2602.12517)
*Lorenzo Magnino,Jiacheng Shen,Matthieu Geist,Olivier Pietquin,Mathieu Laurière*

Main category: cs.LG

TL;DR: 针对Mean Field Games与强化学习交叉领域缺乏标准化评估协议的问题，本文提出了Bench-MFG基准测试套件，包含问题分类、原型环境、随机实例生成方法MF-Garnets，以及新型MF-PSO算法，并提供了标准化实验指南。


<details>
  <summary>Details</summary>
Motivation: 当前MFG与RL交叉领域缺乏统一评估标准，研究者使用定制化、孤立且简单的实验环境，导致难以评估新方法的鲁棒性、泛化能力和失效模式，这种碎片化阻碍了领域的健康发展。

Method: 提出Bench-MFG基准套件，聚焦离散时间、离散空间和稳态设定；建立从非交互到动态耦合博弈的问题分类体系；开发MF-Garnets生成随机MFG实例；实现多种学习算法并进行基准测试；提出新型黑盒优化方法MF-PSO用于最小化可剥削性。

Result: 通过大量实验验证，提出了标准化未来实验对比的指南，相关代码已在GitHub开源。

Conclusion: 该基准测试套件为MFG研究社区提供了统一评估平台，有助于推动领域标准化发展，促进算法公平比较和性能提升。

Abstract: The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.

</details>


### [75] [Constraint-Rectified Training for Efficient Chain-of-Thought](https://arxiv.org/abs/2602.12526)
*Qinhang Wu,Sen Lin,Ming Zhang,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: 本文针对大语言模型思维链推理中存在冗余步骤（过度思考）的问题，提出了一种约束修正训练（CRT）框架。该方法通过参考守卫的约束优化，交替最小化推理长度并在性能低于参考时修正准确性，实现了推理效率与质量的稳定平衡。实验表明CRT能显著减少token使用，同时保持答案质量，并提供了可细粒度控制推理冗长度的中间检查点。


<details>
  <summary>Details</summary>
Motivation: 大语言模型结合思维链（CoT）和强化学习后推理能力显著提升，但更长的推理路径虽能改善答案质量，却带来高推理成本和冗余步骤（过度思考）问题。现有研究通过长度感知奖励设计或基于提示的校准来平衡推理长度与准确性，但这些启发式方法存在严重准确率下降和对超参数敏感的问题。因此，需要一种更稳定、可解释且原则性的训练框架来解决过度思考问题。

Method: 提出约束修正训练（CRT），一种基于参考守卫约束优化的原则性后训练框架。CRT通过交替优化两个目标来工作：1）最小化推理长度；2）仅在性能低于参考水平时修正准确性。该框架进一步扩展为两阶段训练方案：第一阶段发现最短的可靠推理模式；第二阶段在习得的长度预算下精炼准确性，防止冗长CoT再次出现。这种方法通过约束优化实现稳定且有效的冗余推理剪枝。

Result: 综合评估显示，CRT框架在保持答案质量稳定可靠的同时，持续减少token使用。进一步分析表明，CRT不仅通过缩短响应，还通过减少内部语言冗余来提升推理效率，并由此衍生出新的评估指标。更重要的是，CRT训练自然产生一系列中间检查点，形成从短到长且保持正确性的解释长度谱系，无需重训练即可实现推理冗长度的细粒度控制。

Conclusion: CRT为思维链推理中的过度思考问题提供了稳定、可解释的解决方案。该方法通过原则性的约束优化框架，有效平衡了推理效率与准确性，避免了启发式方法的缺陷。其两阶段训练策略不仅减少了token消耗，还产生了可灵活调控的推理路径，为大语言模型的实用化部署提供了新思路。该方法在保持模型性能的同时显著提升了推理效率。

Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.

</details>


### [76] [Analytical Results for Two Exponential Family Distributions in Hierarchical Dirichlet Processes](https://arxiv.org/abs/2602.12527)
*Naiqi Li*

Main category: cs.LG

TL;DR: 本研究将分层狄利克雷过程(HDP)框架从传统的狄利克雷-多项共轭结构推广至指数族分布，针对泊松分布和正态分布分别推导出伽马-泊松和正态-伽马-正态的闭式共轭表达式，为分层贝叶斯非参数模型提供了更广泛的解析工具。


<details>
  <summary>Details</summary>
Motivation: 现有HDP应用主要局限于狄利克雷-多项共轭结构，但HDP框架本身更为一般化，原则上可容纳更广泛的共轭先验-似然对。指数族分布包含多种常用分布，具有统一的解析框架，但其在HDP中的理论结果尚不充分。本研究旨在填补这一空白，扩展HDP在实际建模中的适用范围。

Method: 采用理论推导方法，在HDP构造下对指数族中的两个重要成员——泊松分布和正态分布进行系统性分析。通过数学推导获得相应的伽马-泊松和正态-伽马-正态共轭对，并提供详细的证明过程以阐明其底层数学结构，展示如何在分层非参数模型中系统性地利用共轭性。

Result: 成功推导出泊松-伽马和正态-伽马-正态两种共轭对在分层狄利克雷过程框架下的显式闭式表达式，并提供了完整的数学证明。这些结果揭示了指数族分布在HDP中的解析性质，为实际建模提供了可直接使用的分析工具。

Conclusion: 本研究突破了HDP传统上局限于狄利克雷-多项设置的限制，将框架扩展至更广泛的指数族分布，为研究人员在分层贝叶斯非参数建模中提供了实用的解析结果，显著提升了HDP在计数数据和连续数据建模中的适用性。

Abstract: The Hierarchical Dirichlet Process (HDP) provides a flexible Bayesian nonparametric framework for modeling grouped data with a shared yet unbounded collection of mixture components. While existing applications of the HDP predominantly focus on the Dirichlet-multinomial conjugate structure, the framework itself is considerably more general and, in principle, accommodates a broad class of conjugate prior-likelihood pairs. In particular, exponential family distributions offer a unified and analytically tractable modeling paradigm that encompasses many commonly used distributions. In this paper, we investigate analytic results for two important members of the exponential family within the HDP framework: the Poisson distribution and the normal distribution. We derive explicit closed-form expressions for the corresponding Gamma-Poisson and Normal-Gamma-Normal conjugate pairs under the hierarchical Dirichlet process construction. Detailed derivations and proofs are provided to clarify the underlying mathematical structure and to demonstrate how conjugacy can be systematically exploited in hierarchical nonparametric models. Our work extends the applicability of the HDP beyond the Dirichlet-multinomial setting and furnishes practical analytic results for researchers employing hierarchical Bayesian nonparametrics.

</details>


### [77] [Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models](https://arxiv.org/abs/2602.12529)
*Bowen Ping,Chengyou Jia,Minnan Luo,Hangwei Qian,Ivor Tsang*

Main category: cs.LG

TL;DR: 针对扩散模型和流匹配模型在强化学习人类偏好对齐中面临的代码碎片化、模型特定实现和工程复杂性问题，本文提出了 Flow-Factory 统一框架，通过模块化注册架构解耦算法、模型和奖励函数，支持多种算法和模型架构，提供生产级优化，实现快速原型设计和规模化创新。


<details>
  <summary>Details</summary>
Motivation: 强化学习在扩散模型和流匹配模型的人类偏好对齐方面展现出巨大潜力，但实践者面临代码库碎片化、模型特定实现和工程复杂性的严重挑战，这阻碍了研究效率和创新速度。

Method: 提出 Flow-Factory 统一框架，采用模块化注册架构将算法、模型和奖励解耦，通过标准化接口实现组件灵活组合，支持 GRPO、DiffusionNFT 和 AWM 等多种算法，以及 Flux、Qwen-Image 和 WAN 视频模型。

Result: 该框架成功实现了算法与模型的即插即用，支持多奖励灵活训练和分布式训练，提供生产级内存优化，显著降低了实现开销，使研究人员能够快速原型化和扩展新创新。

Conclusion: Flow-Factory 为扩散模型和流匹配模型的强化学习对齐提供了标准化、可扩展的统一平台，通过工程化优化和模块化设计极大提升了研究效率，有望成为该领域的基础设施，推动未来算法和架构的快速发展。

Abstract: Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples algorithms, models, and rewards through through a modular, registry-based architecture. This design enables seamless integration of new algorithms and architectures, as demonstrated by our support for GRPO, DiffusionNFT, and AWM across Flux, Qwen-Image, and WAN video models. By minimizing implementation overhead, Flow-Factory empowers researchers to rapidly prototype and scale future innovations with ease. Flow-Factory provides production-ready memory optimization, flexible multi-reward training, and seamless distributed training support. The codebase is available at https://github.com/X-GenGroup/Flow-Factory.

</details>


### [78] [AMPS: Adaptive Modality Preference Steering via Functional Entropy](https://arxiv.org/abs/2602.12533)
*Zihan Huang,Xintong Li,Rohan Surana,Tong Yu,Rui Wang,Julian McAuley,Jingbo Shang,Junda Wu*

Main category: cs.LG

TL;DR: 针对多模态大语言模型的模态偏好问题，本文提出实例感知的转向控制方法，通过诊断指标量化模态信息贡献并识别样本敏感性，结合缩放策略和可学习模块实现精准偏好调节，在保持低错误率的同时有效调整模态偏好。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在显著的模态偏好问题，会过度依赖语言先验或视觉信息。现有均匀转向强度方法存在两难：强转向损害推理能力且增加错误率，弱转向又效果不佳。由于不同样本对转向的敏感性差异很大，单一全局强度难以精确校准，亟需一种实例感知的解决方案以最小化对推理的干扰。

Method: 提出一种实例感知的诊断指标，用于量化每种模态的信息贡献并揭示样本特定的转向敏感性。基于此，设计一种缩放策略，对敏感样本减少转向强度，并开发一个可学习模块来推断缩放模式，从而实现实例感知的模态偏好控制。

Result: 实验结果表明，该实例感知转向方法在调节模态偏好方面优于传统均匀转向，能够在实现有效调整的同时保持较低的生成错误率。

Conclusion: 本文的实例感知转向框架通过样本特异性的诊断和自适应缩放，成功解决了多模态大语言模型的模态偏好问题，在保持模型推理性能的前提下实现了精准的偏好控制，为多模态模型的鲁棒性提升提供了新思路。

Abstract: Multimodal Large Language Models (MLLMs) often exhibit significant modality preference, which is a tendency to favor one modality over another. Depending on the input, they may over-rely on linguistic priors relative to visual evidence, or conversely over-attend to visually salient but facts in textual contexts. Prior work has applied a uniform steering intensity to adjust the modality preference of MLLMs. However, strong steering can impair standard inference and increase error rates, whereas weak steering is often ineffective. In addition, because steering sensitivity varies substantially across multimodal instances, a single global strength is difficult to calibrate. To address this limitation with minimal disruption to inference, we introduce an instance-aware diagnostic metric that quantifies each modality's information contribution and reveals sample-specific susceptibility to steering. Building on these insights, we propose a scaling strategy that reduces steering for sensitive samples and a learnable module that infers scaling patterns, enabling instance-aware control of modality preference. Experimental results show that our instance-aware steering outperforms conventional steering in modulating modality preference, achieving effective adjustment while keeping generation error rates low.

</details>


### [79] [Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference](https://arxiv.org/abs/2602.12542)
*Pengfei Hu,Chang Lu,Feifan Liu,Yue Ning*

Main category: cs.LG

TL;DR: 本文提出 ExtraCare 方法，通过分解患者表征为不变和协变成分并强制正交性，在提升跨域临床事件预测性能的同时，提供可解释的医学概念映射，解决了深度学习模型在电子健康记录应用中因数据分布差异导致的黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在电子健康记录（EHR）的临床事件预测中，当部署到不同数据分布时会出现性能下降。尽管领域自适应（DA）方法可以缓解这种偏移，但其"黑盒"特性阻碍了在需要透明度的临床实践中的广泛应用。本文旨在开发一种既能保持良好预测性能又能提供可解释性的解决方案。

Method: 提出 ExtraCare 方法，将患者表征分解为不变成分（invariant）和协变成分（covariant）。通过监督这两个组件并强制它们在训练期间正交化，模型在保留标签信息的同时暴露域特定变化。更重要的是，该方法通过将稀疏潜在维度映射到医学概念，并利用目标消融量化其贡献，提供人类可理解的解释。

Result: 在两个真实世界EHR数据集和多个域划分设置上的评估表明，ExtraCare 相较于大多数特征对齐模型具有更优的预测性能，同时提供了增强的透明度。大量案例研究证实了其准确的预测和解释能力。

Conclusion: ExtraCare 成功地在临床事件预测任务中平衡了性能与可解释性，通过分解表征和正交约束有效处理了分布偏移问题，并通过医学概念映射提供了可理解的解释，为临床实践中的可信AI部署提供了可行方案。

Abstract: Deep learning models for clinical event prediction on electronic health records (EHR) often suffer performance degradation when deployed under different data distributions. While domain adaptation (DA) methods can mitigate such shifts, its "black-box" nature prevents widespread adoption in clinical practice where transparency is essential for trust and safety. We propose ExtraCare to decompose patient representations into invariant and covariant components. By supervising these two components and enforcing their orthogonality during training, our model preserves label information while exposing domain-specific variation at the same time for more accurate predictions than most feature alignment models. More importantly, it offers human-understandable explanations by mapping sparse latent dimensions to medical concepts and quantifying their contributions via targeted ablations. ExtraCare is evaluated on two real-world EHR datasets across multiple domain partition settings, demonstrating superior performance along with enhanced transparency, as evidenced by its accurate predictions and explanations from extensive case studies.

</details>


### [80] [SD-MoE: Spectral Decomposition for Effective Expert Specialization](https://arxiv.org/abs/2602.12556)
*Ruijun Huang,Fang Dong,Xin Zhang,Hengjie Cao,Zhendong Huang,Anrui Chen,Jixian Zhou,Mengyi Chen,Yifeng Yang,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Fan Yang,Tun Lu,Chun Zhang,Li Shang*

Main category: cs.LG

TL;DR: 本文针对MoE架构专家专业化失效问题，通过谱分析发现专家参数与梯度空间存在主谱分量重叠、梯度子空间对齐及门控路由偏好等问题，提出谱解耦MoE（SD-MoE），实现性能提升与有效专业化，计算开销小且兼容现有架构。


<details>
  <summary>Details</summary>
Motivation: MoE架构通过条件计算诱导专家专业化以扩展大语言模型，但实践中专家常出现功能相似或退化为共享专家的现象，限制了模型的有效容量与性能，亟需解决专家专业化不足的根本问题。

Method: 从参数空间与梯度空间的谱分析视角入手，揭示专家间主谱分量高度重叠、梯度子空间因语料低秩结构而强对齐、门控机制沿主方向路由输入的机理，提出在谱空间中对参数和梯度进行解耦的SD-MoE方法。

Result: 所提SD-MoE在多项下游任务上显著提升性能，成功实现有效的专家专业化，额外计算成本极低，且可无缝集成至Qwen、DeepSeek等主流MoE架构中。

Conclusion: 谱空间解耦是解决MoE专家专业化失效的有效途径，SD-MoE通过分离参数与梯度的主谱成分，在保持低计算开销的同时提升模型性能，具有良好的实用性与推广价值。

Abstract: Mixture-of-Experts (MoE) architectures scale Large Language Models via expert specialization induced by conditional computation. In practice, however, expert specialization often fails: some experts become functionally similar, while others functioning as de facto shared experts, limiting the effective capacity and model performance. In this work, we analysis from a spectral perspective on parameter and gradient spaces, uncover that (1) experts share highly overlapping dominant spectral components in their parameters, (2) dominant gradient subspaces are strongly aligned across experts, driven by ubiquitous low-rank structure in human corpus, and (3) gating mechanisms preferentially route inputs along these dominant directions, further limiting specialization. To address this, we propose Spectral-Decoupled MoE (SD-MoE), which decomposes both parameter and gradient in the spectral space. SD-MoE improves performance across downstream tasks, enables effective expert specialization, incurring minimal additional computation, and can be seamlessly integrated into a wide range of existing MoE architectures, including Qwen and DeepSeek.

</details>


### [81] [Fractional Order Federated Learning for Battery Electric Vehicle Energy Consumption Modeling](https://arxiv.org/abs/2602.12567)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: 针对网联电动汽车联邦学习中的不稳定问题，本文提出分数阶粗糙度感知联邦平均算法(FO-RI-FedAvg)，通过客户端自适应正则化和分数阶优化提升稳定性，在真实数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 网联电动汽车联邦学习面临间歇性连接、时变客户端参与和不同运行条件导致的显著客户端异质性，传统FedAvg及先进方法在这些实际约束下会出现过度漂移和收敛性能退化，亟需更稳定的学习框架。

Method: 提出FO-RI-FedAvg，一种轻量级模块化FedAvg扩展：(1)自适应粗糙度感知近端正则化机制，根据局部损失景观粗糙度动态调节向全局模型的拉力；(2)非整数阶局部优化，引入短期记忆效应平滑冲突更新方向。保持标准FedAvg服务器聚合，仅增加可摊销的元素级运算开销，支持组件独立开关。

Result: 在VED和eVED两个真实世界BEV能耗预测数据集上，FO-RI-FedAvg相比强联邦基线展现出更高的预测准确性和更稳定的收敛特性，尤其在客户端参与率降低时优势更为显著。

Conclusion: FO-RI-FedAvg为网联电动汽车联邦学习提供了一种高效实用的稳定性增强方案，通过双机制协同有效缓解了实际部署中的漂移和收敛问题，具有较好的应用推广潜力。

Abstract: Federated learning on connected electric vehicles (BEVs) faces severe instability due to intermittent connectivity, time-varying client participation, and pronounced client-to-client variation induced by diverse operating conditions. Conventional FedAvg and many advanced methods can suffer from excessive drift and degraded convergence under these realistic constraints. This work introduces Fractional-Order Roughness-Informed Federated Averaging (FO-RI-FedAvg), a lightweight and modular extension of FedAvg that improves stability through two complementary client-side mechanisms: (i) adaptive roughness-informed proximal regularization, which dynamically tunes the pull toward the global model based on local loss-landscape roughness, and (ii) non-integer-order local optimization, which incorporates short-term memory to smooth conflicting update directions. The approach preserves standard FedAvg server aggregation, adds only element-wise operations with amortizable overhead, and allows independent toggling of each component. Experiments on two real-world BEV energy prediction datasets, VED and its extended version eVED, show that FO-RI-FedAvg achieves improved accuracy and more stable convergence compared to strong federated baselines, particularly under reduced client participation.

</details>


### [82] [VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction](https://arxiv.org/abs/2602.12579)
*Xin-Qiang Cai,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 针对无验证器强化学习中梯度方差导致训练崩溃的问题，本文提出VI-CuRL框架，利用模型内在置信度构建课程学习，通过优先选择高置信度样本降低方差。理论证明其估计器渐近无偏，在六个基准测试中稳定优于基线方法。


<details>
  <summary>Details</summary>
Motivation: RLVR虽能提升LLM推理能力，但其依赖外部验证器限制可扩展性。新研究表明RLVR主要通过激发潜在能力发挥作用，这推动了无验证器算法的发展。然而，在无验证器场景下，GRPO等标准方法面临破坏性梯度方差的严重挑战，常导致训练崩溃。因此，需要开发一种不依赖外部验证器且能稳定训练的新方法。

Method: 提出验证器无关的课程强化学习（VI-CuRL）框架。该框架利用模型内在置信度构建独立于外部验证器的课程学习策略。通过优先选择高置信度样本，有效管理偏差-方差权衡，特别针对动作方差和问题方差的降低。方法核心是将置信度作为课程学习的排序信号，在训练过程中动态调整样本选择。

Result: 提供严格的理论分析，证明所提估计器具有渐近无偏性。在六个具有挑战性的基准测试上，VI-CuRL显著提升训练稳定性，无论是否使用验证器，都持续优于无验证器基线方法。实验结果验证了课程学习策略在控制方差和防止训练崩溃方面的有效性。

Conclusion: VI-CuRL成功解决了无验证器强化学习的训练崩溃问题，通过内在置信度驱动的课程学习实现稳定且高效的训练。该方法为可扩展的LLM推理增强提供了新方向，证明了无需外部验证器也能实现高性能的强化学习，具有重要理论和实践价值。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a dominant paradigm for enhancing Large Language Models (LLMs) reasoning, yet its reliance on external verifiers limits its scalability. Recent findings suggest that RLVR primarily functions by eliciting latent capabilities, motivating the development of verifier-free algorithms. However, in such settings, standard methods like Group Relative Policy Optimization face a critical challenge: destructive gradient variance that often leads to training collapse. To address this issue, we introduceVerifier-Independent Curriculum Reinforcement Learning (VI-CuRL), a framework that leverages the model's intrinsic confidence to construct a curriculum independent from external verifiers. By prioritizing high-confidence samples, VI-CuRL effectively manages the bias-variance trade-off, specifically targeting the reduction of action and problem variance. We provide a rigorous theoretical analysis, proving that our estimator guarantees asymptotic unbiasedness. Empirically, VI-CuRL promotes stability and consistently outperforms verifier-independent baselines across six challenging benchmarks with/without verifiers.

</details>


### [83] [Multi-Head Attention as a Source of Catastrophic Forgetting in MoE Transformers](https://arxiv.org/abs/2602.12587)
*Anrui Chen,Ruijun Huang,Xin Zhang,Fang Dong,Hengjie Cao,Zhendong Huang,Yifeng Yang,Mengyi Chen,Jixian Zhou,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Tun Lu,Fan Yang,Li Shang*

Main category: cs.LG

TL;DR: 本研究揭示MoE架构在持续学习中遗忘的根本原因在于预路由瓶颈导致的路由冲突，提出通过头级路由提升粒度的MH-MoE方法，在Qwen3-0.6B上将BWT从11.2%降至4.5%。


<details>
  <summary>Details</summary>
Motivation: 虽然MoE的稀疏路由特性被认为天然适合持续学习，但MoE Transformers仍表现出严重遗忘。作者发现这是由于多头注意力将各头信号合并为单一路由输入，迫使路由决策基于共现特征组合而非独立头通道，造成不同特征组合被映射到相同路线，引发路由冲突和灾难性遗忘。

Method: 提出MH-MoE（Multi-Head MoE），采用头级路由机制，在注意力头层面的子表示上进行独立路由决策，而非在拼接后的统一表示上路由，从而提升路由粒度，减少组合冲突。

Result: 在TRACE基准测试中，MH-MoE显著缓解了遗忘。Qwen3-0.6B的BWT（向后迁移）从基线LoRAMoE的11.2%降至4.5%。同时引入路由级有效组合数$N_{eff}$量化冲突效应，发现$N_{eff}$值越高的路线在持续训练后旧任务损失增幅越大。

Conclusion: 预路由瓶颈是导致MoE持续学习性能下降的关键机制。通过将路由粒度从整体表示细化到头级子表示，MH-MoE有效降低了路由冲突，为设计抗遗忘的稀疏专家模型提供了新思路。

Abstract: Mixture-of-Experts (MoE) architectures are often considered a natural fit for continual learning because sparse routing should localize updates and reduce interference, yet MoE Transformers still forget substantially even with sparse, well-balanced expert utilization. We attribute this gap to a pre-routing bottleneck: multi-head attention concatenates head-specific signals into a single post-attention router input, forcing routing to act on co-occurring feature compositions rather than separable head channels. We show that this router input simultaneously encodes multiple separately decodable semantic and structural factors with uneven head support, and that different feature compositions induce weakly aligned parameter-gradient directions; as a result, routing maps many distinct compositions to the same route. We quantify this collision effect via a route-wise effective composition number $N_{eff}$ and find that higher $N_{eff}$ is associated with larger old-task loss increases after continual training. Motivated by these findings, we propose MH-MoE, which performs head-wise routing over sub-representations to increase routing granularity and reduce composition collisions. On TRACE with Qwen3-0.6B/8B, MH-MoE effectively mitigates forgetting, reducing BWT on Qwen3-0.6B from 11.2% (LoRAMoE) to 4.5%.

</details>


### [84] [Vehicle behaviour estimation for abnormal event detection using distributed fiber optic sensing](https://arxiv.org/abs/2602.12591)
*Hemant Prasad,Daisuke Ikefuji,Shin Tominaga,Hitoshi Sakurai,Manabu Otani*

Main category: cs.LG

TL;DR: 针对分布式光纤传感系统在单车道异常检测中的挑战，本文提出一种基于车辆轨迹追踪和频谱质心分析的变道行为检测方法，在真实交通数据上实现80%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有分布式光纤传感系统能够经济高效地监测大范围交通拥堵，但难以检测引发拥堵的单车道异常。通过监测车辆为规避拥堵而进行的变道行为，可间接识别此类异常。

Method: 采用聚类技术估计车辆全时段位置并拟合行驶路径，通过追踪参考车辆振动信号的频谱质心变化来识别变道行为，从而检测单车道异常。

Result: 基于真实交通数据的实验评估表明，该方法对表示异常存在的变道检测事件达到了80%的识别准确率。

Conclusion: 该方法验证了利用DFOS技术通过车辆变道行为检测单车道异常的可行性，为交通监控提供了有效解决方案。

Abstract: The distributed fiber-optic sensing (DFOS) system is a cost-effective wide-area traffic monitoring technology that utilizes existing fiber infrastructure to effectively detect traffic congestions. However, detecting single-lane abnormalities, that lead to congestions, is still a challenge. These single-lane abnormalities can be detected by monitoring lane change behaviour of vehicles, performed to avoid congestion along the monitoring section of a road. This paper presents a method to detect single-lane abnormalities by tracking individual vehicle paths and detecting vehicle lane changes along a section of a road. We propose a method to estimate the vehicle position at all time instances and fit a path using clustering techniques. We detect vehicle lane change by monitoring any change in spectral centroid of vehicle vibrations by tracking a reference vehicle along a highway. The evaluation of our proposed method with real traffic data showed 80% accuracy for lane change detection events that represent presence of abnormalities.

</details>


### [85] [HyperMLP: An Integrated Perspective for Sequence Modeling](https://arxiv.org/abs/2602.12601)
*Jiecheng Lu,Shihao Yang*

Main category: cs.LG

TL;DR: 论文将自注意力重新诠释为动态两层MLP，提出HyperMLP/HyperGLU架构，在特征与序列空间学习动态混合，通过反向偏移布局实现对齐，在参数匹配下持续超越softmax注意力。


<details>
  <summary>Details</summary>
Motivation: 传统观点将自注意力视为概率性查询-键查找，需保持归一化分数和固定位置语义。作者提出更简单统一的视角：自回归注意力头即动态两层MLP，权重来自上下文历史，激活函数实现输入条件化记忆选择而非概率分布。

Method: 引入HyperMLP/HyperGLU，学习特征空间和序列空间的动态混合，采用反向偏移（滞后）布局对齐时间混合与自回归语义，并提供表达能力的理论分析。

Result: 在匹配参数预算下，HyperMLP/HyperGLU持续优于强softmax注意力基线。

Conclusion: 该视角为注意力机制提供了新理论和方法，证明HyperMLP/HyperGLU的有效性，开辟了新的研究方向。

Abstract: Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can be viewed as a dynamic two-layer MLP whose weights are instantiated from the context history. From this view, attention scores form an ever-growing hidden representation, and standard MLP activations such as ReLU or GLU naturally implement input-conditioned selection over a context-dependent memory pool rather than a probability distribution. Based on this formulation, we introduce HyperMLP and HyperGLU, which learn dynamic mixing in both feature space and sequence space, using a reverse-offset (lag) layout to align temporal mixing with autoregressive semantics. We provide theoretical characterizations of the expressivity and implications of this structure, and empirically show that HyperMLP/HyperGLU consistently outperform strong softmax-attention baselines under matched parameter budgets.

</details>


### [86] [Block-Sample MAC-Bayes Generalization Bounds](https://arxiv.org/abs/2602.12605)
*Matthias Frey,Jingge Zhu,Michael C. Gastpar*

Main category: cs.LG

TL;DR: 本文提出了一类新的块样本均值近似正确贝叶斯界，用于界定期望泛化误差。与传统的概率近似正确贝叶斯界不同，新界在散度项中仅使用训练数据的子集（块），从而在理论上显著提升界的紧致性。通过简单数值例子，原始概率近似正确贝叶斯界无论选择何种先验均为无意义，而适当选择块大小可使新界保持有限。此外，论文探讨了是否存在对应的高概率版本（即类似形式的概率近似正确贝叶斯界），并给出否定答案：若均值近似正确贝叶斯界以O(n^{-1/2})速率趋于零，则对应的概率近似正确贝叶斯界不可能以快于O(1/log n)的速率消失，且其对误差概率的依赖必须是对数级的。


<details>
  <summary>Details</summary>
Motivation: 概率近似正确贝叶斯界是机器学习理论中衡量模型泛化能力的重要工具，但在高维或小样本情况下往往过于宽松。均值近似正确贝叶斯界虽针对期望误差，但仍存在类似问题。为此，本文旨在通过引入块样本的思想，构造更紧的期望误差界，并进一步考察其向高概率版本转化的可能性，以弥补现有理论的不足。

Method: 该研究在已有概率近似正确贝叶斯界的期望版本基础上进行推广，提出块样本均值近似正确贝叶斯界。具体做法是将散度项限制在训练数据的若干互不相交的子集（块）上，从而降低散度项的规模并提升界的紧致性。通过调节块的大小，可以在不同数据量下获得最优的界。同时，论文通过构造反例，证明在一般情况下无法得到既满足O(n^{-1/2})消失速率又具备对数误差概率依赖的高概率概率近似正确贝叶斯界。

Result: 1. 提出了一类新颖的块样本均值近似正确贝叶斯界，在期望泛化误差的界定上比传统界更紧。2. 通过数值示例表明，当原始概率近似正确贝叶斯界在所有先验下均为空时，适当选择块大小可使新界为有限值，展示了新界的潜力。3. 证明了一般情况下，若均值近似正确贝叶斯界以O(n^{-1/2})速率消失，则对应的概率近似正确贝叶斯界不可能以快于O(1/log n)的速率消失，且其对误差概率的依赖必须是对数级的，从而否定了存在满足条件的高概率版本的可能。

Conclusion: 块样本均值近似正确贝叶斯界为期望泛化误差提供了更紧的理论界，具有改善现有界的潜力。然而，将其转化为高概率界在一般情况下并不可行，揭示了期望界与高概率界之间的本质差异。未来的研究可考虑在特定模型假设或数据结构下探索高概率版本，或寻找其他改进方向。

Abstract: We present a family of novel block-sample MAC-Bayes bounds (mean approximately correct). While PAC-Bayes bounds (probably approximately correct) typically give bounds for the generalization error that hold with high probability, MAC-Bayes bounds have a similar form but bound the expected generalization error instead. The family of bounds we propose can be understood as a generalization of an expectation version of known PAC-Bayes bounds. Compared to standard PAC-Bayes bounds, the new bounds contain divergence terms that only depend on subsets (or \emph{blocks}) of the training data. The proposed MAC-Bayes bounds hold the promise of significantly improving upon the tightness of traditional PAC-Bayes and MAC-Bayes bounds. This is illustrated with a simple numerical example in which the original PAC-Bayes bound is vacuous regardless of the choice of prior, while the proposed family of bounds are finite for appropriate choices of the block size. We also explore the question whether high-probability versions of our MAC-Bayes bounds (i.e., PAC-Bayes bounds of a similar form) are possible. We answer this question in the negative with an example that shows that in general, it is not possible to establish a PAC-Bayes bound which (a) vanishes with a rate faster than $\mathcal{O}(1/\log n)$ whenever the proposed MAC-Bayes bound vanishes with rate $\mathcal{O}(n^{-1/2})$ and (b) exhibits a logarithmic dependence on the permitted error probability.

</details>


### [87] [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)
*Justin Gu,Rishabh Ranjan,Charilaos Kanatsoulis,Haiming Tang,Martin Jurkovic,Valter Hudovernik,Mark Znidar,Pranshu Chaturvedi,Parth Shroff,Fengyu Li,Jure Leskovec*

Main category: cs.LG

TL;DR: 本文提出了RelBench v2，一个关系型深度学习基准测试的重大扩展。该版本新增四个大规模跨领域数据集，引入"自动补全任务"新范式，并整合多个外部基准框架，总计涵盖11个数据集、29张表和超过2200万行数据。实验证实关系型深度学习模型在多类任务上持续优于单表基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着关系型深度学习向大规模模型和基础模型演进，缺乏可扩展且真实的基准测试已成为制约领域发展的关键瓶颈。现有基准在数据规模、任务类型和生态系统方面存在局限性，无法满足大规模关系建模和系统性评估的需求。

Method: 1) 数据集扩展：新增学术论文、企业资源规划、消费平台和临床记录四个领域的大规模数据集，将基准扩展至11个数据集（29张表，超2200万行）；2) 任务创新：提出"自动补全任务"新范式，要求模型在时序约束下直接推断关系表中的缺失属性值；3) 生态整合：将时序图基准事件流转换为关系模式、对接ReDeLEx提供70+预训练数据库、整合4DBInfer数据集以扩展多表预测覆盖。

Result: 实验结果表明，在自动补全、预测和推荐三类任务中，关系型深度学习模型均持续优于单表基线模型，性能优势显著，验证了显式建模关系结构的有效性。

Conclusion: RelBench v2通过大规模数据扩展、新任务范式引入和生态系统整合，为关系型深度学习提供了全面的评估平台，将推动该领域向更大规模和实际应用发展。核心结论是显式关系建模对提升多表预测性能至关重要，为未来 relational foundation models 的发展奠定了基准基础。

Abstract: Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic benchmarks are essential for enabling systematic evaluation and progress. In this paper, we introduce RelBench v2, a major expansion of the RelBench benchmark for RDL. RelBench v2 adds four large-scale relational datasets spanning scholarly publications, enterprise resource planning, consumer platforms, and clinical records, increasing the benchmark to 11 datasets comprising over 22 million rows across 29 tables. We further introduce autocomplete tasks, a new class of predictive objectives that require models to infer missing attribute values directly within relational tables while respecting temporal constraints, expanding beyond traditional forecasting tasks constructed via SQL queries. In addition, RelBench v2 expands beyond its native datasets by integrating external benchmarks and evaluation frameworks: we translate event streams from the Temporal Graph Benchmark into relational schemas for unified relational-temporal evaluation, interface with ReDeLEx to provide uniform access to 70+ real-world databases suitable for pretraining, and incorporate 4DBInfer datasets and tasks to broaden multi-table prediction coverage. Experimental results demonstrate that RDL models consistently outperform single-table baselines across autocomplete, forecasting, and recommendation tasks, highlighting the importance of modeling relational structure explicitly.

</details>


### [88] [Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13069)
*Juneyoung Park,Yuri Hong,Seongwan Kim,Jaeho Lee*

Main category: cs.LG

TL;DR: 本文提出MeSP方法，通过利用LoRA低秩结构手动推导反向传播，在移动设备上实现隐私保护的大语言模型微调。相比MeBP降低49%内存且计算精确梯度，而MeZO的梯度估计与真实梯度几乎不相关（余弦相似度≈0.001），收敛缓慢。


<details>
  <summary>Details</summary>
Motivation: 移动设备上实现隐私保护的大语言模型微调面临严重内存限制（通常6-12GB共享内存）。现有方法不得不在高内存的精确梯度（MeBP）和低内存的噪声梯度估计（MeZO）之间权衡。MeZO的梯度估计质量差导致收敛慢，而MeBP内存开销大。因此需要一种既能保持梯度精确性又能显著降低内存的方法。

Method: 提出Memory-efficient Structured Backpropagation (MeSP)，核心是手动推导反向传播过程，利用LoRA的低秩结构特性。关键洞察是：由于秩r远小于输入维度d_in，中间投影h = xA可以在反向传播时以极低成本重新计算，从而避免存储该中间结果。

Result: 在Qwen2.5模型（0.5B-3B）上，MeSP相比MeBP实现49%的平均内存降低，同时计算数学上完全相同的梯度。分析表明MeZO的梯度估计与真实梯度几乎不相关（余弦相似度≈0.001），这解释了其收敛缓慢的原因。对于Qwen2.5-0.5B，MeSP将峰值内存从361MB降至136MB。

Conclusion: MeSP成功弥合了精确梯度与高内存、低内存与噪声梯度之间的鸿沟，使内存受限设备上的大语言模型微调成为可能，开启了此前不可行的应用场景。该方法为设备端个性化大模型提供了实用且高效的解决方案。

Abstract: On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \ll d_{in}$, eliminating the need to store it. MeSP achieves 49\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.

</details>


### [89] [LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13073)
*Juneyoung Park,Eunbeen Yoon,Seongwan Kim. Jaeho Lee*

Main category: cs.LG

TL;DR: 本文提出层循环选择性反向传播（LCSB），通过在每个训练步仅对部分Transformer层进行反向传播，利用残差连接和AdamW动量实现梯度流动与隐式更新，从而在移动设备上实现内存高效的LLM微调。LCSB在五个模型和三个任务上实现最高1.40倍加速，质量下降小于2%，并在4-bit量化设置中表现出更优的稳定性。


<details>
  <summary>Details</summary>
Motivation: 尽管内存高效反向传播（MeBP）使得在内存小于1GB的移动设备上对大语言模型进行一阶微调成为可能，但MeBP需在每一步都对所有Transformer层进行反向传播，其中权重解压单独占用32-42%的反向时间，导致训练效率低下。

Method: 提出层循环选择性反向传播（LCSB），在每一步仅计算部分层的梯度。其关键洞察是残差连接保证梯度通过恒等路径传播，而AdamW的动量项为非选中层提供隐式更新。将LCSB解释为在LoRA参数空间上的块坐标下降，并给出收敛的理论依据。

Result: 实验表明，LCSB在五个模型和三个任务上相比MeBP实现最高1.40倍加速，质量下降不超过2%。在4-bit量化环境下，LCSB展现出更强的稳定性：一个在完整反向传播下完全发散的3B模型在使用LCSB时能够平滑收敛，暗示选择性梯度计算具有隐式正则化效应。

Conclusion: LCSB通过选择性反向传播显著提升了内存受限环境下LLM微调的训练效率，同时保持模型质量，并在低精度量化设置中表现出意外的稳定性优势，为移动设备上的模型微调提供了有效的解决方案。

Abstract: Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\times$ speedup with less than 2\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.

</details>


### [90] [Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps](https://arxiv.org/abs/2602.12624)
*Sangwoo Jo,Sungjoon Choi*

Main category: cs.LG

TL;DR: 本文提出SDM框架，通过几何视角分析扩散ODE轨迹，自适应地选择和调度数值求解器，在降低采样成本的同时实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的生成模型虽然性能卓越，但实际部署受限于高昂的采样成本。现有研究多关注训练目标或单个求解器，而采样过程的整体设计（求解器选择与调度）仍依赖于静态启发式方法，缺乏系统性优化。

Method: 从几何角度重新审视采样过程，提出SDM框架：1）通过分析ODE动力学特性，揭示早期高噪声阶段适合低阶求解器，后期非线性增强阶段需渐进使用高阶求解器；2）引入Wasserstein有界优化框架，形式化自适应步长调度，显式约束局部离散化误差。

Result: 在不增加训练或架构修改的情况下，在CIFAR-10、FFHQ和AFHQv2等标准基准上实现SOTA性能（FID分别为1.93、2.41和1.98），且相比现有采样器减少了函数评估次数。

Conclusion: SDM通过将数值求解器与扩散轨迹内在特性对齐，提供了一种原则性的自适应采样框架，有效降低了扩散模型的采样成本，为实际部署提供了新思路。

Abstract: Diffusion-based generative models have achieved remarkable performance across various domains, yet their practical deployment is often limited by high sampling costs. While prior work focuses on training objectives or individual solvers, the holistic design of sampling, specifically solver selection and scheduling, remains dominated by static heuristics. In this work, we revisit this challenge through a geometric lens, proposing SDM, a principled framework that aligns the numerical solver with the intrinsic properties of the diffusion trajectory. By analyzing the ODE dynamics, we show that efficient low-order solvers suffice in early high-noise stages while higher-order solvers can be progressively deployed to handle the increasing non-linearity of later stages. Furthermore, we formalize the scheduling by introducing a Wasserstein-bounded optimization framework. This method systematically derives adaptive timesteps that explicitly bound the local discretization error, ensuring the sampling process remains faithful to the underlying continuous dynamics. Without requiring additional training or architectural modifications, SDM achieves state-of-the-art performance across standard benchmarks, including an FID of 1.93 on CIFAR-10, 2.41 on FFHQ, and 1.98 on AFHQv2, with a reduced number of function evaluations compared to existing samplers. Our code is available at https://github.com/aiimaginglab/sdm.

</details>


### [91] [Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL](https://arxiv.org/abs/2602.12636)
*Xin Liu,Yixuan Li,Yuhui Chen,Yuxing Qin,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: 本文提出DEG框架，通过视频生成模型和双粒度对比奖励，在无人类标注的情况下实现样本高效的密集奖励生成，用于强化学习中的具身操作任务。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的奖励设计是具身操作任务的重大挑战。传统的轨迹成功奖励稀疏性严重限制了样本效率，而现有密集奖励方法依赖高质量人工标注或大量专家监督，难以广泛应用。

Method: 利用大规模视频生成模型的先验知识，仅需少量专家视频进行领域适应，为每轮RL episode生成专用任务指导视频。提出双粒度奖励机制，在对比自监督潜在空间中平衡粗粒度探索和细粒度匹配，引导智能体顺序逼近生成的指导视频。

Result: 在18个仿真和现实世界任务上的实验表明，DEG不仅能作为高效探索刺激帮助智能体快速发现稀疏成功奖励，还能独立引导有效强化学习和稳定策略收敛。

Conclusion: DEG框架无需人工标注即可生成样本高效的密集奖励，显著提升了强化学习在具身操作任务中的探索效率和训练稳定性。

Abstract: Designing suitable rewards poses a significant challenge in reinforcement learning (RL), especially for embodied manipulation. Trajectory success rewards are suitable for human judges or model fitting, but the sparsity severely limits RL sample efficiency. While recent methods have effectively improved RL via dense rewards, they rely heavily on high-quality human-annotated data or abundant expert supervision. To tackle these issues, this paper proposes Dual-granularity contrastive reward via generated Episodic Guidance (DEG), a novel framework to seek sample-efficient dense rewards without requiring human annotations or extensive supervision. Leveraging the prior knowledge of large video generation models, DEG only needs a small number of expert videos for domain adaptation to generate dedicated task guidance for each RL episode. Then, the proposed dual-granularity reward that balances coarse-grained exploration and fine-grained matching, will guide the agent to efficiently approximate the generated guidance video sequentially in the contrastive self-supervised latent space, and finally complete the target task. Extensive experiments on 18 diverse tasks across both simulation and real-world settings show that DEG can not only serve as an efficient exploration stimulus to help the agent quickly discover sparse success rewards, but also guide effective RL and stable policy convergence independently.

</details>


### [92] [Quantization-Robust LLM Unlearning via Low-Rank Adaptation](https://arxiv.org/abs/2602.13151)
*João Vitor Boer Abitante,Joana Meneguzzo Pasquali,Luan Fonseca Garcia,Ewerton de Oliveira,Thomas da Silva Paula,Rodrigo C. Barros,Lucas S. Kupssinskü*

Main category: cs.LG

TL;DR: 该论文揭示了后训练量化会削弱LLM遗忘效果的问题，并提出通过LoRA适配器进行量化鲁棒遗忘的方法，在4-bit量化下显著提升了遗忘后模型的效用并减少了隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 实际部署中需要对训练好的模型进行量化以实现高效推理，但激进的4-bit量化会掩盖或擦除遗忘更新，导致量化模型恢复至遗忘前的行为，现有全参数微调产生的参数变化太小而无法在量化后保留。

Method: 提出量化鲁棒遗忘方法：冻结基础模型，使用低秩适应(LoRA)将遗忘更新集中在可训练适配器中，使有效更新能在量化后得以保留。

Result: 在Llama-2-7B和MUSE数据集上，LoRA将4-bit量化模型的效用提升了7.93分，隐私泄露指标从-25.68改善至-5.86，同时保持强遗忘效果（记忆指标接近0）。

Conclusion: 采用LoRA进行机器遗忘在需要量化的部署场景中具有显著优势，能有效平衡遗忘效果、模型效用和隐私保护。

Abstract: Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.

</details>


### [93] [SLA2: Sparse-Linear Attention with Learnable Routing and QAT](https://arxiv.org/abs/2602.12675)
*Jintao Zhang,Haoxu Wang,Kai Jiang,Kaiwen Zheng,Youhe Jiang,Ion Stoica,Jianfei Chen,Jun Zhu,Joseph E. Gonzalez*

Main category: cs.LG

TL;DR: 针对稀疏线性注意力(SLA)在视频生成扩散模型中的启发式分割次优问题及分解不匹配缺陷，本文提出SLA2，通过引入可学习路由器动态选择注意力机制、采用可学习比率实现更忠实的稀疏-线性注意力融合，并结合量化感知微调的低比特注意力设计，最终在视频扩散模型上实现97%的注意力稀疏度和18.6倍加速比，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏线性注意力(SLA)存在两个核心问题：一是依赖基于注意力权重幅值的启发式分割策略，导致计算分配次优；二是SLA与稀疏注意力和线性注意力的直接分解之间存在理论不匹配。这些问题限制了扩散模型在视频生成任务中的加速效率和性能表现，亟需设计更优的注意力机制来提升计算效率。

Method: SLA2提出三阶段改进方法：(I)设计可学习路由器，根据输入特征动态决策每个注意力计算应分配至稀疏分支或线性分支，替代启发式规则；(II)重构稀疏-线性注意力公式，引入可学习比率参数更精确地融合两个分支的输出，确保数学一致性；(III)创新性地结合稀疏注意力与低比特注意力，通过量化感知微调技术降低量化误差，进一步压缩计算开销。

Result: 在视频扩散模型上的实验表明，SLA2能够达到97%的注意力稀疏度，实现18.6倍的注意力计算加速比，同时完全保持生成视频的视觉质量和语义一致性。该方法在高效推理与生成质量之间取得了显著平衡。

Conclusion: SLA2通过可学习的动态路由机制和更优的数学建模，有效解决了SLA的理论缺陷和效率瓶颈，为扩散模型在视频生成等计算密集型任务中的部署提供了高效的注意力解决方案，证明了学习而非启发式设计在注意力优化中的重要性。

Abstract: Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition into sparse and linear attention. We propose SLA2, which introduces (I) a learnable router that dynamically selects whether each attention computation should use sparse or linear attention, (II) a more faithful and direct sparse-linear attention formulation that uses a learnable ratio to combine the sparse and linear attention branches, and (III) a sparse + low-bit attention design, where low-bit attention is introduced via quantization-aware fine-tuning to reduce quantization error. Experiments show that on video diffusion models, SLA2 can achieve 97% attention sparsity and deliver an 18.6x attention speedup while preserving generation quality.

</details>


### [94] [Trust the uncertain teacher: distilling dark knowledge via calibrated uncertainty](https://arxiv.org/abs/2602.12687)
*Jeonghyun Kim,SooKyung Kim,Richeng Xuan,Hyunsoo Cho*

Main category: cs.LG

TL;DR: 传统知识蒸馏教师模型过度自信导致分布脆弱，无法有效传递暗知识。本文提出校准不确定性蒸馏(CUD)，通过重塑教师预测分布平衡准确性与校准性，显著提升学生模型的准确性、分布外校准性和长尾可靠性。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏的本质是传递教师模型的"暗知识"——揭示类别关联和不确定性的细微概率模式。然而，标准交叉熵训练的教师产生过度自信的尖锐分布，这种脆弱性不仅阻碍表示级迁移，在高基数任务中尤为严重，还导致学生模型在分布偏移下鲁棒性差、校准错误。

Method: 提出校准不确定性蒸馏(CUD)框架，在迁移前直接塑造教师预测分布。该方法使教师在不确定性具有信息量时主动揭示，引导学生从校准目标而非锐化确定性中学习，实现准确性与校准性的平衡。

Result: 在多样化基准测试中，CUD训练的学生模型相比基线方法在准确性、分布偏移下的校准性以及对模糊长尾输入的可靠性方面均取得显著提升。

Conclusion: CUD通过校准教师预测分布有效解决了知识蒸馏中的过度自信问题，使暗知识更忠实地可获取。该方法为构建更准确、鲁棒和可靠的轻量级模型提供了有效途径，特别适用于现实世界中的分布偏移和长尾场景。

Abstract: The core of knowledge distillation lies in transferring the teacher's rich 'dark knowledge'-subtle probabilistic patterns that reveal how classes are related and the distribution of uncertainties. While this idea is well established, teachers trained with conventional cross-entropy often fail to preserve such signals. Their distributions collapse into sharp, overconfident peaks that appear decisive but are in fact brittle, offering little beyond the hard label or subtly hindering representation-level transfer. This overconfidence is especially problematic in high-cardinality tasks, where the nuances among many plausible classes matter most for guiding a compact student. Moreover, such brittle targets reduce robustness under distribution shift, leaving students vulnerable to miscalibration in real-world conditions. To address this limitation, we revisit distillation from a distributional perspective and propose Calibrated Uncertainty Distillation (CUD), a framework designed to make dark knowledge more faithfully accessible. Instead of uncritically adopting the teacher's overconfidence, CUD encourages teachers to reveal uncertainty where it is informative and guides students to learn from targets that are calibrated rather than sharpened certainty. By directly shaping the teacher's predictive distribution before transfer, our approach balances accuracy and calibration, allowing students to benefit from both confident signals on easy cases and structured uncertainty on hard ones. Across diverse benchmarks, CUD yields students that are not only more accurate, but also more calibrated under shift and more reliable on ambiguous, long-tail inputs.

</details>


### [95] [Uncovering spatial tissue domains and cell types in spatial omics through cross-scale profiling of cellular and genomic interactions](https://arxiv.org/abs/2602.12651)
*Rui Yan,Xiaohan Xing,Xun Wang,Zixia Zhou,Md Tauhidul Islam,Lei Xing*

Main category: cs.LG

TL;DR: 本研究提出CellScape，一种用于空间转录组学数据分析的深度学习框架。该框架通过联合建模细胞的空间相互作用与基因组关系，克服数据噪声和复杂性挑战，实现更精准的空间域分割和生物学模式发现。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学数据固有的噪声、高维度及结构复杂性，使得现有计算方法难以有效解析空间相互作用与基因组内在关系之间的复杂关联，从而限制了组织微环境中关键生物学模式的识别。

Method: CellScape采用深度学习方法，同步建模组织空间中细胞间相互作用和细胞间基因组学关系，构建能够无缝整合空间信号与潜在基因调控机制的综合表征。

Result: 该技术能够揭示具有生物学意义的模式，显著提升空间域分割性能，并支持跨多种转录组数据集的全面空间细胞分析。

Conclusion: CellScape为空间转录组学数据提供了精确且通用的深度分析与解释框架，为研究细胞身份、功能与组织微环境空间背景之间的关联提供了有力工具。

Abstract: Cellular identity and function are linked to both their intrinsic genomic makeup and extrinsic spatial context within the tissue microenvironment. Spatial transcriptomics (ST) offers an unprecedented opportunity to study this, providing in situ gene expression profiles at single-cell resolution and illuminating the spatial and functional organization of cells within tissues. However, a significant hurdle remains: ST data is inherently noisy, large, and structurally complex. This complexity makes it intractable for existing computational methods to effectively capture the interplay between spatial interactions and intrinsic genomic relationships, thus limiting our ability to discern critical biological patterns. Here, we present CellScape, a deep learning framework designed to overcome these limitations for high-performance ST data analysis and pattern discovery. CellScape jointly models cellular interactions in tissue space and genomic relationships among cells, producing comprehensive representations that seamlessly integrate spatial signals with underlying gene regulatory mechanisms. This technique uncovers biologically informative patterns that improve spatial domain segmentation and supports comprehensive spatial cellular analyses across diverse transcriptomics datasets, offering an accurate and versatile framework for deep analysis and interpretation of ST data.w

</details>


### [96] [Flow Matching from Viewpoint of Proximal Operators](https://arxiv.org/abs/2602.12683)
*Kenji Fukumizu,Wei Huang,Han Bao,Shuntuo Xu,Nisha Chandramoothy*

Main category: cs.LG

TL;DR: 本文揭示了最优传输条件流匹配（OT-CFM）可通过扩展Brenier势函数获得精确的近端算子表达，无需假设目标分布密度存在。同时证明了小批量训练的收敛性及在流形支撑目标分布下模型的法向指数收缩特性。


<details>
  <summary>Details</summary>
Motivation: 动态生成模型OT-CFM通常依赖目标分布密度假设，且其优化结构与流形上的动力学行为缺乏理论保证。本文旨在通过近端算子框架重新表述OT-CFM，放宽密度假设，并建立其在流形数据分布下的收敛性与稳定性理论。

Method: 采用扩展Brenier势函数构建近端优化框架；运用凸分析中的第二次微分理论；分析小批量近似在批量趋于无穷时的收敛性。

Result: 1) 获得精确的近端算子形式及向量场的显式表达式；2) 证明小批量OT-CFM收敛于总体形式；3) 证实流形支撑下OT-CFM的终端正常双曲性，即经时间重缩放后，法向呈指数收缩而切向保持中性。

Conclusion: 本研究为OT-CFM提供了严格的理论基础，消除了密度假设限制，并揭示了其在低维流形数据上的内在动力学特性，为生成模型的理论与实践提供了新视角。

Abstract: We reformulate Optimal Transport Conditional Flow Matching (OT-CFM), a class of dynamical generative models, showing that it admits an exact proximal formulation via an extended Brenier potential, without assuming that the target distribution has a density. In particular, the mapping to recover the target point is exactly given by a proximal operator, which yields an explicit proximal expression of the vector field. We also discuss the convergence of minibatch OT-CFM to the population formulation as the batch size increases. Finally, using second epi-derivatives of convex potentials, we prove that, for manifold-supported targets, OT-CFM is terminally normally hyperbolic: after time rescaling, the dynamics contracts exponentially in directions normal to the data manifold while remaining neutral along tangential directions.

</details>


### [97] [Leverage-Weighted Conformal Prediction](https://arxiv.org/abs/2602.12693)
*Shreyas Fadnavis*

Main category: cs.LG

TL;DR: 本文提出杠杆加权共形预测(LWCP)，通过用统计杠杆函数加权非符合性得分，从设计矩阵几何结构而非辅助模型中推导出自适应性，在保持有限样本边际有效性的同时，消除了传统共形预测的条件覆盖差距。


<details>
  <summary>Details</summary>
Motivation: 传统分割共形预测虽提供分布无关的有限样本边际覆盖，但产生固定宽度区间，导致低方差区域过度覆盖、高方差区域覆盖不足；现有自适应方法需训练辅助模型，增加计算成本与调参负担。

Method: 提出杠杆加权共形预测(LWCP)，将非符合性得分乘以统计杠杆(帽子矩阵对角线)的权重函数，使预测区间宽度根据数据点杠杆值自动调整，无需拟合额外模型，仅需选择权重函数。

Result: 理论保证：(1)对任意权重函数均保持有限样本边际有效性；(2)当异方差性通过杠杆因子化时，实现渐近最优条件覆盖且几乎不增加区间宽度；(3)高斯假设下恢复经典预测区间形式并保留分布无关性；(4)随机杠杆近似精确保持覆盖且宽度扰动可控；(5)传统CP存在样本量无关的条件覆盖间隙，而LWCP可完全消除。实验证实该方法显著降低条件覆盖差异。

Conclusion: LWCP仅需极小计算开销和单一权重函数选择，无需超参数即可实现自适应预测，在保持分布无关保证的同时达成优异条件覆盖性能，为共形预测提供了更简洁有效的解决方案。

Abstract: Split conformal prediction provides distribution-free prediction intervals with finite-sample marginal coverage, but produces constant-width intervals that overcover in low-variance regions and undercover in high-variance regions. Existing adaptive methods require training auxiliary models. We propose Leverage-Weighted Conformal Prediction (LWCP), which weights nonconformity scores by a function of the statistical leverage -- the diagonal of the hat matrix -- deriving adaptivity from the geometry of the design matrix rather than from auxiliary model fitting. We prove that LWCP preserves finite-sample marginal validity for any weight function; achieves asymptotically optimal conditional coverage at essentially no width cost when heteroscedasticity factors through leverage; and recovers the form and width of classical prediction intervals under Gaussian assumptions while retaining distribution-free guarantees. We further establish that randomized leverage approximations preserve coverage exactly with controlled width perturbation, and that vanilla CP suffers a persistent, sample-size-independent conditional coverage gap that LWCP eliminates. The method requires no hyperparameters beyond the choice of weight function and adds negligible computational overhead to vanilla CP. Experiments on synthetic and real data confirm the theoretical predictions, demonstrating substantial reductions in conditional coverage disparity across settings.

</details>


### [98] [GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories](https://arxiv.org/abs/2602.12828)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: 本文提出GRAIL框架，通过双曲线空间中的结构化几何表示和结构感知检索，改进电子健康记录(EHR)的下次就诊多类型事件预测，在MIMIC-IV数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从纵向电子健康记录预测未来临床事件面临三大挑战：临床事件稀疏且类型多样、医学术语具有层次结构、以及大语言模型在处理长结构化病史时易产生幻觉。现有方法难以同时解决这些问题。

Method: GRAIL框架核心方法包括：(1)构建统一临床图，融合确定性编码系统层次结构与数据驱动的事件类型间时序关联；(2)在双曲线空间中嵌入该图以捕获层次关系；(3)将每次就诊表示为概率性中心事件，以去噪稀疏观测；(4)推理时检索符合层次和时序进展的临床合理事件；(5)可选地使用大语言模型作为约束重排序器优化预测。

Result: 在MIMIC-IV数据集上的实验表明，GRAIL在多类型下次就诊事件预测任务上持续提升性能，并产生更符合医学层次结构的预测结果。

Conclusion: GRAIL通过结合几何表示学习与结构感知检索，有效解决了EHR预测中的稀疏性、层次性和幻觉问题，为临床事件预测提供了新的有效框架。

Abstract: Predicting future clinical events from longitudinal electronic health records (EHRs) is challenging due to sparse multi-type clinical events, hierarchical medical vocabularies, and the tendency of large language models (LLMs) to hallucinate when reasoning over long structured histories. We study next-visit event prediction, which aims to forecast a patient's upcoming clinical events based on prior visits. We propose GRAIL, a framework that models longitudinal EHRs using structured geometric representations and structure-aware retrieval. GRAIL constructs a unified clinical graph by combining deterministic coding-system hierarchies with data-driven temporal associations across event types, embeds this graph in hyperbolic space, and summarizes each visit as a probabilistic Central Event that denoises sparse observations. At inference time, GRAIL retrieves a structured set of clinically plausible future events aligned with hierarchical and temporal progression, and optionally refines their ranking using an LLM as a constrained inference-time reranker. Experiments on MIMIC-IV show that GRAIL consistently improves multi-type next-visit prediction and yields more hierarchy-consistent forecasts.

</details>


### [99] [TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)](https://arxiv.org/abs/2602.12833)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: 本文提出TRACE框架，通过双记忆架构和智能体组件实现冻结LLM的纵向临床推理，在MIMIC-IV数据集上显著提升了预测准确性和安全性，同时保持推理成本有界并提供可解释的推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型蕴含丰富医学知识，但在处理纵向患者轨迹时表现不佳，原因在于临床状态演变、不规则时间间隔和异质性事件。现有微调或检索增强策略存在计算开销、隐私限制和长上下文不稳定性等问题。

Method: 提出TRACE框架，采用静态全局协议（编码机构临床规则）和动态个体协议（追踪患者特定状态）的双记忆架构，通过路由、推理、审计和管理四个智能体组件协调结构化记忆，实现时间推理和状态演化，并通过结构化状态压缩限制推理成本。

Result: 在MIMIC-IV纵向临床事件流评估中，TRACE相比长上下文和检索增强基线显著提升了下一事件预测准确率、协议依从性和临床安全性，同时生成可解释且可审计的推理轨迹。

Conclusion: 该框架通过结构化上下文管理而非扩展上下文窗口或更新参数，为LLM在纵向临床推理中的应用提供了高效、安全且可解释的解决方案，具有重要临床价值。

Abstract: Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a framework that enables temporal clinical reasoning with frozen LLMs by explicitly structuring and maintaining context rather than extending context windows or updating parameters. TRACE operates over a dual-memory architecture consisting of a static Global Protocol encoding institutional clinical rules and a dynamic Individual Protocol tracking patient-specific state. Four agentic components, Router, Reasoner, Auditor, and Steward, coordinate over this structured memory to support temporal inference and state evolution. The framework maintains bounded inference cost via structured state compression and selectively audits safety-critical clinical decisions. Evaluated on longitudinal clinical event streams from MIMIC-IV, TRACE significantly improves next-event prediction accuracy, protocol adherence, and clinical safety over long-context and retrieval-augmented baselines, while producing interpretable and auditable reasoning traces.

</details>


### [100] [Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning](https://arxiv.org/abs/2602.12708)
*Jon Irureta,Gorka Azkune,Jon Imaz,Aizea Lojo,Javier Fernandez-Marques*

Main category: cs.LG

TL;DR: 针对垂直联邦学习中样本对齐不现实的假设，本文提出Split-MoPE框架，融合分割学习与预定义专家混合架构，通过预训练编码器实现单轮通信的SOTA性能，同时具备抗恶意参与方和样本可解释性等优势。


<details>
  <summary>Details</summary>
Motivation: 现有垂直联邦学习框架普遍依赖参与方样本完全对齐的理想化假设，但这一前提在金融、医疗等隐私敏感领域的实际应用中极少成立，导致数据利用率低下且模型性能受限。

Method: 提出Split-MoPE创新框架，将分割学习（Split Learning）与特化的预定义专家混合（MoPE）架构相结合。不同于动态路由的标准MoE，MoPE采用预定义专家处理特定数据对齐情况，并利用目标领域的预训练编码器进行特征提取。

Result: 在CIFAR-10/100和威斯康星乳腺癌数据集上的广泛实验表明，Split-MoPE仅需单轮通信即可达到SOTA性能，显著降低通信开销；在高数据缺失场景下持续优于LASER和Vertical SplitNN等先进系统，同时具备对恶意/噪声参与方的内在鲁棒性和样本级可解释性。

Conclusion: 该框架有效解决了垂直联邦学习中样本未对齐的核心挑战，通过预定义专家架构最大化数据利用效率，为隐私保护下的跨机构协作提供了实用、高效且可解释的解决方案。

Abstract: Vertical Federated Learning (VFL) has emerged as a critical paradigm for collaborative model training in privacy-sensitive domains such as finance and healthcare. However, most existing VFL frameworks rely on the idealized assumption of full sample alignment across participants, a premise that rarely holds in real-world scenarios. To bridge this gap, this work introduces Split-MoPE, a novel framework that integrates Split Learning with a specialized Mixture of Predefined Experts (MoPE) architecture. Unlike standard Mixture of Experts (MoE), where routing is learned dynamically, MoPE uses predefined experts to process specific data alignments, effectively maximizing data usage during both training and inference without requiring full sample overlap. By leveraging pretrained encoders for target data domains, Split-MoPE achieves state-of-the-art performance in a single communication round, significantly reducing the communication footprint compared to multi-round end-to-end training. Furthermore, unlike existing proposals that address sample misalignment, this novel architecture provides inherent robustness against malicious or noisy participants and offers per-sample interpretability by quantifying each collaborator's contribution to each prediction. Extensive evaluations on vision (CIFAR-10/100) and tabular (Breast Cancer Wisconsin) datasets demonstrate that Split-MoPE consistently outperforms state-of-the-art systems such as LASER and Vertical SplitNN, particularly in challenging scenarios with high data missingness.

</details>


### [101] [Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models](https://arxiv.org/abs/2602.12846)
*Zesheng Hong,Jiadong Yu,Hui Pan*

Main category: cs.LG

TL;DR: 针对RLVR范式中出现的"归一化挤压"病理现象——即模式寻求策略梯度与有限采样相互作用，作为高通似然滤波器导致正确但罕见的推理路径概率趋于零——本文提出ARTS方法。该方法解耦生成与验证，采用流匹配目标将验证器转化为概率流守恒估计器，在MATH-500上达到74.6% BoN@16，与全微调模型相当，并在长尾子集上显著优于崩溃的RL基线。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习与可验证奖励结合的方法虽能有效增强大语言模型推理能力，但存在根本性缺陷：策略优化的模式偏好与采样局限性会系统性消除那些正确但低概率的推理轨迹。这种"归一化挤压"现象造成模型潜在多样性的不可逆损失，限制了其在复杂推理任务中的泛化能力，亟需新的技术路径解决。

Method: 提出Amortized Reasoning Tree Search (ARTS)。核心创新在于：1) 解耦生成与验证，避免强制内化导致的分布坍缩；2) 设计流匹配目标，将验证器转化为概率流守恒估计器，实现稀疏高熵搜索空间中的稳健导航；3) 通过摊销推理树搜索保留基础模型的隐式多样性。

Result: 在MATH-500基准测试中，ARTS获得74.6%的BoN@16准确率，与全微调策略的74.7%无显著差异。关键突破在于长尾子集上的表现：传统耦合RL优化在该子集上完全崩溃（0% pass@k），而ARTS成功恢复显著性能，证明了其处理稀有推理路径的有效性。

Conclusion: 本研究揭示了RLVR范式的根本性病理并提出了有效解决方案。ARTS通过解耦验证与生成的设计，不仅避免了归一化挤压，还保持了与全微调相当的性能水平。结果表明，在复杂推理任务中，分离式架构比耦合式优化更具鲁棒性，特别是对于挖掘低概率正确推理路径具有重要价值。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has established itself as the dominant paradigm for instilling rigorous reasoning capabilities in Large Language Models. While effective at amplifying dominant behaviors, we identify a critical pathology in this alignment process: the systematic suppression of valid but rare (low-likelihood under the base model distribution) reasoning paths. We theoretically characterize this phenomenon as a "Normalization Squeeze," where the interplay between mode-seeking policy gradients and finite sampling acts as a high-pass likelihood filter, driving the probability of rare correct traces to statistical extinction. To counteract this collapse without discarding the base model's latent diversity, we propose Amortized Reasoning Tree Search (ARTS). Unlike standard approaches that force internalization via parameter updates, ARTS prioritizes deliberation by decoupling generation from verification. We introduce a Flow Matching objective that repurposes the verifier to estimate the conservation of probability flow, enabling robust navigation through sparse, high-entropy search spaces where traditional discriminative objectives fail. Extensive experiments on the MATH-500 benchmark demonstrate that ARTS achieves a performance of 74.6% (BoN@16), effectively matching fully fine-tuned policies (74.7%) without modifying the generative backbone. Crucially, on the long-tail subset where coupled RL optimization collapses to 0% pass@k, ARTS uniquely recovers significant performance, suggesting that disentangling verification from generation offers a more robust pathway for solving complex reasoning tasks.

</details>


### [102] [ADEPT: RL-Aligned Agentic Decoding of Emotion via Evidence Probing Tools -- From Consensus Learning to Ambiguity-Driven Emotion Reasoning](https://arxiv.org/abs/2602.12714)
*Esther Sun,Bo-Hao Su,Abinay Reddy Naini,Shinji Watanabe,Carlos Busso*

Main category: cs.LG

TL;DR: ADEPT框架将语音情感识别从单轮预测重构为多轮探究过程，通过将语音大模型转化为智能体，结合语义与声学探针工具以及GRPO与证据信任门机制，实现了基于可验证声学证据的情感推理，显著提升了主次情感识别精度与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有语音大模型(SLLMs)在情感推理中往往产生无事实依据、带有文本偏置的判断，缺乏可验证的声学证据；而自监督语音编码器（如WavLM）虽能提供强声学表征，但其判别性模型缺乏可解释性。同时，传统方法将情感标注中的少数观点视为噪声，忽视了人类情感的固有复杂性与情感共现特性。

Method: 提出ADEPT框架：1）将SLLM转化为智能体，维护动态演化的候选情感集合；2）构建"候选生成-证据收集-裁决"结构化管道，自适应调用专用语义和声学探针工具；3）实现从共识学习到模糊驱动情感推理的范式转变，将少数标注作为信息性感知信号；4）集成组相对策略优化(GRPO)与证据信任门，显式耦合工具使用行为与预测质量，强制实现证据驱动推理。

Result: 实验表明，ADEPT在多数实验设置下均能提升主要情感识别准确率，同时显著改善次要情感的表征能力，并生成基于可审计声学和语义证据的解释。

Conclusion: ADEPT成功弥合了SLLMs与语音编码器之间的鸿沟，通过工具化、证据驱动的智能体推理机制，为可解释、可验证的语音情感识别提供了新范式，有效处理了情感复杂性与模糊性。

Abstract: Speech Large Language Models (SLLMs) enable high-level emotion reasoning but often produce ungrounded, text-biased judgments without verifiable acoustic evidence. In contrast, self-supervised speech encoders such as WavLM provide strong acoustic representations yet remain opaque discriminative models with limited interpretability. To bridge this gap, we introduce ADEPT (Agentic Decoding of Emotion via Evidence Probing Tools), a framework that reframes emotion recognition as a multi-turn inquiry process rather than a single-pass prediction. ADEPT transforms an SLLM into an agent that maintains an evolving candidate emotion set and adaptively invokes dedicated semantic and acoustic probing tools within a structured pipeline of candidate generation, evidence collection, and adjudication. Crucially, ADEPT enables a paradigm shift from consensus learning to ambiguity-driven emotion reasoning. Since human affect exhibits inherent complexity and frequent co-occurrence of emotions, we treat minority annotations as informative perceptual signals rather than discarding them as noise. Finally, we integrate Group Relative Policy Optimization (GRPO) with an Evidence Trust Gate to explicitly couple tool-usage behaviors with prediction quality and enforce evidence-grounded reasoning. Experiments show that ADEPT improves primary emotion accuracy in most settings while substantially improving minor emotion characterization, producing explanations grounded in auditable acoustic and semantic evidence.

</details>


### [103] [X-VORTEX: Spatio-Temporal Contrastive Learning for Wake Vortex Trajectory Forecasting](https://arxiv.org/abs/2602.12869)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: 提出X-VORTEX时空对比学习框架，基于增强重叠理论从无标签LiDAR点云序列中学习物理感知表征，仅用1%标注数据即可实现尾涡精准定位与轨迹预测，解决了稀疏扫描与动态演化带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 尾涡对航空安全与流量管理构成重大威胁，现有方法将每帧扫描视为独立全监督分割问题，忽略了时序结构且无法扩展至实际采集的海量未标注数据，同时点级标注成本过高。

Method: 构建时空对比学习框架：通过时间子采样与空间掩码生成同一飞行事件的弱扰动与强增强序列对，迫使模型对齐缺失帧与部分观测下的表征；架构采用时间分布几何编码器提取单帧特征，并结合序列聚合器建模可变长序列的演化状态。

Result: 在超过百万帧的真实LiDAR数据集上，X-VORTEX仅使用1%标注数据即达到监督基线的尾涡中心定位性能，且学习的表征支持高精度轨迹预测。

Conclusion: 该方法有效解决了传感器稀疏性与时变涡旋动力学两大核心挑战，为尾涡追踪提供了可扩展的弱监督学习范式，显著降低了对标注数据的依赖。

Abstract: Wake vortices are strong, coherent air turbulences created by aircraft, and they pose a major safety and capacity challenge for air traffic management. Tracking how vortices move, weaken, and dissipate over time from LiDAR measurements is still difficult because scans are sparse, vortex signatures fade as the flow breaks down under atmospheric turbulence and instabilities, and point-wise annotation is prohibitively expensive. Existing approaches largely treat each scan as an independent, fully supervised segmentation problem, which overlooks temporal structure and does not scale to the vast unlabeled archives collected in practice. We present X-VORTEX, a spatio-temporal contrastive learning framework grounded in Augmentation Overlap Theory that learns physics-aware representations from unlabeled LiDAR point cloud sequences. X-VORTEX addresses two core challenges: sensor sparsity and time-varying vortex dynamics. It constructs paired inputs from the same underlying flight event by combining a weakly perturbed sequence with a strongly augmented counterpart produced via temporal subsampling and spatial masking, encouraging the model to align representations across missing frames and partial observations. Architecturally, a time-distributed geometric encoder extracts per-scan features and a sequential aggregator models the evolving vortex state across variable-length sequences. We evaluate on a real-world dataset of over one million LiDAR scans. X-VORTEX achieves superior vortex center localization while using only 1% of the labeled data required by supervised baselines, and the learned representations support accurate trajectory forecasting.

</details>


### [104] [Adaptive Structured Pruning of Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/2602.12744)
*Javidan Abdullayev,Maxime Devanne,Cyril Meyer,Ali Ismail-Fawaz,Jonathan Weber,Germain Forestier*

Main category: cs.LG

TL;DR: DSP是一种用于时间序列分类的自动结构化剪枝方法，通过实例稀疏损失和全局激活分析，无需预设剪枝率即可移除冗余滤波器，在128个UCR数据集上验证可实现58-75%的模型压缩并保持精度。


<details>
  <summary>Details</summary>
Motivation: 深度学习时间序列分类模型虽然性能优异，但高计算和内存需求限制了其在资源受限设备上的部署。现有结构化剪枝方法依赖人工调优的剪枝率等超参数，可扩展性和泛化能力有限。

Method: 提出动态结构化剪枝框架DSP，通过在训练中引入实例级稀疏损失诱导通道稀疏性，再通过全局激活分析识别并剪除冗余滤波器，完全无需预设剪枝率。

Result: 在128个UCR数据集上，对LITETime和InceptionTime两种先进架构进行验证，平均压缩率分别达58%和75%，同时保持分类精度。冗余分析证实DSP能生成紧凑且信息丰富的表示。

Conclusion: DSP为资源受限设备上可扩展且高效的时间序列分类模型部署提供了实用解决方案。

Abstract: Deep learning models for Time Series Classification (TSC) have achieved strong predictive performance but their high computational and memory requirements often limit deployment on resource-constrained devices. While structured pruning can address these issues by removing redundant filters, existing methods typically rely on manually tuned hyperparameters such as pruning ratios which limit scalability and generalization across datasets. In this work, we propose Dynamic Structured Pruning (DSP), a fully automatic, structured pruning framework for convolution-based TSC models. DSP introduces an instance-wise sparsity loss during training to induce channel-level sparsity, followed by a global activation analysis to identify and prune redundant filters without needing any predefined pruning ratio. This work tackles computational bottlenecks of deep TSC models for deployment on resource-constrained devices. We validate DSP on 128 UCR datasets using two different deep state-of-the-art architectures: LITETime and InceptionTime. Our approach achieves an average compression of 58% for LITETime and 75% for InceptionTime architectures while maintaining classification accuracy. Redundancy analyses confirm that DSP produces compact and informative representations, offering a practical path for scalable and efficient deep TSC deployment.

</details>


### [105] [Transporting Task Vectors across Different Architectures without Training](https://arxiv.org/abs/2602.12952)
*Filippo Rinaldi,Aniello Panariello,Giacomo Salici,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: Theseus是一种无需训练的方法，通过功能匹配和正交Procrustes分析，实现异构模型间任务更新的跨架构传输。


<details>
  <summary>Details</summary>
Motivation: 将大型预训练模型适配到下游任务会产生昂贵的任务特定参数更新。虽然近期研究表明可在相同架构模型间传输更新，但跨不同宽度模型的传输尚未得到充分探索。

Method: Theseus将任务更新定义为对中间表示的功能效应，而非直接参数匹配。通过正交Procrustes分析对齐表示空间，将任务向量传输形式化为观测激活上的功能匹配问题，获得保持更新几何的稳定闭式解。

Result: 在跨宽度的视觉和语言模型上评估显示，Theseus相比强基线具有一致性提升，且无需额外训练或反向传播。

Conclusion: 当从功能角度而非参数角度定义任务身份时，任务更新可在不同架构间实现有意义传输。

Abstract: Adapting large pre-trained models to downstream tasks often produces task-specific parameter updates that are expensive to relearn for every model variant. While recent work has shown that such updates can be transferred between models with identical architectures, transferring them across models of different widths remains largely unexplored. In this work, we introduce Theseus, a training-free method for transporting task-specific updates across heterogeneous models. Rather than matching parameters directly, we characterize a task update by the functional effect it induces on intermediate representations. We formalize task-vector transport as a functional matching problem on observed activations and show that, after aligning representation spaces via orthogonal Procrustes analysis, it admits a stable closed-form solution that preserves the geometry of the update. We evaluate Theseus on vision and language models across different widths, showing consistent improvements over strong baselines without additional training or backpropagation. Our results show that task updates can be meaningfully transferred across architectures when task identity is defined functionally rather than parametrically.

</details>


### [106] [Hierarchical Successor Representation for Robust Transfer](https://arxiv.org/abs/2602.12753)
*Changmin Yu,Máté Lengyel*

Main category: cs.LG

TL;DR: 本文针对经典后继表征（SR）的策略依赖性与谱扩散问题，提出分层后继表征（HSR）框架。HSR通过引入时间抽象学习对策略变化鲁棒的稳定状态特征，结合非负矩阵分解（NMF）获得稀疏低秩表征，实现多 compartment 环境中的高效任务迁移与大规模程序生成环境下的高效探索，为桥接无模型与基于模型的学习提供新范式。


<details>
  <summary>Details</summary>
Motivation: 经典SR虽能解耦预测动态与奖励以实现跨奖励配置的快速泛化，但存在两大局限：其一，策略依赖性——策略会因持续学习、环境非平稳性及任务需求变化而不断演变，导致已建立的预测表征失效；其二，在拓扑复杂环境中，SR遭受谱扩散问题，产生密集重叠特征，扩展性差。

Method: 提出分层后继表征（HSR），在构建预测表征时引入时间抽象机制，学习对策略变化具有鲁棒性的稳定状态特征。进一步应用非负矩阵分解（NMF）于HSR，提取稀疏、低秩的状态表征，以支持在多 compartment 环境中的样本高效迁移。

Result: HSR-NMF能发现可解释的拓扑结构，提供策略无关的分层地图，有效桥接无模型最优性与基于模型的灵活性。其时间扩展的预测结构还可驱动高效探索，成功扩展至大规模程序生成环境。

Conclusion: HSR通过时间抽象机制解决了经典SR的策略依赖与扩展性瓶颈，HSR-NMF进一步提供了稀疏、可解释的策略无关表征，在实现高效任务迁移的同时，也为大规模环境探索提供了新范式，为统一无模型与基于模型的学习方法奠定了重要基础。

Abstract: The successor representation (SR) provides a powerful framework for decoupling predictive dynamics from rewards, enabling rapid generalisation across reward configurations. However, the classical SR is limited by its inherent policy dependence: policies change due to ongoing learning, environmental non-stationarities, and changes in task demands, making established predictive representations obsolete. Furthermore, in topologically complex environments, SRs suffer from spectral diffusion, leading to dense and overlapping features that scale poorly. Here we propose the Hierarchical Successor Representation (HSR) for overcoming these limitations. By incorporating temporal abstractions into the construction of predictive representations, HSR learns stable state features which are robust to task-induced policy changes. Applying non-negative matrix factorisation (NMF) to the HSR yields a sparse, low-rank state representation that facilitates highly sample-efficient transfer to novel tasks in multi-compartmental environments. Further analysis reveals that HSR-NMF discovers interpretable topological structures, providing a policy-agnostic hierarchical map that effectively bridges model-free optimality and model-based flexibility. Beyond providing a useful basis for task-transfer, we show that HSR's temporally extended predictive structure can also be leveraged to drive efficient exploration, effectively scaling to large, procedurally generated environments.

</details>


### [107] [Closing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs](https://arxiv.org/abs/2602.12756)
*Xingyu Zhang,Hanyun Du,Zeen Song,Jianqi Zhang,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 针对LLM时间序列预测中开环自回归生成导致的误差累积问题，本文提出基于控制理论的F-LLM闭环框架，通过可学习残差估计器与反馈控制器主动稳定轨迹，理论证明误差有界性并在基准测试中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM时间序列预测采用朴素自回归策略，推理时以开环方式递归使用自身生成输出，造成误差累积（暴露偏差），导致长时序预测中出现显著轨迹漂移。

Method: 从控制理论视角重构自回归预测，提出F-LLM（反馈驱动LLM）闭环框架，引入可学习的残差估计器（Observer）和反馈控制器主动校正预测轨迹。

Result: 广泛实验验证F-LLM能显著抑制误差传播，在多个时间序列基准测试中实现优异性能。

Conclusion: 在基模型满足局部Lipschitz约束条件下，该闭环机制可理论保证误差均匀有界，为解决LLM时间序列预测的暴露偏差问题提供了有效方案。

Abstract: Large Language Models (LLMs) have recently shown exceptional potential in time series forecasting, leveraging their inherent sequential reasoning capabilities to model complex temporal dynamics. However, existing approaches typically employ a naive autoregressive generation strategy. We identify a critical theoretical flaw in this paradigm: during inference, the model operates in an open-loop manner, consuming its own generated outputs recursively. This leads to inevitable error accumulation (exposure bias), where minor early deviations cascade into significant trajectory drift over long horizons. In this paper, we reformulate autoregressive forecasting through the lens of control theory, proposing \textbf{F-LLM} (Feedback-driven LLM), a novel closed-loop framework. Unlike standard methods that passively propagate errors, F-LLM actively stabilizes the trajectory via a learnable residual estimator (Observer) and a feedback controller. Furthermore, we provide a theoretical guarantee that our closed-loop mechanism ensures uniformly bounded error, provided the base model satisfies a local Lipschitz constraint. Extensive experiments demonstrate that F-LLM significantly mitigates error propagation, achieving good performance on time series benchmarks.

</details>


### [108] [Extending confidence calibration to generalised measures of variation](https://arxiv.org/abs/2602.12975)
*Andrew Thompson,Vivek Desai*

Main category: cs.LG

TL;DR: 本文提出变异校准误差(VCE)指标，将ECE从仅评估置信度校准扩展至评估任意变异指标的校准，并在完美校准的合成数据上验证了其随样本量增加而趋近于零的理想性质。


<details>
  <summary>Details</summary>
Motivation: 传统ECE仅评估最大概率的校准，未能利用概率分布的完整变异信息。尽管香农熵等度量可衡量分布变异，但缺乏系统性的校准评估框架，导致分类器校准性能评估不够全面。

Method: 将ECE方法推广至任意变异指标，构建VCE度量。通过设计完美校准的合成预测进行数值实验，验证指标性质。

Result: 在完美校准场景下，VCE随样本量增大而收敛至零；相比之下，文献中的UCE指标不具备此理想性质。

Conclusion: VCE提供了一个统一的校准评估框架，不仅能评估任意变异指标，还具备良好的统计性质，为分类器校准提供了更全面的评估工具。

Abstract: We propose the Variation Calibration Error (VCE) metric for assessing the calibration of machine learning classifiers. The metric can be viewed as an extension of the well-known Expected Calibration Error (ECE) which assesses the calibration of the maximum probability or confidence. Other ways of measuring the variation of a probability distribution exist which have the advantage of taking into account the full probability distribution, for example the Shannon entropy. We show how the ECE approach can be extended from assessing confidence calibration to assessing the calibration of any metric of variation. We present numerical examples upon synthetic predictions which are perfectly calibrated by design, demonstrating that, in this scenario, the VCE has the desired property of approaching zero as the number of data samples increases, in contrast to another entropy-based calibration metric (the UCE) which has been proposed in the literature.

</details>


### [109] [Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling](https://arxiv.org/abs/2602.12976)
*Jin Li,Kleanthis Malialis,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.LG

TL;DR: 本文针对非平稳环境下未标记流数据的异常检测难题，提出VAE++ESDD方法。该方法创新性地结合增量学习与两级集成，通过变分自编码器集成实现异常预测，并集成统计概念漂移检测器应对分布变化，在极低异常率场景下显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 数字时代产生海量未标记流数据，其中异常事件识别至关重要。然而，非平稳环境中的概念漂移会导致传统模型性能持续退化，现有方法难以同时应对数据稀缺性和分布动态变化的双重挑战。

Method: 设计VAE++ESDD框架，采用增量学习机制与两级集成架构：底层为多个变分自编码器（VAE）组成的异常预测集成，顶层为基于统计检验的概念漂移检测器集成。通过动态模型更新与漂移自适应机制处理流数据。

Result: 在具有极低异常率（严重或极度）和多样化漂移特性的真实及合成数据集上，VAE++ESDD展现出卓越性能，显著优于强基线算法和最先进方法，验证了其有效性与鲁棒性。

Conclusion: 该研究证实了集成化增量学习框架在流数据异常检测中的优势，为动态环境下的实时异常监测提供了实用解决方案，对工业物联网、金融风控等实际应用场景具有重要价值。

Abstract: In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.

</details>


### [110] [Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery](https://arxiv.org/abs/2602.13021)
*Jing Xiao,Xinhai Chen,Jiaming Peng,Qinglin Wang,Menghan Jia,Zhiquan Lai,Guangping Yu,Dongsheng Li,Tiejun Li,Jie Liu*

Main category: cs.LG

TL;DR: 该论文针对符号回归中的"伪方程陷阱"问题，提出PG-SR先验引导框架，通过三阶段流水线（热身、进化、精炼）和先验退火约束评估机制，显式编码领域先验以确保科学一致性，理论证明可降低Rademacher复杂度并获得更紧泛化界，实验验证在多领域超越SOTA且对噪声和数据稀缺具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有符号回归方法过度依赖经验风险最小化，缺乏显式科学约束，导致虽拟合观测数据但与基本科学原理不一致的"伪方程陷阱"问题，无法可靠揭示自然现象背后的真实规律。

Method: 提出PG-SR三阶段框架：1)热身阶段初始化种群；2)进化阶段采用先验退火约束评估(PACE)机制，通过可执行约束程序编码领域先验并逐步引导搜索；3)精炼阶段优化最终方程。全程通过先验约束检查器确保科学一致性。

Result: 理论证明PG-SR降低假设空间的Rademacher复杂度，提供伪方程避免保证；实验表明在多样领域超越现有基线，对先验质量变化、数据噪声和样本稀缺保持稳定性能。

Conclusion: PG-SR通过将领域知识显式建模为可执行约束并渐进式融入搜索过程，有效规避伪方程陷阱，为从数据中可靠发现科学原理提供了理论保障和实践框架。

Abstract: Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.

</details>


### [111] [Geometric Manifold Rectification for Imbalanced Learning](https://arxiv.org/abs/2602.13045)
*Xubin Wang,Qing Li,Weijia Jia*

Main category: cs.LG

TL;DR: 本文提出GMR（几何流形校正）框架，通过局部几何先验解决不平衡表格数据的分类问题。该方法采用逆距离加权kNN投票的自适应距离度量进行几何置信度估计，并实施非对称清洗策略——对多数类样本严格清理，对少数类样本设置保护上限，避免误删重要样本。在多个基准数据集上的实验表明，GMR与现有强采样基线方法具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 不平衡分类是机器学习中的严峻挑战，特别是当表格数据存在噪声和类别边界重叠时。从几何角度看，核心困难在于多数类流形对少数类流形的拓扑入侵，导致真实决策边界模糊。传统欠采样技术（如ENN）采用对称清洗规则和均匀投票，无法捕捉局部流形结构，且常误删信息丰富的少数类样本。

Method: 提出GMR框架，包含两个核心贡献：（1）几何置信度估计：使用逆距离加权kNN投票和自适应距离度量来捕捉局部可靠性；（2）非对称清洗：对多数类样本严格执行清理，同时对少数类样本设置移除保护上限，保守地保护少数类样本。

Result: 在多个基准数据集上的广泛实验表明，GMR与现有强采样基线方法相比具有竞争力。

Conclusion: GMR框架通过利用局部几何先验和非对称清洗策略，能够有效处理不平衡结构化数据，在保护少数类样本的同时实现与现有先进方法相当的性能。

Abstract: Imbalanced classification presents a formidable challenge in machine learning, particularly when tabular datasets are plagued by noise and overlapping class boundaries. From a geometric perspective, the core difficulty lies in the topological intrusion of the majority class into the minority manifold, which obscures the true decision boundary. Traditional undersampling techniques, such as Edited Nearest Neighbours (ENN), typically employ symmetric cleaning rules and uniform voting, failing to capture the local manifold structure and often inadvertently removing informative minority samples. In this paper, we propose GMR (Geometric Manifold Rectification), a novel framework designed to robustly handle imbalanced structured data by exploiting local geometric priors. GMR makes two contributions: (1) Geometric confidence estimation that uses inverse-distance weighted kNN voting with an adaptive distance metric to capture local reliability; and (2) asymmetric cleaning that is strict on majority samples while conservatively protecting minority samples via a safe-guarding cap on minority removal. Extensive experiments on multiple benchmark datasets show that GMR is competitive with strong sampling baselines.

</details>


### [112] [Diverging Flows: Detecting Extrapolations in Conditional Generation](https://arxiv.org/abs/2602.13061)
*Constantinos Tsakonas,Serena Ivaldi,Jean-Baptiste Mouret*

Main category: cs.LG

TL;DR: 针对流匹配模型在安全关键场景中的外推风险问题，本文提出Diverging Flows方法，通过结构性地强制离流形输入的低效传输，实现条件生成与外推检测的同步，在不损失预测精度和推理速度的前提下有效识别外推区域，为医学、机器人等关键领域提供可靠部署方案。


<details>
  <summary>Details</summary>
Motivation: 流匹配已成为机器人、天气预报等预测任务的最先进方法，但其在安全关键场景部署时存在严重外推风险：由于平滑偏置，模型即使在离流形条件下也会产生看似合理的输出，导致难以察觉的静默故障，这些故障与有效预测无法区分。

Method: 提出Diverging Flows，一种通过结构性设计强制离流形输入产生低效传输路径的新方法。该方法使单个模型能够同时进行条件生成和本征外推检测，利用传输效率差异识别外推区域。

Result: 在合成流形、跨域风格迁移和气温预报任务上的评估表明，Diverging Flows能够有效检测外推区域，同时保持预测保真度和推理延迟不降级。

Conclusion: Diverging Flows为构建可信流模型提供了鲁棒解决方案，为在医学、机器人和气候科学等安全关键领域的可靠部署铺平道路。

Abstract: The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.

</details>


### [113] [Bus-Conditioned Zero-Shot Trajectory Generation via Task Arithmetic](https://arxiv.org/abs/2602.13071)
*Shuai Liu,Ning Cao,Yile Chen,Yue Jiang,Gao Cong*

Main category: cs.LG

TL;DR: 本文提出公交条件零样本轨迹生成新范式，解决目标城市真实轨迹数据不可获取的难题。首次将任务算术引入该领域，通过建模源城市从公交时刻表生成到真实轨迹生成的参数偏移并迁移至目标城市，仅利用公开公交时刻表即可生成符合目标城市移动模式的高质量轨迹。


<details>
  <summary>Details</summary>
Motivation: 移动轨迹数据对智慧城市应用至关重要但获取困难。现有轨迹生成方法隐含假设可访问目标城市部分真实数据，限制了其在数据不可访问场景下的适用性。为此，本文创新性地提出完全不依赖目标城市真实轨迹的零样本生成设定，利用公开公交时刻表解决跨城市数据稀缺问题。

Method: 提出MobTA方法，首次将任务算术技术应用于轨迹生成。核心流程为：在源城市学习公交时刻表轨迹生成模型与真实移动轨迹生成模型之间的参数偏移量；将该偏移作为任务向量，通过算术运算直接应用于目标城市；利用目标城市公交时刻表和迁移后的参数生成符合当地移动模式的新轨迹。

Result: 理论分析证实MobTA在基础模型和指令微调大语言模型上均具有稳定性。大量跨城市实验表明，该方法显著优于现有基线方法，生成轨迹的质量与性能接近于使用目标城市真实轨迹数据微调后的监督模型。

Conclusion: 本研究成功实现了无需目标城市真实轨迹数据的零样本生成，为数据稀缺场景下的智慧城市时空数据分析提供了新思路。MobTA通过任务算术有效捕捉了城市间移动模式的迁移规律，验证了大语言模型在轨迹生成领域的强大潜力，具有重要的理论创新价值与实际应用前景。

Abstract: Mobility trajectory data provide essential support for smart city applications. However, such data are often difficult to obtain. Meanwhile, most existing trajectory generation methods implicitly assume that at least a subset of real mobility data from target city is available, which limits their applicability in data-inaccessible scenarios. In this work, we propose a new problem setting, called bus-conditioned zero-shot trajectory generation, where no mobility trajectories from a target city are accessible. The generation process relies solely on source city mobility data and publicly available bus timetables from both cities. Under this setting, we propose MobTA, the first approach to introduce task arithmetic into trajectory generation. MobTA models the parameter shift from bus-timetable-based trajectory generation to mobility trajectory generation in source city, and applies this shift to target city through arithmetic operations on task vectors. This enables trajectory generation that reflects target-city mobility patterns without requiring any real mobility data from it. Furthermore, we theoretically analyze MobTA's stability across base and instruction-tuned LLMs. Extensive experiments show that MobTA significantly outperforms existing methods, and achieves performance close to models finetuned using target city mobility trajectories.

</details>


### [114] [EXCODER: EXplainable Classification Of DiscretE time series Representations](https://arxiv.org/abs/2602.13087)
*Yannik Hahn,Antonin Königsfeld,Hasan Tercan,Tobias Meisen*

Main category: cs.LG

TL;DR: 本文探讨利用向量量化变分自编码器(VQ-VAE)和离散变分自编码器(DVAE)将时间序列转换为离散潜在表示，以增强深度学习模型的可解释性。研究证实，这种压缩表示不仅保持了分类性能，还使XAI方法生成更简洁、结构化的解释，同时提出了相似子序列准确率(SSA)这一新指标，用于量化评估XAI识别的重要子序列与训练数据标签分布的一致性，为可解释时间序列分类提供了系统性验证方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在时间序列分类中取得显著进展，但其缺乏可解释性仍是主要挑战。传统XAI技术因原始时间序列数据的高维度和噪声而效果受限。本研究旨在探索通过表示学习降低数据冗余、聚焦关键模式，从而提升模型透明度的可行路径，解决可解释性与模型性能之间的权衡问题。

Method: 1) 采用VQ-VAE和DVAE架构将高维时间序列编码为离散潜在表示，过滤噪声并提取信息丰富的模式；2) 在压缩后的表示空间上应用XAI方法生成解释；3) 创新性提出相似子序列准确率(SSA)指标，通过计算XAI识别的显著子序列与训练数据中标签分布的统计对齐度，定量评估解释质量；4) 对比分析离散表示与原始数据上的XAI性能差异。

Result: 1) 离散潜在表示成功保留了分类所需的关键特征，未牺牲模型准确率；2) 基于压缩表示的XAI生成的解释更加简洁、结构化，且保持高保真度；3) SSA指标有效量化了XAI特征的真实代表性，为解释验证提供了标准化工具；4) 该方法显著降低了计算复杂度，实现了更高效的推理过程。

Conclusion: 离散潜在表示为时间序列可解释性分析提供了有效范式，既维持了模型判别能力，又产生了紧凑、可理解且计算高效的解释。SSA指标的建立填补了XAI评估领域的空白，使解释质量验证更加系统化。该工作推动了可解释时间序列分类的发展，为高可靠性应用场景提供了更透明的决策支持。

Abstract: Deep learning has significantly improved time series classification, yet the lack of explainability in these models remains a major challenge. While Explainable AI (XAI) techniques aim to make model decisions more transparent, their effectiveness is often hindered by the high dimensionality and noise present in raw time series data. In this work, we investigate whether transforming time series into discrete latent representations-using methods such as Vector Quantized Variational Autoencoders (VQ-VAE) and Discrete Variational Autoencoders (DVAE)-not only preserves but enhances explainability by reducing redundancy and focusing on the most informative patterns. We show that applying XAI methods to these compressed representations leads to concise and structured explanations that maintain faithfulness without sacrificing classification performance. Additionally, we propose Similar Subsequence Accuracy (SSA), a novel metric that quantitatively assesses the alignment between XAI-identified salient subsequences and the label distribution in the training data. SSA provides a systematic way to validate whether the features highlighted by XAI methods are truly representative of the learned classification patterns. Our findings demonstrate that discrete latent representations not only retain the essential characteristics needed for classification but also offer a pathway to more compact, interpretable, and computationally efficient explanations in time series analysis.

</details>


### [115] [Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences](https://arxiv.org/abs/2602.13004)
*Ayush Mohanty,Nazal Mohamed,Nagi Gebraeel*

Main category: cs.LG

TL;DR: 本文首次建立了联邦Granger因果分析的不确定性量化框架，系统区分了偶然不确定性与认知不确定性，推导出闭式不确定性传播递推公式并识别了四种交叉协方差分量，证明了稳态方差仅取决于客户端数据统计特性，在合成与真实工业数据上验证了该方法显著提升了因果推断的可靠性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦Granger因果算法仅提供确定性点估计而忽视不确定性，在数据主权约束下的分布式基础设施（如智能电网）应用中，缺乏不确定性评估会导致因果推断结果不可靠，限制了决策的可解释性与鲁棒性。

Method: 系统分类不确定性来源（数据噪声的偶然不确定性 vs 模型可变性的认知不确定性），推导联邦架构中不确定性的闭式递推关系，识别四种耦合数据与模型参数不确定性的交叉协方差分量，并定义严格的收敛条件以获得服务器和客户端参数的显式稳态方差。

Result: 理论证明稳态方差仅依赖于客户端数据统计特性，消除了对初始认知先验的依赖，增强了算法鲁棒性；在合成基准与真实工业数据集上的实证表明，显式刻画不确定性显著提高了联邦因果推断的可靠性与可解释性。

Conclusion: 该研究为数据主权约束下的分布式时间序列因果分析建立了首个严谨的不确定性量化框架，为智能电网等工业应用提供了可靠的理论基础与实践工具，推动了联邦因果推断在实践中的可信部署。

Abstract: Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursions that model the evolution of uncertainty through client-server interactions and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. We also define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. Our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference.

</details>


### [116] [Probabilistic Wind Power Forecasting with Tree-Based Machine Learning and Weather Ensembles](https://arxiv.org/abs/2602.13010)
*Max Bruninx,Diederik van Binsbergen,Timothy Verstraeten,Ann Nowé,Jan Helsen*

Main category: cs.LG

TL;DR: 本研究基于比利时海上风电场四年数据，对比分析了三种结合树模型的概率预测方法（共形化分位数回归、自然梯度提升和条件扩散模型）用于风电功率日前预测，发现条件扩散模型综合表现最优，且集成天气预测可将点预测精度提升最高达23%。


<details>
  <summary>Details</summary>
Motivation: 准确的风电功率预测对于促进可再生能源并网、保障电网稳定运行至关重要，亟需发展高精度的概率预测方法来应对风电不确定性。

Method: 采用梯度提升树框架，集成多源天气预测数据，对比验证三种前沿概率预测方法：共形化分位数回归、自然梯度提升和条件扩散模型，并使用比利时海上风电场四年实测数据，以功率曲线和校准尾流模型为确定性基准进行性能评估。

Result: 实验表明，相较于功率曲线和校准尾流模型，机器学习方法将平均绝对误差分别降低53%和33%；条件扩散模型在概率和点预测中整体表现最佳；集成天气预测使点预测精度提升最高23%。

Conclusion: 树模型与先进概率方法结合显著提升风电预测精度，条件扩散模型最具应用潜力，集成多天气预测是提升预测性能的有效策略，为高比例可再生能源电网运行提供了可靠技术支撑。

Abstract: Accurate production forecasts are essential to continue facilitating the integration of renewable energy sources into the power grid. This paper illustrates how to obtain probabilistic day-ahead forecasts of wind power generation via gradient boosting trees using an ensemble of weather forecasts. To this end, we perform a comparative analysis across three state-of-the-art probabilistic prediction methods-conformalised quantile regression, natural gradient boosting and conditional diffusion models-all of which can be combined with tree-based machine learning. The methods are validated using four years of data for all wind farms present within the Belgian offshore zone. Additionally, the point forecasts are benchmarked against deterministic engineering methods, using either the power curve or an advanced approach incorporating a calibrated analytical wake model. The experimental results show that the machine learning methods improve the mean absolute error by up to 53% and 33% compared to the power curve and the calibrated wake model. Considering the three probabilistic prediction methods, the conditional diffusion model is found to yield the best overall probabilistic and point estimate of wind power generation. Moreover, the findings suggest that the use of an ensemble of weather forecasts can improve point forecast accuracy by up to 23%.

</details>


### [117] [Resource-Efficient Gesture Recognition through Convexified Attention](https://arxiv.org/abs/2602.13030)
*Daniel Schwartz,Dario Salvucci,Yusuf Osmanlioglu,Richard Vallett,Genevieve Dion,Ali Shokoufandeh*

Main category: cs.LG

TL;DR: 本文提出一种凸化注意力机制，通过单纯形投影和铰链损失实现可穿戴电子纺织品的轻量级手势识别，仅需120-360个参数即可达到100%准确率，推理时间低于1毫秒。


<details>
  <summary>Details</summary>
Motivation: 可穿戴电子纺织品界面需要手势识别能力，但面临功耗、计算能力和形态因子的严格限制，传统深度学习难以部署。现有轻量级架构仍需数千参数，无法满足纺织集成平台的需求。

Method: 提出凸化注意力机制，采用非扩张单纯形投影和凸损失函数动态加权特征。使用欧几里得投影到概率单纯形结合多类铰链损失，替代传统的非凸softmax操作，确保全局收敛保证。

Result: 在纺织电容式传感器上实现，轻触和滑动手势识别准确率均达100%，10折交叉验证和保留测试结果一致。模型仅需120-360个参数（比常规方法减少97%），推理时间290-296微秒，存储需求低于7KB。

Conclusion: 该研究证明凸优化能实现纺织界面的高效设备端机器学习，为资源受限的可穿戴设备提供了可行方案，但需在多用户、复杂环境和手势词汇上进一步验证。

Abstract: Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thousands of parameters, limiting deployment on textile-integrated platforms. We introduce a convexified attention mechanism for wearable applications that dynamically weights features while preserving convexity through nonexpansive simplex projection and convex loss functions. Unlike conventional attention mechanisms using non-convex softmax operations, our approach employs Euclidean projection onto the probability simplex combined with multi-class hinge loss, ensuring global convergence guarantees. Implemented on a textile-based capacitive sensor with four connection points, our approach achieves 100.00\% accuracy on tap gestures and 100.00\% on swipe gestures -- consistent across 10-fold cross-validation and held-out test evaluation -- while requiring only 120--360 parameters, a 97\% reduction compared to conventional approaches. With sub-millisecond inference times (290--296$μ$s) and minimal storage requirements ($<$7KB), our method enables gesture interfaces directly within e-textiles without external processing. Our evaluation, conducted in controlled laboratory conditions with a single-user dataset, demonstrates feasibility for basic gesture interactions. Real-world deployment would require validation across multiple users, environmental conditions, and more complex gesture vocabularies. These results demonstrate how convex optimization can enable efficient on-device machine learning for textile interfaces.

</details>


### [118] [TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios](https://arxiv.org/abs/2602.13040)
*Wentao Xu,Zhongming Yao,Weihao Li,Zhenghang Song,Yumeng Song,Tianyi Li,Yushuai Li*

Main category: cs.LG

TL;DR: 针对约束强化学习中时序耦合扰动鲁棒性不足的问题，本文提出TCRL框架，通过最坏情况感知成本约束和奖励双重约束防御机制，显著提升安全关键领域的鲁棒性表现。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒约束强化学习方法局限于单步扰动和时序独立对抗模型，无法有效应对攻击者通过跨时间步协同扰动造成的更严重安全威胁，这在自动驾驶、机器人等安全关键领域存在重大风险。

Method: 提出TCRL框架，包含两个核心机制：1) 最坏情况感知成本约束函数，无需显式建模对抗攻击者即可估计时序耦合扰动下的安全成本；2) 奖励双重约束防御机制，同步抵御时序耦合攻击并保持奖励不可预测性。

Result: 在多种约束强化学习任务上的实验表明，TCRL对时序耦合扰动攻击的鲁棒性一致优于现有方法。

Conclusion: TCRL成功解决了时序耦合扰动鲁棒性建模的空白，为安全关键领域提供了更可靠的约束强化学习防御框架，具有重要的理论创新和应用价值。

Abstract: Constrained Reinforcement Learning (CRL) aims to optimize decision-making policies under constraint conditions, making it highly applicable to safety-critical domains such as autonomous driving, robotics, and power grid management. However, existing robust CRL approaches predominantly focus on single-step perturbations and temporally independent adversarial models, lacking explicit modeling of robustness against temporally coupled perturbations. To tackle these challenges, we propose TCRL, a novel temporal-coupled adversarial training framework for robust constrained reinforcement learning (TCRL) in worst-case scenarios. First, TCRL introduces a worst-case-perceived cost constraint function that estimates safety costs under temporally coupled perturbations without the need to explicitly model adversarial attackers. Second, TCRL establishes a dual-constraint defense mechanism on the reward to counter temporally coupled adversaries while maintaining reward unpredictability. Experimental results demonstrate that TCRL consistently outperforms existing methods in terms of robustness against temporally coupled perturbation attacks across a variety of CRL tasks.

</details>


### [119] [GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042)
*George Alexandru Adam,Alexander Cui,Edwin Thomas,Emily Napier,Nazar Shmatko,Jacob Schnell,Jacob Junqi Tian,Alekhya Dronavalli,Edward Tian,Dongwon Lee*

Main category: cs.LG

TL;DR: 该论文介绍GPTZero，一种采用分层多任务架构的工业级AI文本检测工具，通过自动化红队测试实现对抗攻击和文本改写的高鲁棒性，可准确区分人类创作与大型语言模型生成的文本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型使文本真实性验证从抄袭检测转向人机 authorship 判别，引发技能评估可信度下降、低质量内容泛滥及错误信息传播等新型风险，亟需可靠的规模化检测方案。

Method: 提出分层多任务学习架构，构建灵活的人类与AI文本分类体系；采用多层次自动化红队测试策略，系统性地提升模型对对抗攻击和文本改写的鲁棒性。

Result: 在跨领域测试中达到最先进检测准确率，支持细粒度预测；对对抗攻击和文本改写的鲁棒性显著优于现有方法，同时提供可解释的检测结果。

Conclusion: GPTZero通过准确透明的检测机制和用户教育体系，为AI时代文本真实性验证提供了负责任的工业级解决方案，确保评估过程的公平性与可信度。

Abstract: While historical considerations surrounding text authenticity revolved primarily around plagiarism, the advent of large language models (LLMs) has introduced a new challenge: distinguishing human-authored from AI-generated text. This shift raises significant concerns, including the undermining of skill evaluations, the mass-production of low-quality content, and the proliferation of misinformation. Addressing these issues, we introduce GPTZero a state-of-the-art industrial AI detection solution, offering reliable discernment between human and LLM-generated text. Our key contributions include: introducing a hierarchical, multi-task architecture enabling a flexible taxonomy of human and AI texts, demonstrating state-of-the-art accuracy on a variety of domains with granular predictions, and achieving superior robustness to adversarial attacks and paraphrasing via multi-tiered automated red teaming. GPTZero offers accurate and explainable detection, and educates users on its responsible use, ensuring fair and transparent assessment of text.

</details>


### [120] [Quantization-Aware Collaborative Inference for Large Embodied AI Models](https://arxiv.org/abs/2602.13052)
*Zhonghao Lyu,Ming Xiao,Mikael Skoglund,Merouane Debbah,H. Vincent Poor*

Main category: cs.LG

TL;DR: 该论文针对资源受限的具身智能体运行大规模AI模型的挑战，提出量化感知的协同推理方法，通过联合优化量化位宽和计算频率，在延迟和能耗约束下最小化推理失真，实现边缘具身AI系统质量、延迟与能耗的平衡。


<details>
  <summary>Details</summary>
Motivation: 大规模AI模型（LAIMs）虽被视为具身AI应用的核心智能引擎，但其巨大的参数量和计算需求对资源受限的具身智能体构成严峻挑战，亟需在有限资源下实现高效推理。

Method: 首先建立量化推理失真的可处理近似模型，推导量化率-失真函数的上下界以刻画其随模型统计特性和量化位宽的变化规律；随后在延迟和能耗约束下，构建量化位宽与计算频率的联合优化问题，通过最小化失真上界并保证下界紧致性来实现最优设计。

Result: 大量评估验证了所提失真近似方法、率失真边界推导及联合设计的有效性；仿真与真实测试平台实验表明，该设计能有效权衡边缘具身AI系统的推理质量、延迟和能耗。

Conclusion: 所提量化感知协同推理框架及其联合优化方案为资源受限的具身AI系统部署大规模模型提供了可行的解决方案，在边缘计算场景下具有显著的实际应用价值。

Abstract: Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.

</details>


### [121] [Backdoor Attacks on Contrastive Continual Learning for IoT Systems](https://arxiv.org/abs/2602.13062)
*Alfous Tim,Kuniyilh Simi D*

Main category: cs.LG

TL;DR: 本文系统分析了对比持续学习(CCL)在物联网系统中面临的回毒攻击威胁，揭示了CCL的嵌入对齐和重放强化机制可被用于植入持久性恶意行为，提出了面向物联网的分层威胁分类体系，并评估了约束条件下的防御策略，指出CCL虽能增强自适应能力但会引入长期表示级安全风险。


<details>
  <summary>Details</summary>
Motivation: 物联网系统日益依赖持续学习适应传感器漂移、用户行为变化、设备老化等非平稳环境，CCL通过结合对比表示学习与增量适应实现强大特征重用，但其几何特性与重放排练、稳定性正则化结合时，会引入嵌入对齐和重放强化可被利用的安全漏洞，亟需系统性安全分析。

Method: 通过形式化嵌入层攻击目标，分析物联网特有的持久化机制，构建面向物联网的分层威胁分类法；对比不同学习范式的脆弱性差异；在有限内存、边缘计算和联邦聚合等物联网约束条件下，评估各类防御策略的有效性与适用性。

Result: 研究发现CCL的几何特性会引入独特安全漏洞，攻击者可利用嵌入对齐和重放强化机制植入持久性后门，这些恶意行为能持续通过模型更新和部署周期；虽然CCL有效增强物联网自适应智能，但也显著提升了长期存在的表示级威胁风险。

Conclusion: CCL在物联网中虽能显著提升自适应能力，但必须通过充分的安全机制缓解其表示级漏洞，否则将面临持久性后门攻击威胁；研究强调需在CCL设计和部署阶段就纳入安全考量，以平衡智能适应与系统安全。

Abstract: The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.

</details>


### [122] [Unified Multi-Domain Graph Pre-training for Homogeneous and Heterogeneous Graphs via Domain-Specific Expert Encoding](https://arxiv.org/abs/2602.13075)
*Chundong Liang,Yongqi Huang,Dongxiao He,Peiyuan Li,Yawen Li,Di Jin,Weixiong Zhang*

Main category: cs.LG

TL;DR: 针对现有图预训练方法无法统一处理同质/异质图的问题，本文提出GPH²框架，通过统一多视图图构建、领域专家编码和任务导向融合策略，实现跨图类型和领域的稳定迁移，在混合图上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图预训练方法局限于单一图类型（同质或异质），无法适应真实世界中混合图共存及分布偏移的挑战，阻碍了统一图建模的发展。

Method: 1）统一多视图图构造：同时编码同质与异质图结构，避免类型特定设计；2）领域特定专家编码：独立预训练各图类型的专家模型以捕获领域知识；3）任务导向专家融合：基于专家判别能力自适应集成多专家表示。

Result: 混合图实验表明，GPH²能够有效缓解跨域分布差异，在不同图类型和下游任务中实现稳定迁移，性能显著超越现有图预训练方法。

Conclusion: GPH²通过统一框架成功弥合了同质与异质图预训练的鸿沟，为复杂真实场景下的图表示学习提供了新范式。

Abstract: Graph pre-training has achieved remarkable success in recent years, delivering transferable representations for downstream adaptation. However, most existing methods are designed for either homogeneous or heterogeneous graphs, thereby hindering unified graph modeling across diverse graph types. This separation contradicts real-world applications, where mixed homogeneous and heterogeneous graphs are ubiquitous, and distribution shifts between upstream pre-training and downstream deployment are common. In this paper, we empirically demonstrate that a balanced mixture of homogeneous and heterogeneous graph pre-training benefits downstream tasks and propose a unified multi-domain \textbf{G}raph \textbf{P}re-training method across \textbf{H}omogeneous and \textbf{H}eterogeneous graphs ($\mathbf{GPH^{2}}$). To address the lack of a unified encoder for homogeneous and heterogeneous graphs, we propose a Unified Multi-View Graph Construction that simultaneously encodes both without explicit graph-type-specific designs. To cope with the increased cross-domain distribution discrepancies arising from mixed graphs, we introduce domain-specific expert encoding. Each expert is independently pre-trained on a single graph to capture domain-specific knowledge, thereby shielding the pre-training encoder from the adverse effects of cross-domain discrepancies. For downstream tasks, we further design a Task-oriented Expert Fusion Strategy that adaptively integrates multiple experts based on their discriminative strengths. Extensive experiments on mixed graphs demonstrate that $\text{GPH}^{2}$ enables stable transfer across graph types and domains, significantly outperforming existing graph pre-training methods.

</details>


### [123] [R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training](https://arxiv.org/abs/2602.13103)
*Gengsheng Li,Jinghan He,Shijie Wang,Dan Zhang,Ruiqi Liu,Renrui Zhang,Zijun Yao,Junfeng Fang,Haiyun Guo,Jinqiao Wang*

Main category: cs.LG

TL;DR: 针对LLM自博弈推理中"多样性幻觉"导致的性能退化问题，本文提出R-Diverse框架，通过记忆增强惩罚和技能感知度量维持持续改进。


<details>
  <summary>Details</summary>
Motivation: 现有自博弈框架（如R-Zero）存在非持续改进问题，其根源是"多样性幻觉"：训练数据表面多样但实际模式坍缩，具体表现为局部多样性幻觉（批次内多样但跨迭代循环）和表面多样性幻觉（问题形式变化但所需推理技能趋同）。

Method: 提出R-Diverse框架，包含：(1) 记忆增强惩罚(MAP)，利用持久记忆库抑制跨迭代模式重复；(2) 技能感知度量(SAM)，从推理技能本质而非问题表面变化评估多样性。

Result: 在10个数学与通用推理基准测试中，R-Diverse能够持续多轮迭代保持性能增益，且显著优于现有自博弈方法。

Conclusion: 该工作揭示了自博弈中多样性幻觉的关键作用，提出的R-Diverse框架为构建更鲁棒的推理系统提供了有效方案，强调了关注推理技能本质多样性的重要性。

Abstract: Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.

</details>


### [124] [Order Matters in Retrosynthesis: Structure-aware Generation via Reaction-Center-Guided Discrete Flow Matching](https://arxiv.org/abs/2602.13136)
*Chenguang Wang,Zihan Zhou,Lei Bai,Tianshu Yu*

Main category: cs.LG

TL;DR: 本文提出了一种结构感知的无模板逆合成框架RetroDiT，通过将反应中心原子置于序列头部，将化学知识转化为显式位置偏置，结合图变换器和离散流匹配，在20-50步内实现SOTA性能，大幅优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 现有无模板逆合成方法将任务视为黑盒序列生成，学习效率有限；而半模板方法依赖刚性反应库，泛化能力受限。两种方法均未能充分利用化学反应的内在结构信息，导致性能瓶颈。

Method: 提出基于位置归纳偏置的结构感知框架，通过将反应中心原子置于序列头部，使模型能优先关注化学关键区域。采用RetroDiT图变换器架构（集成旋转位置编码）和离散流匹配技术，解耦训练与采样过程。

Result: 在USPTO-50k和USPTO-Full数据集上分别达到61.2%和51.3%的top-1准确率；使用oracle反应中心时提升至71.1%和63.4%。仅需20-50步生成，远少于先前扩散方法的500步。280K参数模型配合结构先验性能可匹敌65M参数模型。

Conclusion: 原子排序作为结构先验可显著提升逆合成预测效率，小模型配合恰当的结构偏置即可超越大规模基础模型，为化学反应建模提供了新的方法论视角。

Abstract: Template-free retrosynthesis methods treat the task as black-box sequence generation, limiting learning efficiency, while semi-template approaches rely on rigid reaction libraries that constrain generalization. We address this gap with a key insight: atom ordering in neural representations matters. Building on this insight, we propose a structure-aware template-free framework that encodes the two-stage nature of chemical reactions as a positional inductive bias. By placing reaction center atoms at the sequence head, our method transforms implicit chemical knowledge into explicit positional patterns that the model can readily capture. The proposed RetroDiT backbone, a graph transformer with rotary position embeddings, exploits this ordering to prioritize chemically critical regions. Combined with discrete flow matching, our approach decouples training from sampling and enables generation in 20--50 steps versus 500 for prior diffusion methods. Our method achieves state-of-the-art performance on both USPTO-50k (61.2% top-1) and the large-scale USPTO-Full (51.3% top-1) with predicted reaction centers. With oracle centers, performance reaches 71.1% and 63.4% respectively, surpassing foundation models trained on 10 billion reactions while using orders of magnitude less data. Ablation studies further reveal that structural priors outperform brute-force scaling: a 280K-parameter model with proper ordering matches a 65M-parameter model without it.

</details>
