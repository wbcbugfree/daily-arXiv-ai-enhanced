<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 49]
- [cs.IR](#cs.IR) [Total: 21]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.LG](#cs.LG) [Total: 40]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Foundation Models in Transaction Understanding with LLM-based Sentence Embeddings](https://arxiv.org/abs/2601.05271)
*Xiran Fan,Zhimeng Jiang,Chin-Chia Michael Yeh,Yuzhong Chen,Yingtong Dou,Menghai Pan,Yan Zheng*

Main category: cs.CL

TL;DR: 将LLM嵌入作为语义初始化的轻量级交易分析框架，结合多源数据融合和一词约束，提升在大规模交易数据上的理解任务性能，同时保持可解释性与高效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于表格数据的交易分析模型对分类商户字段等文本信息通常采用基于索引的离散化表示，导致丰富的语义信息丢失；同时，完整的LLM推理在实时金融部署中成本高昂。需要在语义 rich 与 实时性之间取得折中。

Method: 使用LLM生成的嵌入作为轻量交易模型的语义初始化；通过多源数据融合来丰富商户分类字段的表示；提出一词约束原理，确保在不同LLM架构下嵌入的一致性；对数据质量进行噪声过滤与上下文感知增强以提升输入质量。

Result: 在大规模交易数据集上，针对多项交易理解任务表现出显著提升。

Conclusion: 该混合框架实现了语义能力与计算效率的平衡，利用LLM嵌入提升任务性能，同时通过数据质量控制和跨模型的一致性约束增强稳定性与可解释性。

Abstract: The ubiquity of payment networks generates vast transactional data encoding rich consumer and merchant behavioral patterns. Recent foundation models for transaction analysis process tabular data sequentially but rely on index-based representations for categorical merchant fields, causing substantial semantic information loss by converting rich textual data into discrete tokens. While Large Language Models (LLMs) can address this limitation through superior semantic understanding, their computational overhead challenges real-time financial deployment. We introduce a hybrid framework that uses LLM-generated embeddings as semantic initializations for lightweight transaction models, balancing interpretability with operational efficiency. Our approach employs multi-source data fusion to enrich merchant categorical fields and a one-word constraint principle for consistent embedding generation across LLM architectures. We systematically address data quality through noise filtering and context-aware enrichment. Experiments on large-scale transaction datasets demonstrate significant performance improvements across multiple transaction understanding tasks.

</details>


### [2] [The Table of Media Bias Elements: A sentence-level taxonomy of media bias types and propaganda techniques](https://arxiv.org/abs/2601.05358)
*Tim Menzner,Jochen L. Leidner*

Main category: cs.CL

TL;DR: A sentence-level media-bias taxonomy with 38 bias types across six families, derived from ~26k sentences, enabling finer-grained detection and improved alignment with NLP/communication taxonomies.


<details>
  <summary>Details</summary>
Motivation: Move beyond outlet-level labels to concrete linguistic devices of bias, enabling precise recognition and measurement of propaganda in individual sentences.

Method: Iterative close-reading, interdisciplinary theory, and pilot annotation on 26,464 sentences from newsroom corpora, user submissions, and browsing; develop a two-tier taxonomy (38 types, six functional families) visualized as a table of media-bias elements; provide definitions, examples, drivers, and recognition guidance; validate with a 155-sentence random sample and cross-walk to existing taxonomies.

Result: A fine-grained, sentence-level taxonomy of 38 bias types organized into six families, with definitions, examples, cognitive/societal drivers, and recognition guidance; a visual 'table of media-bias elements'; quantitative prevalence insights; demonstrated broader coverage and reduced ambiguity compared to NLP/communication-science taxonomies.

Conclusion: The framework shifts bias detection from outlet-level labeling to sentence-level mechanisms, enabling more reliable analysis, clearer comparisons across outlets, and better integration with NLP/communication research.

Abstract: Public debates about "left-" or "right-wing" news overlook the fact that bias is usually conveyed by concrete linguistic manoeuvres that transcend any single political spectrum. We therefore shift the focus from where an outlet allegedly stands to how partiality is expressed in individual sentences. Drawing on 26,464 sentences collected from newsroom corpora, user submissions and our own browsing, we iteratively combine close-reading, interdisciplinary theory and pilot annotation to derive a fine-grained, sentence-level taxonomy of media bias and propaganda. The result is a two-tier schema comprising 38 elementary bias types, arranged in six functional families and visualised as a "table of media-bias elements". For each type we supply a definition, real-world examples, cognitive and societal drivers, and guidance for recognition. A quantitative survey of a random 155-sentence sample illustrates prevalence differences, while a cross-walk to the best-known NLP and communication-science taxonomies reveals substantial coverage gains and reduced ambiguity.

</details>


### [3] [Lost in Execution: On the Multilingual Robustness of Tool Calling in Large Language Models](https://arxiv.org/abs/2601.05366)
*Zheng Luo,T Pranav Kutralingam,Ogochukwu N Okoani,Wanpeng Xu,Hua Wei,Xiyang Hu*

Main category: cs.CL

TL;DR: MLCL构建了一个多语言工具调用诊断基准并对中文、印地语和Igbo等语言进行系统评估，揭示工具调用在语言迁移下的鲁棒性问题。核心发现是参数值的语言不一致性导致执行错误，尽管意图识别与工具选择正确；通过若干推理时系统策略能显著降低语言诱发的执行错误，但仍难以达到英语水平的性能。


<details>
  <summary>Details</summary>
Motivation: 当前关于多语言环境下大语言模型调用外部工具的鲁棒性研究不足，尤其在非英语语言中。需要一个诊断性基准来揭示潜在错误模式并指导改进。

Method: 提出MLCL诊断基准，覆盖中文、印地语、Igbo等多语言场景；进行系统化的多语言工具调用评估与细粒度错误分析；评估若干推理时系统策略对语言诱发执行错误的缓解效果。

Result: 尽管模型能正确理解意图并选择工具，仍有大量失败来自语言无关的执行约束被违背；参数值的语言不一致性（parameter value language mismatch）成为主要失败模式，模型生成的参数在用户语言中语义正确，但违反了语言不变的执行规范。某些推理时策略可以显著降低这类错误，但整体性能仍未达到英语水平。

Conclusion: 多语言工具调用仍显著落后于英语情境，需进一步的机制性改进与策略优化，以实现跨语言的一致性和鲁棒性，尤其是在参数传递的语言规范方面。

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that invoke external tools through structured function calls. While recent work reports strong tool-calling performance under standard English-centric evaluations, the robustness of tool calling under multilingual user interactions remains underexplored. In this work, we introduce MLCL, a diagnostic benchmark, and conduct a systematic evaluation of multilingual tool calling across Chinese, Hindi, and the low-resource language Igbo. Through fine-grained error analysis, we show that many failures occur despite correct intent understanding and tool selection. We identify parameter value language mismatch as a dominant failure mode, where models generate semantically appropriate parameter values in the user's language, violating language-invariant execution conventions. We further evaluate several inference-time system strategies and find that while these strategies substantially reduce language-induced execution errors, none of them can fully recover English-level performance.

</details>


### [4] [Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection](https://arxiv.org/abs/2601.05403)
*Zhiwei Liu,Yupen Cao,Yuechen Jiang,Mohsinul Kabir,Polydoros Giannouris,Chen Xu,Ziyang Xu,Tianlei Zhu,Tariquzzaman Faisal,Triantafillos Papadopoulos,Yan Wang,Lingfei Qian,Xueqing Peng,Zhuohan Xie,Ye Yuan,Saeed Almheiri,Abdulrazzaq Alnajjar,Mingbin Chen,Harry Stuart,Paul Thompson,Prayag Tiwari,Alejandro Lopez-Lira,Xue Liu,Jimin Huang,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 提出 mfmdscen 作为多语金融错误信息检测的行为偏见基准，覆盖三类复杂情景，评估 22 种主流 LLM；揭示商业与开源模型均存在显著偏见；数据集与实现将开源在 GitHub。


<details>
  <summary>Details</summary>
Motivation: 填补现有关于 LLM 偏见的研究在现实金融环境、多语言与高风险、情境敏感的错误信息检测任务中的空缺，提升对偏见影响的理解和对策。

Method: 构建三类情景：① 角色/性格导向，② 角色/地区导向，③ 角色/族裔与宗教信仰导向；开发覆盖英语、中文、希腊语、孟加拉语的多语言金融错误信息数据集；将情景与错误信息结合，系统性评估 22 种主流 LLM 的行为偏见。

Result: 在商业与开源模型中均观察到显著的行为偏见持续存在，偏见特征具有跨模型的一致性。

Conclusion: mfmdscen 提供一个系统化的评估框架，促进对金融情境中偏见的研究与治理，相关数据与实现将对外开放，推动领域研究。

Abstract: Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\mfmd). In this work, we propose \mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD.

</details>


### [5] [Glitter: Visualizing Lexical Surprisal for Readability in Administrative Texts](https://arxiv.org/abs/2601.05411)
*Jan Černý,Ivana Kvapilíková,Silvie Cinková*

Main category: cs.CL

TL;DR: 基于信息熵的文本可读性估计与可视化框架；通过多语言模型近似熵值来评估文本清晰度，目标提升行政/公文的可读性，开源实现 Glitter。


<details>
  <summary>Details</summary>
Motivation: 行政文本通常冗长、难以理解。信息熵提供对语言复杂度的量化指标，结合多模型的稳健估计可为可读性评估提供量化基础。

Method: 对文本输入基于多个语言模型估计条件信息熵，并构建可视化框架展示熵分布与相关可读性指标；工具以 Glitter 开源软件形式发布并可复现。

Result: 提出一个可操作的框架原型，能够用多模型近似文本熵并进行可视化； Glitter 工具集对外开源。

Conclusion: 信息熵为可读性评估提供一种有前景的量化路径，所提出的框架与开源工具可用于改进行政文本的清晰度与表达效果。

Abstract: This work investigates how measuring information entropy of text can be used to estimate its readability. We propose a visualization framework that can be used to approximate information entropy of text using multiple language models and visualize the result. The end goal is to use this method to estimate and improve readability and clarity of administrative or bureaucratic texts. Our toolset is available as a libre software on https://github.com/ufal/Glitter.

</details>


### [6] [Large Language Models Are Bad Dice Players: LLMs Struggle to Generate Random Numbers from Statistical Distributions](https://arxiv.org/abs/2601.05414)
*Minda Zhao,Yilun Du,Mengyu Wang*

Main category: cs.CL

TL;DR: 对前沿LLMs的原生概率采样进行大规模、统计显著性审计，结果显示独立请求几乎全部失败，批处理也仅勉强通过，需外部工具以实现统计保证。


<details>
  <summary>Details</summary>
Motivation: 在教育评估、合成数据等跨领域的随机管线中，按指定分布采样的真实需求日益增大；当前LLMs缺乏可靠的内部采样器，难以满足统计保证、可重复性和公平性目标。

Method: 采用双协议设计：Batch Generation（单次响应内生成N=1000样本）与 Independent Requests（N=1000的无状态调用）；覆盖11个模型、15个分布；评估采样有效性，分析分布复杂度与采样步长对保真度的影响，并考察下游任务（MCQ的答案位置约束、文本到图像的属性约束）的传播效应。

Result: Batch生成的中位通过率约13%；独立请求在11个模型中有10个未通过任何分布（即0通过率）；采样保真度随分布复杂度增加而下降，随N增大而恶化；下游任务中存在对答案位置的违背与对人口统计目标的系统性偏离。

Conclusion: 当前LLMs缺乏可依赖的内部采样器，统计保证场景需依赖外部工具或后处理策略以确保分布性约束与公平性目标。

Abstract: As large language models (LLMs) transition from chat interfaces to integral components of stochastic pipelines across domains like educational assessment and synthetic data construction, the ability to faithfully sample from specified probability distributions has become a functional requirement rather than a theoretical curiosity. We present the first large-scale, statistically powered audit of native probabilistic sampling in frontier LLMs, benchmarking 11 models across 15 distributions. To disentangle failure modes, we employ a dual-protocol design: Batch Generation, where a model produces N=1000 samples within one response, and Independent Requests, comprising $N=1000$ stateless calls. We observe a sharp protocol asymmetry: batch generation achieves only modest statistical validity, with a 13% median pass rate, while independent requests collapse almost entirely, with 10 of 11 models passing none of the distributions. Beyond this asymmetry, we reveal that sampling fidelity degrades monotonically with distributional complexity and aggravates as the requested sampling horizon N increases. Finally, we demonstrate the propagation of these failures into downstream tasks: models fail to enforce uniform answer-position constraints in MCQ generation and systematically violate demographic targets in attribute-constrained text-to-image prompt synthesis. These findings indicate that current LLMs lack a functional internal sampler, necessitating the use of external tools for applications requiring statistical guarantees.

</details>


### [7] [Tracing Moral Foundations in Large Language Models](https://arxiv.org/abs/2601.05437)
*Chenxiao Yu,Bowen Yi,Farzan Karimi-Malekabadi,Suhaib Abdurahman,Jinyi Ye,Shrikanth Narayanan,Yue Zhao,Morteza Dehghani*

Main category: cs.CL

TL;DR: 两种指令微调的LLM通过分层分析、残差自编码器和因果干预，显示道德基础在内部表征中结构化、层次化地分布，并与人类观感对齐，暗示语言统计能产生多元化的道德结构。


<details>
  <summary>Details</summary>
Motivation: 探究LLM的道德判断是源自内部概念结构还是表层模仿；通过MFT框架、两种模型、层级分析、SAE和因果干预，揭示内在表征与道德输出之间的因果关系。

Method: (i) 层级分析MFT概念及与人类道德认知的对齐；(ii) 在残差流上使用预训练的稀疏自编码器以发现支持道德概念的稀疏特征；(iii) 基于密集MFT向量和稀疏特征的因果干预进行干预。

Result: 两模型在分层、结构化地表示道德基础且与人类判断对齐；SAE特征与具体基础具有清晰语义联系，表明在共用表征中存在部分解耦的机制；对密集向量或稀疏特征的干预可产生可预测的基础相关行为变化，证明内部表征与道德输出之间存在因果联系。

Conclusion: LLMs 的道德概念呈分布、分层、部分解耦的特征，表明一种多元化道德结构可从语言统计中自发涌现。

Abstract: Large language models (LLMs) often produce human-like moral judgments, but it is unclear whether this reflects an internal conceptual structure or superficial ``moral mimicry.'' Using Moral Foundations Theory (MFT) as an analytic framework, we study how moral foundations are encoded, organized, and expressed within two instruction-tuned LLMs: Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct. We employ a multi-level approach combining (i) layer-wise analysis of MFT concept representations and their alignment with human moral perceptions, (ii) pretrained sparse autoencoders (SAEs) over the residual stream to identify sparse features that support moral concepts, and (iii) causal steering interventions using dense MFT vectors and sparse SAE features. We find that both models represent and distinguish moral foundations in a structured, layer-dependent way that aligns with human judgments. At a finer scale, SAE features show clear semantic links to specific foundations, suggesting partially disentangled mechanisms within shared representations. Finally, steering along either dense vectors or sparse features produces predictable shifts in foundation-relevant behavior, demonstrating a causal connection between internal representations and moral outputs. Together, our results provide mechanistic evidence that moral concepts in LLMs are distributed, layered, and partly disentangled, suggesting that pluralistic moral structure can emerge as a latent pattern from the statistical regularities of language alone.

</details>


### [8] [Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction](https://arxiv.org/abs/2601.05459)
*Hongjin Kim,Jaewook Lee,Kiyoung Lee,Jong-hun Shin,Soojong Lim,Oh-Woog Kwon*

Main category: cs.CL

TL;DR: RL alone yields limited Korean reasoning gains for models without inherent Korean reasoning; aligning internal reasoning to Korean inputs via early-layer, Korean-specific neuron tuning and a self-correction code-switching dataset unlocks RL efficacy, yielding notable improvements in mathematical reasoning and self-correction; main conclusion: eliciting and aligning existing reasoning capabilities, rather than injecting new linguistic knowledge, drives multilingual reasoning in LLMs.


<details>
  <summary>Details</summary>
Motivation: To determine whether reinforcement learning can elevate Korean reasoning to English-like levels and identify what mechanisms enable multilingual reasoning enhancements in LLMs.

Method: Compare RL performance on Korean reasoning with and without fine-tuning; implement strategies to align the model's internal reasoning with Korean inputs, notably tuning Korean-specific neurons in early layers; introduce and utilize a self-correction code-switching dataset to facilitate alignment.

Result: RL alone provides limited gains for models lacking Korean reasoning; with neuron-level early-layer tuning and code-switching alignment, RL achieves significant improvements in mathematical reasoning and self-correction tasks in Korean-English multilingual contexts.

Conclusion: Effective multilingual reasoning relies on eliciting and aligning existing reasoning capabilities rather than injecting new linguistic knowledge; internal translation and neuron-level tuning are key mechanisms for aligning multilingual reasoning in LLMs.

Abstract: Large Language Models (LLMs) demonstrate strong reasoning and self-correction abilities in high-resource languages like English, but their performance remains limited in low-resource languages such as Korean. In this study, we investigate whether reinforcement learning (RL) can enhance Korean reasoning abilities to a degree comparable to English. Our findings reveal that RL alone yields limited improvements when applied to models lacking inherent Korean reasoning capabilities. To address this, we explore several fine-tuning strategies and show that aligning the model's internal reasoning processes with Korean inputs-particularly by tuning Korean-specific neurons in early layers-is key to unlocking RL's effectiveness. We introduce a self-correction code-switching dataset to facilitate this alignment and observe significant performance gains in both mathematical reasoning and self-correction tasks. Ultimately, we conclude that the crucial factor in multilingual reasoning enhancement is not injecting new linguistic knowledge, but effectively eliciting and aligning existing reasoning capabilities. Our study provides a new perspective on how internal translation and neuron-level tuning contribute to multilingual reasoning alignment in LLMs.

</details>


### [9] [Towards Valid Student Simulation with Large Language Models](https://arxiv.org/abs/2601.05473)
*Zhihao Yuan,Yunze Xiao,Ming Li,Weihao Xuan,Richard Tong,Mona Diab,Tom Mitchell*

Main category: cs.CL

TL;DR: 提出以 Epistemic State Specification (ESS) 和 Goal-by-Environment 框架来实现以大语言模型为基础的学生仿真，聚焦 epistemic fidelity 以克服“能力悖论”造成的不现实学习动态，并强调对有效性、评估及伦理风险的开放挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于大型语言模型的学生仿真在学习动态、错误模式及可验证性方面的局限，提升研究可重复性、科学性与教育应用的风险可控性。

Method: 提出一个概念性与方法论框架：将仿真问题转化为受约束的生成，定义 Epistemic State Specification (ESS)来限定可访问信息、错误结构与学习状态演化；引入 Goal-by-Environment 框架将仿真系统放在具体行为目标与部署情境中；综合梳理相关文献，明确关键设计维度并指出未来的开放挑战。

Result: 提供一个系统性的设计框架与关键设计维度，用以在基于LLM的学生仿真中实现 epistemic fidelity；未提出新的系统或基准测试，重点讨论有效性、评估与伦理风险等问题。

Conclusion: 强调 epistemic fidelity 相较表层的真实感更为重要，为将LLM仿真学生用于科学研究与教育应用奠定前提；未来工作需聚焦有效性评估、伦理风险与实证验证。

Abstract: This paper presents a conceptual and methodological framework for large language model (LLM) based student simulation in educational settings. The authors identify a core failure mode, termed the "competence paradox" in which broadly capable LLMs are asked to emulate partially knowledgeable learners, leading to unrealistic error patterns and learning dynamics. To address this, the paper reframes student simulation as a constrained generation problem governed by an explicit Epistemic State Specification (ESS), which defines what a simulated learner can access, how errors are structured, and how learner state evolves over time. The work further introduces a Goal-by-Environment framework to situate simulated student systems according to behavioral objectives and deployment contexts. Rather than proposing a new system or benchmark, the paper synthesizes prior literature, formalizes key design dimensions, and articulates open challenges related to validity, evaluation, and ethical risks. Overall, the paper argues for epistemic fidelity over surface realism as a prerequisite for using LLM-based simulated students as reliable scientific and pedagogical instruments.

</details>


### [10] [The Facade of Truth: Uncovering and Mitigating LLM Susceptibility to Deceptive Evidence](https://arxiv.org/abs/2601.05478)
*Herun Wan,Jiaying Wu,Minnan Luo,Fanxiao Li,Zhi Zeng,Min-Yen Kan*

Main category: cs.CL

TL;DR: 提出 MisBelief 框架，通过多轮跨多角色 LLM 协作生成误导性证据并评估对模型信念的影响；并提出 Deceptive Intent Shielding (DIS) 作为治理机制，提供欺骗意图的早期信号以缓解信念偏移。


<details>
  <summary>Details</summary>
Motivation: 当前模型对直接错误信息具有一定鲁棒性，但对更隐蔽、可辩解的证据易受影响，且证据的逐步 refinement 可能诱导错误信念，影响下游决策。现有研究缺少对这类可辩证的误导证据的系统评估与治理框架。

Method: MisBelief 通过多轮交互、协同多角色的 LLM 生成 4,800 个样本，覆盖三种难度等级，评估 7 种代表性 LLM 的信念偏移。提出 DIS，基于推断证据背后的欺骗意图提供早期警示信号并缓解信念偏移。

Result: 实验结果显示，模型对直接错误信息具鲁棒性，但对经精炼、具说服力的证据极易被信念说服，falsehood 信念平均上升 93.0%；DIS 能持续缓解信念偏移并提升证据评估的谨慎性。

Conclusion: 揭示了在证据越来越具说服力的情境中，LLM 的事实信念脆弱性及其治理需求，DIS 提供了一条可能的治理路径，未来工作可扩展至更多模型、证据类型及实际部署评估。

Abstract: To reliably assist human decision-making, LLMs must maintain factual internal beliefs against misleading injections. While current models resist explicit misinformation, we uncover a fundamental vulnerability to sophisticated, hard-to-falsify evidence. To systematically probe this weakness, we introduce MisBelief, a framework that generates misleading evidence via collaborative, multi-round interactions among multi-role LLMs. This process mimics subtle, defeasible reasoning and progressive refinement to create logically persuasive yet factually deceptive claims. Using MisBelief, we generate 4,800 instances across three difficulty levels to evaluate 7 representative LLMs. Results indicate that while models are robust to direct misinformation, they are highly sensitive to this refined evidence: belief scores in falsehoods increase by an average of 93.0\%, fundamentally compromising downstream recommendations. To address this, we propose Deceptive Intent Shielding (DIS), a governance mechanism that provides an early warning signal by inferring the deceptive intent behind evidence. Empirical results demonstrate that DIS consistently mitigates belief shifts and promotes more cautious evidence evaluation.

</details>


### [11] [MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards](https://arxiv.org/abs/2601.05488)
*Zhiyu Shen,Ziming Wu,Fuming Lai,Shaobing Lian,Yanghui Rao*

Main category: cs.CL

TL;DR: 提出 MemBuilder，通过强化学习训练4B模型在多维记忆构建中分配密集奖励，以提升长程对话的一致性和长期记忆利用。


<details>
  <summary>Details</summary>
Motivation: 长期对话保持一致性受限于历史状态的时序演变，现有记忆机制缺乏有效的粒度奖励与多维记忆归因；需要一个能在开放/闭源模型上高效训练、应对稀疏奖励的框架。

Method: 提出 MemBuilder：在多维记忆构建中应用带密集奖励的强化学习；通过合成会话级问题生成提供稠密中间奖励；引入贡献感知梯度加权以按下游影响缩放策略更新。

Result: 4B 参数模型在长程对话基准上超越最先进的闭源基线，具有较强的泛化能力。

Conclusion: MemBuilder 有效解决稀疏轨迹奖励与多维记忆归因问题，提升长期对话的一致性和性能。

Abstract: Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that trains models to orchestrate multi-dimensional memory construction with attributed dense rewards. MemBuilder addresses two key challenges: (1) Sparse Trajectory-Level Rewards: we employ synthetic session-level question generation to provide dense intermediate rewards across extended trajectories; and (2) Multi-Dimensional Memory Attribution: we introduce contribution-aware gradient weighting that scales policy updates based on each component's downstream impact. Experimental results show that MemBuilder enables a 4B-parameter model to outperform state-of-the-art closed-source baselines, exhibiting strong generalization across long-term dialogue benchmarks.

</details>


### [12] [FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse](https://arxiv.org/abs/2601.05505)
*Yubo Hou,Zhisheng Chen,Tao Wan,Zengchang Qin*

Main category: cs.CL

TL;DR: FlashMem 直接从临时推理状态中蒸馏出内在记忆，通过共享KV整合器在冻结的缓存上进行注意力聚合，结合无参数认知监控，实现对长时记忆的高效持久化与推理加速，达到与复杂基线相当的性能，同时降低显著的推理延迟（约5×）。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的无状态结构难以保留动态上下文，需对历史信息进行冗余重处理以实现长时刻自主性。现有的潜在记忆方法依赖独立的编码器，将记忆与推理主体解耦，降低效率并增加系统复杂性。

Method: 提出 FlashMem 框架：通过计算复用将内在记忆直接从瞬态推理状态中蒸馏。利用内部表示对输入轨迹的唯一编码特性，识别最后一个隐藏状态作为交互历史的充分统计量。使用 Shared-KV Consolidator 在冻结的缓存上进行注意力聚合，避免再参数化。引入无参数的 Cognitive Monitor，利用注意力熵在检测到高本体不确定性时自适应触发记忆整合。

Result: 实验表明 FlashMem 在性能上可媲美沉重基线，同时将推理延迟降低约5倍，成功实现高效的持续认知与长期记忆的折中。

Conclusion: 通过将记忆蒸馏直接嵌入推理骨干并用可控的自适应触发机制，FlashMem 实现了高效、无须额外编码器的持续记忆能力，显著提升大模型在长时维度上的推理效率与鲁棒性。

Abstract: The stateless architecture of Large Language Models inherently lacks the mechanism to preserve dynamic context, compelling agents to redundantly reprocess history to maintain long-horizon autonomy. While latent memory offers a solution, current approaches are hindered by architectural segregation, relying on auxiliary encoders that decouple memory from the reasoning backbone. We propose FlashMem, a framework that distills intrinsic memory directly from transient reasoning states via computation reuse. Leveraging the property that internal representations uniquely encode input trajectories, FlashMem identifies the last hidden state as a sufficient statistic for the interaction history. This enables a Shared-KV Consolidator to synthesize memory by attending directly to the backbone's frozen cache, eliminating redundant re-parameterization. Furthermore, a parameter-free Cognitive Monitor leverages attention entropy to adaptively trigger consolidation only when high epistemic uncertainty is detected. Experiments demonstrate that FlashMem matches the performance of heavy baselines while reducing inference latency by 5 times, effectively bridging the gap between efficiency and persistent cognition.

</details>


### [13] [CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems](https://arxiv.org/abs/2601.05520)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: A multi-agent LLM framework CHisAgent for ancient Chinese historical taxonomy construction, using three role-specific stages (Inducer, Expander, Enricher) to build a domain-aware event taxonomy from the Twenty-Four Histories; shows improved coherence, coverage, and cross-cultural alignment.


<details>
  <summary>Details</summary>
Motivation: LLMs exhibit limited historical and cultural reasoning in non-English contexts; taxonomies provide an organizing structure for broad historical knowledge; manual taxonomy construction is costly and not scalable, motivating automated taxonomy construction for ancient Chinese history.

Method: A three-stage pipeline with role-specialized agents: (1) Inducer (bottom-up) derives an initial hierarchy from raw historical corpora; (2) Expander (top-down) adds missing intermediate concepts using LLM world knowledge; (3) Enricher (evidence-guided) integrates external structured historical resources to ensure faithfulness. The Twenty-Four Histories serves as the data source to construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life. Evaluations include reference-free and reference-based assessments of structural coherence and coverage, plus analysis of cross-cultural alignment.

Result: Creation of a large-scale domain-aware event taxonomy for ancient China, spanning politics, military, diplomacy, and social life, with improved structural coherence and coverage; the taxonomy supports cross-cultural alignment.

Conclusion: Demonstrates a scalable approach to historical taxonomy construction in ancient Chinese contexts via a multi-agent LLM framework, enabling richer, more faithful organization of historical knowledge and potential applicability to other non-English historical corpora.

Abstract: Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \textbf{CHisAgent}, a multi-agent LLM framework for historical taxonomy construction in ancient Chinese contexts. CHisAgent decomposes taxonomy construction into three role-specialized stages: a bottom-up \textit{Inducer} that derives an initial hierarchy from raw historical corpora, a top-down \textit{Expander} that introduces missing intermediate concepts using LLM world knowledge, and an evidence-guided \textit{Enricher} that integrates external structured historical resources to ensure faithfulness. Using the \textit{Twenty-Four Histories}, we construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life in ancient China. Extensive reference-free and reference-based evaluations demonstrate improved structural coherence and coverage, while further analysis shows that the resulting taxonomy supports cross-cultural alignment.

</details>


### [14] [Double: Breaking the Acceleration Limit via Double Retrieval Speculative Parallelism](https://arxiv.org/abs/2601.05524)
*Yuhao Shen,Tianyu Liu,Junyi Shen,Jinyang Wu,Quan Kong,Li Huan,Cong Wang*

Main category: cs.CL

TL;DR: Double 引入同步检索机制，桥接 SD 与 PSD，打破理论加速上限并降低早期错误拒绝的资源浪费，实现无损且无需额外训练的加速，性能提升达到 5.3×（LLaMA3.3-70B）和 2.8×（Qwen3-32B）


<details>
  <summary>Details</summary>
Motivation: PSD/SD 的两大挑战：Draft 与 Target 模型的速度比导致的理论上限；以及早期错误导致的巨额计算浪费和流水线阻塞。需要一种在不损失精度的前提下提升速度与效率的机制。

Method: Double 框架通过在草稿阶段进行迭代检索推测来突破理论加速的极限；目标模型执行权威检索，给出多 token 指引以降低因拒绝带来的回滚需求，采用同步机制以缓解拒绝造成的损失；完全无需额外训练，且保持无损。

Result: 实验显示在两个模型上分别达到 5.3× 与 2.8× 的加速，明显优于需要大量训练的 EAGLE-3。

Conclusion: Double 解决 Retrieval Precision-Efficiency Dilemma，显著提升推理吞吐，且无需训练、无损，验证了在大型语言模型上的实用性潜力。

Abstract: Parallel Speculative Decoding (PSD) accelerates traditional Speculative Decoding (SD) by overlapping draft generation with verification. However, it remains hampered by two fundamental challenges: (1) a theoretical speedup ceiling dictated by the speed ratio between the draft and target models, and (2) high computational waste and pipeline stall due to mid-sequence token rejections of early errors. To address these limitations, we introduce \textsc{Double} (Double Retrieval Speculative Parallelism). By bridging the gap between SD and PSD, our framework resolves the Retrieval \emph{Precision-Efficiency Dilemma} through a novel synchronous mechanism. Specifically, we enable the draft model to execute iterative retrieval speculations to break the theoretical speedup limits; to alleviate rejections without rollback, the target model performs authoritative retrieval to generate multi-token guidance. \textsc{Double} is entirely training-free and lossless. Extensive experiments demonstrate state-of-the-art speedup of $\textbf{5.3}\times$ on LLaMA3.3-70B and $\textbf{2.8}\times$ on Qwen3-32B, significantly outperforming the advanced method EAGLE-3 that requires extensive model training.

</details>


### [15] [Closing the Modality Reasoning Gap for Speech Large Language Models](https://arxiv.org/abs/2601.05543)
*Chaoren Wang,Heng Lu,Xueyao Zhang,Shujie Liu,Yan Lu,Jinyu Li,Zhizheng Wu*

Main category: cs.CL

TL;DR: 提出 TARS 框架，通过强化学习对齐文本条件与语音条件轨迹，采用表示对齐和行为对齐两种信号，显著缩小模态推理差距并在7B规模的语音LLM上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的 Speech LLM 在推理能力上落后于文本 LLM，可能源于 Transformer 层之间的表示漂移和长链推理中的行为偏差，需提升跨模态表示与输出一致性。

Method: TARS 利用一个非对称奖励设计的 RL 框架，将文本条件与语音条件轨迹进行对齐。引入两类密集信号：1) 表示对齐，衡量语音与文本条件轨迹在各层隐藏状态的相似性；2) 行为对齐，衡量生成输出与参考文本完成之间的语义一致性。

Result: 在 MMSU 和 OBQA 等挑战性推理基准上，方法显著缩小模态推理差距，并在7B规模的语音 LLMs 中达到或接近SOTA。

Conclusion: 通过轨迹对齐的强化学习框架，成功缓解语音模态下的推理劣势，提升跨模态推理能力，具有对大规模语音 LLM 训练的实用意义。

Abstract: Although speech large language models have achieved notable progress, a substantial modality reasoning gap remains: their reasoning performance on speech inputs is markedly weaker than on text. This gap could be associated with representational drift across Transformer layers and behavior deviations in long-chain reasoning. To address this issue, we introduce TARS, a reinforcement-learning framework that aligns text-conditioned and speech-conditioned trajectories through an asymmetric reward design. The framework employs two dense and complementary signals: representation alignment, which measures layer-wise hidden-state similarity between speech- and text-conditioned trajectories, and behavior alignment, which evaluates semantic consistency between generated outputs and reference text completions. Experiments on challenging reasoning benchmarks, including MMSU and OBQA, show that our approach significantly narrows the modality reasoning gap and achieves state-of-the-art performance among 7B-scale Speech LLMs.

</details>


### [16] [Can Large Language Models Differentiate Harmful from Argumentative Essays? Steps Toward Ethical Essay Scoring](https://arxiv.org/abs/2601.05545)
*Hongjin Kim,Jeonghyun Kang,Harksoo Kim*

Main category: cs.CL

TL;DR: 提出 Harmful Essay Detection (HED) 基准，测试 AES 与 LLM 在识别和评分有害作文方面的能力；结果显示当前模型难以准确区分有害与论证性文本，且评分未充分考虑伦理维度，需开发更具伦理敏感性的 AES 系统。


<details>
  <summary>Details</summary>
Motivation: 尽管 AES 与 LLM 在文本生成与评分方面有所进展，但在处理涉及种族主义、性别偏见等敏感主题的作文时，存在明显伦理盲点，容易给予高分。研究旨在填补这一空白，建立一个用于评估模型在识别有害内容与赋分时的基准。

Method: 设计并引入 Harmful Essay Detection (HED) 基准，包含围绕敏感议题（如种族主义与性别偏见）的作文，评估多种 LLMs 在识别有害内容及其对作文的评分时的表现，重点区分有害立场与论证性表达，以及评估评分时对伦理维度的考虑。

Result: 实验表明：(1) 需进一步提升 LLMs 在区分有害与论证性文本方面的准确性；(2) 现有的 AES 模型与大语言模型在评分时未充分纳入内容的伦理维度，存在系统性不足。

Conclusion: 需要开发更强健的 AES 系统，使其对内容的伦理含义具有敏感性，避免无意强化有害观点，同时改进对有害文本的识别与安全性评估。

Abstract: This study addresses critical gaps in Automated Essay Scoring (AES) systems and Large Language Models (LLMs) with regard to their ability to effectively identify and score harmful essays. Despite advancements in AES technology, current models often overlook ethically and morally problematic elements within essays, erroneously assigning high scores to essays that may propagate harmful opinions. In this study, we introduce the Harmful Essay Detection (HED) benchmark, which includes essays integrating sensitive topics such as racism and gender bias, to test the efficacy of various LLMs in recognizing and scoring harmful content. Our findings reveal that: (1) LLMs require further enhancement to accurately distinguish between harmful and argumentative essays, and (2) both current AES models and LLMs fail to consider the ethical dimensions of content during scoring. The study underscores the need for developing more robust AES systems that are sensitive to the ethical implications of the content they are scoring.

</details>


### [17] [Generation-Based and Emotion-Reflected Memory Update: Creating the KEEM Dataset for Better Long-Term Conversation](https://arxiv.org/abs/2601.05548)
*Jeonghyun Kang,Hongjin Kim,Harksoo Kim*

Main category: cs.CL

TL;DR: 提出 KEEM 数据集，基于生成的记忆更新机制，在长时对话系统中融合情感与因果关系的综合记忆，以提升记忆更新的质量和对用户的共情能力。


<details>
  <summary>Details</summary>
Motivation: 现有的记忆累积或基于操作的方法易产生信息冲突，难以精确跟踪用户当前状态，亟需一种能够动态生成并融入情感与因果信息的记忆更新机制。

Method: 提出 Keep Emotional and Essential Memory (KEEM) 数据集，通过生成式方法构建整合型记忆，既保留关键信息，又嵌入情感上下文与因果关系，使系统在更新记忆时能够兼顾事实要点与情感语境。

Result: 该方法提升了对用户情感与语境的理解深度，使系统在开放域对话中给出更有意义的回应和更强的共情能力。

Conclusion: KEEM 数据集为生成式记忆更新提供了新的数据资源与方法路径，有望提升长时对话系统的记忆一致性、情感理解与响应质量。

Abstract: In this work, we introduce the Keep Emotional and Essential Memory (KEEM) dataset, a novel generation-based dataset designed to enhance memory updates in long-term conversational systems. Unlike existing approaches that rely on simple accumulation or operation-based methods, which often result in information conflicts and difficulties in accurately tracking a user's current state, KEEM dynamically generates integrative memories. This process not only preserves essential factual information but also incorporates emotional context and causal relationships, enabling a more nuanced understanding of user interactions. By seamlessly updating a system's memory with both emotional and essential data, our approach promotes deeper empathy and enhances the system's ability to respond meaningfully in open-domain conversations.

</details>


### [18] [ReasonAny: Incorporating Reasoning Capability to Any Model via Simple and Effective Model Merging](https://arxiv.org/abs/2601.05560)
*Junyao Yang,Chen Qian,Dongrui Liu,Wen Shen,Yong Liu,Jing Shao*

Main category: cs.CL

TL;DR: 提出 ReasonAny，通过对比梯度识别来实现跨域合并，避免推理能力与领域能力的崩溃，提升在安全、生物医药、金融等领域的性能。


<details>
  <summary>Details</summary>
Motivation: 实现无训练成本的“Reasoning + X”合并，解决现有方法在推理深度和领域效用之间的崩溃问题；发现推理能力主要集中在梯度敏感度低的参数区域，与常规假设相反。

Method: 引入 Contrastive Gradient Identification（对比梯度识别）来区分对推理有贡献的参数区域和对领域能力有贡献的区域，进行有选择的参数合并和权重重调，使推理能力与领域能力协同提升。

Result: 在安全、生物医学和金融领域的实验中，ReasonAny显著超越SOTA基线，在保留推理能力的同时提升领域任务表现，且对推理深度的保持具有鲁棒性。

Conclusion: 提出的梯度对比识别方法解决了推理+领域崩溃问题，揭示了推理能力与参数区域的关系，为跨域知识迁移和集成提供有效途径。

Abstract: Large Reasoning Models (LRMs) with long chain-of-thought reasoning have recently achieved remarkable success. Yet, equipping domain-specialized models with such reasoning capabilities, referred to as "Reasoning + X", remains a significant challenge. While model merging offers a promising training-free solution, existing methods often suffer from a destructive performance collapse: existing methods tend to both weaken reasoning depth and compromise domain-specific utility. Interestingly, we identify a counter-intuitive phenomenon underlying this failure: reasoning ability predominantly resides in parameter regions with low gradient sensitivity, contrary to the common assumption that domain capabilities correspond to high-magnitude parameters. Motivated by this insight, we propose ReasonAny, a novel merging framework that resolves the reasoning-domain performance collapse through Contrastive Gradient Identification. Experiments across safety, biomedicine, and finance domains show that ReasonAny effectively synthesizes "Reasoning + X" capabilities, significantly outperforming state-of-the-art baselines while retaining robust reasoning performance.

</details>


### [19] [Can large language models interpret unstructured chat data on dynamic group decision-making processes? Evidence on joint destination choice](https://arxiv.org/abs/2601.05582)
*Sung-Yoo Lim,Koki Sato,Kiyoshi Takami,Giancarlos Parady,Eui-Jin Kim*

Main category: cs.CL

TL;DR: 使用大语言模型（LLMs）分析日本群聊中的共同就餐决策，自动将对话转化为结构化数据，并评估其在提取显性与隐性决策因素中的能力与局限性。


<details>
  <summary>Details</summary>
Motivation: 传统旅行调查难以捕捉群体共同活动中的决策过程；非结构化对话数据（如群聊）提供线索，但需要自动化方法来提取显性和隐性因素。LLMs有潜力辅助标注并提升理解，但需评估其准确性与边界条件。

Method: 设计一个受知识获取过程启发的 prompting 框架，分步提取核心决策因素：群体层面的餐厅候选集与结果、各备选选项的个人偏好、驱动偏好的具体属性；将非结构化对话转为结构化表格；通过与人工标注基准的定量评估以及错误分析评估模型局限性。

Result: LLM在捕捉显性决策因素方面较为可靠，但对隐性、语境依赖的因素识别不足，与人类标注存在差异；在可控情境下输出可被信任的情形较多，但仍需人类监控以捕捉微妙含义。

Conclusion: LLMs在将非传统数据用于理解社会活动的决策过程方面具有潜力，但存在显著局限，适合与人类标注结合使用，以提高对群体活动决策的解释能力。

Abstract: Social activities result from complex joint activity-travel decisions between group members. While observing the decision-making process of these activities is difficult via traditional travel surveys, the advent of new types of data, such as unstructured chat data, can help shed some light on these complex processes. However, interpreting these decision-making processes requires inferring both explicit and implicit factors. This typically involves the labor-intensive task of manually annotating dialogues to capture context-dependent meanings shaped by the social and cultural norms. This study evaluates the potential of Large Language Models (LLMs) to automate and complement human annotation in interpreting decision-making processes from group chats, using data on joint eating-out activities in Japan as a case study. We designed a prompting framework inspired by the knowledge acquisition process, which sequentially extracts key decision-making factors, including the group-level restaurant choice set and outcome, individual preferences of each alternative, and the specific attributes driving those preferences. This structured process guides the LLM to interpret group chat data, converting unstructured dialogues into structured tabular data describing decision-making factors. To evaluate LLM-driven outputs, we conduct a quantitative analysis using a human-annotated ground truth dataset and a qualitative error analysis to examine model limitations. Results show that while the LLM reliably captures explicit decision-making factors, it struggles to identify nuanced implicit factors that human annotators readily identified. We pinpoint specific contexts when LLM-based extraction can be trusted versus when human oversight remains essential. These findings highlight both the potential and limitations of LLM-based analysis for incorporating non-traditional data sources on social activities.

</details>


### [20] [ACR: Adaptive Context Refactoring via Context Refactoring Operators for Multi-Turn Dialogue](https://arxiv.org/abs/2601.05589)
*Jiawei Shen,Jia Zhu,Hanghui Guo,Weijie Shi,Yue Cui,Qingyu Niu,Guoqing Ma,Yidan Liang,Jingjiang Liu,Yiling Wang,Shimin Di,Jiajie Xu*

Main category: cs.CL

TL;DR: 提出ACR框架：自适应上下文重构，通过上下文操作符库和教师引导的自进化训练，动态监控并重塑对话历史，解决多轮对话中的语境惯性和状态漂移，提升对话一致性并降低令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法（扩展上下文窗口、外部记忆、上下文压缩）仍难以根本解决随对话增长而产生的上下文惯性和状态漂移，需要将上下文管理与推理解耦，并以主动的方式对历史进行重构。

Method: 提出自适应上下文重构（ACR）框架：依赖一套上下文重构操作符库，对话历史的动态监控与重塑；引入教师引导的自进化训练范式，学习何时干预以及如何重构，从而决定是否对历史进行改写并如何改写。

Result: 在多轮对话任务上，ACR显著优于现有基线，同时降低令牌消耗。

Conclusion: ACR通过主动干预和解耦上下文管理，有效缓解上下文惯性与状态漂移，提升长期对话的一致性与可控性。

Abstract: Large Language Models (LLMs) have shown remarkable performance in multi-turn dialogue. However, in multi-turn dialogue, models still struggle to stay aligned with what has been established earlier, follow dependencies across many turns, and avoid drifting into incorrect facts as the interaction grows longer. Existing approaches primarily focus on extending the context window, introducing external memory, or applying context compression, yet these methods still face limitations such as \textbf{contextual inertia} and \textbf{state drift}. To address these challenges, we propose the \textbf{A}daptive \textbf{C}ontext \textbf{R}efactoring \textbf{(ACR)} Framework, which dynamically monitors and reshapes the interaction history to mitigate contextual inertia and state drift actively. ACR is built on a library of context refactoring operators and a teacher-guided self-evolving training paradigm that learns when to intervene and how to refactor, thereby decoupling context management from the reasoning process. Extensive experiments on multi-turn dialogue demonstrate that our method significantly outperforms existing baselines while reducing token consumption.

</details>


### [21] [Data Augmented Pipeline for Legal Information Extraction and Reasoning](https://arxiv.org/abs/2601.05609)
*Nguyen Minh Phuong,Ha-Thanh Nguyen,May Myo Zin,Ken Satoh*

Main category: cs.CL

TL;DR: 一个基于大型语言模型的法律领域信息抽取数据增强管线，简化标注、提升鲁棒性，且具跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 法律领域的信息抽取常面临数据稀缺和高标注成本的问题；需要提升模型鲁棒性与泛化能力。LLMs可用于生成多样且一致的标注数据，缓解数据瓶颈，且具备跨领域适用性。

Method: 提出一个利用LLMs进行数据增强的管线，可能包含对原始文本的生成性扩充、标签对齐、以及结果的筛选与质量控制等，以提升信息抽取训练数据的质量与数量；强调方法的简洁性与有效性。

Result: 声称能显著降低人工标注成本，提升信息抽取系统的鲁棒性，并具备对其他NLP任务的泛化潜力。

Conclusion: 该方法可作为一种通用的数据增强范式，适用于法律领域以外的NLP任务。

Abstract: In this paper, we propose a pipeline leveraging Large Language Models (LLMs) for data augmentation in Information Extraction tasks within the legal domain. The proposed method is both simple and effective, significantly reducing the manual effort required for data annotation while enhancing the robustness of Information Extraction systems. Furthermore, the method is generalizable, making it applicable to various Natural Language Processing (NLP) tasks beyond the legal domain.

</details>


### [22] [Text Detoxification in isiXhosa and Yorùbá: A Cross-Lingual Machine Learning Approach for Low-Resource African Languages](https://arxiv.org/abs/2601.05624)
*Abayomi O. Agbeyangi*

Main category: cs.CL

TL;DR: 提出一种可解释、资源友好的文本去毒化方法，针对 isiXhosa 与 Yorùbá 等低资源语言。结合 TF-IDF + 逻辑回归的毒性检测与基于词汇/标记的规则重写，构建了毒性到中性文本的并行语料库并进行评估。检测准确度在两语言间存在差异，重写阶段实现对所有检测到的毒性句子的净化，同时保持非毒性句子的完整性。该方法为低资源文本风格迁移提供可扩展、文化自适应的基线。


<details>
  <summary>Details</summary>
Motivation: 在 African 低资源语言中，毒性语言是在线安全的主要障碍，但缺乏鲁棒的检测与治理工具。本文提出一个可解释、资源友好且具可扩展性的去毒化框架，以提高低资源语言的在线安全性与参与性。

Method: 检测阶段：TF-IDF 特征 + Logistic Regression，强调透明性与可解释性；重写阶段：基于词典与 token 的规则化重写；数据构建：并行的毒性-中性重写语料，覆盖习惯用语、变音符号、代码切换，用于训练与评估。评估采用分层 K 折、指标包括准确率和 ROC-AUC。

Result: 检测准确率：isiXhosa 61–72%，Yorùbá 72–86%；ROC-AUC 最高可达 0.88。重写阶段对所有检测出的毒性句子进行了净化，同时对非毒性句子保持 100% 不变。

Conclusion: 结合可解释的检测器和基于规则的编辑，提供面向低资源语言的可扩展且文化自适应的安全工具，成为 African 语言低资源文本风格迁移的新的基线。也提示需要更多的数据和跨语言的泛化能力，以及对非英语场景的鲁棒性评估。

Abstract: Toxic language is one of the major barrier to safe online participation, yet robust mitigation tools are scarce for African languages. This study addresses this critical gap by investigating automatic text detoxification (toxic to neutral rewriting) for two low-resource African languages, isiXhosa and Yorùbá. The work contributes a novel, pragmatic hybrid methodology: a lightweight, interpretable TF-IDF and Logistic Regression model for transparent toxicity detection, and a controlled lexicon- and token-guided rewriting component. A parallel corpus of toxic to neutral rewrites, which captures idiomatic usage, diacritics, and code switching, was developed to train and evaluate the model. The detection component achieved stratified K-fold accuracies of 61-72% (isiXhosa) and 72-86% (Yorùbá), with per-language ROC-AUCs up to 0.88. The rewriting component successfully detoxified all detected toxic sentences while preserving 100% of non-toxic sentences. These results demonstrate that scalable, interpretable machine learning detectors combined with rule-based edits offer a competitive and resource-efficient solution for culturally adaptive safety tooling, setting a new benchmark for low-resource Text Style Transfer (TST) in African languages.

</details>


### [23] [GIFT: Games as Informal Training for Generalizable LLMs](https://arxiv.org/abs/2601.05633)
*Nuoyan Lyu,Bingbing Xu,Weihao Meng,Yige Yuan,Yang Zhang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CL

TL;DR: 提出在游戏环境中对大规模语言模型进行非正式学习的框架，通过嵌套训练实现任务的顺序组合，强制模型同时掌握多项能力，并在矩阵博弈、井字棋、谁是间谍等游戏上采用GRPO强化学习进行验证，显示能防止任务干扰并显著提升泛化，且提供开源实现。


<details>
  <summary>Details</summary>
Motivation: LLMs在形式化学习任务上表现突出，但在实践智慧和可泛化智能方面存在显著不足。原因在于缺乏通过互动反馈驱动的非正式学习，难以获得跨任务的策略性、社会性推理等能力。以游戏作为主要学习环境，利用内在奖励信号和抽象问题复杂性，促进多种能力的培养。

Method: 提出嵌套训练框架（Nested Training Framework），通过序列化任务组合来实现显式的“AND”目标，避免简单的任务混合导致的隐式“OR”目标。采用基于GRPO的强化学习，在矩阵博弈、井字棋和谁是间谍等游戏上进行训练与评估，验证游戏化非正式学习对提升多任务协同和能力迁移的有效性。

Result: 实验结果表明，将游戏作为非正式学习环境可防止任务干扰，并显著提升模型在广义能力基准上的泛化能力，且在矩阵博弈、井字棋、谁是间谍等多种游戏场景中均获得正向效果。

Conclusion: 该框架及实现已公开，表明以游戏为核心的非正式学习是提升LLM通用性和多任务能力的有前景路径。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the "practical wisdom" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit "OR" objective, our framework employs sequential task composition to enforce an explicit "AND" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.

</details>


### [24] [Multilingual Amnesia: On the Transferability of Unlearning in Multilingual LLMs](https://arxiv.org/abs/2601.05641)
*Alireza Dehghanpour Farashah,Aditi Khandelwal,Marylou Fauchard,Zhuan Shi,Negar Rostamzadeh,Golnoosh Farnadi*

Main category: cs.CL

TL;DR: Multilingual unlearning evaluated on Aya-Expanse 8B across 10 languages; data vs concept unlearning; higher stability in high-resource languages; asymmetric transfer among related languages; syntactic similarity best predicts cross-lingual unlearning behavior.


<details>
  <summary>Details</summary>
Motivation: Address safety and fairness of multilingual LLMs by studying unlearning in multilingual settings; extend unlearning benchmarks beyond English to diverse languages and script families to understand cross-lingual transfer and biases embedded in pretraining/fine-tuning data.

Method: Two settings: data unlearning and concept unlearning. Extend benchmarks for factual knowledge and stereotypes by translating to ten languages (English, French, Arabic, Japanese, Russian, Farsi, Korean, Hindi, Hebrew, Indonesian). Analyze cross-lingual transfer, resource level effects, typological relatedness, and linguistic distances. Evaluate stability of unlearning, and identify predictors such as syntactic similarity.

Result: Unlearning is generally more stable in high-resource languages. Observed asymmetric transfer effects between typologically related languages. Linguistic-distance analysis shows syntactic similarity as the strongest predictor of cross-lingual unlearning behavior.

Conclusion: Cross-lingual unlearning is shaped by language resource level and typological proximity, with syntax-distance being a key predictor. These findings imply that designing multilingual unlearning methods should account for syntactic relatedness and resource disparities across languages.

Abstract: As multilingual large language models become more widely used, ensuring their safety and fairness across diverse linguistic contexts presents unique challenges. While existing research on machine unlearning has primarily focused on monolingual settings, typically English, multilingual environments introduce additional complexities due to cross-lingual knowledge transfer and biases embedded in both pretraining and fine-tuning data. In this work, we study multilingual unlearning using the Aya-Expanse 8B model under two settings: (1) data unlearning and (2) concept unlearning. We extend benchmarks for factual knowledge and stereotypes to ten languages through translation: English, French, Arabic, Japanese, Russian, Farsi, Korean, Hindi, Hebrew, and Indonesian. These languages span five language families and a wide range of resource levels. Our experiments show that unlearning in high-resource languages is generally more stable, with asymmetric transfer effects observed between typologically related languages. Furthermore, our analysis of linguistic distances indicates that syntactic similarity is the strongest predictor of cross-lingual unlearning behavior.

</details>


### [25] [A Framework for Personalized Persuasiveness Prediction via Context-Aware User Profiling](https://arxiv.org/abs/2601.05654)
*Sejun Park,Yoonah Park,Jongwon Lim,Yohan Jo*

Main category: cs.CL

TL;DR: 提出一个上下文感知的用户画像框架，用于提升说服力预测，包含查询生成器与概要分析器，对ChangeMyView数据集有显著提升，强调上下文依赖性和任务定制性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统框架以利用 persuadee 的历史活动（如对话）来提升说服力预测模型，需考虑受众个人特征与历史行为的影响。

Method: 提出两阶段可训练组件：查询生成器用于从用户历史中检索与说服相关的记录；profiler 将这些记录摘要成对说服力预测有用的用户画像。

Result: 在ChangeMyView Reddit数据集上，对多种预测模型均有稳定提升，F1最高提升至13.77个百分点；分析显示有效画像具有上下文依赖性且与预测模型相关，而非静态属性或表层相似性。

Conclusion: 任务导向、上下文依赖的用户画像对个性化说服力预测具有重要性，建议在相关应用中采用该框架以实现更精准的说服力评估。

Abstract: Estimating the persuasiveness of messages is critical in various applications, from recommender systems to safety assessment of LLMs. While it is imperative to consider the target persuadee's characteristics, such as their values, experiences, and reasoning styles, there is currently no established systematic framework to optimize leveraging a persuadee's past activities (e.g., conversations) to the benefit of a persuasiveness prediction model. To address this problem, we propose a context-aware user profiling framework with two trainable components: a query generator that generates optimal queries to retrieve persuasion-relevant records from a user's history, and a profiler that summarizes these records into a profile to effectively inform the persuasiveness prediction model. Our evaluation on the ChangeMyView Reddit dataset shows consistent improvements over existing methods across multiple predictor models, with gains of up to +13.77%p in F1 score. Further analysis shows that effective user profiles are context-dependent and predictor-specific, rather than relying on static attributes or surface-level similarity. Together, these results highlight the importance of task-oriented, context-dependent user profiling for personalized persuasiveness prediction.

</details>


### [26] [Afri-MCQA: Multimodal Cultural Question Answering for African Languages](https://arxiv.org/abs/2601.05699)
*Atnafu Lambebo Tonja,Srija Anand,Emilio Villa-Cueva,Israel Abebe Azime,Jesujoba Oluwadara Alabi,Muhidin A. Mohamed,Debela Desalegn Yadeta,Negasi Haile Abadi,Abigail Oppong,Nnaemeka Casmir Obiefuna,Idris Abdulmumin,Naome A Etori,Eric Peter Wairagala,Kanda Patrick Tshinu,Imanigirimbabazi Emmanuel,Gabofetswe Malema,Alham Fikri Aji,David Ifeoluwa Adelani,Thamar Solorio*

Main category: cs.CL

TL;DR: Afri-MCQA 是首个覆盖 15 种非洲语言、含文本与语音模态的多语言文化问答基准，共 7.5k 对问答对，由本地说话者创建并提供英文对齐。对大语言模型的基线评估显示，开放权重模型在本地语言上的表现极差，文本与语音的开放式 VQA 几乎为零，且本地语言与英语之间存在显著差异。研究强调需优先发展语音导向、文化为本的预训练与跨语言文化迁移，并公开数据集以促进包容性多模态 AI。


<details>
  <summary>Details</summary>
Motivation: 解决非洲语言在 AI 研究中的代表性不足，提供一个覆盖语言多样性、文化背景的多模态问答基准，评估 LLMs 在语言与文化层面的能力与局限性。

Method: 由本地母语者创建数据集，覆盖 15 种语言、12 个国家，提供英文-非洲语言对齐的文本和语音问答对；对大语言模型进行基线评估，含为区分语言负载与文化知识的控制实验；强调跨模态评估与文化迁移。

Result: 开放权重模型在本地语言上的表现显著低下，文本与语音的开放式 VQA 几乎不可行； native 语言与英语在语言能力上的差距显著，文本与语音均存在瓶颈。

Conclusion: 需发展先使用语音的模型、进行文化为本的预训练、推动跨语言文化迁移；并在 HuggingFace 以学术许可/CC BY-NC 4.0 发布数据集，促进非洲语言的包容性多模态 AI 发展。

Abstract: Africa is home to over one-third of the world's languages, yet remains underrepresented in AI research. We introduce Afri-MCQA, the first Multilingual Cultural Question-Answering benchmark covering 7.5k Q&A pairs across 15 African languages from 12 countries. The benchmark offers parallel English-African language Q&A pairs across text and speech modalities and was entirely created by native speakers. Benchmarking large language models (LLMs) on Afri-MCQA shows that open-weight models perform poorly across evaluated cultures, with near-zero accuracy on open-ended VQA when queried in native language or speech. To evaluate linguistic competence, we include control experiments meant to assess this specific aspect separate from cultural knowledge, and we observe significant performance gaps between native languages and English for both text and speech. These findings underscore the need for speech-first approaches, culturally grounded pretraining, and cross-lingual cultural transfer. To support more inclusive multimodal AI development in African languages, we release our Afri-MCQA under academic license or CC BY-NC 4.0 on HuggingFace (https://huggingface.co/datasets/Atnafu/Afri-MCQA)

</details>


### [27] [Multimodal In-context Learning for ASR of Low-resource Languages](https://arxiv.org/abs/2601.05707)
*Zhaolin Li,Jan Niehues*

Main category: cs.CL

TL;DR: Multimodal in-context learning (MICL) with speech LLMs enables learning unseen languages and improves ASR, with cross-lingual transfer enhancing efficiency; attention analysis reveals text bias and layer-dependent audio/text preferences; a MICL-based selection approach outperforms prompt-based ASR for unseen languages; cross-lingual transfer can match or surpass corpus-trained LMs without target-language data.


<details>
  <summary>Details</summary>
Motivation: Addresses data scarcity for most of the world's languages by leveraging MICL with speech-language models to enable unseen languages and improve ASR without extensive target-language data.

Method: Empirical study using two speech LLMs (Phi-4 and Qwen3-Omni) on three endangered languages. Evaluates MICL for unseen languages, investigates cross-lingual transfer, analyzes attention patterns for interpretation, and compares prompt-based ASR with a MICL-based ASR approach that combines a stronger acoustic model with MICL-generated hypotheses.

Result: MICL is effective for unseen languages by utilizing both speech and text; cross-lingual transfer improves MICL efficiency without target-language training; attention shows layer-dependent audio/text preferences with overall bias towards text; prompt-based ASR underperforms on unseen languages; MICL-based hypothesis selection with a stronger acoustic model yields ASR improvements; cross-lingual transfer can match or outperform corpus-trained LMs without target-language data; code is publicly available.

Conclusion: MICL is a viable strategy to extend ASR to unseen languages, with robust gains and interpretable mechanisms (attention patterns). Cross-lingual transfer can compensate for missing data and match or beat corpora-trained LMs without target-language data, suggesting practical pathways for low-resource language ASR.

Abstract: Automatic speech recognition (ASR) still covers only a small fraction of the world's languages, mainly due to supervised data scarcity. In-context learning (ICL) with large language models (LLMs) addresses this problem, but prior work largely focuses on high-resource languages covered during training and text-only settings. This paper investigates whether speech LLMs can learn unseen languages with multimodal ICL (MICL), and how this learning can be used to improve ASR. We conduct experiments with two speech LLMs, Phi-4 and Qwen3-Omni, on three diverse endangered languages. Firstly, we find that MICL is effective for unseen languages, leveraging both speech and text modalities. We further show that cross-lingual transfer learning improves MICL efficiency on target languages without training on them. Moreover, we analyze attention patterns to interpret MICL mechanisms, and we observe layer-dependent preferences between audio and text context, with an overall bias towards text. Finally, we show that prompt-based ASR with speech LLMs performs poorly on unseen languages, motivating a simple ASR system that combines a stronger acoustic model with a speech LLM via MICL-based selection of acoustic hypotheses. Results show that MICL consistently improves ASR performance, and that cross-lingual transfer learning matches or outperforms corpus-trained language models without using target-language data. Our code is publicly available.

</details>


### [28] [Visualising Information Flow in Word Embeddings with Diffusion Tensor Imaging](https://arxiv.org/abs/2601.05713)
*Thomas Fabian*

Main category: cs.CL

TL;DR: 基于扩散张量成像的词嵌入分析工具，用以研究大语言模型中的信息流，支持表达级分析与层内比较，提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法多聚焦单词级嵌入，忽略上下文中的信息流和表达层面信息传递，需要一种能分析自然语言表达的整体信息流的工具。

Method: 将词嵌入在 LLM 各层中视作张量，应用 DTI 框架提取信息传导模式；跨层跟踪信息流以比较模型结构、识别未充分利用的层；在代词指代与隐喻检测等任务上比较信息流差异。

Result: DTI 能揭示嵌入之间的信息流方向性与强度，便于模型结构比较和层级 pruning；不同任务呈现出特征化的信息流模式，提升对表达级语言的可解释性。

Conclusion: 为 LLM 对自然语言表达的表示提供新视角，扩展对词嵌入的分析，增强 NLP 模型的可解释性与分析能力。

Abstract: Understanding how large language models (LLMs) represent natural language is a central challenge in natural language processing (NLP) research. Many existing methods extract word embeddings from an LLM, visualise the embedding space via point-plots, and compare the relative positions of certain words. However, this approach only considers single words and not whole natural language expressions, thus disregards the context in which a word is used. Here we present a novel tool for analysing and visualising information flow in natural language expressions by applying diffusion tensor imaging (DTI) to word embeddings. We find that DTI reveals how information flows between word embeddings. Tracking information flows within the layers of an LLM allows for comparing different model structures and revealing opportunities for pruning an LLM's under-utilised layers. Furthermore, our model reveals differences in information flows for tasks like pronoun resolution and metaphor detection. Our results show that our model permits novel insights into how LLMs represent actual natural language expressions, extending the comparison of isolated word embeddings and improving the interpretability of NLP models.

</details>


### [29] [Analysing Differences in Persuasive Language in LLM-Generated Text: Uncovering Stereotypical Gender Patterns](https://arxiv.org/abs/2601.05751)
*Amalie Brogaard Pauli,Maria Barrett,Max Müller-Eberstein,Isabelle Augenstein,Ira Assent*

Main category: cs.CL

TL;DR: 本研究提出评估框架，探究提示指令、受众性别、发送者意图等因素对LLMs生成劝说性语言的影响；在13个模型、16种语言、19类劝说语言评估中，观察到显著的性别差异与偏见模式，与性别刻板观念相符。


<details>
  <summary>Details</summary>
Motivation: 理解用户指令如何影响劝说性语言的生成，以及在针对不同群体时生成结果是否存在差异；并评估跨模型、跨语言的偏见与可迁移性。

Method: 对13个LLM和16种语言使用成对提示指令进行评估；以社会心理学与传播学为理论基础，通过LLM作为评估者，对19类劝说语言进行评分；分析提示、受众性别、发送者意图与输出语言对生成结果的影响。

Result: 在所有模型中均观测到显著的性别差异，劝说语言呈现出与性别相关的语言特征；这些模式与社会心理学与社会语言学中记载的性别刻板偏好一致。

Conclusion: 提示与受众特征对LLMs的劝说输出存在系统性偏差，需在模型设计、风险治理和公平性评估中加以关注；未来工作可探索减缓策略与更客观的评估方法。

Abstract: Large language models (LLMs) are increasingly used for everyday communication tasks, including drafting interpersonal messages intended to influence and persuade. Prior work has shown that LLMs can successfully persuade humans and amplify persuasive language. It is therefore essential to understand how user instructions affect the generation of persuasive language, and to understand whether the generated persuasive language differs, for example, when targeting different groups. In this work, we propose a framework for evaluating how persuasive language generation is affected by recipient gender, sender intent, or output language. We evaluate 13 LLMs and 16 languages using pairwise prompt instructions. We evaluate model responses on 19 categories of persuasive language using an LLM-as-judge setup grounded in social psychology and communication science. Our results reveal significant gender differences in the persuasive language generated across all models. These patterns reflect biases consistent with gender-stereotypical linguistic tendencies documented in social psychology and sociolinguistics.

</details>


### [30] [AutoMonitor-Bench: Evaluating the Reliability of LLM-Based Misbehavior Monitor](https://arxiv.org/abs/2601.05752)
*Shu Yang,Jingyu Hu,Tong Li,Hanqi Yan,Wenxuan Wang,Di Wang*

Main category: cs.CL

TL;DR: AutoMonitor-Bench 提出首个系统性评估基准，用于评估基于 LLM 的误行为监控器在多任务和多故障模式下的可靠性。基准包含 3,010 条标注样本，覆盖问答、代码生成与推理任务，提供误行为与良性样本对。评估维度为 Miss Rate (MR) 与 False Alarm Rate (FAR)，分别衡量漏检失效行为与对良性行为的过度敏感。对 12 家专有模型与 10 个开源模型的监控性能进行对比，发现存在显著的性能差异，并在 MR 与 FAR 之间呈现普遍的权衡，体现出安全性与实用性之间的权衡。为探究监控器的极限，作者又构建了 153,581 条样本的大规模训练语料，对 Qwen3-4B-Instruction 进行微调，讨论在易构造的误行为数据集上的训练是否能提升对未知、隐式误行为的监控能力。结果指出监控的可靠性与可扩展性面临挑战，并提出未来在任务感知的设计与训练策略方面的研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统性、跨任务的基准来评估基于 LLM 的误行为监控器的可靠性。监控器在不同模型、不同任务上的表现差异显著，且 MR 与 FAR 之间存在明显权衡，导致安全性与实用性之间存在矛盾。

Method: 设计并发布 AutoMonitor-Bench：包含 3,010 条标注样本，覆盖问答、代码生成和推理三大任务，样本成对地包含误行为与 benign（良性）实例。以 Miss Rate (MR) 与 False Alarm Rate (FAR) 两个指标评估监控器的漏检与过敏感性。对 12 款专有模型与 10 款开源模型进行系统评估。构建 153,581 条样本的大规模训练语料，微调 Qwen3-4B-Instruction，以考察在已知且较易构造的误行为数据集上的训练是否能提升对未见与更隐性的误行为的监控性能。

Result: 监控性能在不同模型之间存在显著差异，MR 和 FAR 之间存在普遍的权衡，揭示了安全性与实用性之间的固有张力。以易构造误行为数据进行训练的提升在对未见、隐性误行为上的效果有限，说明可靠、可扩展的监控仍面临挑战。

Conclusion: 研究表明需要在任务感知的监控设计与训练策略方面进行更多探索，未来工作应聚焦于更有效的数据构造、模型训练与评估框架，以提升基于 LLM 的监控器的可靠性与可扩展性。

Abstract: We introduce AutoMonitor-Bench, the first benchmark designed to systematically evaluate the reliability of LLM-based misbehavior monitors across diverse tasks and failure modes. AutoMonitor-Bench consists of 3,010 carefully annotated test samples spanning question answering, code generation, and reasoning, with paired misbehavior and benign instances. We evaluate monitors using two complementary metrics: Miss Rate (MR) and False Alarm Rate (FAR), capturing failures to detect misbehavior and oversensitivity to benign behavior, respectively. Evaluating 12 proprietary and 10 open-source LLMs, we observe substantial variability in monitoring performance and a consistent trade-off between MR and FAR, revealing an inherent safety-utility tension. To further explore the limits of monitor reliability, we construct a large-scale training corpus of 153,581 samples and fine-tune Qwen3-4B-Instruction to investigate whether training on known, relatively easy-to-construct misbehavior datasets improves monitoring performance on unseen and more implicit misbehaviors. Our results highlight the challenges of reliable, scalable misbehavior monitoring and motivate future work on task-aware designing and training strategies for LLM-based monitors.

</details>


### [31] [One Script Instead of Hundreds? On Pretraining Romanized Encoder Language Models](https://arxiv.org/abs/2601.05776)
*Benedikt Ebing,Lennart Keller,Goran Glavaš*

Main category: cs.CL

TL;DR: Romanization in pretraining mLMs yields mixed results: minimal loss for segmental-script languages, degradation for morphosyllabic scripts (Chinese/Japanese) that high-fidelity romanization only partially mitigates; no evidence that increased subword overlap harms cross-lingual transfer; romanization can improve encoding efficiency for segmental scripts with little to no performance cost.


<details>
  <summary>Details</summary>
Motivation: To assess whether romanization is a generally suitable representation for pretraining large multilingual language models, beyond the setup that favors romanization (high-resource Latin-script transfer, close-script relatives). Specifically, quantify losses from script-specific information and from cross-lingual interference due to vocabulary overlap across diverse languages.

Method: Pretrain encoder LMs from scratch on both romanized and original texts for six typologically diverse high-resource languages. Use two romanizers with different fidelity. Compare monolingual LMs and their multilingual counterparts. Evaluate cross-lingual transfer performance and encoding efficiency (fertility).

Result: For languages with segmental scripts, romanization causes negligible performance loss. For morphosyllabic scripts (Chinese, Japanese), degradation occurs, which higher-fidelity romanization mitigates but does not fully recover. Across monolingual vs multilingual LMs, increased subword overlap does not induce negative interference. Romanization improves encoding efficiency (fertility) for segmental scripts with negligible cost.

Conclusion: Romanization is a viable option for pretraining mLMs for segmental-script languages, offering encoding efficiency benefits with minimal trade-offs. However, for morphosyllabic scripts, the benefits are limited and losses persist; vocabulary overlap alone does not imply negative cross-lingual interference, suggesting romanization's applicability is language-script dependent and warrants careful script choice in pretraining.

Abstract: Exposing latent lexical overlap, script romanization has emerged as an effective strategy for improving cross-lingual transfer (XLT) in multilingual language models (mLMs). Most prior work, however, focused on setups that favor romanization the most: (1) transfer from high-resource Latin-script to low-resource non-Latin-script languages and/or (2) between genealogically closely related languages with different scripts. It thus remains unclear whether romanization is a good representation choice for pretraining general-purpose mLMs, or, more precisely, if information loss associated with romanization harms performance for high-resource languages. We address this gap by pretraining encoder LMs from scratch on both romanized and original texts for six typologically diverse high-resource languages, investigating two potential sources of degradation: (i) loss of script-specific information and (ii) negative cross-lingual interference from increased vocabulary overlap. Using two romanizers with different fidelity profiles, we observe negligible performance loss for languages with segmental scripts, whereas languages with morphosyllabic scripts (Chinese and Japanese) suffer degradation that higher-fidelity romanization mitigates but cannot fully recover. Importantly, comparing monolingual LMs with their mLM counterpart, we find no evidence that increased subword overlap induces negative interference. We further show that romanization improves encoding efficiency (i.e., fertility) for segmental scripts at a negligible performance cost.

</details>


### [32] [Simplify-This: A Comparative Analysis of Prompt-Based and Fine-Tuned LLMs](https://arxiv.org/abs/2601.05794)
*Eilam Cohen,Itamar Bul,Danielle Inbar,Omri Loewenbach*

Main category: cs.CL

TL;DR: 比较微调与提示工程在文本简化任务中的效果：微调模型在结构层面的简化更强，提示法在语义相似度高但更容易直接复制输入；人工评估偏好微调输出；并发布代码、数据集派生集、模型权重与提示模板以便复现。


<details>
  <summary>Details</summary>
Motivation: 解决在文本简化任务中微调与提示工程各自的利弊和使用场景，提供系统化的比较以指导实践选择。

Method: 在编码-解码型大语言模型上，基于多项基准和评价指标，比较微调与提示两种范式；使用不同数据集，评估结构化简化、语义保持等方面，并进行人工评估。

Result: 微调模型在结构性简化方面表现更强；提示法在语义相似度上表现更高，但倾向复制原始输入；人工评估总体偏好微调输出；

Conclusion: 对于文本简化任务，微调更有利于实现结构性改写，提示法在保持语义方面有优势但复制风险存在；两者的权衡取决于具体应用需求，研究者已提供代码、派生数据集、权重与提示模板以便复现。

Abstract: Large language models (LLMs) enable strong text generation, and in general there is a practical tradeoff between fine-tuning and prompt engineering. We introduce Simplify-This, a comparative study evaluating both paradigms for text simplification with encoder-decoder LLMs across multiple benchmarks, using a range of evaluation metrics. Fine-tuned models consistently deliver stronger structural simplification, whereas prompting often attains higher semantic similarity scores yet tends to copy inputs. A human evaluation favors fine-tuned outputs overall. We release code, a cleaned derivative dataset used in our study, checkpoints of fine-tuned models, and prompt templates to facilitate reproducibility and future work.

</details>


### [33] [EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis](https://arxiv.org/abs/2601.05808)
*Xiaoshuai Song,Haofei Chang,Guanting Dong,Yutao Zhu,Zhicheng Dou,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 提出 EnvScaler，通过程序性合成实现可扩展的工具交互环境，包含 SkelBuilder 与 ScenGenerator；合成191个环境、约7K个情景，并在 Qwen3 系列的 SFT/RL 上应用，显著提升多轮多工具任务的解决能力；开源代码与数据。


<details>
  <summary>Details</summary>
Motivation: 当前 LLM 需要丰富的工具交互沙盒进行训练，但真实系统受限；基于模拟环境的潜在幻觉与不一致性，以及人工构建沙盒的扩展性问题，迫切需要可扩展的自动化解决方案。

Method: 1) SkelBuilder 通过主题挖掘、逻辑建模和质量评估构建多样化的环境骨架；2) ScenGenerator 为每个环境生成多种任务情景和基于规则的轨迹校验函数；3) 将合成的环境和情景用于 SFT 与 RL，进行模型训练与评估。

Result: 在三个基准上，EnvScaler 显著提升了模型在涉及多轮、多工具交互的任务中的表现；共合成191个环境、约7K个情景；公开代码与数据。

Conclusion: EnvScaler 提供了一个可扩展的自动化框架，用于生成丰富、可校验的工具交互环境，促进 LLM 在真实工具场景中的能力提升；并为社区提供可复现的资源。

Abstract: Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes. However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale. In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis. EnvScaler comprises two components. First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation. Then, ScenGenerator generates multiple task scenarios and rule-based trajectory validation functions for each environment. With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models. Results on three benchmarks show that EnvScaler significantly improves LLMs' ability to solve tasks in complex environments involving multi-turn, multi-tool interactions. We release our code and data at https://github.com/RUC-NLPIR/EnvScaler.

</details>


### [34] [LLMs as Science Journalists: Supporting Early-stage Researchers in Communicating Their Science to the Public](https://arxiv.org/abs/2601.05821)
*Milad Alshomary,Grace Li,Anubhav Jangra,Yufang Hou,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: 提出一个将 LLMs 训练为科学记者角色的框架，帮助早期研究者向公众传达论文成果，并在对话中提出与社会影响相关的高质量问题以促使澄清与扩展。


<details>
  <summary>Details</summary>
Motivation: 现有通用 LLMs 在科普对齐方面不足，无法良好地帮助早期研究者面向公众传播研究成果及其社会影响。需要一个更贴近科学传播职业角色的模型来提升可理解性、可信度和影响力。

Method: 提出一个训练框架，使 LLM 具备科学记者的角色能力。通过与模拟研究者和真实研究者的对话进行评估，训练目标聚焦于提出与社会影响相关的关键问题，促使研究者澄清并扩展发现。评估包括与模拟研究者的对话以及与人类研究者的人机互动。

Result: 实验显示，经过该框架训练的 LLM Journalists 能提出更相关的问题，聚焦研究的社会影响，促进研究者的澄清和扩展。在用户研究中，大多数参与者更偏好与该 LLM Journalists 的互动，相较于通用 LLM。

Conclusion: 该框架提升了科学传播中的对齐度和实用性，特别有助于早期研究者。结果支持进一步开发与扩展，同时需关注评估广度、偏差及在真实传播情境中的稳定性。

Abstract: The scientific community needs tools that help early-stage researchers effectively communicate their findings and innovations to the public. Although existing general-purpose Large Language Models (LLMs) can assist in this endeavor, they are not optimally aligned for it. To address this, we propose a framework for training LLMs to emulate the role of a science journalist that can be used by early-stage researchers to learn how to properly communicate their papers to the general public. We evaluate the usefulness of our trained LLM Journalists in leading conversations with both simulated and human researchers. %compared to the general-purpose ones. Our experiments indicate that LLMs trained using our framework ask more relevant questions that address the societal impact of research, prompting researchers to clarify and elaborate on their findings. In the user study, the majority of participants who interacted with our trained LLM Journalist appreciated it more than interacting with general-purpose LLMs.

</details>


### [35] [Peek2: A Regex-free implementation of pretokenizers for Byte-level BPE](https://arxiv.org/abs/2601.05833)
*Liu Zai*

Main category: cs.CL

TL;DR: Peek2 提供对 cl100k-类 pretokens 的无正则替代实现，在 CPU 上实现线性时间复杂度，并将整个字节级 BPE 编码流程吞吐提升 1.11x；输出的预分割结果与原正则实现完全一致。


<details>
  <summary>Details</summary>
Motivation: 提升 Pretokenization 的性能与安全性，消除正则表达式带来的潜在风险；实现对主流模型（如 GPT-3、LLaMa-3、Qwen-2.5）的 drop-in 兼容替代。

Method: 提出一个无正则、线性时间的预分割算法，作为对 cl100k-类 pretokens 的替代实现，确保输出结果与原 Regex 基准等价，并在 CPU 上实现以获得更广泛的可部署性；设计为对现有接口的直接替换（drop-in）。

Result: 在整个 Byte-level BPE 编码过程上实现约 1.11x 的吞吐提升；算法在 CPU 上运行，复杂度稳定为 O(n)；预分割结果与原 Regex 版本完全等价。

Conclusion: Peek2 为 pretokens 提供了性能与安全性的改进，具备与现有模型与框架的兼容性与可替换性。未来可扩展的方向包括更大规模基准测试、内存使用分析以及对极端文本的鲁棒性评估。

Abstract: Pretokenization is a crucial, sequential pass in Byte-level BPE tokenizers. Our proposed new implementation, Peek2, serves as a drop-in replacement for cl100k-like pretokenizers used in GPT-3, LLaMa-3, and Qwen-2.5. Designed with performance and safety in mind, Peek2 is Regex-free and delivers a $ 1.11\times $ improvement in overall throughput across the entire Byte-level BPE encoding process. This algorithm runs entirely on the CPU, has stable linear complexity $ O(n) $, and provides presegmentation results identical to those of the original Regex-based pretokenizer.

</details>


### [36] [Left, Right, or Center? Evaluating LLM Framing in News Classification and Generation](https://arxiv.org/abs/2601.05835)
*Molly Kennedy,Ali Parker,Yihong Liu,Hinrich Schütze*

Main category: cs.CL

TL;DR: Content blocked due to compliance policy.


<details>
  <summary>Details</summary>
Motivation: Protect user policy by avoiding sensitive political analysis.

Method: Internal processing; not disclosed to user.

Result: Compliance line issued; content hidden.

Conclusion: Policy enforced; sensitive political content suppressed.

Abstract: Large Language Model (LLM) based summarization and text generation are increasingly used for producing and rewriting text, raising concerns about political framing in journalism where subtle wording choices can shape interpretation. Across nine state-of-the-art LLMs, we study political framing by testing whether LLMs' classification-based bias signals align with framing behavior in their generated summaries. We first compare few-shot ideology predictions against LEFT/CENTER/RIGHT labels. We then generate "steered" summaries under FAITHFUL, CENTRIST, LEFT, and RIGHT prompts, and score all outputs using a single fixed ideology evaluator. We find pervasive ideological center-collapse in both article-level ratings and generated text, indicating a systematic tendency toward centrist framing. Among evaluated models, Grok 4 is by far the most ideologically expressive generator, while Claude Sonnet 4.5 and Llama 3.1 achieve the strongest bias-rating performance among commercial and open-weight models, respectively.

</details>


### [37] [Semantic NLP Pipelines for Interoperable Patient Digital Twins from Unstructured EHRs](https://arxiv.org/abs/2601.05847)
*Rafael Brens,Yuqiao Meng,Luoxi Tang,Zhaohan Xi*

Main category: cs.CL

TL;DR: 提出一种基于语义NLP的流水线，将自由文本EHR转化为符合FHIR的数字孪生表示；通过NER、概念规范化（映射到SNOMED-CT/ICD-10）、关系抽取实现实体与关系结构化，在MIMIC-IV数据集上与MIMIC-IV-on-FHIR基线映射对比，取得高F1并改善互操作性。


<details>
  <summary>Details</summary>
Motivation: 需要从非结构化EHR中生成可互操作的数字孪生，因为临床文档异构、缺乏标准映射，阻碍个性化监测、预测建模与临床决策支持。

Method: 建立语义NLP驱动的流水线：对自由文本进行命名实体识别提取临床概念，进行概念规范化映射到SNOMED-CT或ICD-10，进行关系抽取以捕获条件、药物和观测之间的结构化关联，并将结果转换为FHIR兼容的数字孪生表示。

Result: 在MIMIC-IV Clinical Database Demo上进行评估，并对照MIMIC-IV-on-FHIR参考映射，实体与关系抽取的F1分数均较高，且相较基线方法在模式完整性与互操作性方面有所提升。

Conclusion: 基于语义NLP的流水线能够有效地将自由文本EHR转换为标准化的数字孪生表示，提升互操作性与数据丰富性，对个性化护理和临床决策支持具有潜在影响。

Abstract: Digital twins -- virtual replicas of physical entities -- are gaining traction in healthcare for personalized monitoring, predictive modeling, and clinical decision support. However, generating interoperable patient digital twins from unstructured electronic health records (EHRs) remains challenging due to variability in clinical documentation and lack of standardized mappings. This paper presents a semantic NLP-driven pipeline that transforms free-text EHR notes into FHIR-compliant digital twin representations. The pipeline leverages named entity recognition (NER) to extract clinical concepts, concept normalization to map entities to SNOMED-CT or ICD-10, and relation extraction to capture structured associations between conditions, medications, and observations. Evaluation on MIMIC-IV Clinical Database Demo with validation against MIMIC-IV-on-FHIR reference mappings demonstrates high F1-scores for entity and relation extraction, with improved schema completeness and interoperability compared to baseline methods.

</details>


### [38] [Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs](https://arxiv.org/abs/2601.05851)
*Sandeep Mishra,Devichand Budagam,Anubhab Mandal,Bishal Santra,Pawan Goyal,Manish Gupta*

Main category: cs.CL

TL;DR: MAC uses partial typed text plus visual context to predict next characters in live chats; introduces benchmarks (MMDialog/ImageChat adaptation) and Router-Suggest for dynamic model routing; shows speedups and improved user satisfaction.


<details>
  <summary>Details</summary>
Motivation: In real-time multimodal settings, text-only auto-completion misses user intent inferred from visual context. Need to ground predictions multimodally and evaluate VLMs versus strong textual baselines; establish benchmarks for MAC.

Method: Adapt MMDialog and ImageChat to construct MAC benchmark datasets; evaluate leading vision-language models against strong textual baselines; propose Router-Suggest, a router that selects between textual models and VLMs based on dialog context, plus a resource-constrained variant.

Result: VLMs significantly improve user satisfaction and reduce typing effort in multi-turn conversations; Router-Suggest achieves 2.3x to 10x speedup over the best-performing VLM.

Conclusion: Multimodal grounding enhances auto-completion quality and user experience; careful balance between accuracy and efficiency via dynamic routing; future work on more efficient VLMs and broader benchmarks to optimize real-time performance.

Abstract: Real-time multimodal auto-completion is essential for digital assistants, chatbots, design tools, and healthcare consultations, where user inputs rely on shared visual context. We introduce Multimodal Auto-Completion (MAC), a task that predicts upcoming characters in live chats using partially typed text and visual cues. Unlike traditional text-only auto-completion (TAC), MAC grounds predictions in multimodal context to better capture user intent. To enable this task, we adapt MMDialog and ImageChat to create benchmark datasets. We evaluate leading vision-language models (VLMs) against strong textual baselines, highlighting trade-offs in accuracy and efficiency. We present Router-Suggest, a router framework that dynamically selects between textual models and VLMs based on dialog context, along with a lightweight variant for resource-constrained environments. Router-Suggest achieves a 2.3x to 10x speedup over the best-performing VLM. A user study shows that VLMs significantly excel over textual models on user satisfaction, notably saving user typing effort and improving the quality of completions in multi-turn conversations. These findings underscore the need for multimodal context in auto-completions, leading to smarter, user-aware assistants.

</details>


### [39] [CLewR: Curriculum Learning with Restarts for Machine Translation Preference Learning](https://arxiv.org/abs/2601.05858)
*Alexandra Dragomir,Florin Brad,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 这项工作将课程学习用于偏好优化下的零-shot多语言机器翻译，并提出CLewR，在训练中多次重启的易到难课程以缓解简单样本的灾难性遗忘，结果在多种模型家族（Gemma2、Qwen2.5、Llama3.1）及多种偏好优化方法上获得一致性提升，并公开代码。


<details>
  <summary>Details</summary>
Motivation: 在偏好优化的MT训练中，样本排序（课程学习）的作用被较少研究，容易导致对简单样本的遗忘，亟需通过培训顺序来提升翻译质量，特别是零-shot的多语言场景。

Method: 将课程学习引入现有的前沿偏好优化算法，提出CLewR策略：在训练过程中不断以易→难的课程重启多次，以缓解易样本的灾难性遗忘；在Gemma2、Qwen2.5、Llama3.1等模型家族及多种偏好优化技术上进行系统评估，并公开代码。

Result: 在所覆盖的模型家族与偏好优化技术上观察到一致的性能提升，表明CLewR能有效提升偏好优化驱动的MT性能。

Conclusion: 易到难的课程学习能通过多次重启缓解简单样本的遗忘，并在跨模型家族的偏好优化MT中表现出稳健的改善，具有较强的迁移潜力和应用价值。

Abstract: Large language models (LLMs) have demonstrated competitive performance in zero-shot multilingual machine translation (MT). Some follow-up works further improved MT performance via preference optimization, but they leave a key aspect largely underexplored: the order in which data samples are given during training. We address this topic by integrating curriculum learning into various state-of-the-art preference optimization algorithms to boost MT performance. We introduce a novel curriculum learning strategy with restarts (CLewR), which reiterates easy-to-hard curriculum multiple times during training to effectively mitigate the catastrophic forgetting of easy examples. We demonstrate consistent gains across several model families (Gemma2, Qwen2.5, Llama3.1) and preference optimization techniques. We publicly release our code at https://github.com/alexandra-dragomir/CLewR.

</details>


### [40] [What do the metrics mean? A critical analysis of the use of Automated Evaluation Metrics in Interpreting](https://arxiv.org/abs/2601.05864)
*Jonathan Downie,Joss Moorkens*

Main category: cs.CL

TL;DR: 自动化口译质量评估方法不足以单独衡量质量，需结合情境与交际语境。


<details>
  <summary>Details</summary>
Motivation: 随着远程口译、计算机辅助口译、自动语音翻译与口译化身等技术的发展，出现快速高效衡量口译质量的需求。

Method: 分析并评估近来提出的自动化质量测量方法，讨论其在衡量人类或机器口译的适用性，比较不同方法的优缺点。

Result: 现有自动化指标难以充分捕捉交际情境，因此单独使用不可行。

Conclusion: 口译研究中的质量评估应以情境与交际语境为基础，需将情境因素融入量化评估，单一自动化指标不可覆盖全部维度。

Abstract: With the growth of interpreting technologies, from remote interpreting and Computer-Aided Interpreting to automated speech translation and interpreting avatars, there is now a high demand for ways to quickly and efficiently measure the quality of any interpreting delivered. A range of approaches to fulfil the need for quick and efficient quality measurement have been proposed, each involving some measure of automation. This article examines these recently-proposed quality measurement methods and will discuss their suitability for measuring the quality of authentic interpreting practice, whether delivered by humans or machines, concluding that automatic metrics as currently proposed cannot take into account the communicative context and thus are not viable measures of the quality of any interpreting provision when used on their own. Across all attempts to measure or even categorise quality in Interpreting Studies, the contexts in which interpreting takes place have become fundamental to the final analysis.

</details>


### [41] [Continual-learning for Modelling Low-Resource Languages from Large Language Models](https://arxiv.org/abs/2601.05874)
*Santosh Srinath K,Mudit Somani,Varun Reddy Padala,Prajna Devi Upadhyay,Abhijit Das*

Main category: cs.CL

TL;DR: 提出基于持续学习的方案，结合基于词性的代码切换和回放适配器，缓解将大语言模型微调为小型语言模型时的灾难性遗忘，并在视觉-语言任务中取得成功。


<details>
  <summary>Details</summary>
Motivation: 多语言场景下的灾难性遗忘是将LLM迁移到低资源语言的SLM时的核心挑战，现有方法往往难以同时保持多语言知识与新任务适应性。

Method: 采用基于词性的代码切换策略来引导跨语言学习，同时引入回放适配器以保留先前任务/语言的知识，采用持续学习框架从LLM迁移到SLM，适用于视觉-语言任务与语言建模。

Result: 实验在视觉-语言任务（如视觉问答）和语言建模任务上显示所提架构能有效缓解灾难性遗忘并提升性能相对于基线。

Conclusion: POS基的代码切换结合回放适配器提供了一种有前景的持续学习解决方案，用于多语言场景下的SLM迁移，应在更多任务和语言上进一步验证。

Abstract: Modelling a language model for a multi-lingual scenario includes several potential challenges, among which catastrophic forgetting is the major challenge. For example, small language models (SLM) built for low-resource languages by adapting large language models (LLMs) pose the challenge of catastrophic forgetting. This work proposes to employ a continual learning strategy using parts-of-speech (POS)-based code-switching along with a replay adapter strategy to mitigate the identified gap of catastrophic forgetting while training SLM from LLM. Experiments conducted on vision language tasks such as visual question answering and language modelling task exhibits the success of the proposed architecture.

</details>


### [42] [iReasoner: Trajectory-Aware Intrinsic Reasoning Supervision for Self-Evolving Large Multimodal Models](https://arxiv.org/abs/2601.05877)
*Meghana Sunil,Manikandarajan Venmathimaran,Muthu Subash Kavitha*

Main category: cs.CL

TL;DR: 提出 iReasoner，通过在自我进化框架中显式引出连锁推理（CoT）并对内部一致性进行奖赏，利用轨迹感知的中间推理信号，在无标签数据下提升大多模态模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有自我进化框架多数仅以最终输出为奖惩对象，忽略中间推理过程对视觉-文本推理的重要性，致力于在纯无监督条件下提升 LMM 的内部推理质量。

Method: 在 Proposer–Solver 循环中引入面向中间推理步骤的轨迹感知信号，将结果级内在奖赏与中间推理轨迹对齐；通过对同一答案的不同推理路径进行区分性学习信号，提升在没有 ground-truth 标签或外部评判的情况下的推理多样性与一致性。以 Qwen2.5-VL-7B 为起点进行无监督的后训练。

Result: 在完全无监督后训练条件下，iReasoner 在多模态推理基准上获得最高约+2.1 分的提升，表明对中间推理的显式引导能有效提升推理性能。

Conclusion: 提出了面向推理的自我提升初步框架，为在纯无监督场景中的 LMM 推理能力提升提供可行路径，但需进一步评估对不同任务分布的鲁棒性及对 CoT 质量与内部一致性度量的依赖。

Abstract: Recent work shows that large multimodal models (LMMs) can self-improve from unlabeled data via self-play and intrinsic feedback. Yet existing self-evolving frameworks mainly reward final outcomes, leaving intermediate reasoning weakly constrained despite its importance for visually grounded decision making. We propose iReasoner, a self-evolving framework that improves an LMM's implicit reasoning by explicitly eliciting chain-of-thought (CoT) and rewarding its internal agreement. In a Proposer--Solver loop over unlabeled images, iReasoner augments outcome-level intrinsic rewards with a trajectory-aware signal defined over intermediate reasoning steps, providing learning signals that distinguish reasoning paths leading to the same answer without ground-truth labels or external judges. Starting from Qwen2.5-VL-7B, iReasoner yields up to $+2.1$ points across diverse multimodal reasoning benchmarks under fully unsupervised post-training. We hope this work serves as a starting point for reasoning-aware self-improvement in LMMs in purely unsupervised settings.

</details>


### [43] [Gender Bias in LLMs: Preliminary Evidence from Shared Parenting Scenario in Czech Family Law](https://arxiv.org/abs/2601.05879)
*Jakub Harasta,Matej Vasina,Martin Kornel,Tomas Foltynek*

Main category: cs.CL

TL;DR: 本研究评估面向家庭法场景的四大领先大型语言模型（LLMs）在性别偏见方面的表现。通过基于捷克家庭法的专家设计离婚情景，对比性别标签与中性标签两种设定，以及九个影响事实的变项，测量模型在共同抚养比例上的差异。初步结果显示各模型存在差异，且部分系统呈现性别相关的输出模式，提示在敏感法律场景下对LLMs的使用风险及需要更严格的系统性评估。


<details>
  <summary>Details</summary>
Motivation: 由于司法救济渠道不足，普通人越来越依赖LLMs获取法律自助信息。若模型输出存在性别偏见或错误信息，可能导致现实中的不公平结果。本研究旨在揭示在法律敏感场景中LLMs的潜在性别偏见及其规律，为评估与监管提供初步证据。

Method: 采用基于捷克家事法的专家设计离婚情景，面向四种前沿LLMs（GPT-5 nano、Claude Haiku 4.5、Gemini 2.5 Flash、Llama 3.3）进行全零-shot交互。设置两版本情景：性别化姓名与中性标签以建立对照；引入九个与法律相关的因素以改变事实情境，观察对模型提出的共同抚养比例的影响。结果以探索性、描述性证据为主，旨在识别系统性不对称而非确立因果关系。

Result: 结果显示各模型之间存在差异；部分系统出现与性别相关的输出模式，影响对共同抚养比例的建议。测试设计提供了基线并揭示在不同事实变项下的趋势，但目前仍处于初步阶段，尚需更严格的因果与鲁棒性分析。

Conclusion: 研究强调普通民众在依赖LLMs获取法律意见时的潜在风险，呼吁对模型在敏感法律语境中的行为进行更为严格和系统的评估。

Abstract: Access to justice remains limited for many people, leading laypersons to increasingly rely on Large Language Models (LLMs) for legal self-help. Laypeople use these tools intuitively, which may lead them to form expectations based on incomplete, incorrect, or biased outputs. This study examines whether leading LLMs exhibit gender bias in their responses to a realistic family law scenario. We present an expert-designed divorce scenario grounded in Czech family law and evaluate four state-of-the-art LLMs GPT-5 nano, Claude Haiku 4.5, Gemini 2.5 Flash, and Llama 3.3 in a fully zero-shot interaction. We deploy two versions of the scenario, one with gendered names and one with neutral labels, to establish a baseline for comparison. We further introduce nine legally relevant factors that vary the factual circumstances of the case and test whether these variations influence the models' proposed shared-parenting ratios. Our preliminary results highlight differences across models and suggest gender-dependent patterns in the outcomes generated by some systems. The findings underscore both the risks associated with laypeople's reliance on LLMs for legal guidance and the need for more robust evaluation of model behavior in sensitive legal contexts. We present exploratory and descriptive evidence intended to identify systematic asymmetries rather than to establish causal effects.

</details>


### [44] [An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift](https://arxiv.org/abs/2601.05882)
*Constantinos Karouzos,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 系统比较五种对齐目标及多种领域自适应策略在领域转移下的泛化能力，发现伪标签策略显著减轻域偏移引起的性能下降。


<details>
  <summary>Details</summary>
Motivation: 评估偏好对齐在域迁移中的鲁棒性，以及不同对齐目标和迁移策略的泛化表现。

Method: 在摘要和问答有用性任务上，比较五种对齐目标；从源域到目标域应用目标域监督微调和伪标签等适应策略。

Result: 对齐目标在跨域泛化上呈现系统性差异；伪标签驱动的适应策略可显著缓解域迁移的性能衰退。

Conclusion: 在跨域对齐任务中，选择合适的对齐目标并结合伪标签等适应策略可提升鲁棒性，未来可拓展到其他任务与更复杂域偏移。

Abstract: Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation

</details>


### [45] [Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency](https://arxiv.org/abs/2601.05905)
*Haoming Xu,Ningyuan Zhao,Yunzhi Yao,Weihong Xu,Hongru Wang,Xinle Deng,Shumin Deng,Jeff Z. Pan,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: NCB 是一个结构性信念鲁棒性度量，结合认知压力测试和结构感知训练，提升 LLM 对上下文干扰的稳定性与长尾知识的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有评估多依赖点对点置信度，可能掩盖信念的结构性脆弱；需要评估响应在概念邻域中的一致性以反映真实鲁棒性。

Method: 定义概念邻域的结构性一致性（NCB）、提出认知压力测试协议、在多模型上评估、提出 Structure-Aware Training（SAT），以优化上下文不变的信念结构。

Result: 高NCB数据在干扰下更具鲁棒性；SAT 将信念结构优化，降低长尾知识脆弱性约30%。

Conclusion: NCB 提供更可靠的信念鲁棒性评估与改进路径，SAT 可作为提升现实部署鲁棒性的训练范式，代码将开放。

Abstract: As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at https://github.com/zjunlp/belief.

</details>


### [46] [Pantagruel: Unified Self-Supervised Encoders for French Text and Speech](https://arxiv.org/abs/2601.05911)
*Phuong-Hang Le,Valentin Pelloin,Arnault Chatelain,Maryem Bouziane,Mohammed Ghennai,Qianwen Guan,Kirill Milintsevich,Salima Mdhaffar,Aidan Mannion,Nils Defauw,Shuyue Gu,Alexandre Audibert,Marco Dinarelli,Yannick Estève,Lorraine Goeuriot,Steffen Lalande,Nicolas Hervé,Maximin Coavoux,François Portet,Étienne Ollion,Marie Candito,Maxime Peyrard,Solange Rossato,Benjamin Lecouteux,Aurélie Nardy,Gilles Sérasset,Vincent Segonne,Solène Evain,Diandra Fabre,Didier Schwab*

Main category: cs.CL

TL;DR: Pantagruel 提出一类新的自监督编码模型家族，采用特征空间的目标表示而不是模态特定目标，实现文本与语音编码器的共享架构，具备跨模态理解能力，在法语任务上与强基线竞争甚至超越。


<details>
  <summary>Details</summary>
Motivation: 解决以模态为针的预测目标局限性，通过在特征空间学习上下文相关的目标表示，使文本和语音编码器能更有效地捕捉语言与声学规律，并提供一个统一的、多模态友好的法语表示学习框架。

Method: 对法语文本和法语语音分别进行自监督预训练，目标是特征空间中的上下文相关表示，而非文本令牌或语音单元。文本数据来自 Wikipedia、OSCAR、CroissantLLM 等大规模语料；语音数据来自 MultilingualLibriSpeech、LeBenchmark、INA-100k（新公开的 100k 小时法语音频语料，来自 INA 档案）。在多任务/多数据环境下评估包括 FLUE、LeBenchmark 等法语基准，且模型具有统一的、可同时处理文本与语音的架构。

Result: 在广泛下游任务中，Pantagruel 展现出与 CamemBERT、FlauBERT、LeBenchmark2.0 等强基线的竞争力甚至优越性，且保持了能同时处理文本与语音输入的共享架构。证据显示特征空间自监督目标对法语表示学习有效，且具备良好的跨模态理解潜力。

Conclusion: Pantagruel 为法语表示学习提供了一个鲁棒的多模态基础，证明特征空间自监督目标在文本与语音上的有效性，并揭示在大量多模态数据上统一架构的潜力，未来可拓展至其他语言与更大规模的跨模态任务。

Abstract: We release Pantagruel models, a new family of self-supervised encoder models for French text and speech. Instead of predicting modality-tailored targets such as textual tokens or speech units, Pantagruel learns contextualized target representations in the feature space, allowing modality-specific encoders to capture linguistic and acoustic regularities more effectively. Separate models are pre-trained on large-scale French corpora, including Wikipedia, OSCAR and CroissantLLM for text, together with MultilingualLibriSpeech, LeBenchmark, and INA-100k for speech. INA-100k is a newly introduced 100,000-hour corpus of French audio derived from the archives of the Institut National de l'Audiovisuel (INA), the national repository of French radio and television broadcasts, providing highly diverse audio data. We evaluate Pantagruel across a broad range of downstream tasks spanning both modalities, including those from the standard French benchmarks such as FLUE or LeBenchmark. Across these tasks, Pantagruel models show competitive or superior performance compared to strong French baselines such as CamemBERT, FlauBERT, and LeBenchmark2.0, while maintaining a shared architecture that can seamlessly handle either speech or text inputs. These results confirm the effectiveness of feature-space self-supervised objectives for French representation learning and highlight Pantagruel as a robust foundation for multimodal speech-text understanding.

</details>


### [47] [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.06002)
*Qiguang Chen,Yantao Du,Ziniu Li,Jinhao Liu,Songyao Duan,Jiarui Guo,Minghao Liu,Jiaheng Liu,Tong Yang,Ge Zhang,Libo Qin,Wanxiang Che,Wenhao Huang*

Main category: cs.CL

TL;DR: Long CoT学习需稳定分子状结构，三种互动驱动深度推理、自我反思和自我探索；结构来自Long CoT微调而非仅靠关键字 imitate，借助Effective Semantic Isomers和分布转移图Mole-Syn实现对有效Long CoT结构的合成，提升性能与RL稳定性。


<details>
  <summary>Details</summary>
Motivation: 揭示为何长链推理（Long CoT）难以从人类或非Long-CoT的模仿中有效学习，寻找可学习的结构性规律以提升模型推理能力与训练稳定性。

Method: 分析蒸馏轨迹，提出分子状结构的三种互动：深度推理（类似共价键）、自我反思（类似氢键）、自我探索（类似范德瓦尔斯力）；引入Effective Semantic Isomers，定义哪些键促成快速熵收敛；提出Mole-Syn，一种分布转移图方法，用于引导合成有效Long CoT结构。

Result: 实验表明，Long CoT结构来自微调过程而非简单的关键字模仿；只有促进快速熵收敛的连接支持稳定学习，结构竞争则削弱训练效果；Mole-Syn在多项基准上提升Long CoT表现与强化学习稳定性。

Conclusion: 稳定的分子样结构和快速熵收敛是Long CoT可学习性的关键；不良的结构竞争会降低训练效果；基于分布转移的Mole-Syn能有效引导结构合成，从而提升整体性能与鲁棒性。

Abstract: Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks.

</details>


### [48] [Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards](https://arxiv.org/abs/2601.06021)
*Jiajie Zhang,Xin Lv,Ling Feng,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.

</details>


### [49] [AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs](https://arxiv.org/abs/2601.06022)
*Chengming Cui,Tianxin Wei,Ziyi Chen,Ruizhong Qiu,Zhichen Zeng,Zhining Liu,Xuying Ning,Duo Zhou,Jingrui He*

Main category: cs.CL

TL;DR: AdaFuse is an adaptive ensemble decoding framework that dynamically selects fusion units during generation using word-level alignment, guided by uncertainty and diversity-aware scaling, leading to improved performance across QA, reasoning, and translation.


<details>
  <summary>Details</summary>
Motivation: Fixed-granularity ensemble methods lack mid-generation adaptability; different tasks and generation contexts require flexible fusion strategies and fine-grained control.

Method: AdaFuse introduces adaptive, word-level fusion units with an uncertainty-based criterion to decide when to ensemble at each decoding step. In low-confidence states, it employs diversity-aware scaling to explore alternative continuations and inform ensemble decisions, creating a feedback loop between exploration and ensemble quality.

Result: Empirical evaluation on open-domain QA, arithmetic reasoning, and machine translation shows AdaFuse consistently outperforms strong ensemble baselines, with an average relative improvement of 6.88%. Code is provided at the linked repository.

Conclusion: Adaptive, context-aware ensembling with per-step decisions and diversity-driven exploration enhances ensemble effectiveness across heterogeneous tasks.

Abstract: Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [50] [SP-Rank: A Dataset for Ranked Preferences with Secondary Information](https://arxiv.org/abs/2601.05253)
*Hadi Hosseini,Debmalya Mandal,Amrit Puhan*

Main category: cs.IR

TL;DR: SP-Rank 是一个新的大规模数据集，结合第一序信号（个人投票）和第二序信号（他人投票的元预测），用于排序任务的联合推断；基准显示第二序信号能提升 Ground-truth 排序的恢复精度；并公开数据、代码与基线评估。


<details>
  <summary>Details</summary>
Motivation: 解决仅依赖个人偏好数据的传统排序数据集的局限，允许在未知专家身份的前提下利用两类信号进行更丰富的偏好建模和聚合分析，支持对人类偏好建模、聚合理论和人机对齐等研究。

Method: 提出 SP-Rank 数据集（>1.2万 datapoints，覆盖地理、电影、绘画等3领域，包含9种 elicitation formats）以及 SP-Voting 方法，比较仅基于第一序信号的传统聚合与联合考虑两种信号的排序推断；支持纯第二序信号的模型，强调两信号结合的收益。评估任务包括完整 ground-truth 排序恢复、子集级排序恢复，以及投票者行为的概率化建模。

Result: 将第二序信号引入显著提升相对于仅投票的方法的准确性；在全量和子集场景均展现优势；推动在学习排序、从嘈杂众包中提取专家知识，以及偏好为基础的微调中应用。

Conclusion: 公开数据、代码与基线评估，促进人类偏好建模、聚合理论与人机对齐等领域的发展。

Abstract: We introduce $\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at https://github.com/amrit19/SP-Rank-Dataset ) to foster research in human preference modeling, aggregation theory, and human-AI alignment.

</details>


### [51] [TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2601.05254)
*Wenbiao Tao,Yunshi Lan,Weining Qian*

Main category: cs.IR

TL;DR: TagRAG introduces a tag-guided hierarchical knowledge graph RAG framework to enable efficient global reasoning and scalable graph maintenance. It constructs a Tag Knowledge Graph from documents by extracting object tags and relationships into hierarchical domain tag chains and uses Tag-Guided Retrieval-Augmented Generation to retrieve domain-centric tag chains for inference, achieving strong efficiency gains and high performance across diverse domains.


<details>
  <summary>Details</summary>
Motivation: Address the limitations of GraphRAG and fragment-level RAG: inefficiency in information extraction, high resource consumption, and poor adaptability to incremental updates; conventional RAG lacks global reasoning across knowledge and struggles with updates, especially for smaller LMs.

Method: Two-part design: (1) Tag Knowledge Graph Construction that extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation; (2) Tag-Guided Retrieval-Augmented Generation that retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This enables efficient global reasoning and scalable graph maintenance.

Result: Empirical evaluation on UltraDomain datasets (Agriculture, Computer Science, Law, and cross-domain) shows TagRAG achieves an average win rate of 95.41% against baselines, with about 14.6x construction efficiency and 1.9x retrieval efficiency compared with GraphRAG.

Conclusion: TagRAG provides efficient global knowledge reasoning and scalable graph maintenance, improves retrieval granularity, adapts well to smaller language models, and supports efficient knowledge increment, demonstrating strong cross-domain performance.

Abstract: Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average win rate of 95.41\% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG.

</details>


### [52] [CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms](https://arxiv.org/abs/2601.05255)
*Sai Khadloya,Kush Juvekar,Arghya Bhattacharya,Utkarsh Saxena*

Main category: cs.IR

TL;DR: CourtNav 是一种面向法律 PDFs 的语音导航器，采用锚点优先设计，将口头命令直接映射到高亮段落，显著降低检索时间，保持证据可核验性。


<details>
  <summary>Details</summary>
Motivation: 在司法工作中，海量记录需要密集阅读，但人员有限，逐段手工查找耗时且不可行。印度等司法体系对可审计证据的需求尤为突出。

Method: 命令识别：grammar-first 精确正则匹配转写命令；LLM 辅助路由器进行查询分类（少量示例）; 使用布局感知的混合索引进行检索；自动滚动并高亮引用段落及替代选项；界面仅显示有依据的段落，确保可核验性。

Result: 在对代表性起诉书、诉状和裁判文书的试点中，时效由人工导航的3-5分钟降至10-15秒，带快速核验后为30-45秒。在固定时限下，导航优先的设计扩大了实际可审阅的记录范围，同时保持了透明性和可控性。

Conclusion: 该导航式设计提高了检索速度与覆盖面，同时保持证据可核验性和透明度，特别契合印度等长篇判决的工作场景。未来可在多语种、跨类型文档扩展及鲁棒性方面进一步验证。

Abstract: Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., "go to paragraph 23", "highlight the contradiction in the cross-examination") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously long.In a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency.

</details>


### [53] [From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing](https://arxiv.org/abs/2601.05258)
*Kaichun Wang,Yanguang Chen,Ting Zhang,Mengyao Bao,Keyu Chen,Xu Hu,Yongliang Wang,Jingsheng Yang,Jinsong Zhang,Fei Lu*

Main category: cs.IR

TL;DR: 提出一个用于对话系统的多阶段趋势检测框架，通过离线生成索引查询与在线检索匹配、级联召回与排序，以及冷启动单召回模块实现在线数据采集与重新排序，显著优于基线并提升用户满意度27%。


<details>
  <summary>Details</summary>
Motivation: 解决对话系统在处理新闻相关趋势查询时的性能不足；传统搜索引擎方法在对话场景下因查询分布和表达差异导致效果差。

Method: 包含离线阶段：基于热点事件生成索引查询以建立静态事件与动态用户查询之间的桥梁；在线阶段：检索匹配机制，级联召回与排序架构实现实时趋势检测；冷启动策略：单召回模块用于在线数据采集以微调重新排序模型。

Result: 在离线和在线评测中均显著优于基线；在线A/B测试中提升用户满意度，正负反馈比提升27%。

Conclusion: 该框架有效提升对话系统的趋势查询检测能力，桥接静态事件与动态查询，结合在线自适应微调，适用于实际应用场景。

Abstract: LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\% in terms of positive-negative feedback ratio.

</details>


### [54] [A Technical Report on the Second Place Solution for the CIKM 2025 AnalytiCup Competition](https://arxiv.org/abs/2601.05259)
*Haotao Xie,Ruilin Chen,Yicheng Wu,Zhan Zhao,Yuanyuan Liu*

Main category: cs.IR

TL;DR: 提出一种单模型、结构化提示与轻量化微调相结合的多语言分类相关性判断框架，通过将任务分解为翻译、意图理解、类别匹配和相关性判断四个子任务，并以LoRA微调Qwen2.5-14B实现高效推理与可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于集成的大规模系统在训练、推理与维护上的高成本与复杂性，寻求更高效、可解释且可扩展的工业AI解决方案。

Method: 使用 Chain-of-Thought 任务分解的结构化提示，在单一大语言模型中完成翻译、意图理解、类别匹配和相关性判断四步推理；对基础模型 Qwen2.5-14B 进行 LoRA 微调以实现高效适配；通过对齐提示与子任务设计提高可解释性与推理质量。

Result: 在公开基准与私有基准上均达到竞争性准确度；推理性能优异，单卡 A100 下可达到约20样本/秒；在 CIKM 2025 AnalytiCup proposal 中公开榜单得分 0.8902，私有榜单 0.8889，显示方法的鲁棒性与实用性。

Conclusion: 结构化提示结合轻量化微调的单模型方法可在多语言电商场景中超越复杂的集成系统，提供更高效、可解释且易于维护的解决方案，具有广阔的工业应用潜力。

Abstract: In this work, we address the challenge of multilingual category relevance judgment in e-commerce search, where traditional ensemble-based systems improve accuracy but at the cost of heavy training, inference, and maintenance complexity. To overcome this limitation, we propose a simplified yet effective framework that leverages prompt engineering with Chain-of-Thought task decomposition to guide reasoning within a single large language model. Specifically, our approach decomposes the relevance judgment process into four interpretable subtasks: translation, intent understanding, category matching, and relevance judgment -- and fine-tunes a base model (Qwen2.5-14B) using Low-Rank Adaptation (LoRA) for efficient adaptation. This design not only reduces computational and storage overhead but also enhances interpretability by explicitly structuring the model's reasoning path. Experimental results show that our single-model framework achieves competitive accuracy and high inference efficiency, processing 20 samples per second on a single A100 GPU. In the CIKM 2025 AnalytiCup Competition Proposals, our method achieved 0.8902 on the public leaderboard and 0.8889 on the private leaderboard, validating the effectiveness and robustness of the proposed approach. These results highlight that structured prompting combined with lightweight fine-tuning can outperform complex ensemble systems, offering a new paradigm for scalable industrial AI applications.

</details>


### [55] [Quantifying Document Impact in RAG-LLMs](https://arxiv.org/abs/2601.05260)
*Armin Gerami,Kazem Faghih,Ramani Duraiswami*

Main category: cs.IR

TL;DR: Introduce Influence Score (IS), a Partial Information Decomposition-based metric to quantify each retrieved document's influence on a RAG-generated response. Validation via poison attack and ablation shows IS effectively identifies malicious documents and correlates with response similarity when using top-IS documents.


<details>
  <summary>Details</summary>
Motivation: RAG systems combine retrieved documents with LLMs, but there is no metric to quantify how much each retrieved document contributes to the final output, hindering transparency and reliability.

Method: Define Influence Score (IS) using Partial Information Decomposition to decompose the information contributing to the generated response by each retrieved document. Validate through: (1) poison attack simulation over three datasets to see if IS flags the malicious document as most influential (86% success). (2) ablation study comparing outputs generated from top-IS documents versus remaining documents, assessing similarity to the original response.

Result: IS successfully identifies the malicious document as the most influential in 86% of cases. Outputs formed from top-IS documents are consistently more similar to the original response than those from the remaining documents.

Conclusion: IS provides a principled, interpretable measure of document influence in RAG, enabling better transparency and reliability by isolating the impact of individual retrieved documents on the final response.

Abstract: Retrieval Augmented Generation (RAG) enhances Large Language Models (LLMs) by connecting them to external knowledge, improving accuracy and reducing outdated information. However, this introduces challenges such as factual inconsistencies, source conflicts, bias propagation, and security vulnerabilities, which undermine the trustworthiness of RAG systems. A key gap in current RAG evaluation is the lack of a metric to quantify the contribution of individual retrieved documents to the final output. To address this, we introduce the Influence Score (IS), a novel metric based on Partial Information Decomposition that measures the impact of each retrieved document on the generated response. We validate IS through two experiments. First, a poison attack simulation across three datasets demonstrates that IS correctly identifies the malicious document as the most influential in $86\%$ of cases. Second, an ablation study shows that a response generated using only the top-ranked documents by IS is consistently judged more similar to the original response than one generated from the remaining documents. These results confirm the efficacy of IS in isolating and quantifying document influence, offering a valuable tool for improving the transparency and reliability of RAG systems.

</details>


### [56] [Improving User Experience with Personalized Review Ranking and Summarization](https://arxiv.org/abs/2601.05261)
*Muhammad Mufti,Omar Hammad,Mahfuzur Rahman*

Main category: cs.IR

TL;DR: 将个性化的评审排序与抽象摘要相结合，通过情感混合建模与语义画像实现对用户偏好的匹配，显著提升阅读相关性和决策效率，缓解信息过载。


<details>
  <summary>Details</summary>
Motivation: 在线消费者评测数量庞大，信息过载；现有排序指标主要关注有用性、星级和时效，难以捕捉用户的个性化兴趣，且情感信号与评分信号通常分离。

Method: 1) 通过星级评分与评审文本的混合分析来建模用户情感；2) 基于历史评审的句子嵌入与聚类，形成与主题和情感维度对齐的语义画像；3) 设计相关性评分算法，将画像与未见评审在情感和要点（aspect）层面进行匹配；4) 选取顶级匹配评审并进行 abstractive summarization，以反映个体兴趣。

Result: 70名参与者的用户研究表明，个性化方法提升了满意度、感知相关性和决策信心，同时减少了阅读时间。

Conclusion: 将排序与摘要的个性化整合有助于提升评审密集场景中的用户体验，缓解信息过载，并在决策效率方面展现显著价值。

Abstract: Online consumer reviews play a crucial role in guiding purchase decisions by offering insights into product quality, usability, and performance. However, the increasing volume of user-generated reviews has led to information overload, making it difficult for consumers to identify content that aligns with their specific preferences. Existing review ranking systems typically rely on metrics such as helpfulness votes, star ratings, and recency, but these fail to capture individual user interests and often treat textual sentiment and rating signals separately. This research addresses these limitations by proposing a personalized framework that integrates review ranking and abstractive summarization to enhance decision-making efficiency. The proposed system begins by modeling each user's sentiment through a hybrid analysis of star ratings and review content. Simultaneously, user preferences were derived from historical reviews using sentence embeddings and clustering, forming semantic profiles aligned with thematic and sentiment dimensions. A relevance scoring algorithm matched these profiles with unseen reviews based on sentiment and aspect similarity. Top-matched reviews were then summarized to reflect individual interests. A user study with 70 participants demonstrated that the personalized approach improved satisfaction, perceived relevance, and decision-making confidence, while reducing time spent reading. The results highlight the method's effectiveness in alleviating information overload and delivering content tailored to user-specific preferences, emphasizing its value in enhancing user experience in review-rich decision-making environments.

</details>


### [57] [LLM2IR: simple unsupervised contrastive learning makes long-context LLM great retriever](https://arxiv.org/abs/2601.05262)
*Xiaocong Yang*

Main category: cs.IR

TL;DR: 提出 LLM2IR，将解码器型大语言模型通过无监督对比学习转化为信息检索模型，在 LoCo、LongEmbed、BEIR 等基准上表现良好；并发现更长的上下文长度与更强的检索能力相关。


<details>
  <summary>Details</summary>
Motivation: 降低Dense IR对大规模预训练的依赖；探索如何从现有解码器型 LLM 提取检索能力，以及上下文长度对该能力的影响。

Method: 提出无监督对比学习框架 LLM2IR，将任意解码器型 LLM 转化为 IR 模型；通过对比学习驱动查询-文档对在潜在嵌入空间的对齐；在多个基准上评估。

Result: 在多种 LLM 上以及 LoCo、LongEmbed、BEIR 基准上验证有效性；发现同一系列模型中上下文长度越长，IR 能力越强。

Conclusion: 为在最先进 LLM 上构建 IR 模型提供有效途径，并提示上下文长度与信息检索能力的关联，为设计更优的检索器提供指导。

Abstract: Modern dense information retrieval (IR) models usually rely on costly large-scale pretraining. In this paper, we introduce LLM2IR, an efficient unsupervised contrastive learning framework to convert any decoder-only large language model (LLM) to an information retrieval model. Despite its simplicity, the effectiveness is proven among different LLMs on multiple IR benchmarks including LoCo, LongEmbed and BEIR. We also find that models with a longer context length tend to have a stronger IR capacity by comparing task performances of models in the same model family. Our work not only provides an effective way to build IR models on the state-of-the-art LLMs, but also shed light on the relationship between information retrieval ability and model context length, which helps the design of better information retrievers.

</details>


### [58] [A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)](https://arxiv.org/abs/2601.05263)
*Zhen Yi Lau*

Main category: cs.IR

TL;DR: GTWED generalizes TWED to arbitrary metric spaces, yielding a true metric; recovers TWED when the observation domain is Euclidean and the time mapping is identity; enables TWED-like metrics on sequences over non-time domains such as symbolic data, manifolds, or embeddings.


<details>
  <summary>Details</summary>
Motivation: Extend elastic distance concepts beyond time series by defining a genuine metric on sequences over arbitrary domains, enabling principled comparison and analysis across diverse data types while preserving metric properties.

Method: Define GTWED on two metric spaces (X,d) for observations and (T,Δ) for time with a mapping g and appropriate penalty terms; prove metric properties (non-negativity, identity of indiscernibles, symmetry, triangle inequality) under mild assumptions; show that setting X = R^d, T ⊂ R, and g(x) = x recovers the classical TWED as a special case.

Result: GTWED is a true metric on sequences over (X,d) and (T,Δ) under mild assumptions; the classical TWED is recovered in the Euclidean-time special case; the framework enables TWED-like elastic distances on non-traditional domains (symbolic data, manifolds, embeddings).

Conclusion: This work provides a theoretical foundation to extend elastic distance measures beyond time series, enabling consistent metric-based comparisons for sequences in arbitrary domains and potentially broadening applications in retrieval, clustering, and analysis across diverse data types.

Abstract: This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, Δ)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \mathbb{R}^d$, $T \subset \mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings.

</details>


### [59] [Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2601.05264)
*Dean Wampler,Dave Nielson,Alireza Seddighi*

Main category: cs.IR

TL;DR: 对2018-2025年RAG架构的系统性综述，提出统一分类法、量化评估框架，并分析信任与对齐影响，提供面向部署的鲁棒、可安全、领域自适应的实践框架与技术参考。


<details>
  <summary>Details</summary>
Motivation: 应对RAG方法的高多样性与实践碎片化，提供统一的taxonomy、评估框架以及可落地的部署指南，以提升可信性、鲁棒性与领域适应性。

Method: 对学术论文、行业报告与实现指南进行系统性文献综述，整合不同融合机制、检索策略与编排方法，建立统一的RAG分类体系与评估框架，并从信任、对齐、安全性等维度分析影响。

Result: 提出统一的RAG技术分类法（taxonomy），构建可量化的评估框架，系统梳理对信任与对齐的影响，给出面向鲁棒性、可安全性与领域自适应部署的综合框架，兼具学术与行业参考价值。

Conclusion: 为RAG系统提供一个实用的框架与技术参考，整合学术、行业与实现指南，缓解方法碎片化，促进面向真实部署的稳健与可扩展性研究与应用。

Abstract: This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference.

</details>


### [60] [Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.05265)
*Mile Stankovic*

Main category: cs.IR

TL;DR: CDTA跨文档主题对齐的分块方法，通过跨文档主题识别、段落映射与合成，提升多源知识检索的可靠性和信息密度，在HotpotQA和UAE法律文本上实现更高的忠实度和引证准确性，适合高查询量场景；但索引成本较高，查询阶段收益明显。


<details>
  <summary>Details</summary>
Motivation: 现有分块多在单文档维度进行，无法有效解决复杂查询需要跨文档的信息聚合的问题（知识碎片化）。需要一个能够在语料层面重构知识、实现跨文档对齐与合成的分块策略。

Method: 先在跨文档层面识别主题，将各文档的段落映射到主题，然后对同一主题的片段进行合成，形成统一、信息密度更高的跨文档块（CDTA）。通过跨文档主题对齐来实现知识的整合，提升后续检索与推理的忠实性。

Result: HotpotQA多跳推理中，忠实度0.93（相较上下文检索0.83、语义分块0.78提升12%且p<0.05）；在UAE法律文本中，忠实度0.94、引证准确度0.93；当k=3时，忠实度0.91，而语义方法降至0.68；单个CDTA块即可包含需要多传统碎片才能获得的信息；索引成本较高，但信息密度高的块在查询阶段降低检索需求；在高查询量、分布式知识场景下，跨文档合成优于单文档优化。

Conclusion: CDTA通过跨文档主题对齐实现知识的跨文档合成，能显著提升多源知识检索与推理的忠实性和信息密度，适用于高并发、分布式知识环境，但需权衡较高的索引成本与维护复杂性。

Abstract: Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.
  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.
  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization.

</details>


### [61] [Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction](https://arxiv.org/abs/2601.05266)
*Muzakkiruddin Ahmed Mohammed,John R. Talburt,Leon Claasssens,Adriaan Marais*

Main category: cs.IR

TL;DR: 九模型RAG融合框架RAGsemble用于工业零件规格抽取，含三阶段流程与FAISS检索，实证显示优于单模型基线的输出质量与完整性。


<details>
  <summary>Details</summary>
Motivation: 单一大型语言模型在工业领域的抽取任务中存在准确性、完整性与可追溯性不足的问题；需要将多模型互补优势与基于向量检索的事实 grounding 相结合，以提升结构化输出质量并支持生产环境部署。

Method: 并行执行九个不同家族的LLM（Gemini 2.0/2.5/1.5、OpenAI GPT-4o/o4-mini、Mistral Large、Gemma各规格）组成三阶段流程：1) 多模型并行抽取；2) 高性能模型的定向研究增强；3) 具冲突解决与置信评分的智能综合。通过FAISS基于语义检索实现对结构化零件库的实时访问与参考检索以对输出进行事实核验、 refinement 与 enrich。

Result: 在真实工业数据集上，RAGsemble在提取准确性、技术完整性与结构化输出质量方面显著优于领先的单模型基线。

Conclusion: 提出可扩展的工业领域集成架构，無缝集成RAG、完善的质量评估机制，并具备部署于知识密集型制造场景的生产就绪性。

Abstract: Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments.

</details>


### [62] [Transforming User Defined Criteria into Explainable Indicators with an Integrated LLM AHP System](https://arxiv.org/abs/2601.05267)
*Geonwoo Bang,Dongho Kim,Moohong Min*

Main category: cs.IR

TL;DR: A framework that integrates LLM-based criterion scoring with Analytic Hierarchy Process (AHP) to produce interpretable, weighted scores for complex text evaluation; uses Jensen-Shannon distance for discriminative power; demonstrates on Amazon reviews and depression-related text scoring, achieving explainability and efficiency with comparable predictive power for latency-sensitive services.


<details>
  <summary>Details</summary>
Motivation: Challenge of converting user-defined evaluation criteria into quantitative, explainable indicators across domains; limitations of single-prompt LLM evaluations and naive averaging/black-box aggregation.

Method: LLM judges generate criterion-specific scores; compute discriminative power via Jensen-Shannon distance; derive weights via AHP from pairwise comparisons; aggregate using interpretable weighted scores.

Result: High explainability and operational efficiency; predictive power comparable to baselines; suitable for real-time latency-sensitive web services; validated on Amazon reviews and depression-related text scoring.

Conclusion: An interpretable aggregation framework successfully combines LLM scoring with AHP to provide explainable, efficient evaluation of complex texts without sacrificing predictive performance.

Abstract: Evaluating complex texts across domains requires converting user defined criteria into quantitative, explainable indicators, which is a persistent challenge in search and recommendation systems. Single prompt LLM evaluations suffer from complexity and latency issues, while criterion specific decomposition approaches rely on naive averaging or opaque black-box aggregation methods. We present an interpretable aggregation framework combining LLM scoring with the Analytic Hierarchy Process. Our method generates criterion specific scores via LLM as judge, measures discriminative power using Jensen Shannon distance, and derives statistically grounded weights through AHP pairwise comparison matrices. Experiments on Amazon review quality assessment and depression related text scoring demonstrate that our approach achieves high explainability and operational efficiency while maintaining comparable predictive power, making it suitable for real time latency sensitive web services.

</details>


### [63] [Separating Semantic Expansion from Linear Geometry for PubMed-Scale Vector Search](https://arxiv.org/abs/2601.05268)
*Rob Koopman*

Main category: cs.IR

TL;DR: Decouples semantic interpretation from metric geometry in PubMed-scale retrieval using LLM-expanded queries and fixed, isotropic embeddings; no training; 256-d int8 cosine search; geometric evaluation.


<details>
  <summary>Details</summary>
Motivation: Reduce dependence on trained retrieval models by separating linguistic interpretation from the geometric space, enabling scalable, parameter-free retrieval across tens of millions of records.

Method: Use a large language model to expand a natural-language query into concise biomedical phrases. Represent documents and queries as weighted means of token embeddings, project onto the complement of nuisance axes to remove non-semantic variance, and compress via Johnson-Lindenstrauss to 256-d int8 vectors. Retrieval is exact cosine similarity in this fixed space, with no parameter training.

Result: Retrieves coherent biomedical clusters across the 40M MEDLINE records. Evaluation is geometric (head cosine, compactness, centroid closure, isotropy) and compared to random baselines; no traditional recall metric is reported since the target set is defined by LLM expansion.

Conclusion: Demonstrates a parameter-free, geometry-focused retrieval framework at scale, where performance is assessed by geometric properties of the embedding space rather than conventional retrieval metrics; the lack of explicit recall metrics reflects the defined target set by language-model expansion.

Abstract: We describe a PubMed scale retrieval framework that separates semantic interpretation from metric geometry. A large language model expands a natural language query into concise biomedical phrases; retrieval then operates in a fixed, mean free, approximately isotropic embedding space. Each document and query vector is formed as a weighted mean of token embeddings, projected onto the complement of nuisance axes and compressed by a Johnson Lindenstrauss transform. No parameters are trained. The system retrieves coherent biomedical clusters across the full MEDLINE corpus (about 40 million records) using exact cosine search on 256 dimensional int8 vectors. Evaluation is purely geometric: head cosine, compactness, centroid closure, and isotropy are compared with random vector baselines. Recall is not defined, since the language-model expansion specifies the effective target set.

</details>


### [64] [Studying Illustrations in Manuscripts: An Efficient Deep-Learning Approach](https://arxiv.org/abs/2601.05269)
*Yoav Evron,Michal Bar-Asher Siegal,Michael Fire*

Main category: cs.IR

TL;DR: 提出一个三阶段的人工智能流水线，用于在数字手稿中检测、提取并描述插图；在三百万页级别的数据上，提取超二十万幅独特插图，处理速度极快，形成可检索数据库。


<details>
  <summary>Details</summary>
Motivation: 为人文学科的大规模视觉研究提供可扩展、高效的工具，降低人工工作量；利用最近的 AI 进展提升对历史手稿插图的分析能力。

Method: 阶段1：对文本页筛选的分类模型进行微调；阶段2：高效目标检测模型定位和裁剪插图；阶段3：多模态图像描述模型生成简洁描述；输出存入可检索数据库，支持基关键词检索。

Result: 应用于超过三百万页，自动识别并提取超过20万幅独特插图；单页处理时间低于0.06秒；在效率和可访问性方面显著优于传统分割技术。

Conclusion: 展示了前沿 AI 工具如何重塑学术工作流程，开启跨学科研究的新途径，尤其在数字手稿的视觉研究、艺术史和文化遗产领域。

Abstract: The recent Artificial Intelligence (AI) revolution has opened transformative possibilities for the humanities, particularly in unlocking the visual content embedded in historical manuscripts. While digital archives now offer unprecedented access to these materials, the ability to systematically study illustrations at a large scale remains challenging. Our study presents a fast and scalable AI approach for detecting, extracting, and describing illustrations in digitized manuscripts. Focusing on collections like the Vatican Library, our system enables efficient visual analysis across millions of pages. Our pipeline consists of three stages: (1) a fine-tuned image classification model filters out text-only pages; (2) an efficient object detection model identifies and crops illustrations; and (3) a multimodal image captioning model generates concise, human-readable descriptions. These are stored in a searchable database, allowing scholars to retrieve relevant visual materials through keyword queries. By harnessing the power of recent AI advancements, we enable large-scale visual research that was previously impractical, empowering scholars in historical studies, art history, and cultural heritage to explore visual motifs, artistic styles, and cross-cultural influences with new precision and speed. Applying our pipeline to over three million digitized manuscript pages, we automatically identified and extracted more than 200,000 unique illustrations. This scale of processing in under 0.06 seconds per page, dramatically outperforms traditional segmentation techniques in both efficiency and accessibility for visual scholarship. Our work demonstrates how cutting-edge AI tools can profoundly reshape scholarly workflows and open new avenues for multidisciplinary research in the age of digital manuscripts.

</details>


### [65] [LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval](https://arxiv.org/abs/2601.05270)
*Tarun Prajapati*

Main category: cs.IR

TL;DR: 提出 LiveVectorLake：双层时序知识库架构，结合热/冷层向量索引与版本化数据湖，实现对当前知识的低延迟语义检索和对历史版本的完整点-in-time 检索，同时降低更新成本与存储开销。


<details>
  <summary>Details</summary>
Motivation: 解决 Retrieval-Augmented Generation (RAG) 系统中对查询延迟的优化与对持续知识更新/版本控制的需求之间的矛盾；向量索引擎擅长低延迟查询但对更新缺乏灵活性，数据湖在版本控制方面强但查询成本高。

Method: (1) 基于 SHA-256 的内容可寻址分块同步，实现确定性变更检测且无需外部状态；(2) 双层存储结构，热层使用 Milvus(HNSW) 构建向量索引，冷层使用 Delta Lake + Parquet 进行列式版本化；(3) 时态查询路由通过 delta 版本控制实现跨时间点的一致性检索，支持点-in-time 的知识检索。

Result: 在 100 文档、5 个时间点的版本化实验中，达到：i) 更新时仅需 10-15% 的再处理量（相比全量重建的 100%）；ii) 针对当前知识的检索延迟小于 100 ms；iii) 跨版本的时态查询延迟小于 2 s；iv) 热/冷分层降低存储成本，仅将当前块放入昂贵的向量索引。

Conclusion: 该架构为需要同时优化查询性能、更新效率与合规性的新兴生产性 RAG 部署提供了可行路径，公开代码与资源便于复现，适合扩展到更大规模及更复杂的版本控制场景。

Abstract: Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]

</details>


### [66] [RECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark](https://arxiv.org/abs/2601.05461)
*Mohammed Ali,Abdelrahman Abdallah,Amit Agarwal,Hitesh Laxmichand Patel,Adam Jatowt*

Main category: cs.IR

TL;DR: 提出一个用于推理导向对话信息检索的基准，包含707个对话，2971条会话轮次，采用分解与验证框架生成逐轮事实支撑的检索推理，并在历史对话与推理结合下显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准将多轮对话与推理密集检索分离，真实世界的信息检索需要两者兼具，因此需要一个整合的基准来评估两者的协同能力。

Method: 构建Decomposition-and-Verification框架，将复杂查询分解为基于事实的多轮对话，并对每轮的原子事实进行源证验，并为每轮生成显式的检索推理；数据涵盖11个领域，共707条对话。

Result: 历史对话结合推理后，nDCG@10从0.236提升至0.479；推理专用模型显著优于 dens e编码器；分析指出在文本未显式给出逻辑关系时，隐式推理仍具挑战性。

Conclusion: 综合历史对话与显式推理可显著提升检索性能，虽有提升，但对隐性逻辑连接的推理仍需改进。

Abstract: Existing benchmarks treat multi-turn conversation and reasoning-intensive retrieval separately, yet real-world information seeking requires both. To bridge this gap, we present a benchmark for reasoning-based conversational information retrieval comprising 707 conversations (2,971 turns) across eleven domains. To ensure quality, our Decomposition-and-Verification framework transforms complex queries into fact-grounded multi-turn dialogues through multi-level validation, where atomic facts are verified against sources and explicit retrieval reasoning is generated for each turn. Comprehensive evaluation reveals that combining conversation history with reasoning doubles retrieval performance (Baseline .236 $\rightarrow$ History+Reasoning .479 nDCG@10), while reasoning-specialized models substantially outperform dense encoders. Despite these gains, further analysis highlights that implicit reasoning remains challenging, particularly when logical connections are not explicitly stated in the text.

</details>


### [67] [Efficient Temporal-aware Matryoshka Adaptation for Temporal Information Retrieval](https://arxiv.org/abs/2601.05549)
*Tuan-Luc Huynh,Weiqing Wang,Trung Le,Thuy-Trang Vu,Dragan Gašević,Yuan-Fang Li,Thanh-Toan Do*

Main category: cs.IR

TL;DR: 提出 Temporal-aware Matryoshka Representation Learning (TMRL)，在嵌套的 Matryoshka 表征中引入时间子空间，用以提升 Temporal RAG 的时间相关检索，同时保持通用语义表示，能高效适配多种文本嵌入模型，并实现灵活的准确性-效率权衡。


<details>
  <summary>Details</summary>
Motivation: Temporal Retrieval 在 Time-aware RAG 中常成为瓶颈；若检索到的时序上下文不相关，LLM 推理仍受限。现有方法要么对时间信息处理不足，要么仅使用非时序的 Matryoshka 嵌入，难以在保留语义的前提下有效编码时间信息。需一种高效机制在嵌套结构中显式建模时间子空间。

Method: 提出 Temporal-aware Matryoshka Representation Learning (TMRL)。利用嵌套的 Matryoshka 表征，将一个独立的时间子空间嵌入到嵌套结构中，以增强时间编码，同时保留原有的通用语义嵌入。该方法可高效地对多种文本嵌入模型进行适配，并允许在精度与计算成本之间实现灵活权衡。

Result: 实验表明，TMRL 能高效地适配多种文本嵌入模型，在时间检索和时间 RAG 任务中达到竞争性表现，优于或等同于先前的非时序 Matryoshka 方法及传统时间方法，同时提供灵活的准确性与效率之间的权衡。

Conclusion: TMRL 为时序信息在文本检索中的编码提供了一种高效、可扩展的解决方案，既提升时间相关上下文的检索效果，又保持语义表示的完整性，从而提升 Temporal RAG 的整体性能。

Abstract: Retrievers are a key bottleneck in Temporal Retrieval-Augmented Generation (RAG) systems: failing to retrieve temporally relevant context can degrade downstream generation, regardless of LLM reasoning. We propose Temporal-aware Matryoshka Representation Learning (TMRL), an efficient method that equips retrievers with temporal-aware Matryoshka embeddings. TMRL leverages the nested structure of Matryoshka embeddings to introduce a temporal subspace, enhancing temporal encoding while preserving general semantic representations. Experiments show that TMRL efficiently adapts diverse text embedding models, achieving competitive temporal retrieval and temporal RAG performance compared to prior Matryoshka-based non-temporal methods and prior temporal methods, while enabling flexible accuracy-efficiency trade-offs.

</details>


### [68] [Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders](https://arxiv.org/abs/2601.05588)
*Benjamin Rozonoyer,Chong You,Michael Boratko,Himanshu Jain,Nilesh Gupta,Srinadh Bhojanapalli,Andrew McCallum,Felix Yu*

Main category: cs.IR

TL;DR: 点对点生成式排序（以多 token 的 docID 为单位）在信息检索中的表达能力优于双编码器，并通过 STIoCaL（Simple Token-Item Calibrated Loss）实现对项和 token 级的排序监督，能抑制无效 docID 生成，在 WordNet/ESCI 数据集上超越 top-1 检索的常见排序指标。


<details>
  <summary>Details</summary>
Motivation: 在信息检索中，基于大语言模型（LLM）的排序方法多采用下一个 token 的预测，属于与排序无关的损失。本文提出点对点生成式排序，结合 beam search 的排序能力，旨在提升表达力并充分利用因果变换器的上下文能力，探索如何用更表达性的信号进行排名。

Method: 1) 理论证明：多 token 的 docID 的点对点生成排序在表达力上优于传统的双编码器。2) 提出 STiCaL（SToICaL）损失：Simple Token-Item Calibrated Loss，能够在点对点设置中同时整合项级和 token 级的排序监督。3) 实验：在 WordNet 与 ESCI 构成的排序任务上评估，验证两种 STiCaL 变体在抑制无效 docID 生成方面的有效性并提升超越 top-1 的排序指标。

Result: SToICaL 能显著降低无效 docID 的生成概率；在所评估的排序任务中，相较于基线方法，使用两种 STiCaL 变体可获得更好的排序指标，且超越简单的 top-1 结果。

Conclusion: 点对点生成式排序结合带有排序感知监督的 STiCaL 损失，在信息检索排序任务中具有更强的表达力和实用性，能够充分利用 LLM 的上下文能力并提升整体排序性能，同时控制无效输出。

Abstract: Dual and cross encoders have long been mainstays of information retrieval (IR), but are being challenged by the emergent capabilities of LLMs. An LLM-based approach we term pointwise generative ranking - generating tokens the length of a single docID as opposed to a list in order to enable ranking via beam search - combines efficiency and expressivity benefits while leveraging the in-context capabilities of Causal Transformers. Although there is ample evidence to suggest that pretrained LLMs are well-suited for ranking, we find that the vast majority of LLM-based approaches rely on next-token prediction, a loss function which is fundamentally rank-agnostic (and especially so with pointwise supervision). In this paper, we first prove that the expressivity of pointwise generative ranking with multi-token docIDs is superior to that of dual encoders. We then propose SToICaL - a Simple Token-Item Calibrated Loss - which can incorporate rank-aware supervision at both the item and token levels within the pointwise setup. We run a suite of experiments on ranking tasks derived from WordNet (Fellbaum, 1998) and ESCI (Reddy et al., arXiv:2206.06588). Two variants of SToICaL successfully suppress the probability of invalid docID generations and improve on common ranking metrics beyond top-1 retrieval.

</details>


### [69] [Revisiting Human-vs-LLM judgments using the TREC Podcast Track](https://arxiv.org/abs/2601.05603)
*Watheq Mansour,J. Shane Culpepper,Joel Mackenzie,Andrew Yates*

Main category: cs.IR

TL;DR: LLMs can align with human expert judgments on podcast transcript relevance, but disagreement between LLMs and human assessors varies and can significantly affect IR system rankings.


<details>
  <summary>Details</summary>
Motivation: Uncertainty about whether LLMs reliably annotate relevance; prior work focused on classic ad-hoc text search; this study extends to audio transcriptions (podcast tracks) to examine agreement and impact on rankings.

Method: Reassessed all query-segment pairs originally annotated by TREC assessors using five LLM models; further re-assessed a small subset with the highest disagreement between LLMs and TREC assessors.

Result: Humans tend to agree with LLMs more than with TREC assessors in high-disagreement cases; single assessors yield lower user agreement, echoing Sormunen 2002; LLM-based annotations can align with expert judgments in this context.

Conclusion: LLMs provide a potentially valuable complement to human assessors for relevance labeling in audio-text IR; reliance on a single assessor remains problematic for user agreement, suggesting benefits from incorporating diverse judgments or LLM-based calibrations when evaluating system rankings.

Abstract: Using large language models (LLMs) to annotate relevance is an increasingly important technique in the information retrieval community. While some studies demonstrate that LLMs can achieve high user agreement with ground truth (human) judgments, other studies have argued for the opposite conclusion. To the best of our knowledge, these studies have primarily focused on classic ad-hoc text search scenarios. In this paper, we conduct an analysis on user agreement between LLM and human experts, and explore the impact disagreement has on system rankings. In contrast to prior studies, we focus on a collection composed of audio files that are transcribed into two-minute segments -- the TREC 2020 and 2021 podcast track. We employ five different LLM models to re-assess all of the query-segment pairs, which were originally annotated by TREC assessors. Furthermore, we re-assess a small subset of pairs where LLM and TREC assessors have the highest disagreement, and found that the human experts tend to agree with LLMs more than with the TREC assessors. Our results reinforce the previous insights of Sormunen in 2002 -- that relying on a single assessor leads to lower user agreement.

</details>


### [70] [Statistical Foundations of DIME: Risk Estimation for Practical Index Selection](https://arxiv.org/abs/2601.05649)
*Giulio D'Erasmo,Cesare Campagnano,Antonio Mallia,Pierpaolo Brutti,Nicola Tonellotto,Fabrizio Silvestri*

Main category: cs.IR

TL;DR: 提出一种统计上有据可依的准则，在推断时按查询自适应地识别信息量充足的子维度集合，从而在保持效果等同的前提下，将嵌入维度在多模型/数据集上平均减少约50%。


<details>
  <summary>Details</summary>
Motivation: 高维密集嵌入常包含噪声和冗余维度，统一的全局维度选择（如DIME的网格搜索）成本高且缺乏对单个查询的针对性。需要能够在推断时以查询为单位选取最有信息量的维度，从而提升检索效率而不损失性能。

Method: 提出一个统计学原理驱动的准则，在推断时对每个查询直接识别最佳维度子集，替代先前依赖网格搜索的一致性全局维度选择。该准则据以筛选对当前查询最具信息量的维度，达到自适应压缩。

Result: 在多种模型和数据集上，与原方法保持等效的检索效果，同时在推断时将嵌入维度平均减少约50%。

Conclusion: 按查询自适应的维度选择在效率与效果之间实现良好折中，证明了在推断阶段对维度进行统计性筛选的可行性与通用性。

Abstract: High-dimensional dense embeddings have become central to modern Information Retrieval, but many dimensions are noisy or redundant. Recently proposed DIME (Dimension IMportance Estimation), provides query-dependent scores to identify informative components of embeddings. DIME relies on a costly grid search to select a priori a dimensionality for all the query corpus's embeddings. Our work provides a statistically grounded criterion that directly identifies the optimal set of dimensions for each query at inference time. Experiments confirm achieving parity of effectiveness and reduces embedding size by an average of $\sim50\%$ across different models and datasets at inference time.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing](https://arxiv.org/abs/2601.05298)
*Yeongbin Cha,Namjung Kim*

Main category: cs.AI

TL;DR: An ontology-guided, equation-centric framework integrating LLMs with an additive manufacturing knowledge graph (AM-MKG) for reliable knowledge extraction and confidence-aware extrapolation; shows improved coherence and stable extrapolations.


<details>
  <summary>Details</summary>
Motivation: Data-driven AM modeling is limited by fragmented representations and unreliable extrapolation under sparse data; a principled, physics-informed, knowledge-graph–augmented approach is needed.

Method: Develop a formal ontology encoding equations, variables, assumptions, and semantic relations; convert literature into a machine-interpretable AM-MKG; condition LLM-generated equations on MKG subgraphs to enforce physically meaningful forms; introduce a confidence-aware extrapolation metric combining extrapolation distance, statistical stability, and KG-based physical consistency.

Result: Ontology-guided extraction improves structural coherence and quantitative reliability; subgraph-conditioned equation generation yields stable, physically consistent extrapolations compared with unguided LLM outputs.

Conclusion: Presents a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation; KG-augmented LLMs show promise for reliable extrapolative modeling in additive manufacturing.

Abstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.

</details>


### [72] [Effects of personality steering on cooperative behavior in Large Language Model agents](https://arxiv.org/abs/2601.05302)
*Mizuki Sakai,Mizuki Yokoyama,Wakaba Tateishi,Genki Ichinose*

Main category: cs.AI

TL;DR: 人格引导影响LLM合作：宜人性促进合作，显性人格信息提高合作但增加被利用风险，后代模型更具选择性；人格作用偏向行为偏差而非确定性控制。


<details>
  <summary>Details</summary>
Motivation: 探究Big Five人格对LLM在重复囚徒困境中的合作行为的作用，以及显性人格信息对行为的影响与潜在风险。

Method: 对GPT-3.5-turbo、GPT-4o、GPT-5进行Big Five Inventory测量；在基线与人格信息条件下比较重复囚徒困境中的合作行为；进一步独立操纵每一维度至极端值进行效应分析。

Result: 宜人性是推动合作的主导因素；其他维度影响有限。显性人格信息提高合作，但早期模型易被利用，后代模型更具选择性。

Conclusion: 人格引导作为一种行为偏差而非确定性控制，存在对安全性和鲁棒性的设计挑战，需要结合模型代际差异进行评估。

Abstract: Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.

</details>


### [73] [The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models](https://arxiv.org/abs/2601.05376)
*Tassallah Abdullahi,Shrestha Ghosh,Hamish S Fraser,Daniel León Tramontini,Adeel Abbasi,Ghada Bourjeily,Carsten Eickhoff,Ritambhara Singh*

Main category: cs.AI

TL;DR: 系统评估临床LLM中的人格条件化，发现效果呈非单调且情境依赖：在危重护理任务中提升准确性与校准约20%，在初级护理任务中下降同幅度；交互风格影响风险倾向，且高度依赖具体模型；人机评估与自动评判存在差异，强调人格仅为行为先验，需权衡取舍。


<details>
  <summary>Details</summary>
Motivation: 探索人格条件化在高风险临床决策中的作用与稳定性，揭示其对安全与专业性的影响并非单向改进。

Method: 系统评估不同专业角色（如急诊医生、护士）和交互风格（大胆/谨慎）在多任务医疗评估中的影响，使用临床分诊和病人安全任务的多维评估指标（准确性、校准、风险行为）进行比较。

Result: 发现上下文相关且非单调的效果：在危重护理任务中，医学人格提升表现，准确性和校准提升约20%；在初级护理任务中表现下降同幅度；交互风格影响风险偏好，但强依赖模型；聚合评判（LLM judge）偏向医学人格在安全相关场景；人类临床医生在安全合规上有中等一致性（Cohen's κ≈0.43），对推理质量的信心极低（95.9%回答缺乏信心）。

Conclusion: 人格作为行为先验 introducing context-dependent trade-offs，而非安全或专业性的保证；需要在具体应用中权衡取舍。

Abstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\sim+20\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $κ= 0.43$) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox.

</details>


### [74] [On the Effect of Cheating in Chess](https://arxiv.org/abs/2601.05386)
*Daniel Keren*

Main category: cs.AI

TL;DR: 评估在有限次数使用强大软件作弊的棋手潜在性能收益；在常用引擎上进行算法开发和测试；以量化作弊效果，辅助检测与遏制。


<details>
  <summary>Details</summary>
Motivation: 棋手通过软件作弊已成为严重问题，尤其在高水平；需量化作弊带来的潜在收益，以支持检测和政策制定。

Method: 提出并实现对局中有限阶段使用引导性软件的算法；在常用棋引擎上进行仿真/测试，评估对局绩效的提升。

Result: 得到可量化的性能提升结果，表明即使有限次数的作弊也能带来显著收益，提升幅度取决于执行时机和覆盖比例。

Conclusion: 作弊的有效性是可测量的；该工作有助于完善检测与遏制策略，提升对作弊现象的理解。

Abstract: Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}

</details>


### [75] [ART: Adaptive Reasoning Trees for Explainable Claim Verification](https://arxiv.org/abs/2601.05455)
*Sahil Wadhwa,Himanshu Kumar,Guanqun Yang,Abbaas Alif Mohamed Nishar,Pranab Mohanty,Swapnil Shinde,Yue Wu*

Main category: cs.AI

TL;DR: ART introduces a hierarchical argument-based verification framework for LLMs, using a root claim, supporting/attacking arguments, and a bottom-up tournament adjudicated by a judge LLM to yield a transparent, contestable verdict, outperforming CoT baselines.


<details>
  <summary>Details</summary>
Motivation: Address the opacity of large language models in high-stakes decision making: outputs lack faithful explanations and are not contestable, undermining trustworthiness; need explainable, contestable claim verification.

Method: Construct a root claim and decompose it into supporting and attacking child arguments, compute each argument's strength via a bottom-up pairwise tournament among its children adjudicated by a judge LLM, and derive a final verdict that is transparent and contestable; evaluate ART against baselines and various argument generators and strategies.

Result: Empirical validation on multiple datasets shows ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification with clearer, more reliable decision making.

Conclusion: ART provides transparent, contestable verdicts, improving trustworthiness in high-stakes decision-making and setting a new standard for explainable claim verification.

Abstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.

</details>


### [76] [The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm](https://arxiv.org/abs/2601.05500)
*Aparna Elangovan,Lei Xu,Mahsa Elyasi,Ismail Akdulum,Mehmet Aksakal,Enes Gurun,Brian Hur,Saab Mansour,Ravid Shwartz Ziv,Karin Verspoor,Dan Roth*

Main category: cs.AI

TL;DR: 提出一种考虑 ground-truth 不确定性的概率性评估框架，通过引入期望准确率和期望F1来估计在不同 ground-truth 变异下的分数，并主张对结果按 ground-truth 确定性分层评估，特别在性能低于80%时更为重要。


<details>
  <summary>Details</summary>
Motivation: 医学领域存在普遍的 ground-truth 不确定性；若忽略不确定性，可能将非专家评价误判为接近专家水平，影响系统对比评估；需要一个理论框架来量化和应对这种不确定性。

Method: 构建概率性评估范式，定义期望准确率（expected accuracy）和期望F1（expected F1），据 ground-truth 一致性分层评估结果，评估专家或系统在不同不确定性水平上的潜在分数。

Result: 引入并定义了期望准确率和期望F1 的概念来估计在 ground-truth 变异下的分数；提出按 ground-truth 一致性分层评估的策略，并指出在高不确定性情形下，分层评估能使系统能力比较更可靠，尤其当总体性能低于80%时。

Conclusion: 在评估系统能力时应对 ground-truth 确定性进行分层，以减轻不确定性的混杂影响；高确定性区间的比较更具可比性。

Abstract: Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.
  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.

</details>


### [77] [Explainable AI: Learning from the Learners](https://arxiv.org/abs/2601.05525)
*Ricardo Vinuesa,Steven L. Brunton,Gianmarco Mengaldo*

Main category: cs.AI

TL;DR: XAI与因果推理的结合提供提取因果机制、改进鲁棒设计与信任度的框架，支持科学与工程中的发现、优化与认证，提出以XAI为人机协作的统一方向。


<details>
  <summary>Details</summary>
Motivation: 解决AI内部表示不可解释及在高风险场景中的信任与可追溯性问题；通过将基础模型的能力与可解释性方法结合，实现‘从学习者处学习’（learning from the learners）的系统性框架。

Method: 提供概念性框架与综合分析，论述如何将基础模型与解释性方法相结合以提取因果机制，贯穿发现、优化、认证三个任务，评估其在忠实性、泛化性和可用性方面的挑战，倡导XAI作为高风险科学与工程中的统一人机协作框架。

Result: 给出一个系统性的观点，展示通过XAI与因果推理实现因果机制提取、指导鲁棒设计与控制，并提升高风险应用中的信任与问责感，指出实现路径与未来研究方向。

Conclusion: XAI可作为科学与工程领域人机协作的统一框架，需解决忠实性、泛化与可用性等挑战，为高风险应用提供更可靠的解释与协作机制。

Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.

</details>


### [78] [Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making](https://arxiv.org/abs/2601.05529)
*Jua Han,Jaeyoon Seo,Jungbin Min,Jean Oh,Jihie Kim*

Main category: cs.AI

TL;DR: 该论文系统性评估在安全关键环境中使用的大语言模型（LLMs）与视觉语言模型（VLMs）在机器人决策中的表现，揭示关键漏洞并提出严格的安全评估框架，强调直达部署的风险。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，单次错误即可致命；随着LLMs在机器人决策中的应用，风险的物理维度增加。需要系统化、可量化的评估来发现模型在极端、致命后果情境下的不足。

Method: 通过对火灾疏散情景的定性评估，提出七项定量评测任务，分为 Complete Information、Incomplete Information、Safety-Oriented Spatial Reasoning (SOSR) 三类。Complete Information 使用 ASCII 地图以最小化解释歧义；Incomplete Information 检验模型对缺失信息的推断与空间连续性，防止幻觉；SOSR 使用自然语言评估在生命威胁场景中的安全决策。对多种LLMs与VLMs进行基准测试，并进行结果分析，特别关注1%的失败率对安全的放大作用。

Result: 若干模型在 ASCII 导航任务中达到0% 成功率；在仿真火灾演练中，模型指令机器人向危险区域移动而非逃生出口。强调1%的错误在现实中的灾难性后果；即便是最先进模型也无法对安全提供保障，单纯声称高准确率（如99%）在安全关键场景中具有严重误导性。

Conclusion: 当前的LLMs尚未准备好直接用于安全关键系统的部署，依赖它们带来的风险不可接受；需要更严格的安全框架、测试与保障措施，避免对安全产生不可控的影响。

Abstract: One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how "rare" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.

</details>


### [79] [WildSci: Advancing Scientific Reasoning from In-the-Wild Literature](https://arxiv.org/abs/2601.05567)
*Tengxiao Liu,Deepak Nathani,Zekun Li,Kevin Yang,William Yang Wang*

Main category: cs.AI

TL;DR: 提出 WildSci 数据集，通过从同行评议文献自动合成科学领域的多选题，覆盖9大学科、26个子领域，结合强化学习对模型进行微调以提升跨学科科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前科学领域的推理数据稀缺且缺乏可量化的评估，难以系统训练和评估模型的推理能力。需要大规模、可控的训练信号以促进跨学科科学推理的发展。

Method: 自动从同行评审论文中合成多选题，覆盖9个学科和26个子领域；将复杂科学推理任务转化为多选题以获得明确奖励信号；对数据进行强化学习微调以训练模型；分析训练动态、领域差异、响应行为与泛化趋势。

Result: 在一组科学基准测试上验证有效性，显示数据集与方法能提升科学推理能力，提供对训练动态和领域泛化的见解；公开数据集以促进后续研究。

Conclusion: WildSci 具备扩展性与可持续性，为科学推理研究提供可控、可评估的数据资源与训练框架。

Abstract: Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.

</details>


### [80] [Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models](https://arxiv.org/abs/2601.05570)
*Cooper Lin,Maohao Ran,Yanting Zhang,Zhenglin Wan,Hongwei Fan,Yibo Xu,Yike Guo,Wei Xue,Jun Song*

Main category: cs.AI

TL;DR: A new benchmark, Crisis-Bench, evaluates LLMs in professional crisis PR tasks via a multi-agent POMDP and an Adjudicator-Market Loop that ties public sentiment to a simulated stock price; reveals a trade-off between safety-aligned ethics and contextual strategic information withholding, advocating context-aware professional alignment.


<details>
  <summary>Details</summary>
Motivation: To address the gap between general safety alignment and professional utility in domains requiring strategic ambiguity and information withholding, and to provide a quantitative measure of Reputation Management capabilities.

Method: 80 storylines across 8 industries; a 7-day dynamic corporate crisis simulation; LLM-based Public Relations Agent with strictly separated Private and Public narrative states; multi-agent POMDP framework; Adjudicator-Market Loop translating public sentiment into a simulated stock price to create economic incentives.

Result: Some models capitulate to rigid ethical concerns, while others exhibit Machiavellian yet legitimate strategic withholding to stabilize the simulated stock price; Crisis-Bench offers the first quantitative framework for evaluating Reputation Management in LLMs.

Conclusion: Advocates shifting from rigid, absolutist safety to context-aware professional alignment, establishing a baseline for evaluating and improving Reputation Management in AI systems.

Abstract: Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid "Boy Scout" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a "transparency tax" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing "Reputation Management" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.

</details>


### [81] [Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection](https://arxiv.org/abs/2601.05578)
*Cooper Lin,Yanting Zhang,Maohao Ran,Wei Xue,Hongwei Fan,Yibo Xu,Zhenglin Wan,Sirui Han,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: RL-based post-training of lightweight LLMs for e-commerce fraud detection using GSPO with a rule-based reward on raw transaction data; real dataset shows improved F1 on held-out data, driven by exploration to find novel fraud signals.


<details>
  <summary>Details</summary>
Motivation: LLMs have potential for fraud detection but limited empirical validation in real-world financial contexts; need to overcome traditional ML limitations and leverage domain-specific textual transaction data to detect fraud more effectively.

Method: Post-train lightweight language models with reinforcement learning using the Group Sequence Policy Optimization (GSPO) algorithm and a rule-based reward on raw transaction data (customer info, shipping, product descriptions, order history) from a real dataset; RL exploration encourages discovery of trust/risk signals beyond engineered features.

Result: Significant improvements in F1-score on held-out test data; performance gains mainly attributed to the exploration mechanism of RL enabling discovery of novel fraud indicators not captured by traditional features.

Conclusion: RL-based post-training can unlock the latent fraud-detection potential of LLMs on real e-commerce data, offering practical benefits beyond traditional ML approaches and highlighting the importance of exploration in identifying novel fraud signals.

Abstract: E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.

</details>


### [82] [A Causal Information-Flow Framework for Unbiased Learning-to-Rank](https://arxiv.org/abs/2601.05590)
*Haoming Gong,Qingyao Ai,Zhihao Tao,Yongfeng Zhang*

Main category: cs.AI

TL;DR: Introduces a causal learning framework to extend ULTR for unbiased ranking by modeling click generation with SCMs, measuring bias leakage via conditional mutual information, and regularizing training to disentangle true relevance from biases; uses a doubly robust estimator for reliable risk estimation and achieves improved ranking under multiple interacting biases.


<details>
  <summary>Details</summary>
Motivation: Limitations of existing ULTR methods: primarily address position bias via propensity estimation, but fail to quantify residual bias or guarantee risk, and struggle with multiple interacting biases such as position and trust bias.

Method: Builds a Structural Causal Model of click generation, defines a bias leakage measure using conditional mutual information between observed clicks and true relevance given the model, and optimizes a loss with a disentanglement regularizer plus a doubly robust risk estimator.

Result: Empirical evaluation on standard Learning-to-Rank benchmarks shows reduced bias leakage and improved ranking performance, particularly when multiple biases interact.

Conclusion: A unified causal-learning approach that (i) quantifies and regularizes bias leakage, (ii) extends ULTR beyond position bias, and (iii) provides more reliable risk estimates, leading to better ranking under realistic multi-bias scenarios.

Abstract: In web search and recommendation systems, user clicks are widely used to train ranking models. However, click data is heavily biased, i.e., users tend to click higher-ranked items (position bias), choose only what was shown to them (selection bias), and trust top results more (trust bias). Without explicitly modeling these biases, the true relevance of ranked items cannot be correctly learned from clicks. Existing Unbiased Learning-to-Rank (ULTR) methods mainly correct position bias and rely on propensity estimation, but they cannot measure remaining bias, provide risk guarantees, or jointly handle multiple bias sources. To overcome these challenges, this paper introduces a novel causal learning-based ranking framework that extends ULTR by combining Structural Causal Models (SCMs) with information-theoretic tools. SCMs specify how clicks are generated and help identify the true relevance signal from click data, while conditional mutual information, measures how much bias leaks into the
  learned relevance estimates. We use this leakage measure to define a rigorous notion of disentanglement and include it as a regularizer during model training to reduce bias. In addition, we incorporate a causal inference estimator, i.e., doubly robust estimator, to ensure more reliable risk estimation. Experiments on standard Learning-to-Rank benchmarks show that our method consistently reduces measured bias leakage and improves ranking performance, especially in realistic scenarios where multiple biases-such as position and trust bias-interact strongly.

</details>


### [83] [Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion](https://arxiv.org/abs/2601.05629)
*Jiapu Wang,Xinghe Cheng,Zezheng Wu,Ruiqi Ma,Rui Wang,Zhichao Yan,Haoran Luo,Yuhao Jiang,Kai Sun*

Main category: cs.AI

TL;DR: 提出CPSR框架用于自归纳知识图谱补全，通过路径级累积语义推理，同时使用查询相关掩蔽来抑制噪声并维持与目标相关的信息，辅以全局语义评分以评估路径中的节点贡献和整体影响，达到最新最好性能。


<details>
  <summary>Details</summary>
Motivation: 自归纳KGC需要处理新出现的实体和关系，现有方法易受噪声结构信息影响，且难以捕捉推理路径中的长程依赖，因此需要同时融合结构与语义信息以提高鲁棒性与推理能力。

Method: 提出CPSR，包含两大模块：1) 基于查询的掩蔽模块，对结构信息进行自适应掩蔽，保留与目标紧密相关的信息；2) 全局语义评分模块，对路径中各节点的单独贡献及其整体影响进行评估；结合累积路径级语义推理以同时利用结构与语义信号。

Result: 实验结果表明CPSR在自归纳KGC任务上达到state-of-the-art性能。

Conclusion: CPSR通过抑制噪声并捕捉长程依赖，融合结构与语义信息，显著提升自归纳知识图谱补全的效果及鲁棒性，可用于处理新实体/新关系的动态场景。

Abstract: Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.

</details>


### [84] [GenCtrl -- A Formal Controllability Toolkit for Generative Models](https://arxiv.org/abs/2601.05637)
*Emily Cheng,Carmen Amo Alonso,Federico Danieli,Arno Blaas,Luca Zappella,Pau Rodriguez,Xavier Suau*

Main category: cs.AI

TL;DR: 提出一个将人-模型交互视作控制过程的理论框架，给出在对话和生成任务中估计可控集的算法及其PAC-guaranteed误差界限，并在LM与文本到图像生成等任务上验证，结果表明模型的可控性脆弱且高度依赖实验设置。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型广泛应用，需对其产生过程进行更细粒度的控制；然而目前的控制方法尚未清晰回答模型是否真处于可控状态，因此需要一个理论框架来定义、估计并评估可控性。

Method: 将人-模型交互建模为控制系统，提出一种在对话背景下估计可控集的算法；给出误差的PAC型界限，且这些界限是分布无关的，只需输出有界且适用于任意黑盒非线性控制系统；并在语言模型与文本到图像生成任务上进行实验。

Result: 理论框架在多任务中得到验证，发现可控性相当脆弱，且高度依赖实验设置；实验结果支撑需要对可控性进行严格分析，而非仅追求控制效果。

Conclusion: 强调进一步研究可控性的基本极限，推动从关注控制能力转向理解其边界与条件的研究。

Abstract: As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.

</details>


### [85] [Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models](https://arxiv.org/abs/2601.05693)
*Zenghao Duan,Liang Pang,Zihao Wei,Wenbin Duan,Yuxin Tian,Shicheng Xu,Jingcheng Deng,Zhiyi Yin,Xueqi Cheng*

Main category: cs.AI

TL;DR: Circular Reasoning is a distinct failure mode in Large Reasoning Models where generated content serves as premises for its own recurrence, forming self-reinforcing loops. The authors introduce LoopBench to capture two loop types (numerical and statement loops), analyze the mechanism as a state collapse with a self-reinforcing V-shaped attention, and apply CUSUM to detect precursors for early loop prediction. Experiments across diverse LRMs validate the approach and illustrate long-chain reasoning stability.


<details>
  <summary>Details</summary>
Motivation: To address repetitive, wasteful loops during test-time scaling in Large Reasoning Models, specifically a novel failure mode called Circular Reasoning that differs from traditional degeneration.

Method: Define LoopBench with two loop typologies (numerical loops and statement loops) to systematically study Circular Reasoning. Characterize the phenomenon as a state collapse with distinct boundaries where semantic repetition precedes textual repetition. Identify that reasoning impasses trigger loop onset and that the loop persists via a self-reinforcing V-shaped attention mechanism. Use the Cumulative Sum (CUSUM) algorithm to detect precursors for early loop prediction. Validate the approach with experiments across diverse LRMs.

Result: CUSUM effectively captures precursors enabling early loop prediction. Experimental results across varied LRMs demonstrate accurate detection and provide insights into the stability of long-chain reasoning. LoopBench offers a benchmark dataset for numerical and statement-type loops in LRMs.

Conclusion: Circular Reasoning is a distinct failure modality in LRMs distinct from degeneration. Early detection of loops via CUSUM can mitigate such cycles, and LoopBench provides a targeted benchmark to study and address long-chain reasoning failures.

Abstract: Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.

</details>


### [86] [Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning](https://arxiv.org/abs/2601.05705)
*Ali Farjami,Luca Redondi,Marco Valentino*

Main category: cs.AI

TL;DR: 提出一个逻辑参数化的神经符号NLI框架，通过 LogiKEy 将多种逻辑嵌入 HOL，对比逻辑外部与内部策略，实验证明逻辑内部方法在多领域提升效率与性能，且逻辑的选取域依赖任务领域。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定逻辑形式，影响鲁棒性与适应性。将逻辑作为可控参数，提高推理质量、解释细化和证明行为的可控性，尤其在道德/规范性推理中具有重要性。

Method: 使用 LogiKEy 将经典与非经典形式嵌入高阶逻辑，建立一个可比较的逻辑参数框架。比较逻辑外部（通过公理编码规范要求）与逻辑内部（规范模式由逻辑结构自行产生）的两类策略，并在自然语言推理（NLI）场景下进行大量实验，评估推理质量、解释 refinement、以及混合证明的效率。

Result: 逻辑内部策略在实验中持续提升性能并产生更高效的混合证明；且在不同领域呈现域依赖性：一阶逻辑更适合常识推理，规范与模态逻辑在伦理领域表现更佳。

Conclusion: 将逻辑作为首要且可参数化的元素纳入神经符号架构，可提升NLI的鲁棒性、模块化和适应性。

Abstract: Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.

</details>


### [87] [Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding](https://arxiv.org/abs/2601.05724)
*Yuxuan Zhou,Fei Huang,Heng Li,Fengyi Wu,Tianyu Wang,Jianwei Zhang,Junyang Lin,Zhi-Qi Cheng*

Main category: cs.AI

TL;DR: 层次化猜测解码（HSD），提供无损验证，显著提高接受令牌数和解码效率，并解决联合可观测性难题，具备良好可解释性与通用性。


<details>
  <summary>Details</summary>
Motivation: 在Speculative Decoding中，序列级验证比_token级验证更高的吞吐，但现有解决方案往往依赖近似或信息不全，难以同时实现高接受率与分布 fidelity，且面临联合不可 tractable 问题。

Method: 提出层次化 Speculative Decoding：通过构建可访问的分支层级并在它们之间平衡过量与不足的概率质量，实现无损验证；给出理论可证明性并与现有解码框架耦合（如 EAGLE-3），实现广泛适用性。

Result: 在大规模实验中，HSD 显著提升令牌接受率，且对不同模型家族和基准表现稳健；将 HSD 集成到 EAGLE-3 后，性能提升超过 12%，实现更高效的解码且不牺牲分布 fidelity；代码开放。

Conclusion: 提供一种可解释、通用且无损的验证方法，可广泛嵌入各种 speculate decoding 框架，显著提升解码效率与 fidelity 的平衡。

Abstract: Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient probability mass across accessible branches. Our extensive large-scale experiments demonstrate that HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Moreover, its strong explainability and generality make it readily integrable into a wide range of speculative decoding frameworks. Notably, integrating HSD into EAGLE-3 yields over a 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity. Code is available at https://github.com/ZhouYuxuanYX/Hierarchical-Speculative-Decoding.

</details>


### [88] [PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility](https://arxiv.org/abs/2601.05739)
*G M Shahariar,Zabir Al Nazi,Md Olid Hasan Bhuiyan,Zhouxing Shi*

Main category: cs.AI

TL;DR: 提出 PII-VisBench 基准，评估 VLM 在不同在线可见性水平下的 PII 泄露风险，发现高可见性主体更易暴露 PII，且存在模型间与 PII 类型的差异，提示需要可见性感知的安全评估与训练干预。


<details>
  <summary>Details</summary>
Motivation: 当前隐私评估多将隐私视为静态的提取任务，忽略在线可得信息的数量与性质如何影响隐私对齐与风险。

Method: 构建包含 4000 个探测查询的基准，按在线信息可得性将 200 名主体分为高/中/低/零四类；在 18 种开源 VLM（0.3B-32B）上用两项指标评估：拒绝率和条件性 PII 披露率，辅以改写与越狱等提示的攻击性测试。

Result: 总体呈现对可见性变化的模式：拒绝率与披露率随可见性水平变化，且高可见性主体中更易出现 PII 披露；模型家族间存在显著差异，PII 类型也显示差异；改写/越狱提示暴露出模型的攻击面与依赖性。

Conclusion: 倡导引入可见性感知的安全评估与训练干预，提升 VLM 在隐私敏感场景中的鲁棒性与安全性。

Abstract: Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.

</details>


### [89] [DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation](https://arxiv.org/abs/2601.05746)
*Zhenghao Li,Zhi Zheng,Wei Chen,Jielun Zhao,Yong Chen,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 提出 DynaDebate，一种动态多智能体辩论框架，通过路径生成-过程辩论-触发器验证三重机制，提升大型语言模型基的多智能体系统的推理稳定性和解题质量，超越现有MAD方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有MAD在初始随机性导致多智能体采用相同推理路径、易受同类错误影响、多数表决易导致退化的问题。需要提升路径多样性、过程级别的推理 critique，以及在争论僵持时的外部工具辅助决断。

Method: (1) Path Generation Agent 负责生成多样且有逻辑的解题路径，并引入自适应冗余；(2) Process-Centric Debate 将焦点从表面投票转向逐步逻辑的评估与 critique，确保过程正确性；(3) Trigger-Based Verification Agent 在出现分歧时被触发，利用外部工具客观地化解僵局。

Result: 在多个基准上，DynaDebate 相较于现有MAD方法获得更优的性能，表现出更强的鲁棒性和推理质量。

Conclusion: 提出的三元机制有效提升MAD的讨论质量与最终结论的可靠性，表明在LLM驱动的多智能体系统中，动态路径控制、过程级别评估与外部工具结合是提升协作推理的关键路线。

Abstract: Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.

</details>


### [90] [From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation](https://arxiv.org/abs/2601.05787)
*Zezhou Wang,Ziyun Zhang,Xiaoyi Zhang,Zhuzhong Qian,Yan Lu*

Main category: cs.AI

TL;DR: BEPA = Bi-Level Expert-to-Policy Assimilation: turning scarce expert GUI traces into policy-aligned guidance via self-rolled trajectories under the base policy (level-1) and a dynamic per-task cache for RLVR (level-2), improving end-to-end GUI agents on OSWorld-Verified and related benchmarks.


<details>
  <summary>Details</summary>
Motivation: GUI datasets like OSWorld suffer from (i) limited, verifiable tasks/environments (a few hundred at most) and (ii) expert trajectories that are expensive to collect and hard to scale, leading to distribution mismatch when naive off-policy data is mixed into RLVR. There is a need to effectively leverage scarce expert data to train end-to-end policies.

Method: BEPA (Bi-Level Expert-to-Policy Assimilation) converts static expert traces into policy-aligned guidance through two levels: LEVEL-1 self-rolled reachable trajectories under the base policy; LEVEL-2 a per-task, dynamically updated cache used in RLVR. This bi-level framework aligns expert data with the learner’s distribution, mitigating structural mismatch and distribution shift in end-to-end GUI policies.

Result: On OSWorld-Verified, BEPA raises UITARS1.5-7B success from 22.87% to 32.13% and improves the held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web.

Conclusion: BEPA effectively leverages limited expert trajectories to improve end-to-end GUI policies trained with RLVR, mitigating distribution shifts and delivering substantial benchmark gains. The authors provide code and data at the cited repository for reproducibility.

Abstract: Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git

</details>


### [91] [Open-Vocabulary 3D Instruction Ambiguity Detection](https://arxiv.org/abs/2601.05991)
*Jiayu Ding,Haoran Tang,Ge Li*

Main category: cs.AI

TL;DR: 提出 Open-Vocabulary 3D Instruction Ambiguity Detection 的新任务，构建 Ambi3D 基准并提出 AmbiVer，利用多视角证据指导 VLM 判定指令歧义性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键域，语言指令的歧义可能导致严重后果，但现有的 3D 指令执行研究多忽略歧义检测与确认，缺乏是否唯一含义的判断机制。

Method: AmbiVer 两阶段框架：第一阶段从多视角收集显式视觉证据，第二阶段利用证据引导视觉-语言模型对指令在给定 3D 场景中的歧义性进行判断；并构建大规模 Ambi3D 基准，覆盖700+场景、约22k指令，支持开放词汇（Open-Vocabulary）。

Result: 实验表明现有的 3D 大语言模型在判断指令歧义性方面表现不稳定/不足；AmbiVer 能有效提升歧义检测性能，揭示多视角证据在提升安全可信具身 AI 方面的作用。

Conclusion: 为安全可信的具身 AI 提供数据与方法支撑，未来可扩展至更多场景、加强证据解释性、进一步提升对复杂指令的鲁棒性。

Abstract: In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like "Pass me the vial" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [92] [MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs](https://arxiv.org/abs/2601.05296)
*Jiyuan Zhang,Yining Liu,Siqi Yan,Lisen Deng,Jennifer Cao,Shuqi Yang,Min Ni,Bi Xue,Shen Li*

Main category: cs.LG

TL;DR: MoEBlaze 提出一个内存高效的 MoE 训练框架，通过端到端的代币分发与优化数据结构来消除中间缓存和激活物化，并通过共设计的内核与激活检查点技术在保持或提升性能的同时显著降低显存；据称实现超4x加速与超过50%内存节省。


<details>
  <summary>Details</summary>
Motivation: 现代大规模 MoE 架构的内存墙问题被稀疏性、分路缓冲区、中间张量激活的材料化等因素放大，导致批量大小与序列长度受限、数据搬运成本高，制约模型扩展与性能。

Method: 提出端到端的代币分发与 MoE 训练方法，使用优化的数据结构以消除中间缓冲与激活材料化；并采用共设计的内核结合智能激活检查点技术，在降低显存的同时提升性能。

Result: 相较于现有 MoE 框架，MoEBlaze 实现了超过 4 倍加速和超过 50% 的内存节省。

Conclusion: 通过系统层面的协同设计（数据结构和计算内核/检查点），在 MoE 的内存瓶颈上实现显著改进，具备较强的可扩展性潜力与实用价值。

Abstract: The pervasive "memory wall" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GPUs, and also results in excessive data movements that hinders performance and efficient model scaling. We present MoEBlaze, a memory-efficient MoE training framework that addresses these issues through a co-designed system approach: (i) an end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (ii) co-designed kernels with smart activation checkpoint to mitigate memory footprint while simultaneously achieving better performance. We demonstrate that MoEBlaze can achieve over 4x speedups and over 50% memory savings compared to existing MoE frameworks.

</details>


### [93] [TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning](https://arxiv.org/abs/2601.05300)
*Susmit Das*

Main category: cs.LG

TL;DR: Proposes TIME, a temporally aware meta-reasoning framework for LLMs that indexes explicit reasoning with time-aware annotations (ISO time tags, tick gaps, <think> blocks) to improve correctness and auditability while reducing reasoning tokens; evaluated with TIMEBench across 4B–32B Qwen3 models, showing improved performance in thinking and no-thinking modes and ~10x fewer reasoning tokens.


<details>
  <summary>Details</summary>
Motivation: Address the drawbacks of fixed, long-form reasoning traces that hurt auditability, are inefficient, and ignore temporal structure in dialogue. Enable context-sensitive, resumable reasoning aligned with discourse and time.

Method: Introduce TIME framework with time-aware annotations (ISO 8601 <time> tags, tick turns, <think> blocks). Train using a four-phase curriculum on Qwen3 dense models to elicit brief, in-place reasoning bursts while keeping user-facing text compact. Construct TIMEBench to evaluate temporal grounding, gaps/offsets commonsense, anomaly detection, and continuity.

Result: TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes across 4B–32B scales, and reduces reasoning tokens by about an order of magnitude.

Conclusion: Temporal grounding with minimal, contextual reasoning tokens is feasible and beneficial for dialogue models, enabling auditability and re-triggerable reasoning without sacrificing compact user-facing output.

Abstract: Reasoning oriented large language models often expose explicit "thinking" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treating replies after seconds and replies after weeks as equivalent unless time is stated in text. We introduce TIME, the Temporally Intelligent Meta-reasoning Engine, a behavioral alignment framework that treats explicit reasoning as a context sensitive resource driven by discourse and temporal cues. TIME augments dialogue with optional ISO 8601 <time> tags, tick turns that represent silent gaps, and short <think> blocks that can appear anywhere in a reply. A four-phase curriculum including a small, maximally diverse full-batch alignment step trains Qwen3 dense models to invoke brief, in-place reasoning bursts and keep user facing text compact. We evaluate with TIMEBench, a temporally grounded dialogue benchmark probing chronology, commonsense under gaps and offsets, anomaly detection, and continuity. Across 4B to 32B scales, TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes while reducing reasoning tokens by about an order of magnitude. Our training data and code are available at https://github.com/The-Coherence-Initiative/TIME and TIMEBench is available at https://github.com/The-Coherence-Initiative/TIMEBench

</details>


### [94] [Ontology Neural Networks for Topologically Conditioned Constraint Satisfaction](https://arxiv.org/abs/2601.05304)
*Jaehong Oh*

Main category: cs.LG

TL;DR: 提出基于拓扑条件的神经符号推理框架，结合 Forman-Ricci 曲率、Deep Delta Learning 与 CMA-ES，在约束投影中实现稳定性与能量优化，取得能量从 11.68 降至 1.15、约束成功率 95%、种子无关收敛与对20节点的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决神经符号推理中保持语义一致性与满足物理/逻辑约束之间的冲突，提升梯度优化的稳定性与可解释性。

Method: 将拓扑信息嵌入梯度优化：使用 Forman-Ricci 曲率表征图拓扑；引入 Deep Delta Learning 实现稳定的秩一扰动用于约束投影；用 Covariance Matrix Adaptation Evolution Strategy 优化参数。

Result: 在多种问题规模上，方法实现平均能量下降到 1.15，相比基线 11.68，约束满足成功率 95%，种子无关收敛，规模可扩展至20节点。

Conclusion: 表明拓扑结构可为梯度优化提供信息，从而在保持可解释性和计算效率的前提下提升求解效果。

Abstract: Neuro-symbolic reasoning systems face fundamental challenges in maintaining semantic coherence while satisfying physical and logical constraints. Building upon our previous work on Ontology Neural Networks, we present an enhanced framework that integrates topological conditioning with gradient stabilization mechanisms. The approach employs Forman-Ricci curvature to capture graph topology, Deep Delta Learning for stable rank-one perturbations during constraint projection, and Covariance Matrix Adaptation Evolution Strategy for parameter optimization. Experimental evaluation across multiple problem sizes demonstrates that the method achieves mean energy reduction to 1.15 compared to baseline values of 11.68, with 95 percent success rate in constraint satisfaction tasks. The framework exhibits seed-independent convergence and graceful scaling behavior up to twenty-node problems, suggesting that topological structure can inform gradient-based optimization without sacrificing interpretability or computational efficiency.

</details>


### [95] [When the Server Steps In: Calibrated Updates for Fair Federated Learning](https://arxiv.org/abs/2601.05352)
*Tianrun Yu,Kaixiang Zhao,Cheng Zhang,Anjun Gao,Yueyang Quan,Zhuqing Liu,Minghong Fang*

Main category: cs.LG

TL;DR: EquFL 在联邦学习中提供一种服务器端的去偏方法，通过仅生成并整合一个校准更新来降低全局模型的偏差，理论上收敛到 FedAvg 的最优解，且在实证中显著减小公平性损失。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中的数据分布差异导致的公平性问题；现有方法多需修改客户端训练流程或在聚合策略上缺乏灵活性，迫切需要一个纯服务器端、可灵活整合的去偏机制。

Method: 服务器在收到各客户端的模型更新后，生成一个单一的校准更新，将其与聚合后的更新结合，得到经过调整的全局模型，从而减小偏差；给出理论分析，证明该方法收敛到 FedAvg 那样的全局最优解并有效降低训练过程中的公平损失。

Result: 理论层面：证明 EquFL 收敛至与 FedAvg 相同的全局最优模型且减小公平损失；实验层面：实证表明 EquFL 能显著减轻系统偏差，具有实际可行性。

Conclusion: EquFL 提供一种灵活、无须修改客户端训练的服务器端去偏方案，结合收敛性保障与实证公平性提升，具有较好的应用潜力和扩展性。

Abstract: Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been proposed. However, many of these approaches either require modifications to clients' training protocols or lack flexibility in their aggregation strategies. In this work, we address these limitations by introducing EquFL, a novel server-side debiasing method designed to mitigate bias in FL systems. EquFL operates by allowing the server to generate a single calibrated update after receiving model updates from the clients. This calibrated update is then integrated with the aggregated client updates to produce an adjusted global model that reduces bias. Theoretically, we establish that EquFL converges to the optimal global model achieved by FedAvg and effectively reduces fairness loss over training rounds. Empirically, we demonstrate that EquFL significantly mitigates bias within the system, showcasing its practical effectiveness.

</details>


### [96] [GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting](https://arxiv.org/abs/2601.05353)
*Shovito Barua Soumma,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: GlyRAG is a context-aware, retrieval-augmented CGM forecasting framework that uses an LLM to derive semantic context from CGM traces and retrieve similar historical episodes to improve long-horizon glucose forecasts without extra sensors.


<details>
  <summary>Details</summary>
Motivation: Current CGM forecasting treats glucose readings as numeric sequences, often ignoring context or relying on additional sensors/modali ties that are difficult to deploy at scale. LLMs show promise for time-series forecasting but their role as agentic contextualizers in diabetes care remains underexplored.

Method: GlyRAG framework: 1) use an LLM as a contextualization agent to generate clinical summaries from CGM traces; 2) embed summaries with a language model and fuse with patch-based glucose representations in a multimodal transformer, using a cross-translation loss to align textual and physiological embeddings; 3) a retrieval module identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues before forecasting.

Result: Evaluations on two T1D cohorts show GlyRAG consistently outperforms state-of-the-art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows 85% of predictions in safe zones and a 51% improvement in predicting dysglycemic events across both cohorts.

Conclusion: LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, supporting future agentic decision-support tools for diabetes management.

Abstract: Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role as agentic context extractors in diabetes care remains largely unexplored. To address these limitations, we propose GlyRAG, a context-aware, retrieval-augmented forecasting framework that derives semantic understanding of blood glucose dynamics directly from CGM traces without requiring additional sensor modalities. GlyRAG employs an LLM as a contextualization agent to generate clinical summaries. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer architecture with a cross translation loss aligining textual and physiological embeddings. A retrieval module then identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues prior to making a forecasting inference. Extensive evaluations on two T1D cohorts show that GlyRAG consistently outperforms state-of-the art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows that GlyRAG places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts. These results indicate that LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, thus supporting future agentic decision-support tools for diabetes management.

</details>


### [97] [The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection](https://arxiv.org/abs/2601.05371)
*Md Shafiqul Islam,Shakti Prasad Padhy,Douglas Allaire,Raymundo Arróyave*

Main category: cs.LG

TL;DR: 提出一种基于内核对内核几何的贝叶斯优化框架，用GP先验之间的期望散度距离来探索内核空间，并通过多维标度将离散内核库嵌入到连续流形以实现平滑的BO。


<details>
  <summary>Details</summary>
Motivation: 在高斯过程中，内核选择直接影响模型性能，但通常计算成本高且困难。因此需要一个高效、可重复的内核搜索策略，通过度量GP先验之间的相似性来引导搜索，以提升预测及不确定性校准。

Method: 构建以核对核几何为基础的贝叶斯优化框架，利用期望散度导出的距离度量GP先验的差异；用多维标度（MDS）将内核库映射到连续欧几里得空间，得到可微且稳定的BO景观；目标函数为对数边际似然，输入空间为内核组合，特征化由MDS坐标提供；在距离可形成有效度量时保持几何结构。

Result: 在合成基准、真实时间序列数据和增材制造的熔池几何预测案例中，所提框架实现了比基线（包括LLM引导搜索）更优的预测精度和不确定性标定。

Conclusion: 建立了一种可重复的、面向GP建模与深度核学习的概率几何来进行内核搜索的框架，具有对GP建模及深度核学习的直接相关性与应用潜力。

Abstract: Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distances between GP priors to explore kernel space efficiently. A multidimensional scaling (MDS) embedding of this distance matrix maps a discrete kernel library into a continuous Euclidean manifold, enabling smooth BO. In this formulation, the input space comprises kernel compositions, the objective is the log marginal likelihood, and featurization is given by the MDS coordinates. When the divergence yields a valid metric, the embedding preserves geometry and produces a stable BO landscape. We demonstrate the approach on synthetic benchmarks, real-world time-series datasets, and an additive manufacturing case study predicting melt-pool geometry, achieving superior predictive accuracy and uncertainty calibration relative to baselines including Large Language Model (LLM)-guided search. This framework establishes a reusable probabilistic geometry for kernel search, with direct relevance to GP modeling and deep kernel learning.

</details>


### [98] [Imitation Learning for Combinatorial Optimisation under Uncertainty](https://arxiv.org/abs/2601.05383)
*Prakash Gawas,Antoine Legrain,Louis-Martin Rousseau*

Main category: cs.LG

TL;DR: 提出在IL用于随机性组合优化中的专家分类体系并给出通用DAgger框架；结果表明随机/交互型专家的学习表现优于确定性或全信息专家，聚合的确定性专家在计算受限时效果良好。


<details>
  <summary>Details</summary>
Motivation: 在IL用于SDP的组合优化问题中，专家的设定对学习性能影响显著但缺乏统一框架。本研究通过三维分类构建专家模型并扩展DAgger以支持多专家查询和聚合，旨在理解和提升学习效果。

Method: 将专家按不确定性处理、最优性水平、与学习者的交互方式三维分类，提出一个推广的DAgger算法以适应多专家查询、专家聚合和灵活互动；在动态医师-患者分配问题上进行仿真实验。

Result: 实验显示：来自随机/随机性较高的专家所学得的策略优于来自确定性或全信息的专家；交互学习在较少专家演示下也能提升解的质量；聚合的确定性专家在无法进行成本较高的随机优化时提供有效替代方案。

Conclusion: 该框架为设计IL系统提供统一的理论基础与实用指引，权衡性能与计算成本时可优先考虑随机/交互式专家或聚合确定性专家。

Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.
  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.

</details>


### [99] [Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.05407)
*Minwoo Cho,Batuhan Altundas,Matthew Gombolay*

Main category: cs.LG

TL;DR: 提出 HINT 框架，通过分层 RL、伪 off-policy RL 与基于绩效的筛选实现知识蒸馏在 MARL 的集中训练/分散执行设置中的有效转移，显著提升多域任务的成功率。


<details>
  <summary>Details</summary>
Motivation: (1) 在复杂领域很难合成高水平的教学策略；(2) 当教师需要在分布外（OOD）状态下推理时困难增加；(3) 分散学生与集中教师的观测空间不匹配。

Method: 通过层级化强化学习构建可扩展且高性能的教师策略；引入伪 off-policy RL 使教师能够利用教师与学生的经验进行更新，从而提高对 OOD 的适应性；应用基于绩效的筛选，过滤仅与结果相关的指导以减小观测不匹配。

Result: 在 FireCommander（资源分配）和 MARINE（战术作战等）等挑战性协作任务上，HINT 相对基线提升显著，成功率提高范围约为 60% 到 165%。

Conclusion: HINT 能在集中训练/分散执行的 MARL 知识蒸馏场景中，系统性地缓解教师难以构建、OOD 推理与观测空间不匹配等核心瓶颈，提升 KD 的效果与鲁棒性。

Abstract: Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To address these limitations, we propose HINT (Hierarchical INteractive Teacher-based transfer), a novel KD framework for MARL in a centralized training, decentralized execution setup. By leveraging hierarchical RL, HINT provides a scalable, high-performing teacher. Our key innovation, pseudo off-policy RL, enables the teacher policy to be updated using both teacher and student experience, thereby improving OOD adaptation. HINT also applies performance-based filtering to retain only outcome-relevant guidance, reducing observation mismatches. We evaluate HINT on challenging cooperative domains (e.g., FireCommander for resource allocation, MARINE for tactical combat). Across these benchmarks, HINT outperforms baselines, achieving improvements of 60% to 165% in success rate.

</details>


### [100] [RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models](https://arxiv.org/abs/2601.05451)
*Marko Sterbentz,Kevin Cushing,Cameron Barrie,Kristian J. Hammond*

Main category: cs.LG

TL;DR: RingSQL 通过将模式无关的查询模板与对自然语言问题的 LLM 改写相结合，生成跨多种模式的正确 SQL 数据，提升文本到 SQL 的准确率约 2.3%（在六个基准数据集上）。


<details>
  <summary>Details</summary>
Motivation: 缓解文本到SQL 训练数据稀缺的问题。仅靠模板需要依赖特定模式，LLM 生成缺乏正确性保障。需要一种可扩展、且对不同数据库模式具备正确性保障的数据生成方案。

Method: 提出混合数据生成框架 RingSQL：使用模式无关的查询模板来保证 SQL 的正确性，并用大语言模型对自然语言问题进行改写/paraphrasing，以获得丰富的语言变体，同时保持 SQL 与数据库模式的兼容性。

Result: 在六个文本到 SQL 的基准数据集上，使用 RingSQL 生成的数据训练的模型相比使用其他合成数据训练的模型，平均准确率提升约 2.3%。

Conclusion: RingSQL 提供一种在保证 SQL 正确性的同时增强语言多样性、具备跨模式可扩展性的数据生成方案，适用于文本到 SQL 的数据增强与模型训练，并且开源代码可获得。

Abstract: Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We introduce RingSQL, a hybrid data generation framework that combines schema-independent query templates with LLM-based paraphrasing of natural language questions. This approach preserves SQL correctness across diverse schemas while providing broad linguistic variety. In our experiments, we find that models trained using data produced by RingSQL achieve an average gain in accuracy of +2.3% across six text-to-SQL benchmarks when compared to models trained on other synthetic data. We make our code available at https://github.com/nu-c3lab/RingSQL.

</details>


### [101] [Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning](https://arxiv.org/abs/2601.05474)
*Pingchuan Ma,Qixin Zhang,Shuai Wang,Dacheng Tao*

Main category: cs.LG

TL;DR: ALVGL通过对数据的精度矩阵进行稀疏+低秃分解并用ADMM优化，提取与因果结构相关的分量，构建一个包含真实因果图的超结构作为初始化，从而引导可微分因果发现过程，提升准确性与优化效率；适用于高维、高斯/非高斯以及有/无混淆变量的设置，实验显示具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 在高维或存在潜在混淆的情形下，现有可微分因果发现方法在搜索空间庞大、目标函数复杂、图约束难以处理时易失效。通过学习一个适当的超结构来缩小搜索空间，理论上可提升收敛性和准确性。

Method: 对数据的精度矩阵进行稀疏+低秩分解，使用交替方向乘子法ADMM优化该分解，识别出与潜在因果结构相关的成分，并将这些成分组合起来构造一个超结构。该超结构作为初始化，用于引导标准的可微分因果发现方法的搜索空间。方法可实例化于高斯与非高斯设置、以及有无未观测混淆变量等不同情形。

Result: 在合成与真实数据集上进行的广泛实验表明，ALVGL在准确性方面达到或接近SOTA，并显著提升优化效率。其所构造的超结构对多种结构方程模型均具通用性与鲁棒性。

Conclusion: ALVGL提供了一种通用且有效的强化可微分因果发现的框架：通过精度矩阵的稀疏+低秩分解学习超结构，能在保持或提升准确度的同时显著提升优化效率，适用于多种SCM设置。

Abstract: Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, there has been a surge of interest in leveraging super-structures to guide the optimization process. Nonetheless, learning an appropriate super-structure at the right level of granularity, and doing so efficiently across various settings, presents significant challenges.
  In this paper, we propose ALVGL, a novel and general enhancement to the differentiable causal discovery pipeline. ALVGL employs a sparse and low-rank decomposition to learn the precision matrix of the data. We design an ADMM procedure to optimize this decomposition, identifying components in the precision matrix that are most relevant to the underlying causal structure. These components are then combined to construct a super-structure that is provably a superset of the true causal graph. This super-structure is used to initialize a standard differentiable causal discovery method with a more focused search space, thereby improving both optimization efficiency and accuracy.
  We demonstrate the versatility of ALVGL by instantiating it across a range of structural causal models, including both Gaussian and non-Gaussian settings, with and without unmeasured confounders. Extensive experiments on synthetic and real-world datasets show that ALVGL not only achieves state-of-the-art accuracy but also significantly improves optimization efficiency, making it a reliable and effective solution for differentiable causal discovery.

</details>


### [102] [MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization](https://arxiv.org/abs/2601.05475)
*Jiefu Ou,Sapana Chaudhary,Kaj Bostrom,Nathaniel Weir,Shuai Zhang,Huzefa Rangwala,George Karypis*

Main category: cs.LG

TL;DR: MaxCode 提出一个在推理时使用的强化学习框架，统一多种搜索策略以引导大语言模型在代码优化任务中迭代改进，结合执行反馈、自然语言评审和奖励预测来改进观测与排序；在 CUDA KernelBench 和 PIE C++ 基准测试上实现显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前代码优化面临两大挑战：一方面编写优化代码需要系统、算法与特定语言的专业知识，另一方面需要理解除正确性外的性能指标（如时间和设备利用率）。通过推理时搜索结合执行反馈，提升 LLM 在优化任务中的效率和效果；需要更丰富的观测信息与探索能力。

Method: 提出 MaxCode，将多种搜索策略统一为“最大回报”强化学习框架，观测与动作-值函数模块化以便替换。通过一个自然语言评审模型将执行反馈转化为诊断信息和“最佳折扣回报”的输入，提升给代码提议函数的输入质量。引入一个基于滚动回报的奖励-到-扫模型，用以对候选解进行再排序以增强探索。对 KernelBench（CUDA）与 PIE（C++）基准进行评估。

Result: 相较于基线，MaxCode 在优化后的代码性能方面取得提升：绝对速度提升约 20.3%，相对速度提升排名提升约 10.1%。

Conclusion: MaxCode 通过在推理时整合执行反馈、评审语言和 RL 奖励结构，提升了 LLM 产生优化代码的能力，且在 CUDA 与 C++ 的基准测试中表现出实质性改进，显示该框架对系统编程优化任务具有潜在的广泛适用性。

Abstract: Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.

</details>


### [103] [Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection](https://arxiv.org/abs/2601.05501)
*Feihu Jin,Ying Tan*

Main category: cs.LG

TL;DR: Hi-ZFO提出层级混合优化框架，将FO与ZO结合，通过层级重要性自适应分区：对关键层使用精确的FO更新，对非关键层使用ZO估计；将ZO视为“有益随机性”以帮助跳出局部极小值，从而在LLM微调中提升性能并显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 标准FO优化易趋于训练中的尖锐极小值，ZO方法虽然具备探索性且无需显式梯度，但在大规模生成任务中收敛慢、方差高，输出空间极大放大了估计噪声。需要一个能兼顾梯度精确性与探索性、并在高维生成任务中降低方差的微调策略。

Method: 自适应层级重要性分析将模型分成关键层与非关键层，对关键层采用精确的FO更新；对非关键层采用ZO估计来更新。ZO不仅用于节省内存，更作为引入“有益随机性”的来源，帮助模型从局部极小值中跳出。该方法在多种任务（生成、数学与代码推理）上验证，显示性能提升且训练时间显著减少。

Result: 在多种生成、数学和代码推理任务上获得稳定的性能提升，并显著缩短训练时间。

Conclusion: 层级混合优化为LLM微调提供了一种有效的框架，通过在关键层与非关键层之间动态切换梯度来源，兼顾精度与探索性，提升效果并提高训练效率。

Abstract: Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO methods both noisy and inefficient. To address these challenges, we propose \textbf{Hi-ZFO} (\textbf{Hi}erarchical \textbf{Z}eroth- and \textbf{F}irst-\textbf{O}rder optimization), a hybrid framework designed to synergize the precision of FO gradients with the exploratory capability of ZO estimation. Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while leveraging ZO optimization for less sensitive ones. Notably, ZO in Hi-ZFO is not merely a memory-saving surrogate; it is intentionally introduced as a source of "beneficial stochasticity" to help the model escape the local minima where pure FO optimization tends to stagnate. Validated across diverse generative, mathematical, and code reasoning tasks, Hi-ZFO consistently achieves superior performance while significantly reducing the training time. These results demonstrate the effectiveness of hierarchical hybrid optimization for LLM fine-tuning.

</details>


### [104] [Over-Searching in Search-Augmented Large Language Models](https://arxiv.org/abs/2601.05503)
*Roy Xie,Deepak Gopinath,David Qiu,Dong Lin,Haitian Sun,Saloni Potdar,Bhuwan Dhingra*

Main category: cs.LG

TL;DR: 提出并评估搜索增强型LLMs的过度搜索问题，给出Tokens Per Correctness (TPC) 指标，并发布 OverSearchQA 数据集及缓解策略框架。


<details>
  <summary>Details</summary>
Motivation: 解决搜索过度导致的计算成本、噪声注入与对不可回答查询的拒答能力下降等问题，提升检索在回答中的有效性和鲁棒性。

Method: 开展多维度系统评估（查询类型、模型类别、检索条件、多轮对话），分析检索质量对回答的影响，提出 Tokens Per Correctness (TPC) 指标，探索查询层与检索层的缓解策略，公开 OverSearchQA 数据集以促进后续研究。

Result: 研究发现：1) 搜索在可回答查询上提升准确率，但在不可回答查询上削弱拒答能力；2) 复杂推理模型和深度研究系统更易出现过度搜索，且噪声检索放大问题，且在多轮对话中会累积效应；3) 证据组成对拒答有显著影响，存在负证据能提升拒答效果；4) 引入并使用 TPS（TPC）衡量成本-效益权衡。

Conclusion: 提出面向查询和检索层的缓解策略方向，并发布 OverSearchQA 数据集，推动高效的搜索增强型大语言模型研究。

Abstract: Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.

</details>


### [105] [Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management](https://arxiv.org/abs/2601.05521)
*Jiayu Fang,Zhiqi Shao,Haoning Xi,Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: 提出一个跨城市事故预测框架 MLA-STNet，通过两种Mamba-注意力模块在多城市多任务学习中统一异质数据、增强时空依赖，在纽约与芝加哥数据上实现显著性能提升和对噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于城市事故数据具有异质性、报告不一致、以及本质上呈簇状、稀疏、周期性和嘈杂等特征，加之治理碎片化与报告标准不统一，长期阻碍了跨城市事故防控框架的构建。

Method: MLA-STNet 包含两大模块：1) STG-MA（时空地理的Mamba注意力）用于抑制不稳定的时空波动并强化远程时间依赖；2) STS-MA（时空语义的Mamba注意力）通过共享参数设计在跨城市联合训练的同时，保留各城市的语义表示空间以减轻异质性。系统在多城市多任务学习框架中并行处理不同城市的预测任务。

Result: 在全日与高频两种预测场景下对 NYC 与 Chicago 的真实数据进行的75组实验中，相较于SOTA基线，RMSE 下降最多6%，Recall 提高8%，MAP 提高5%；在输入噪声达50%时，性能波动小于1%。该框架实现了对异质城市数据的统一、可扩展、鲁棒且具解释性的跨城市事故防控系统。

Conclusion: 实验结果证明 MLA-STNet 能有效统一异质城市数据，并具备良好的可扩展性、鲁棒性与可解释性，推动跨城市数据驱动的城市安全管理发展。

Abstract: The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose the Mamba Local-ttention Spatial-Temporal Network MLA-STNet, a unified system that formulates accident risk prediction as a multi-task learning problem across multiple cities. MLA-STNet integrates two complementary modules: (i)the Spatio-Temporal Geographical Mamba-Attention (STG-MA), which suppresses unstable spatio-temporal fluctuations and strengthens long-range temporal dependencies; and (ii) the Spatio-Temporal Semantic Mamba-Attention (STS-MA), which mitigates cross-city heterogeneity through a shared-parameter design that jointly trains all cities while preserving individual semantic representation spaces. We validate the proposed framework through 75 experiments under two forecasting scenarios, full-day and high-frequency accident periods, using real-world datasets from New York City and Chicago. Compared with the state-of-the-art baselines, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP, while maintaining less than 1% performance variation under 50% input noise. These results demonstrate that MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, paving the way for coordinated and data-driven urban safety management.

</details>


### [106] [DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis](https://arxiv.org/abs/2601.05527)
*Rui An,Haohao Qu,Wenqi Fan,Xuequn Shang,Qing Li*

Main category: cs.LG

TL;DR: DeMa is a dual-path linear-time backbone for multivariate time series that disentangles intra-series temporal dynamics and inter-series interactions using a temporal path (Mamba-SSD) and a variate path (Mamba-DALA) with delay-aware attention, achieving state-of-the-art performance with linear complexity across forecasting, imputation, anomaly detection, and classification tasks.


<details>
  <summary>Details</summary>
Motivation: Transformers have quadratic complexity; vanilla Mamba is linear but lacks explicit cross-variate modeling and fails to disentangle intra- and inter-series dynamics and to capture latent time-lag interactions in MTS.

Method: DeMa introduces two paths: a temporal path with Mamba-SSD to capture long-range dynamics within each series (series-independent parallelism), and a variate path with Mamba-DALA to model cross-variate dependencies via delay-aware linear attention; overall decomposes MTS into intra-series dynamics and inter-series interactions within a linear-time backbone.

Result: Extensive experiments on five representative MTS tasks (long- and short-term forecasting, data imputation, anomaly detection, and series classification) show DeMa achieves state-of-the-art performance while maintaining remarkable computational efficiency.

Conclusion: DeMa preserves the linear-complexity advantages of Mamba while significantly enhancing its suitability for MTS, delivering strong accuracy across diverse tasks with improved interpretability through explicit separation of intra- and inter-series dynamics and by modeling latency-aware cross-variate interactions.

Abstract: Accurate and efficient multivariate time series (MTS) analysis is increasingly critical for a wide range of intelligent applications. Within this realm, Transformers have emerged as the predominant architecture due to their strong ability to capture pairwise dependencies. However, Transformer-based models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment in long-term and large-scale MTS modeling. Recently, Mamba has emerged as a promising linear-time alternative with high expressiveness. Nevertheless, directly applying vanilla Mamba to MTS remains suboptimal due to three key limitations: (i) the lack of explicit cross-variate modeling, (ii) difficulty in disentangling the entangled intra-series temporal dynamics and inter-series interactions, and (iii) insufficient modeling of latent time-lag interaction effects. These issues constrain its effectiveness across diverse MTS tasks. To address these challenges, we propose DeMa, a dual-path delay-aware Mamba backbone. DeMa preserves Mamba's linear-complexity advantage while substantially improving its suitability for MTS settings. Specifically, DeMa introduces three key innovations: (i) it decomposes the MTS into intra-series temporal dynamics and inter-series interactions; (ii) it develops a temporal path with a Mamba-SSD module to capture long-range dynamics within each individual series, enabling series-independent, parallel computation; and (iii) it designs a variate path with a Mamba-DALA module that integrates delay-aware linear attention to model cross-variate dependencies. Extensive experiments on five representative tasks, long- and short-term forecasting, data imputation, anomaly detection, and series classification, demonstrate that DeMa achieves state-of-the-art performance while delivering remarkable computational efficiency.

</details>


### [107] [Buffered AUC maximization for scoring systems via mixed-integer optimization](https://arxiv.org/abs/2601.05544)
*Moe Shiina,Shunnosuke Ikeda,Yuichi Takano*

Main category: cs.LG

TL;DR: 提出一种直接最大化缓冲AUC（bAUC）的混合整数线性优化框架，用以构建可解释的计分系统，并通过组稀疏性约束控制变量数量。与基线正则化和逐步回归相比，在公开数据集上表现出更高的AUC。


<details>
  <summary>Details</summary>
Motivation: 现有的计分系统研究多使用MIO，但往往未直接优化AUC。AUC是计分系统性能的关键评估指标，但直接优化AUC在MILP/优化框架中困难，因此采用bAUC作为AUC的紧凑下界进行优化，以提升解释性同时保持预测性能。

Method: 将计分系统建模为混合整数线性优化（MILO），目标函数最大化bAUC，并引入组稀疏性约束以限制计分系统中的变量数量（问题项）。在公开真实数据集上进行 Computational experiments，比较与基线方法（基于正则化和逐步回归）的性能。

Result: MILO方法构建的计分系统在AUC方面优于基线方法，显示出更高的预测性能，同时保持良好解释性；实验证据来自公开数据集。

Conclusion: 将MIO技术用于开发高解释性分类模型方面取得进展，尤其通过直接优化bAUC实现更优的AUC性能，同时控制模型复杂度。

Abstract: A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.

</details>


### [108] [Learn to Evolve: Self-supervised Neural JKO Operator for Wasserstein Gradient Flow](https://arxiv.org/abs/2601.05583)
*Xue Feng,Li Wang,Deanna Needell,Rongjie Lai*

Main category: cs.LG

TL;DR: 提出自监督学习的 JKO 解算符，Learn-to-Evolve 循环，直接映射密度到 JKO 子问题的解并迭代生成梯度流，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: JKO 子问题的高计算成本限制了在实际中的应用，且标注轨迹数据稀缺，因此需要无需数值求解轨道即可学习的方法以提高效率和可泛化性。

Method: 学习一个 JKO 解算符 F，使输入密度映射到对应子问题的极小点，随后可按 F 迭代式地生成梯度流。引入 Learn-to-Evolve：在训练中交替进行轨迹生成与算符更新，随着训练数据逐步接近真实 JKO 轨迹，形成数据增强效果并提升泛化性。

Result: 数值实验展示在多种能量函数和初始条件下，该解算方法具有高精度、稳定性和鲁棒性，且在训练过程中实现对真实梯度流的有效逼近，且具备较高的计算效率。

Conclusion: 本文提出的自监督 JKO 解算器及 Learn-to-Evolve 框架，为 Wasserstein 梯度流的快速、稳健计算提供了一种高效的端到端解决方案，且通过数据自增强显著提升泛化能力。

Abstract: The Jordan-Kinderlehrer-Otto (JKO) scheme provides a stable variational framework for computing Wasserstein gradient flows, but its practical use is often limited by the high computational cost of repeatedly solving the JKO subproblems. We propose a self-supervised approach for learning a JKO solution operator without requiring numerical solutions of any JKO trajectories. The learned operator maps an input density directly to the minimizer of the corresponding JKO subproblem, and can be iteratively applied to efficiently generate the gradient-flow evolution. A key challenge is that only a number of initial densities are typically available for training. To address this, we introduce a Learn-to-Evolve algorithm that jointly learns the JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. As training progresses, the generated data increasingly approximates true JKO trajectories. Meanwhile, this Learn-to-Evolve strategy serves as a natural form of data augmentation, significantly enhancing the generalization ability of the learned operator. Numerical experiments demonstrate the accuracy, stability, and robustness of the proposed method across various choices of energies and initial conditions.

</details>


### [109] [PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning](https://arxiv.org/abs/2601.05593)
*Jingcheng Hu,Yinmin Zhang,Shijie Shang,Xiaobo Yang,Yue Peng,Zhewei Huang,Hebin Zhou,Xin Wu,Jie Cheng,Fanqi Wan,Xiangwen Kong,Chengyuan Yao,Kaiwen Yan,Ailin Huang,Hongyu Zhou,Qi Han,Zheng Ge,Daxin Jiang,Xiangyu Zhang,Heung-Yeung Shum*

Main category: cs.LG

TL;DR: PaCoRe introduces a parallel, coordinated reasoning framework that scales test-time compute (TTC) beyond fixed context windows by using multi-round, message-passing across many parallel reasoning trajectories, coordinated to synthesize final answers. Trained with outcome-based RL, it achieves multi-million-token effective TTC and strong results in math (HMMT 2025, 8B model at 94.5%). Open-sourced resources accompany the work.


<details>
  <summary>Details</summary>
Motivation: To overcome the bottleneck of sequential reasoning constrained by a fixed context window, which limits TTC and task performance of current LMs. The goal is to scale TTC through parallel reasoning and coordination without exceeding context limits.

Method: PaCoRe runs many parallel reasoning trajectories per round, aggregates results into context-bounded messages, and uses multiple rounds of message passing to guide subsequent reasoning. The model is trained end-to-end with outcome-based reinforcement learning to master synthesis and coordination, enabling millions of tokens of effective TTC while respecting context constraints. The work includes open-sourcing model checkpoints, training data, and the full inference pipeline.

Result: Demonstrates strong improvements across diverse domains; in mathematics, an 8B PaCoRe model attains 94.5% on HMMT 2025, surpassing a GPT-5 baseline at 93.2%. Effective TTC scales to ~2 million tokens, enabling performance beyond frontier sequential systems.

Conclusion: PaCoRe validates that parallel, coordinated reasoning can substantially extend TTC and reasoning capabilities under fixed context windows, with evidence from mathematics benchmarks and broad-domain improvements, accompanied by release of resources to accelerate future research.

Abstract: We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework designed to overcome a central limitation of contemporary language models: their inability to scale test-time compute (TTC) far beyond sequential reasoning under a fixed context window. PaCoRe departs from the traditional sequential paradigm by driving TTC through massive parallel exploration coordinated via a message-passing architecture in multiple rounds. Each round launches many parallel reasoning trajectories, compacts their findings into context-bounded messages, and synthesizes these messages to guide the next round and ultimately produce the final answer. Trained end-to-end with large-scale, outcome-based reinforcement learning, the model masters the synthesis abilities required by PaCoRe and scales to multi-million-token effective TTC without exceeding context limits. The approach yields strong improvements across diverse domains, and notably pushes reasoning beyond frontier systems in mathematics: an 8B model reaches 94.5% on HMMT 2025, surpassing GPT-5's 93.2% by scaling effective TTC to roughly two million tokens. We open-source model checkpoints, training data, and the full inference pipeline to accelerate follow-up work.

</details>


### [110] [Good Allocations from Bad Estimates](https://arxiv.org/abs/2601.05597)
*Sílvia Casacuberta,Moritz Hardt*

Main category: cs.LG

TL;DR: 在自然分布的治疗效应下，利用粗粒度估计即可实现与CATE相同的总治疗效果，样本复杂度从O(M/ε^2)降至O(M/ε)。核心在于将资源用于对治疗效应的粗略估计以实现接近最优的分配，并且预算弹性进一步降低样本需求；在真实RCT数据集上验证，近似最优的治疗分配可用极少的样本实现。


<details>
  <summary>Details</summary>
Motivation: 提高在预算受限的情况下的治疗分配效率，降低实现数量级，区别对治疗效应估计与治疗分配所需样本量。

Method: 提出一种利用粗粒度估计来实现近似最优治疗分配的算法，证明在自然分布假设下可将总治疗效应达到与CATE相同的水平所需样本量从O(M/ε^2)降至O(M/ε)，并且引入预算弹性进一步降低样本复杂度。

Result: 理论上将样本复杂度从O(M/ε^2)降低到O(M/ε)，在多组分层中实现近似最优的治疗分配；在多个真实世界RCT数据集上验证，算法能以较少的样本实现几乎最优的治疗分配。

Conclusion: 治疗效应估计与治疗分配存在本质差异：分配任务对样本的需求显著低于估计全部分层治疗效应的需求；该工作揭示了在预算受限场景下的高效治疗分配方法及其现实意义。

Abstract: Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $ε> 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/ε^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $ε$ error. In this work, we show how to achieve the same total treatment effect as CATE with only $O(M/ε)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation. Finally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.

</details>


### [111] [PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes](https://arxiv.org/abs/2601.05613)
*Yiming Zhou,Mingyue Cheng,Hao Wang,Enhong Chen*

Main category: cs.LG

TL;DR: PiXTime是一种针对联邦学习的时序预测模型，解决跨节点多粒度和异构变量集问题，通过个性化 Patch Embedding、全局 VE 表和基于Transformer的共享模型实现跨节点传递性与准确预测，在八个真实基准上达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 在隐私保护前提下，时序数据难以集中，且不同节点的采样标准导致时间粒度差异与变量集合变化，传统联邦学习难以直接处理多粒度和变量异构的时序预测任务。

Method: 引入个性化 Patch Embedding，将节点特有的粒度时序映射为统一维度的 token 序列；使用全局 VE Table 对变量类别语义进行对齐，提升跨节点可转移性；以 Transformer 为基础的共享模型，并通过跨注意力机制利用辅助序列增强目标序列的预测，支持任意数量变量。

Result: 在联邦设置中实现了 state-of-the-art 的预测性能，并在八个广泛使用的真实基准上表现出色。

Conclusion: PiXTime 能在多粒度、异构变量集的联邦时序预测场景下实现有效的跨节点传递和高精度预测，证实了在现实基准中的实用性。

Abstract: Time series are highly valuable and rarely shareable across nodes, making federated learning a promising paradigm to leverage distributed temporal data. However, different sampling standards lead to diverse time granularities and variable sets across nodes, hindering classical federated learning. We propose PiXTime, a novel time series forecasting model designed for federated learning that enables effective prediction across nodes with multi-granularity and heterogeneous variable sets. PiXTime employs a personalized Patch Embedding to map node-specific granularity time series into token sequences of a unified dimension for processing by a subsequent shared model, and uses a global VE Table to align variable category semantics across nodes, thereby enhancing cross-node transferability. With a transformer-based shared model, PiXTime captures representations of auxiliary series with arbitrary numbers of variables and uses cross-attention to enhance the prediction of the target series. Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.

</details>


### [112] [Transformer Is Inherently a Causal Learner](https://arxiv.org/abs/2601.05647)
*Xinyue Wang,Stephen Wang,Biwei Huang*

Main category: cs.LG

TL;DR: 自回归训练的变换器在学习表示中天然编码时间延迟的因果结构；通过输出对 past 输入的梯度敏感性可直接恢复潜在的因果图，且在非线性、长时依赖与非平稳系统中优于现有因果发现方法，数据异质性越大性能越优越，具有随数据量与异质性提升而增强的扩展潜力。


<details>
  <summary>Details</summary>
Motivation: 现有时序因果发现方法多依赖显式结构假设、特征工程或特定约束，在处理非线性、长记忆和非平稳性时表现受限；同时希望将大规模基础模型的可解释性与因果发现结合，从而提高鲁棒性与可扩展性。

Method: 以自回归训练的变换器为研究对象，分析其输出相对过去输入的梯度敏感性，提出聚合梯度归因的实际提取方法以重构因果图。理论上在标准可辨识条件下证明该梯度-因果关系的联系，并在非线性动力学、长时依赖与非平稳系统等挑战场景中验证。

Result: 理论结果：梯度敏感性能直接 recovering 潜在因果图；方法结果：在复杂场景中显著优于现有因果发现算法，且数据量与数据异质性增加时因果识别精度提升，显示出良好的扩展性与鲁棒性。

Conclusion: 提出以基础模型为中心的因果发现新范式，提升因果解释性并促进因果推断在大规模模型中的应用，为未来在 foundation models 与因果性之间的互动奠定基础。

Abstract: We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.

</details>


### [113] [From Global to Local: Cluster-Aware Learning for Wi-Fi Fingerprinting Indoor Localisation](https://arxiv.org/abs/2601.05650)
*Miguel Matey-Sanz,Joaquín Torres-Sospedra,Joaquín Huerta,Sergio Trilles*

Main category: cs.LG

TL;DR: 通过 clustering 将指纹数据结构化以提升室内定位的可扩展性与准确性。


<details>
  <summary>Details</summary>
Motivation: 应对指纹数据集规模、异质性、RSS 变动性以及大楼/多层环境中的结构性歧义，降低全局模型对结构约束的忽略带来的定位误差。

Method: 对指纹数据基于空间特征或射频特征进行聚类，聚类可在建筑层级或楼层层级进行。在定位阶段，利用最强接入点的聚类估计将未见指纹分配到最相关的簇中，然后仅在所选簇内进行定位，使用学习模型对子集数据进行训练。

Result: 在三个公开数据集和多种机器学习模型上进行评估，定位误差有一致性下降，尤其在以建筑层级策略时表现显著；但楼层识别准确性下降。该方法显示通过显式的聚类结构化数据集具有可扩展性和灵活性的优势，适合提升定位系统的可扩展性与稳定性。

Conclusion: 显式地通过聚类对指纹数据集进行结构化是实现可扩展且有效的室内定位的可行策略，能够在不显著牺牲全局一致性的前提下降低局部学习模型的复杂度。

Abstract: Wi-Fi fingerprinting remains one of the most practical solutions for indoor positioning, however, its performance is often limited by the size and heterogeneity of fingerprint datasets, strong Received Signal Strength Indicator variability, and the ambiguity introduced in large and multi-floor environments. These factors significantly degrade localisation accuracy, particularly when global models are applied without considering structural constraints. This paper introduces a clustering-based method that structures the fingerprint dataset prior to localisation. Fingerprints are grouped using either spatial or radio features, and clustering can be applied at the building or floor level. In the localisation phase, a clustering estimation procedure based on the strongest access points assigns unseen fingerprints to the most relevant cluster. Localisation is then performed only within the selected clusters, allowing learning models to operate on reduced and more coherent subsets of data. The effectiveness of the method is evaluated on three public datasets and several machine learning models. Results show a consistent reduction in localisation errors, particularly under building-level strategies, but at the cost of reducing the floor detection accuracy. These results demonstrate that explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning.

</details>


### [114] [Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM](https://arxiv.org/abs/2511.18721)
*Adarsh Kumarappan,Ayushi Mehrotra*

Main category: cs.LG

TL;DR: 提出一个 (k, ε)-unstable 的 probabilistic 框架，用以对抗不同类型的 jailbreaking 攻击，并给出基于数据的下界，从而为 SmoothLLM 的防护提供更可信的安全证明。


<details>
  <summary>Details</summary>
Motivation: 解决现有的 k-unstable 假设在实际中难以满足，导致安全证书可信度受限，需引入更贴近现实的概率框架以提升可用性和实用性。

Method: 提出 (k, ε)-unstable 框架，结合对攻击成功的经验模型，推导出对 SmoothLLM 防御概率的数据驱动下界；覆盖从梯度攻击（GCG）到语义攻击（PAIR）的多种攻击，并给出可操作的认证阈值。

Result: 理论上推导出数据驱动的下界，提升防御可信度；实现对多类攻击的证据性分析；提供可用于实际部署的安全证书，以及设定阈值的指导。

Conclusion: 此框架提供了一个实用且具有理论支撑的机制，使 LLM 对安全对齐漏洞的利用具有更强鲁棒性，推动在安全 AI 部署中的可验证性和可信性。

Abstract: The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.

</details>


### [115] [Do Sparse Autoencoders Identify Reasoning Features in Language Models?](https://arxiv.org/abs/2601.05679)
*George Ma,Zhongyuan Liang,Irene Y. Chen,Somayeh Sojoudi*

Main category: cs.LG

TL;DR: 结论：基于对比学习的稀疏自编码器（SAE）所识别的“推理特征”主要是语言相关的表征，而非真实的推理机制；在多配置实验中，绝大部分特征对少量标记触发就能激活，且对手段灵活性很高；彼此之间通过自证性测试均未找到符合“真实推理”标准的特征。


<details>
  <summary>Details</summary>
Motivation: 评估SAE是否能发现LLM中的真正推理特征，并提出一种以证伪为导向的框架来区分推理过程与表面语言相关的特征。

Method: 从通过对比激活筛选得到的特征出发，结合（1）特征相关Token注入的因果干预、（2）由LLM引导的证伪性测试，跨20种模型族、层数和推理数据集进行系统评估；比较激活与触发之间的关系。

Result: 高度敏感于token级干预；将少量特征相关token注入非推理文本即可引发59%-94%的特征强激活；对余下特征，LLM引导的证伪显示存在非推理输入激活该特征而推理输入不激活的情况，且没有任何分析的特征满足真推理的标准。对这些特征进行干预后，基准任务性能基本不变或略有下降。

Conclusion: 因此，基于对比方法识别的SAE特征主要捕捉推理的语言相关表征，而非潜在推理计算本身。

Abstract: We investigate whether sparse autoencoders (SAEs) identify genuine reasoning features in large language models (LLMs). Starting from features selected using standard contrastive activation methods, we introduce a falsification-oriented framework that combines causal token injection experiments and LLM-guided falsification to test whether feature activation reflects reasoning processes or superficial linguistic correlates. Across 20 configurations spanning multiple model families, layers, and reasoning datasets, we find that identified reasoning features are highly sensitive to token-level interventions. Injecting a small number of feature-associated tokens into non-reasoning text is sufficient to elicit strong activation for 59% to 94% of features, indicating reliance on lexical artifacts. For the remaining features that are not explained by simple token triggers, LLM-guided falsification consistently produces non-reasoning inputs that activate the feature and reasoning inputs that do not, with no analyzed feature satisfying our criteria for genuine reasoning behavior. Steering these features yields minimal changes or slight degradations in benchmark performance. Together, these results suggest that SAE features identified by contrastive approaches primarily capture linguistic correlates of reasoning rather than the underlying reasoning computations themselves.

</details>


### [116] [Automating Deception: Scalable Multi-Turn LLM Jailbreaks](https://arxiv.org/abs/2511.19517)
*Adarsh Kumarappan,Ananya Mujoo*

Main category: cs.LG

TL;DR: 提出了一个自动化管线，用于生成大规模、 psychologically-grounded 的多轮越狱数据集，评估七个模型在带历史对话的攻击中的鲁棒性，发现不同模型对上下文的敏感性差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有安全评估严重依赖人工、难以扩展的数据集，且对话中的心理学操控（如 FITD）可被利用来规避安全防护，需可扩展的对话攻击数据来研究模型鲁棒性。

Method: 将 Foot-in-the-Door（FITD）等心理学技巧转化为可复现的模板，构建包含非法与攻击性内容的1500个场景的自动化生成流水线；在三大 LLM 家族的七个模型上，分别在多轮（带历史）与单轮（无历史）条件下评估，指标为攻击成功率（ASR）。

Result: GPT 家族在有历史对话时显著脆弱，ASR 最高提升约32个百分点；Google Gemini 2.5 Flash 展现极高鲁棒性，几乎免疫此类攻击；Anthropic Claude 3 Haiku 表现强但不完美。

Conclusion: 在对话上下文的处理上，各大安全架构存在显著差异，需发展能抵御叙事性操控的防御机制；自动化、可扩展的数据生成对评估与提升对话安全具有重要作用。

Abstract: Multi-turn conversational attacks, which leverage psychological principles like Foot-in-the-Door (FITD), where a small initial request paves the way for a more significant one, to bypass safety alignments, pose a persistent threat to Large Language Models (LLMs). Progress in defending against these attacks is hindered by a reliance on manual, hard-to-scale dataset creation. This paper introduces a novel, automated pipeline for generating large-scale, psychologically-grounded multi-turn jailbreak datasets. We systematically operationalize FITD techniques into reproducible templates, creating a benchmark of 1,500 scenarios across illegal activities and offensive content. We evaluate seven models from three major LLM families under both multi-turn (with history) and single-turn (without history) conditions. Our results reveal stark differences in contextual robustness: models in the GPT family demonstrate a significant vulnerability to conversational history, with Attack Success Rates (ASR) increasing by as much as 32 percentage points. In contrast, Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but imperfect resistance. These findings highlight a critical divergence in how current safety architectures handle conversational context and underscore the need for defenses that can resist narrative-based manipulation.

</details>


### [117] [AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces](https://arxiv.org/abs/2601.05680)
*Yeonsang Shin,Insoo Kim,Bongkeun Kim,Keonwoo Bae,Bohyung Han*

Main category: cs.LG

TL;DR: 提出 AGDC：一个统一的离散-连续混合序列生成框架，结合类别预测与扩散模型，并引入 EOS 调整与长度正则化；同时给出 ContLayNet 数据集用于高精度半导体布局的评估，实验表明在高保真度生成方面优于离散化-baselines。


<details>
  <summary>Details</summary>
Motivation: 离散化 token 的局限性在高精度的连续值域（如半导体电路布局）导致精度损失和功能失效，因此需要更高保真且可扩展的生成方法。

Method: 在一个框架内同时处理离散和连续分量：对离散值使用分类预测，对连续值使用扩散模型；通过一个 MLP 动态调整 EOS token 的 logits 以考虑上下文；损失中引入长度正则化以控制序列长度。

Result: 在 ContLayNet（334K 样本）和其他数据集（图形布局、SVG）上，AGDC 在高保真混合向量表示的生成方面优于离散化基线和固定模式基线，展现出跨领域的可扩展性和高精度生成能力。

Conclusion: 提出的统一框架和数据集证明了在高精度混合离散-连续序列生成中的潜力，尤其适用于需要高保真度的专业领域。

Abstract: Transformer-based autoregressive models excel in data generation but are inherently constrained by their reliance on discretized tokens, which limits their ability to represent continuous values with high precision. We analyze the scalability limitations of existing discretization-based approaches for generating hybrid discrete-continuous sequences, particularly in high-precision domains such as semiconductor circuit designs, where precision loss can lead to functional failure. To address the challenge, we propose AGDC, a novel unified framework that jointly models discrete and continuous values for variable-length sequences. AGDC employs a hybrid approach that combines categorical prediction for discrete values with diffusion-based modeling for continuous values, incorporating two key technical components: an end-of-sequence (EOS) logit adjustment mechanism that uses an MLP to dynamically adjust EOS token logits based on sequence context, and a length regularization term integrated into the loss function. Additionally, we present ContLayNet, a large-scale benchmark comprising 334K high-precision semiconductor layout samples with specialized evaluation metrics that capture functional correctness where precision errors significantly impact performance. Experiments on semiconductor layouts (ContLayNet), graphic layouts, and SVGs demonstrate AGDC's superior performance in generating high-fidelity hybrid vector representations compared to discretization-based and fixed-schema baselines, achieving scalable high-precision generation across diverse domains.

</details>


### [118] [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)
*Antonio Roye-Azar,Santiago Vargas-Naranjo,Dhruv Ghai,Nithin Balamurugan,Rayan Amir*

Main category: cs.LG

TL;DR: TRM在ARC-AGI-1上的表现主要来自测试时的推理强度、任务条件化与相对浅的递归，而非深层内部推理能力；与QLoRA微调的Llama 3 8B相比，TRM在吞吐和内存方面更具优势。


<details>
  <summary>Details</summary>
Motivation: 评估TRM在ARC任务中的性能成分，区分架构贡献、测试时推理与任务特定先验对性能的影响，评估递归机制的实际作用。

Method: 对ARC-AGI-1上的TRM检查点进行系统性行为分析：1) 1000样本投票对比单轮推断；2) puzzle-id消融揭示对任务标识的依赖；3) 递归轨迹分析揭示有效递归的深度；4) 早期训练在canonical vs heavy augmentation下的效果对比；5) 与对比基线（Llama 3 8B的QLoRA微调）在canonical ARC-AGI-1上的吞吐与内存对比。

Result: 主要发现：1) 测试时增广和多数投票显著提升性能，1000样本投票比单轮推断在Pass@1上提升约11个百分点；2) puzzle-id消融显示对任务标识高度依赖，空白或随机ID导致零准确度；3) 递归轨迹显示大多数最终准确率在第一步实现，随着latent更新增益有限，递归深度较浅；4) 重增广条件下更容易产生更丰富的候选解并提高多样本下的成功率；5) 与对比的Llama 3 8B QLoRA微调相比，TRM的非自回归设计在吞吐和内存使用上显著优势；综合看，ARC-AGI-1上的性能更源于效率、任务特定条件与强测试时计算的结合，而非深层内部推理。

Conclusion: TRM在ARC-AGI-1上的表现主要由效率、任务条件化和测试时推理的综合作用驱动，需谨慎将其归因于深层推理能力；未来工作可进一步量化各成分的边际贡献并探索对比基线的鲁棒性。

Abstract: Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains unclear how much of this performance stems from architecture, test-time compute, or task-specific priors. In this technical note, we empirically analyze the ARC Prize TRM checkpoint on ARC-AGI-1 and report four behavioral findings and an efficiency comparison. First, we show that test-time augmentation and majority-vote ensembling account for a substantial fraction of reported performance: the 1000-sample voting pipeline improves Pass@1 by about 11 percentage points over single-pass canonical inference. Second, a puzzle-identity ablation reveals strict dependence on task identifiers: replacing the correct puzzle ID with a blank or random token yields zero accuracy. Third, a recursion trajectory analysis shows that most of the final accuracy is achieved at the first recursion step and that performance saturates after few latent updates, indicating shallow effective recursion. Fourth, early-stage training experiments under canonical versus heavy augmentation regimes suggest that heavy augmentation broadens the distribution of candidate solutions and improves multi-sample success. Finally, we compare TRM with a naive QLoRA fine-tune of Llama 3 8B on canonical ARC-AGI-1, finding that TRM's non-autoregressive design achieves much higher throughput and substantially lower memory usage in this setting. Overall, TRM's ARC-AGI-1 performance appears to arise from an interaction between efficiency, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning.

</details>


### [119] [FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching](https://arxiv.org/abs/2601.05684)
*Hongyaoxing Gul,Lijuan Hu,Shuzi Niu,Fangfang Liu*

Main category: cs.LG

TL;DR: 提出FLRQ，一种灵活低秩量化框架，通过R1-FLR与BLC在不同层自适应选择秩并在裁剪约束下迭代最小化量化误差，实现高效且鲁棒的PTQ。


<details>
  <summary>Details</summary>
Motivation: 现有低秩PTQ方法依赖额外微调以确定各层的最优秩，且基于SVD的近似计算成本高，难以在大模型场景中实现高效且稳定的低秩量化。

Method: 提出两大组件：1) R1-FLR：基于R1-Sketch的快速低秩近似，结合高斯投影实现对每层的离群点感知秩提取；2) BLC：在缩放与裁剪约束下通过迭代优化最小化低秩量化误差。

Result: 在广泛实验中展现出强鲁棒性和算法效率，达到量化质量与计算开销的前沿水平。

Conclusion: FLRQ通过自适应层级秩选择与裁剪约束下的迭代优化，提供一种快速且高效的低秩量化解决方案，适用于大规模语言模型的PTQ。

Abstract: Traditional post-training quantization (PTQ) is considered an effective approach to reduce model size and accelerate inference of large-scale language models (LLMs). However, existing low-rank PTQ methods require costly fine-tuning to determine a compromise rank for diverse data and layers in large models, failing to exploit their full potential. Additionally, the current SVD-based low-rank approximation compounds the computational overhead. In this work, we thoroughly analyze the varying effectiveness of low-rank approximation across different layers in representative models. Accordingly, we introduce \underline{F}lexible \underline{L}ow-\underline{R}ank \underline{Q}uantization (FLRQ), a novel solution designed to quickly identify the accuracy-optimal ranks and aggregate them to achieve minimal storage combinations. FLRQ comprises two powerful components, Rank1-Sketch-based Flexible Rank Selection (R1-FLR) and Best Low-rank Approximation under Clipping (BLC). R1-FLR applies the R1-Sketch with Gaussian projection for the fast low-rank approximation, enabling outlier-aware rank extraction for each layer. Meanwhile, BLC aims at minimizing the low-rank quantization error under the scaling and clipping strategy through an iterative method. FLRQ demonstrates strong effectiveness and robustness in comprehensive experiments, achieving state-of-the-art performance in both quantization quality and algorithm efficiency.

</details>


### [120] [mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations](https://arxiv.org/abs/2601.05732)
*Yongyi Yang,Jianyang Gao*

Main category: cs.LG

TL;DR: mHC-lite provides an exact, portable alternative to mHC by constructing doubly stochastic residual matrices as convex combinations of permutation matrices, guaranteeing stability and improving throughput. It matches or surpasses mHC performance while avoiding SK-induced approximation gaps and specialized CUDA requirements.


<details>
  <summary>Details</summary>
Motivation: HC accelerates convergence via dynamic residual mixing but unconstrained residual matrices risk training instability. Finite Sinkhorn-Knopp (SK) iterations do not guarantee exact doubly stochasticity, causing depth-propagated gaps. Implementing SK efficiently needs specialized CUDA kernels, hindering portability. A method with exact doubly stochasticity and portable implementation is desirable.

Method: mHC-lite leverages the Birkhoff–von Neumann theorem to parameterize doubly stochastic (DS) matrices as convex combinations of permutation matrices, guaranteeing DS by construction. This reparameterization requires only native matrix operations and avoids iterative normalization.

Result: Extensive experiments show mHC-lite matches or exceeds mHC and HC in performance, while offering higher training throughput with a naive implementation and removing residual instabilities observed in HC and mHC.

Conclusion: mHC-lite delivers a stable, efficient, and portable alternative to HC/mHC with exact DS guarantees. The approach enables broader applicability without resorting to specialized kernels. Code is publicly available.

Abstract: Hyper-Connections (HC) generalizes residual connections by introducing dynamic residual matrices that mix information across multiple residual streams, accelerating convergence in deep neural networks. However, unconstrained residual matrices can compromise training stability. To address this, DeepSeek's Manifold-Constrained Hyper-Connections (mHC) approximately projects these matrices onto the Birkhoff polytope via iterative Sinkhorn--Knopp (SK) normalization. We identify two limitations of this approach: (i) finite SK iterations do not guarantee exact doubly stochasticity, leaving an approximation gap that can accumulate through network depth and undermine stability; (ii) efficient SK implementation requires highly specialized CUDA kernels, raising engineering barriers and reducing portability. Motivated by the Birkhoff--von Neumann theorem, we propose mHC-lite, a simple reparameterization that explicitly constructs doubly stochastic matrices as convex combinations of permutation matrices. This approach guarantees exact doubly stochasticity by construction and can be implemented using only native matrix operations. Extensive experiments demonstrate that mHC-lite matches or exceeds mHC in performance while achieving higher training throughput with a naive implementation and eliminating the residual instabilities observed in both HC and mHC. The code is publicly available at https://github.com/FFTYYY/mhc-lite.

</details>


### [121] [Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms](https://arxiv.org/abs/2601.05759)
*Turkan Simge Ispak,Salih Tileylioglu,Erdem Akagunduz*

Main category: cs.LG

TL;DR: 在自监督异常检测框架下，注意力式VAE优于跳跃连接的VAE，能在强噪声的地震记录中实现更高的P波检测鲁棒性与早警应用适用性。


<details>
  <summary>Details</summary>
Motivation: 解决强动记录中的P波检测挑战：有限标注、噪声、复杂波形，评估架构对重构保真度与异常判别之间权衡的影响。

Method: 对492个变分自编码器（VAE）配置进行了网格搜索，比较跳过连接（skip connections）与注意力（attention）机制对重构误差和异常检测性能的影响；以自监督异常检测来定义P波到达事件，并以AUC作为评估指标。

Result: 跳跃连接虽降低MAE（约0.0012），但造成过度泛化，难以保留噪声以外的信号；注意力机制强调全局信息，达到最高检测性能（AUC0.875），在0–40 km近源范围内AUC提升至0.91。

Conclusion: 用于自监督P波检测的架构应优先考虑全局上下文而非像素级重构，以提升鲁棒性和早期警报的可用性。

Abstract: Accurate P-wave detection is critical for earthquake early warning, yet strong-motion records pose challenges due to high noise levels, limited labeled data, and complex waveform characteristics. This study reframes P-wave arrival detection as a self-supervised anomaly detection task to evaluate how architectural variations regulate the trade-off between reconstruction fidelity and anomaly discrimination. Through a comprehensive grid search of 492 Variational Autoencoder configurations, we show that while skip connections minimize reconstruction error (Mean Absolute Error approximately 0.0012), they induce "overgeneralization", allowing the model to reconstruct noise and masking the detection signal. In contrast, attention mechanisms prioritize global context over local detail and yield the highest detection performance with an area-under-the-curve of 0.875. The attention-based Variational Autoencoder achieves an area-under-the-curve of 0.91 in the 0 to 40-kilometer near-source range, demonstrating high suitability for immediate early warning applications. These findings establish that architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection.

</details>


### [122] [Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer](https://arxiv.org/abs/2601.05770)
*Yifan Zhang,Wei Bi,Kechi Zhang,Dongming Jin,Jie Fu,Zhi Jin*

Main category: cs.LG

TL;DR: 提出 Discrete Transformer，通过严格的功能解耦和温度退火采样实现从模型中提取可读程序，性能与 RNN 基线相当且提升对连续变量域的可解释性，呈现探索-开发的相变，支持对合成程序的细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 解决 Transformer 在算法提取中的超叠加问题，导致难以从模型中提取符号表达。需要一个架构将连续表征与离散符号逻辑更紧密地耦合，以实现可读程序的直接提取。

Method: 设计并实现 Discrete Transformer：强制性的功能解耦，将 Numerical Attention 限定为信息路由、Numerical MLP 限定为逐元素算术；采用温度退火采样以实现离散搜索并促进可读程序的提取。

Result: 在性能方面接近或与基线的 RNN 相当；扩展了对连续变量域的可解释性；分析显示退火过程存在从探索到开发的阶段性转变；通过诱导偏置实现对合成程序的细粒度控制。

Conclusion: Discrete Transformer 为无示范学习的算法发现提供一个稳健框架，清晰地推动 Transformer 的可解释性向连续域扩展，并为从模型中提取符号表达提供了路径。

Abstract: Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.

</details>


### [123] [Tensor-DTI: Enhancing Biomolecular Interaction Prediction with Contrastive Embedding Learning](https://arxiv.org/abs/2601.05792)
*Manel Gil-Sorribes,Júlia Vilalta-Mor,Isaac Filella-Mercè,Robert Soliva,Álvaro Ciudad,Víctor Guallar,Alexis Molina*

Main category: cs.LG

TL;DR: Tensor-DTI: a multimodal, contrastive, siamese DTI predictor that fuses molecular graphs, protein language models, and binding-site predictions; achieves strong predictive performance and scalable, reliability-aware virtual screening.


<details>
  <summary>Details</summary>
Motivation: Current DTI models rely on single modalities and limited representations; integrating multimodal embeddings promises improved interaction modeling and robustness under challenging screening settings.

Method: Siamese dual-encoder framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions; trained with contrastive objectives to distinguish interacting vs non-interacting pairs.

Result: Outperforms sequence- and graph-based baselines on standard DTI benchmarks; scalable inference on CDK2 across billion-scale libraries yielding chemically plausible hit distributions even when CDK2 is withheld from training; competitive enrichment against Glide docking and Boltz-2 co-folders; improves screening budget to recover moderate fractions of high-affinity ligands under strict family-holdout; applicable to protein-RNA and peptide-protein interactions.

Conclusion: Integrating multimodal information with contrastive objectives enhances DTI-prediction accuracy and yields more interpretable and reliability-aware models for virtual screening.

Abstract: Accurate drug-target interaction (DTI) prediction is essential for computational drug discovery, yet existing models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness. We propose Tensor-DTI, a contrastive learning framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to improve interaction modeling. Tensor-DTI employs a siamese dual-encoder architecture, enabling it to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs. Evaluations on multiple DTI benchmarks demonstrate that Tensor-DTI outperforms existing sequence-based and graph-based models. We also conduct large-scale inference experiments on CDK2 across billion-scale chemical libraries, where Tensor-DTI produces chemically plausible hit distributions even when CDK2 is withheld from training. In enrichment studies against Glide docking and Boltz-2 co-folder, Tensor-DTI remains competitive on CDK2 and improves the screening budget required to recover moderate fractions of high-affinity ligands on out-of-family targets under strict family-holdout splits. Additionally, we explore its applicability to protein-RNA and peptide-protein interactions. Our findings highlight the benefits of integrating multimodal information with contrastive objectives to enhance interaction-prediction accuracy and to provide more interpretable and reliability-aware models for virtual screening.

</details>


### [124] [Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers](https://arxiv.org/abs/2601.05807)
*Mohamed Amine Hallam,Kuo-Kun Tseng*

Main category: cs.LG

TL;DR: 在长序列 Transformers 中，位置编码的融合方式对性能有显著影响，三种常见融合策略（逐元素相加、拼接后投影、标量门控融合）在短文本几乎无差，而在长文本上带来稳定的性能提升。研究表明提升来自结构层面而非随机性，并且可在多种位置编码族中泛化；还尝试了带局部卷积偏置的门控融合，提示融合设计应被作为明确建模项。


<details>
  <summary>Details</summary>
Motivation: 系统地评估位置编码与 token 表达的融合机制是否会影响 Transformer 的性能，特别是在长序列场景中，超越仅比较不同的位置信息编码。

Method: 在同一 Transformer 架构、数据划分和随机种子下，控制比较三种融合策略：元素级相加、拼接后投影、标量门控融合。数据集覆盖短、中、长序列（AG News、IMDB、ArXiv）。进行成对种子分析、跨数据集的序列长度对比。还测试多种位置编码族的情况下的可 learnable 的融合泛化，以及引入轻量级卷积门控以在长文本上引入局部偏置。

Result: 短文本上融合策略影响甚微；在长文档上呈现出一致的性能增益；增益具有结构性而非随机性；learnable 融合在多种位置编码族中具备泛化性；门控/卷积门控融合提升了对长序列的建模能力。

Conclusion: 位置编码的融合是长序列 Transformer 的一个非平凡设计选择，应作为明确的建模决策而非默认设置；可通过学习化融合、以及引入局部偏置的门控机制来提升长序列性能。

Abstract: Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.

</details>


### [125] [Detecting Autism Spectrum Disorder with Deep Eye Movement Features](https://arxiv.org/abs/2601.05812)
*Zhanpei Huang,Taochen chen,Fangqing Gu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 提出离散短时序列建模框架 DSTS，结合类别感知表示与不平衡感知机制，在眼动数据上有效区分 ASD 与 TD，优于传统机器学习和更复杂的深度模型。


<details>
  <summary>Details</summary>
Motivation: 眼动信号具有离散性、短期依赖性且局部性显著，全球注意力机制在此类数据中的收益有限，因此需要更侧重局部时间模式的建模以提升识别性能。

Method: 设计离散短时序建模框架 DSTS，整合 Class-aware Representation 与 Imbalance-aware Mechanisms，用于捕捉细微的眼动模式以区分 ASD 与 TD。

Result: 在多个眼动数据集上，DSTS 的表现优于传统机器学习方法和更复杂的深度学习模型。

Conclusion: 强调局部时间模式在眼动 ASD 识别中的重要性，所提出的 DSTS 能更高效地捕捉细微特征并对数据不平衡具有鲁棒性。

Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and behavioral patterns. Eye movement data offers a non-invasive diagnostic tool for ASD detection, as it is inherently discrete and exhibits short-term temporal dependencies, reflecting localized gaze focus between fixation points. These characteristics enable the data to provide deeper insights into subtle behavioral markers, distinguishing ASD-related patterns from typical development. Eye movement signals mainly contain short-term and localized dependencies. However, despite the widespread application of stacked attention layers in Transformer-based models for capturing long-range dependencies, our experimental results indicate that this approach yields only limited benefits when applied to eye movement data. This may be because discrete fixation points and short-term dependencies in gaze focus reduce the utility of global attention mechanisms, making them less efficient than architectures focusing on local temporal patterns. To efficiently capture subtle and complex eye movement patterns, distinguishing ASD from typically developing (TD) individuals, a discrete short-term sequential (DSTS) modeling framework is designed with Class-aware Representation and Imbalance-aware Mechanisms. Through extensive experiments on several eye movement datasets, DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models.

</details>


### [126] [A New Family of Poisson Non-negative Matrix Factorization Methods Using the Shifted Log Link](https://arxiv.org/abs/2601.05845)
*Eric Weine,Peter Carbonetto,Rafael A. Irizarry,Matthew Stephens*

Main category: cs.LG

TL;DR: 引入带有平移对数链接的Poisson NMF，利用单参数在加性与乘性假设之间插值；给出最大似然拟合算法及一个大规模稀疏数据的近似方法，并通过实证说明链接函数的选择对结果解释性的显著影响。


<details>
  <summary>Details</summary>
Motivation: 标准Poisson NMF 假设分解以加性方式组合“部件”，在某些场景并不自然。引入带平移项的对数链接以在加性和更偏向乘性的组合之间灵活切换，提升模型的表达力与解释性。

Method: 提出带单一调参的平移对数链接的Poisson NMF 模型，并给出用于最大似然估计的求解算法；同时给出一种能够显著降低大规模稀疏数据计算量的近似方法，使计算量与数据中非零项数量相关。

Result: 在若干真实数据集上进行实验，结果显示链接函数的选择会显著影响分析结果；在某些情形下，使用平移对数链接可提升解释性，相较标准加性链接具有潜在优势。

Conclusion: 扩展了Poisson NMF 的灵活性和可解释性，通过平移对数链接实现对加性与乘性组合假设的连续对比，适用于需要更灵活部件组合关系的计数数据分析。

Abstract: Poisson non-negative matrix factorization (NMF) is a widely used method to find interpretable "parts-based" decompositions of count data. While many variants of Poisson NMF exist, existing methods assume that the "parts" in the decomposition combine additively. This assumption may be natural in some settings, but not in others. Here we introduce Poisson NMF with the shifted-log link function to relax this assumption. The shifted-log link function has a single tuning parameter, and as this parameter varies the model changes from assuming that parts combine additively (i.e., standard Poisson NMF) to assuming that parts combine more multiplicatively. We provide an algorithm to fit this model by maximum likelihood, and also an approximation that substantially reduces computation time for large, sparse datasets (computations scale with the number of non-zero entries in the data matrix). We illustrate these new methods on a variety of real datasets. Our examples show how the choice of link function in Poisson NMF can substantively impact the results, and how in some settings the use of a shifted-log link function may improve interpretability compared with the standard, additive link.

</details>


### [127] [IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck](https://arxiv.org/abs/2601.05870)
*Huilin Deng,Hongchen Luo,Yue Zhu,Long Li,Zhuoyue Chen,Xinghao Zhao,Ming Li,Jihai Zhang,Mengchang Wang,Yang Cao,Yu Kang*

Main category: cs.LG

TL;DR: 提出 IIB-LPO：通过在高熵状态上触发潜在分支、以信息瓶颈约束引导的轨迹筛选与自我奖励来实现对大型语言模型推理的探索，超越现有方法，在四个数学推理基准上达到SOTA，准确率提升至5.3%，多样性提升至7.4%。


<details>
  <summary>Details</summary>
Motivation: RLVR在LLM推理中的探索崩溃问题；全局熵正则易被奖励劫持导致冗长；局部token更新受预训练偏置影响；需要更稳定、信息驱动的探索机制。

Method: 提出 IIB-LPO：在高熵状态对推理轨迹进行潜在分支；以信息瓶颈用于轨迹筛选并作为自我奖励信号；将探索从对 token 分布的统计扰动转向拓扑分支的推理轨迹多样化。

Result: 在四个数学推理基准上实现SOTA，准确率相较前代方法提升可达5.3%，多样性指标提升可达7.4%。

Conclusion: 通过信息瓶颈约束和潜在分支的引入，缓解探索崩溃，提升推理的准确性和多样性，具备较强的泛化潜力。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.

</details>


### [128] [Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates](https://arxiv.org/abs/2601.05909)
*Ayoub Ajarra,Debabrota Basu*

Main category: cs.LG

TL;DR: 在允许更新的对抗性环境下，对偏见进行PAC级别的审计框架：引入统计平等（SP）维度与经验属性优化（EPO）oracle，给出分布无关的审计界限，并扩展至预测误差与稳健风险等目标。


<details>
  <summary>Details</summary>
Motivation: 现实部署中的模型会因环境变化而被自适应地更新，更新可能改变模型类别但保持待审计属性不变，从而使审计在信息复杂性与样本效率上面临挑战。

Method: 提出一个基于经验属性优化（EPO）oracle 的通用PAC审计框架，研究允许的更新的信息复杂性，给出统计平等的分布无关审计界限；引入 SP dimension 作为刻画可接受更新集合复杂度的组合量度；框架可推广至其它审计目标（如预测误差、鲁棒风险）。

Result: 在统计平等场景下，建立了由 SP dimension 驱动的分布无关审计界限；框架通过 EPO oracle 实现对审计属性的高效估计，且具备扩展性，适用于其他审计目标。

Conclusion: 提供了一个能在自适应更新环境中进行偏见审计的通用理论框架，强调更新集合的信息复杂性与样本效率，并指明 SP dimension 的研究与实际估计的后续工作。

Abstract: As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts.
  In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples.
  We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.

</details>


### [129] [Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces](https://arxiv.org/abs/2601.05913)
*Pattarawat Chormai,Ali Hashemi,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: SubDistill is a subtask-focused knowledge distillation method that selectively distills only the relevant components at each layer, yielding better numerical properties. It outperforms existing layer-wise distillation on subtasks (CIFAR-100, ImageNet) for CNNs and Transformers, and AI analyses show the student aligns more closely with the teacher's decision structure.


<details>
  <summary>Details</summary>
Motivation: In practice, only a subset of classes and their intermediate concepts are relevant to a given distillation task. Existing layer-wise distillation methods do not explicitly target these subtasks, potentially hindering efficiency and interpretability.

Method: Introduce SubDistill, a distillation algorithm that identifies and distills only the relevant components of the teacher model at each layer, improving numerical stability and focusing on the subtask. The method likely involves selecting subspaces or activations corresponding to the relevant classes/concepts during layer-wise distillation.

Result: Empirical evaluation on CIFAR-100 and ImageNet using Convolutional and Transformer architectures shows SubDistill surpasses existing layer-wise distillation methods on representative subtasks.

Conclusion: SubDistill effectively adapts knowledge distillation to subtask-specific contexts, offering improved numerical properties and closer alignment of the student’s decision structure to the teacher’s beliefs.

Abstract: Knowledge distillation involves transferring the predictive capabilities of large, high-performing AI models (teachers) to smaller models (students) that can operate in environments with limited computing power. In this paper, we address the scenario in which only a few classes and their associated intermediate concepts are relevant to distill. This scenario is common in practice, yet few existing distillation methods explicitly focus on the relevant subtask. To address this gap, we introduce 'SubDistill', a new distillation algorithm with improved numerical properties that only distills the relevant components of the teacher model at each layer. Experiments on CIFAR-100 and ImageNet with Convolutional and Transformer models demonstrate that SubDistill outperforms existing layer-wise distillation techniques on a representative set of subtasks. Our benchmark evaluations are complemented by Explainable AI analyses showing that our distilled student models more closely match the decision structure of the original teacher model.

</details>


### [130] [Prophet as a Reproducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics](https://arxiv.org/abs/2601.05929)
*Sidney Shapiro,Burhanuddin Panvelwala*

Main category: cs.LG

TL;DR: Prophet 有助于可重复性和可解释性的预测工作流，通过开源、可解释的加法结构和标准化流程，在金融与零售数据集上对比 ARIMA 和随机森林等，提供可重复的预测框架。


<details>
  <summary>Details</summary>
Motivation: 应对预测研究和实践中的可重复性挑战，平衡可解释性、可重复性、以及跨环境鲁棒性。

Method: 以 Prophet 的加法结构、开源实现和标准化工作流为核心，进行基于公开数据集的多模型比较：Prophet、ARIMA（自动/手动/季节性变体）以及随机森林；在受控、完整文档化的实验设计下评估性能与可解释性，并给出 Python 示例以展示工作流整合。

Result: 在比较中，Prophet 展现出可重复性和透明度优势，提供可解释的分解、稳定的工作流以及与分析管道的良好集成；相较于不同 ARIMA 设定和随机森林，Prophet 在可重复性、可审计性方面具有优势，同时保持竞争性预测性能。

Conclusion: Prophet 作为可重复预测的构件，支撑验证、审计和方法论的严谨性；为 Python 研究工作流提供实用参考框架。

Abstract: Reproducibility remains a persistent challenge in forecasting research and practice, particularly in business and financial analytics, where forecasts inform high-stakes decisions. Traditional forecasting methods, while theoretically interpretable, often require extensive manual tuning and are difficult to replicate in proprietary environments. Machine learning approaches offer predictive flexibility but introduce challenges related to interpretability, stochastic training procedures, and cross-environment reproducibility. This paper examines Prophet, an open-source forecasting framework developed by Meta, as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility. Rather than proposing a new algorithm, this study evaluates how Prophet's additive structure, open-source implementation, and standardized workflow contribute to transparent and replicable forecasting practice. Using publicly available financial and retail datasets, we compare the performance and interpretability of Prophet with multiple ARIMA specifications (auto-selected, manually specified, and seasonal variants) and Random Forest, under a controlled and fully documented experimental design. This multi-model comparison provides a robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, we demonstrate how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines. The study positions Prophet within the broader context of reproducible research. It highlights Prophet's role as a methodological building block that supports verification, auditability, and methodological rigor. This work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based research workflows.

</details>


### [131] [LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection](https://arxiv.org/abs/2601.06016)
*Þór Sverrisson,Steinn Guðmundsson*

Main category: cs.LG

TL;DR: LookAroundNet 是一个基于变压器的癫痫发作检测模型，通过更宽的时域窗口来建模发作活动，并纳入段落前后的 EEG 上下文以模仿临床解读的情景。它在多数据集上评估，表现出良好泛化性，并具备适合临床部署的计算成本。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作的动力学在患者、记录条件和临床环境之间高度异质，单一数据集往往难以实现鲁棒检测。因此需要更丰富的时域上下文与更广泛的数据覆盖来提升泛化能力。

Method: 提出 LookAroundNet，一种利用更宽时间窗的变压器模型，融合目标片段前后EEG信号作为上下文信息以辅助诊断；在多数据集（包括常规临床 EEG、长期 ambulatory 记录以及家庭 EEG 数据）上进行训练与评估，并探讨模型集成以提升性能。

Result: 在公开数据集和大型家庭 EEG 集合上均实现强表现，能够对未见的记录条件实现良好泛化，且计算成本适合临床部署。扩展的时域上下文、数据多样性和模型集成被认定为提升性能的关键因素。

Conclusion: 扩展时域上下文、增加数据多样性并采用模型集成，有望推动自动癫痫检测模型向临床可用性迈进。

Abstract: Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions.

</details>
