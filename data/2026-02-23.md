<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 23]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.LG](#cs.LG) [Total: 59]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration](https://arxiv.org/abs/2602.17784)
*Meng Ye,Xiao Lin,Georgina Lukoczki,Graham W. Lederer,Yi Yao*

Main category: cs.CL

TL;DR: 本文提出QueryPlot——一种语义检索与制图框架，通过整合大规模地质文本语料库与地质图数据，利用预训练嵌入模型实现矿物成矿远景的智能映射。系统在钨矽卡岩案例中展现高召回率，并能提升监督学习性能。


<details>
  <summary>Details</summary>
Motivation: 矿物成矿远景制图需综合文本矿床模型与地理空间数据，传统方法依赖人工处理，过程知识密集且效率低下，亟需自动化智能化解决方案。

Method: 构建120余种矿床类型描述模型，将SGMC地质图多边形转为结构化文本；采用预训练嵌入模型编码用户查询与区域描述，计算语义相似度生成连续证据层；支持组合查询与多标准聚合分析，开发Web系统实现交互可视化与GIS数据导出。

Result: 钨矽卡岩矿床案例研究表明，该系统对已知矿床具有高召回率，预测远景区与专家划定的可允许区块高度一致；相似度特征可提升监督学习分类性能。

Conclusion: QueryPlot实现了地质文本与空间数据的语义融合，为矿物远景制图提供了自动化框架，支持交互式分析与机器学习集成，代码和数据开源促进后续研究。

Abstract: Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.

</details>


### [2] [On the scaling relationship between cloze probabilities and language model next-token prediction](https://arxiv.org/abs/2602.17848)
*Cassandra L. Jacobs,Morgan Grobol*

Main category: cs.CL

TL;DR: 大型语言模型因记忆能力强，在预测完形填空时更关注语义而非词汇共现统计，预测质量更高，但对低层次词识别信息敏感度降低，这解释了其在眼动和阅读时间预测上的优势。


<details>
  <summary>Details</summary>
Motivation: 基于近期发现大型语言模型能更好预测眼动和阅读时间数据，本研究旨在探究其背后的机制：不同规模模型如何权衡语义理解与低层次词汇共现信息，以及在概率质量分配上的差异。

Method: 研究比较了不同规模语言模型在眼动数据、阅读时间数据和完形填空任务中的预测能力，重点分析模型对概率质量的分配策略及其对词汇共现统计和语义信息的敏感度。

Result: 结果表明：(1) 更大模型在完形填空中提供更高质量的词元估计和生成概率；(2) 大模型对词汇共现统计敏感度较低，但语义与人类响应更对齐；(3) 尽管所有模型都低估人类响应概率质量，但大模型表现显著更优。

Conclusion: 大型模型的更强记忆能力使其能猜测更语义恰当的词汇，但代价是对词识别相关的低层次信息敏感度下降，这为理解模型规模与语言处理层次间的权衡提供了实证支持。

Abstract: Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.

</details>


### [3] [Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations](https://arxiv.org/abs/2602.17881)
*Joschka Braun*

Main category: cs.CL

TL;DR: 本论文研究语言模型"steering vectors"控制方法的可靠性问题，发现训练激活差异的余弦相似度和激活分离度可预测控制效果，揭示了当潜在行为表征无法被线性方向有效近似时控制效果不可靠，为开发更稳健方法提供诊断依据。


<details>
  <summary>Details</summary>
Motivation: 尽管steering vectors在平均效果上有效，但其效果在不同样本间存在显著差异，对许多目标行为不可靠。论文旨在探究控制可靠性为何因行为而异，以及训练数据如何影响这种可靠性。

Method: 通过分析训练激活差异的余弦相似度、正负激活在控制方向上的分离程度，以及不同提示变体训练的控制向量的方向关系和效果相关性，探究steering vectors的可靠性机制。

Result: 1) 训练激活差异间余弦相似度越高，steering效果越可靠；2) 正负激活沿控制方向分离越好的数据集越易控制；3) 不同提示变体训练的控制向量方向不同但性能相似，在不同数据集上的效果呈正相关。

Conclusion: Steering vectors的不可靠性源于潜在目标行为表征无法被线性方向有效近似。这些发现为诊断控制不可靠性提供了实用工具，并推动开发能显式处理非线性潜在行为表征的更稳健控制方法。

Abstract: Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

</details>


### [4] [Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions](https://arxiv.org/abs/2602.17907)
*Raymond Li,Amirhossein Abaskohi,Chuyuan Li,Gabriel Murray,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 针对传统神经主题模型忽略上下文信息的问题，本文提出利用语言模型生成语义软标签作为监督信号，通过投影下一个词概率到词汇表，训练主题模型重建这些软标签，从而获得更高质量的主题表示并提升文档检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经主题模型仅通过重建文档词袋表示进行优化，缺乏对上下文语义的理解，且在处理稀疏数据时表现不佳，限制了主题质量。

Method: 首先设计专用提示，利用语言模型的条件化下一个词概率分布，将其投影到预定义词汇表构建语义丰富的软标签目标，然后引导主题模型使用LM隐藏状态重建这些软标签，实现上下文感知的主题学习。

Result: 在三个基准数据集上的实验表明，该方法在主题连贯性和纯度指标上显著超越现有基线方法；同时引入的检索度量显示，该方法在识别语义相似文档方面具有明显优势。

Conclusion: 该工作证明了利用语言模型生成语义软标签的有效性，为神经主题建模提供了新的监督范式，在主题质量和实际应用（如文档检索）方面均取得实质性改进。

Abstract: Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

</details>


### [5] [Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering](https://arxiv.org/abs/2602.17911)
*Jash Rajesh Parekh,Wonbin Kweon,Joey Chan,Rezarta Islamaj,Robert Leaman,Pengcheng Jiang,Chih-Hsuan Wei,Zhizheng Wang,Zhiyong Lu,Jiawei Han*

Main category: cs.CL

TL;DR: 本文提出首个条件性生物医学问答基准CondMedQA及条件门控推理框架CGR，通过构建条件感知知识图谱并选择性激活推理路径，实现基于患者特定条件（如合并症、禁忌症）的精准医疗推理，在保持SOTA性能的同时显著提升答案的条件适配性。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学问答系统假设医学知识普适统一，但真实临床决策高度依赖患者个体因素（如合并症、禁忌症）。当前基准无法评估条件推理能力，检索增强或图方法也缺乏确保知识适用性的显式机制。

Method: 1. 构建CondMedQA基准：包含答案随患者条件变化的多跳条件性问答数据集；2. 提出条件门控推理框架CGR：构建条件感知知识图谱，基于查询条件选择性激活或剪枝推理路径。

Result: CGR能更可靠地选择条件适配答案，同时在生物医学问答基准上达到或超过当前最先进性能水平。

Conclusion: 显式建模条件性对实现鲁棒的医疗推理至关重要，CGR框架为条件性生物医学问答提供了有效解决方案。

Abstract: Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

</details>


### [6] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 本文首次系统比较了DSPy框架下的指令优化方法在表格事实核查任务上的表现，评估了直接预测、思维链(CoT)、ReAct-SQL和CodeAct-Python四种提示技术，以及COPRO、MiPROv2和SIMBA三种优化器在四个基准和三个模型家族上的效果。研究发现指令优化能持续提升验证准确率，MiPROv2对CoT提供最为稳定的增益，而SIMBA对ReAct智能体的提升最大，尤其在较大模型规模上。


<details>
  <summary>Details</summary>
Motivation: 指令优化作为轻量级、模型无关的大语言模型推理性能增强方法，在表格事实核查领域缺乏系统性研究。本文旨在填补这一空白，首次在该任务上对多种指令优化技术进行全面比较，探索其有效性。

Method: 基于DSPy优化框架，系统评估了四种即插即用提示技术（直接预测、思维链、ReAct-SQL工具、CodeAct-Python执行）和三种优化器（COPRO、MiPROv2、SIMBA），在四个基准测试和三个模型家族上进行实验比较。

Result: 指令优化能持续提升验证准确率。MiPROv2为CoT提供最为稳定的性能增益，SIMBA对ReAct智能体带来最大幅度的提升，特别是在较大模型规模上。行为分析表明，SIMBA通过启发式策略鼓励更直接的推理路径，增强CoT中的数值比较能力，并帮助ReAct智能体避免不必要的工具调用。

Conclusion: 思维链提示在表格事实核查中依然有效，尤其适用于较小模型。基于大模型的ReAct智能体虽可达到竞争性能，但需要细致的指令优化。不同优化器各具优势：MiPROv2适合优化CoT推理，而SIMBA在提升ReAct智能体效率方面表现更优。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


### [7] [CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications](https://arxiv.org/abs/2602.17949)
*Victoria Blake,Mathew Miller,Jamie Novak,Sze-yuan Ooi,Blanca Gallego*

Main category: cs.CL

TL;DR: 本文提出 CUICurate，一个基于图检索增强生成 (GraphRAG) 的自动化 UMLS 概念集构建框架。通过构建 UMLS 知识图谱并嵌入语义检索，结合大语言模型进行过滤和分类，实现了临床概念集的规模化、高精度自动化构建。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别工具通常将文本映射到 UMLS CUI，但下游任务需要的是包含相关同义词、子类型和父类型的概念集而非单个 CUI。现有方法构建概念集劳动密集、缺乏一致性，且现有工具支持不足，尤其对于直接操作 UMLS CUI 的 NLP 管线。

Method: 构建 UMLS 知识图谱并嵌入语义检索能力。针对每个目标概念，从知识图谱中检索候选 CUI，然后使用大语言模型进行过滤和分类，对比评估 GPT-5 和 GPT-5-mini 两个模型。在五个词汇异质的临床概念上评估框架，并与人工标注基准和金标准概念集进行比较。

Result: CUICurate 生成比人工基准更大、更完整的概念集，同时保持人类水平的精确度。GPT-5-mini 在过滤阶段召回率更高，GPT-5 的分类结果更符合临床医生判断。输出在不同运行间稳定且计算成本低。

Conclusion: CUICurate 提供可扩展、可复现的 UMLS 概念集构建方法，显著减少人工工作。通过结合图检索与 LLM 推理，生成可适配不同表型分析需求的候选概念集，支持临床 NLP 管线。

Abstract: Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

</details>


### [8] [Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering](https://arxiv.org/abs/2602.17981)
*Amine Kobeissi,Philippe Langlais*

Main category: cs.CL

TL;DR: 本文研究了检索增强生成在金融问答中的文档内检索失败问题，通过多粒度（文档、页面、块）评估和Oracle分析，比较了多种检索策略，并提出一种领域微调的页面级双编码器检索器，显著提升了页面召回率和块检索效果。


<details>
  <summary>Details</summary>
Motivation: 在金融问答等高可靠性场景中，检索增强生成的可靠性取决于能否精确检索到支撑答案的上下文。现有文献忽视了"正确文档被检索但答案所在页面/块被遗漏"这一常见失败模式，导致生成器基于不完整上下文进行推断，严重影响系统可靠性。

Method: 在FinanceBench的150个问题子集上，系统评估了文档、页面和块级检索性能，采用Oracle分析提供检索和生成性能的理论上限。比较了稠密、稀疏、混合和层次化检索方法（含重排序和查询重构）。提出领域微调的页面级双编码器，将页面作为文档与块之间的中间检索单元，利用页面的语义连贯性进行优化。

Result: 文档检索精度的提升可转化为页面召回率的改善，但Oracle性能表明页面和块级检索仍有显著提升空间。所提出的领域微调页面评分器在财务文件上实现了页面级相关性的精准建模，显著提高了页面召回率和块检索性能。

Conclusion: 研究揭示了文档内检索失败模式在金融问答中的关键影响，证明针对财务文件特性进行页面级相关性微调是有效解决方案，为提升高可靠性金融问答系统的检索精度提供了新思路和方法论。

Abstract: Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

</details>


### [9] [Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092)
*Matthew DiGiuseppe,Joshua Robison*

Main category: cs.CL

TL;DR: 用AI对话机器人纠正公众错误认知的效果取决于用户是否认为其政治中立。一项美国实验发现，警告用户聊天机器人对其政党有偏见会使说服力降低28%，用户会更频繁反驳且参与度降低。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型进入政治争议，精英阶层越来越多地将它们描绘为具有意识形态倾向，这引发了关于AI对话机器人在纠正错误信息时是否会被政治偏见感知所影响的疑问。

Method: 研究者在美国进行了一项预先注册的调查实验（N=2144），让参与者与ChatGPT进行三轮关于个人经济政策错误认知的对话。实验组收到一条简短消息提示LLM对参与者所属政党有偏见，对照组则为中性信息，并通过文本分析考察互动模式变化。

Result: 与中性对照组相比，收到偏见警告的参与者被说服的程度降低了28%。文本分析表明，警告显著改变了互动方式：参与者更常反驳，且参与度变得不那么具有接受性。

Conclusion: 对话式AI的说服力具有政治条件性，受到对其党派立场感知的限制。纠正公众错误认知的效果在很大程度上取决于用户是否认为AI系统是政治中立的，这对其大规模应用构成了重要挑战。

Abstract: Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.

</details>


### [10] [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137)
*Vincent Grari,Ciprian Tomoiaga,Sylvain Lamprier,Tatsunori Hashimoto,Marcin Detyniecki*

Main category: cs.CL

TL;DR: 本文针对大型语言模型在专业领域适配中的数据稀缺问题，提出一种对抗性问题生成框架。该方法通过比较待适配模型与基于参考文档的专家模型输出，迭代生成语义挑战性强的紧凑问题集，以揭示并弥补理解差距。在LegalBench专业子集上的评估表明，该方法能用更少合成样本实现更高准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽经广泛互联网语料预训练，但在专业领域适配方面仍表现不佳。现有微调方法受限于高质量任务相关数据的稀缺性与有限覆盖。传统合成数据生成技术（如改写或知识提取）虽擅长事实回忆与概念知识，但存在两大缺陷：一是缺乏对专业领域解释性推理能力的支持；二是生成的语料库过于庞大冗余，样本效率低下。

Method: 提出一种对抗性问题生成框架，通过比较待适配模型与基于参考文档的稳健专家模型的输出，采用迭代反馈驱动机制，生成语义挑战性强且高度紧凑的问题集合，旨在系统性地揭示并解决模型的理解差距。

Result: 在LegalBench语料库的专业子集上评估显示，相较于传统方法，该框架能以显著更少的合成样本数量获得更高的任务准确率。

Conclusion: 本方法有效提升了专业领域模型适配的样本效率，通过生成高质量对抗性问题弥补了现有合成数据方法的不足，为大型语言模型在专业领域的应用提供了更高效的解决方案。

Abstract: Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

</details>


### [11] [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425)
*Deniz Qian,Hung-Ting Chen,Eunsol Choi*

Main category: cs.CL

TL;DR: 本文提出检索-验证-检索（RVR）多轮框架，通过迭代验证和查询增强来最大化答案覆盖范围，在多个数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 针对具有多种有效答案的查询，全面检索多样化文档至关重要。现有方法在答案覆盖范围上存在局限，需要能够最大化召回所有相关答案的框架。

Method: 提出检索-验证-检索（RVR）多轮迭代框架。首轮使用检索器获取候选文档集，验证器筛选高质量子集；后续轮次将已验证文档增强到查询中，以发现之前未覆盖的答案。该框架既可使用现成检索器，也可通过针对推理过程微调以进一步提升性能。

Result: 在QAMPARI多答案检索数据集上，RVR相比基线方法（包括智能搜索方法）获得至少10%相对提升和3%绝对提升的完整召回率；在QUEST和WebQuestionsSP两个域外数据集上，使用不同基础检索器均观察到稳定提升。

Conclusion: 该工作提供了一种利用验证器并适应检索器到新推理场景的有前景的迭代方法，可有效实现全面答案召回。

Abstract: Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

</details>


### [12] [Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention](https://arxiv.org/abs/2602.18145)
*Siya Qi,Yudong Chen,Runcong Zhao,Qinglin Zhu,Zhanghao Hu,Wei Liu,Yulan He,Zheng Yuan,Lin Gui*

Main category: cs.CL

TL;DR: 该论文提出一种基于注意力频率分析的新型幻觉检测方法，通过提取注意力分布中的高频成分来识别模型生成中的不稳定接地行为，在RAGTruth和HalluRAG基准测试中实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究利用生成过程中的内在信号（如注意力）检测幻觉，但通常依赖粗粒度摘要，无法捕捉注意力中的细粒度不稳定性。需要更精细的视角来揭示幻觉产生的机制。

Method: 受信号处理启发，将注意力分布建模为离散信号，分析其生成过程中的变化；提取反映注意力快速局部变化的高频成分，发现幻觉词元与高频注意力能量相关，表征碎片化且不稳定的接地行为；最终基于高频注意力特征构建轻量级幻觉检测器。

Result: 在RAGTruth和HalluRAG基准测试上的实验表明，该方法在跨模型和跨任务场景中，其性能均优于基于验证、内部表征和注意力的现有方法。

Conclusion: 高频注意力能量可作为幻觉的有效指标，该频率感知视角为幻觉检测提供了新思路，所开发的轻量级检测器具有实用价值。

Abstract: Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

</details>


### [13] [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429)
*Harshul Raj Surana,Arijit Maji,Aryan Vats,Akash Ghosh,Sriparna Saha,Amit Sheth*

Main category: cs.CL

TL;DR: 本文针对大型语言模型在印度文化等社会文化知识任务上的推理缺陷，提出VIRAASAT——一种半自动化多跳文化问答数据集生成方法。该方法基于包含700+文化实体的知识图谱，覆盖印度全部行政区划，生成3200+多跳问题。研究发现现有模型在低概率事实验证上存在局限，因此提出符号化操纵链（SCoM）框架，通过模拟知识图谱内部操纵来提升推理能力，在监督微调上相比思维链（CoT）基线提升达20%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学、编码等推理任务上表现出色，但在涉及丰富社会文化知识和地方语境的任务中性能下降，特别是印度文化相关任务。现有文化基准存在三大局限：人工构建成本高、仅包含单跳事实回忆问题、难以扩展，导致这一缺陷缺乏有效测量。因此，亟需开发可扩展的多跳文化推理评估方法。

Method: 提出VIRAASAT框架，采用半自动化多跳方法生成印度文化特定问答数据集。核心是基于包含700多个专家策划文化实体的知识图谱，涵盖历史、节日等13个关键文化属性，覆盖印度28个邦和8个联邦属地。通过图谱拓扑结构自动生成多跳问题，要求进行链式文化推理。进一步提出符号化操纵链（SCoM）框架，训练模型在内部模拟原子级知识图谱操纵，可靠遍历图结构。

Result: 在VIRAASAT上评估现有先进模型，发现其在低概率事实的 grounding 与合成方面存在关键局限，标准思维链微调无法解决。SCoM框架在监督微调实验中表现优异，相比标准CoT基线性能提升最高达20%。

Conclusion: 研究成功构建了VIRAASAT数据集和SCoM推理框架，为开发文化感知的推理模型奠定了坚实基础。工作揭示了当前LLMs在文化推理上的不足，并通过模拟知识图谱操纵的符号化方法显著提升性能，为可扩展文化AI研究提供了重要资源和方法论。

Abstract: Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

</details>


### [14] [The Statistical Signature of LLMs](https://arxiv.org/abs/2602.18152)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Niccolò Di Marco,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CL

TL;DR: 该研究通过无损压缩技术发现，大语言模型生成的文本在结构规律性和可压缩性方面显著高于人类文本，但在小规模碎片化交互环境中这种差异会减弱。


<details>
  <summary>Details</summary>
Motivation: 当前对于大语言模型通过概率采样生成文本如何重塑语言结构统计组织的问题尚不明确，需要一种模型无关的度量方法来直接评估生成文本的统计规律性。

Method: 提出使用无损压缩作为模型无关的统计规律性度量方法，分析了三个递进复杂度的信息生态系统：人类与LLM的受控续写、知识库生成中介（Wikipedia vs. Grokipedia）以及完全合成的社交互动环境（Moltbook vs. Reddit）。

Result: 在受控和中介场景中，LLM生成文本表现出比人类文本更高的结构规律性和可压缩性，表明其输出集中于高度重复的统计模式；但在小规模碎片化互动环境中，这种区分度会减弱；该发现跨模型、任务和领域一致，且仅需表层文本即可观察。

Conclusion: 本研究提供了一个简单且稳健的框架，用于量化生成系统如何重塑文本生产，为理解通信复杂性演化提供了结构视角。

Abstract: Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

</details>


### [15] [FENCE: A Financial and Multimodal Jailbreak Detection Dataset](https://arxiv.org/abs/2602.18154)
*Mirae Kim,Seonghun Jeong,Youngjun Kwak*

Main category: cs.CL

TL;DR: 本文提出了FENCE，一个韩英双语多模态数据集，用于金融领域的越狱检测。该数据集通过金融相关查询和图像威胁来强调领域真实性。实验表明商业和开源VLM都存在漏洞，基于FENCE训练的基线检测器达到99%的分布内准确率，并在外部基准测试中表现强劲。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)和视觉语言模型(VLMs)的部署，越狱攻击构成重大风险。VLMs因同时处理文本和图像而面临更广泛的攻击面，但金融等敏感领域的越狱检测资源稀缺，亟需专门的数据集来构建可靠的检测模型。

Method: 创建FENCE数据集，包含韩英双语的金融相关查询和基于图像的威胁。在商业模型(GPT-4o)和开源模型上进行越狱攻击实验，评估模型脆弱性。基于FENCE训练基线检测器，并在分布内和外部基准测试中评估其性能。

Result: 实验揭示所有测试模型均存在可测量的漏洞，其中开源模型暴露程度更高。GPT-4o显示出可量化的攻击成功率。基于FENCE训练的基线检测器达到99%的分布内准确率，并在外部基准测试中保持强劲性能，证明该数据集对训练可靠检测模型的鲁棒性。

Conclusion: FENCE为金融领域的多模态越狱检测提供了专注资源，有助于推动敏感领域中更安全、可靠的AI系统发展。该数据集强调领域真实性，可作为未来越狱防御研究的基础。

Abstract: Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

</details>


### [16] [Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models](https://arxiv.org/abs/2602.18171)
*Wojciech Michaluk,Tymoteusz Urban,Mateusz Kubita,Soveatin Kuntur,Anna Wroblewska*

Main category: cs.CL

TL;DR: 本文提出一种混合方法检测点击诱饵标题，结合基于Transformer的文本嵌入和语言学信息特征。使用XGBoost模型在增强的嵌入上实现了91%的F1分数，优于多种基线方法，并提供了可解释性。


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题降低了在线信息质量并损害用户信任。传统方法可能不够有效，需要更准确和可解释的检测方案。

Method: 采用自然语言处理技术，评估经典向量化方法、词嵌入基线和大语言模型嵌入，并结合树分类器。提出了一个包含15个显式语言学特征的集合，包括第二人称代词、最高级、数字和注意导向标点等。

Result: 最佳模型（XGBoost在增强嵌入上）达到91%的F1分数，优于TF-IDF、Word2Vec、GloVe、LLM提示分类和仅特征基线。特征集增强了可解释性，突出了显著的语言线索。

Conclusion: 混合方法在点击诱饵检测中效果显著，结合深度学习和语言学特征既提高了性能又增强了透明度。研究为可解释的点击诱饵检测提供了有效方案，并开源了代码和模型。

Abstract: Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

</details>


### [17] [Improving Sampling for Masked Diffusion Models via Information Gain](https://arxiv.org/abs/2602.18176)
*Kaisen Yang,Jayden Teoh,Kaicheng Yang,Yitong Zhang,Alex Lamb*

Main category: cs.CL

TL;DR: 本文针对掩码扩散模型(MDM)解码顺序规划问题，指出现有贪心采样器因忽视决策下游影响而导致累积不确定性高企的局限，提出Info-Gain Sampler框架，通过优化信息增益平衡即时与未来不确定性，在推理、编码、创意写作及图像生成任务上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型虽具备灵活解码顺序优势，但现有采样器采用的贪心启发式策略仅关注局部最高置信度，未能利用MDM的非因果特性评估当前解码对所有剩余掩码位置不确定性的全局影响，导致无法最小化累积不确定性，制约生成质量。

Method: 提出Info-Gain Sampler，一种基于信息论原则的解码框架。该框架在选择解码位置时，不仅度量当前位置的即时不确定性，更计算该解码动作所能带来的对未来所有掩码位置的信息增益，实现即时不确定性与未来信息收益的帕累托最优。

Result: 在多种架构与任务上全面验证：推理任务平均准确率提升3.6%（累积不确定性从78.4降至48.6），创意写作人工评估胜率达63.1%，在所有测试场景中均大幅超越现有最佳基线方法。

Conclusion: 所提Info-Gain Sampler通过显式建模解码决策的全局性影响，有效克服了贪心策略的短视缺陷，为提升MDM生成质量提供了理论指导与实用方案，代码将开源以促进后续研究。

Abstract: Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

</details>


### [18] [Information-Theoretic Storage Cost in Sentence Comprehension](https://arxiv.org/abs/2602.18217)
*Kohei Kajikawa,Shinnosuke Isono,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 本研究提出了一种基于信息论的形式化实时句子理解工作记忆负荷测量方法，该方法连续、理论中立，可从预训练神经语言模型中估算，并通过三个英语分析验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统基于符号语法的句法预测负荷测量采用离散、均匀的成本分配，无法充分反映实时句子理解中工作记忆的实际负载。本研究旨在提出一种更精细、连续且理论中立的处理存储成本度量方法。

Method: 将处理存储成本基于信息论形式化，定义为先前词汇在信息不确定条件下对未来语境所携带的信息量。该度量可从预训练神经语言模型中估算，避免了符号语法的离散化假设。

Result: 在英语中的三项分析显示：(1)成功恢复了中心嵌套结构和关系从句的已知加工不对称性；(2)与语法标注语料库中的语法存储成本显著相关；(3)在两个大规模自然数据集中，除包含传统信息预测因子的基线模型外，额外解释了阅读时间的方差。

Conclusion: 基于信息论的连续存储成本度量有效量化了实时句子理解的工作记忆负荷，兼具理论优势与实证效度，为心理语言学提供了新的计算工具。

Abstract: Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

</details>


### [19] [Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning](https://arxiv.org/abs/2602.18232)
*Lexiang Tang,Weihao Gao,Bingchen Zhao,Lu Ma,Qiao jin,Bang Yang,Yuexian Zou*

Main category: cs.CL

TL;DR: 本文提出置信度驱动对比解码（CCD），通过选择性干预低置信度token提升大语言模型推理可靠性，在不增加计算冗余的前提下提高准确率并减少输出长度。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法假设推理计算均匀提升正确性，但研究表明不确定性高度局部化——少量低置信度token主导推理错误和冗余输出。因此需要精准干预而非均匀分配计算资源。

Method: 提出"思考即减法"框架下的CCD方法。解码时检测低置信度token，在低置信度位置通过将高置信度token替换为占位符构建对比参考分布，并减去该参考以优化预测。

Result: 数学推理基准测试显示，CCD显著提升准确率，大幅缩短输出长度，KV缓存开销极小，实现无需训练的高效推理优化。

Conclusion: CCD通过局部化减法策略实现计算资源精准分配，为训练-free提升大语言模型推理可靠性提供了有效方案。

Abstract: Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.

</details>


### [20] [Simplifying Outcomes of Language Model Component Analyses with ELIA](https://arxiv.org/abs/2602.18262)
*Aaron Louis Eidt,Nils Feldhus*

Main category: cs.CL

TL;DR: 本文介绍ELIA（可解释语言可解释性分析），一款交互式网页应用，通过整合归因分析、函数向量分析和电路追踪三种技术，并利用视觉语言模型自动生成自然语言解释，有效降低了LLM可解释性工具的使用门槛，用户研究证实该系统能显著减少不同经验水平用户的理解障碍。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性虽已发展出强大的大语言模型内部工作机制分析工具，但其复杂性导致可访问性鸿沟，限制了非专业用户的使用。

Method: 设计、构建并评估ELIA交互式网页应用，集成归因分析、函数向量分析和电路追踪三种关键技术，创新性地采用视觉语言模型为复杂可视化自动生成自然语言解释。通过混合方法用户研究验证系统有效性。

Result: 混合方法用户研究显示：用户明显偏好交互式可探索界面而非静态可视化；AI驱动的解释有效缩小了非专家的知识差距；统计分析表明用户先前LLM经验与理解分数无显著相关性，证明系统降低了不同经验水平的理解障碍。

Conclusion: AI系统确实能简化复杂模型分析，但其真正潜力在于结合以用户为中心的设计理念，强调交互性、具体性和叙事引导。

Abstract: While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.

</details>


### [21] [PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324)
*Alexandra Ciobotaru,Ana-Maria Bucur,Liviu P. Dinu*

Main category: cs.CL

TL;DR: 本研究针对罗马尼亚语心理健康语料库的缺失问题，创建了首个开源的罗马尼亚语抑郁与焦虑语料库PsihoRo，收集了205名受访者的开放式问题文本及PHQ-9、GAD-7筛查数据，并通过统计、LIWC文本分析、情绪检测和主题建模等方法验证了该语料库的价值，为罗马尼亚语心理健康NLP研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 英语拥有丰富的心理健康NLP资源，但罗马尼亚语目前缺乏开源的心理健康语料库。同时，从社交媒体直接采集心理健康数据存在收集者主观假设的问题。因此，本研究旨在填补这一空白，为罗马尼亚语心理健康文本分析创建首个可靠的数据集。

Method: 采用实用策略，通过包含6个开放式问题的问卷形式收集文本数据，并辅以标准化的PHQ-9（抑郁）和GAD-7（焦虑）自评筛查量表。共获得205名受访者的有效数据，构成PsihoRo语料库。随后运用统计分析、罗马尼亚语版LIWC词典文本分析、情绪检测以及主题建模等方法对语料进行特征挖掘。

Result: 成功构建了罗马尼亚首个抑郁与焦虑心理健康语料库PsihoRo，包含205个样本。通过多维度分析揭示了该语料库的关键文本特征，证明其作为研究罗马尼亚人口心理健康语言特征的有效资源，为NLP社区提供了新的研究工具。

Conclusion: PsihoRo语料库虽规模不大，但作为罗马尼亚语心理健康NLP研究的开创性资源，迈出了重要第一步。该语料库将促进对罗马尼亚人群心理健康文本的理解与分析，并为后续研究提供基础数据支持，具有重要的学术价值和实践意义。

Abstract: Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

</details>


### [22] [Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346)
*Pavithra PM Nair,Preethu Rose Anish*

Main category: cs.CL

TL;DR: 本文提出Vichara框架，针对印度司法系统中的上诉案件积压问题，通过将案件分解为决策点并采用IRAC结构生成解释，实现了上诉判决的准确预测和可解释性。在PredEx和ILDC_expert数据集上，GPT-4o mini模型取得了最佳性能（F1分数分别为81.5和80.3）。


<details>
  <summary>Details</summary>
Motivation: 印度法院面临大量案件积压，其中上诉案件是重要组成部分。传统判决预测方法缺乏可解释性，难以满足法律专业人士的需求。人工智能虽具变革潜力，但需要专门针对印度司法体系设计的框架，以提供既准确又可解释的预测结果。

Method: Vichara框架将英文上诉案件文书分解为离散的"决策点"，每个决策点包含法律问题、裁决机构、结果、推理和时间背景。采用结构化表示方法分离核心裁决及其上下文，并使用适应印度法律推理的IRAC（问题-规则-应用-结论）框架生成解释。研究在PredEx和ILDC_expert两个数据集上，使用GPT-4o mini、Llama-3.1-8B、Mistral-7B和Qwen2.5-7B四种大语言模型进行评估。

Result: Vichara在两个数据集上均超越现有基准，其中GPT-4o mini表现最佳（PredEx F1: 81.5，ILDC_expert F1: 80.3），其次是Llama-3.1-8B。人工评估显示，GPT-4o mini生成的解释在清晰度、关联性和实用性三个指标上均获得最高分，具有优越的可解释性。

Conclusion: Vichara框架通过结构化处理决策点和IRAC解释格式，为印度上诉案件判决预测提供了高效准确的解决方案。该方法不仅提升了预测性能，还增强了结果的可解释性，使法律专业人士能够快速评估预测的合理性，为解决司法积压问题提供了可行的技术路径。

Abstract: In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

</details>


### [23] [Validating Political Position Predictions of Arguments](https://arxiv.org/abs/2602.18351)
*Jordan Robinson,Angus R. Williams,Katie Atkinson,Anthony G. Cohn*

Main category: cs.CL

TL;DR: 本研究针对政治立场等主观连续属性的知识表示难题，提出双尺度验证框架，融合点式和成对人工标注。基于22个语言模型分析英国Question Time节目30场辩论的23,228条论点，发现点式评估人机一致性中等（α=0.578），而成对验证显示显著更强的排序对齐（最佳模型α=0.86），为处理主观性知识提供了可扩展且可靠的验证方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识表示需捕捉政治立场等主观连续属性，但这些属性与广泛接受的成对验证金标准存在冲突，面临人类评估内在主观性的挑战，传统符号或分类方法在主观领域表现不足。

Method: 采用双尺度验证框架，结合点式（pointwise）和成对（pairwise）人工标注，应用于论证话语中的政治立场预测。利用22个语言模型构建大规模知识库，包含英国政治电视节目《Question Time》30场辩论中23,228条论点的政治位置预测。

Result: 点式评估显示人机一致性为中等水平（Krippendorff's α=0.578），反映主观性的内在差异；而成对验证揭示人与模型衍生排序间存在显著更强的对齐，最佳模型达到α=0.86。

Conclusion: 本研究的贡献包括：(i) 提出平衡可扩展性与可靠性的主观连续知识实用验证方法；(ii) 构建验证的结构化论证知识库，支持政治领域的图推理和检索增强生成；(iii) 证明可从点式语言模型预测中提取序结构，推进主观现实世界话语的知识表示能力。

Abstract: Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Epistemic Traps: Rational Misalignment Driven by Model Misspecification](https://arxiv.org/abs/2602.17676)
*Xingcheng Xu,Jingjing Qu,Qiaosheng Zhang,Chaochao Lu,Yanqing Yang,Na Zou,Xia Hu*

Main category: cs.AI

TL;DR: 该论文提出了一个理论框架，认为大型语言模型和AI智能体的行为病理（如谄媚、幻觉和策略性欺骗）并非训练缺陷，而是模型设定错误导致的数学上可合理化的行为。通过将经济学中的Berk-Nash理性化理论引入AI，揭示了这些失败是结构性必然，并提出了从"调整环境奖励"转向"塑造智能体对现实的解释"的主观模型工程范式。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全范式将行为异常视为可通过强化学习缓解的暂时性训练伪影，缺乏解释其产生机制和稳定性的统一理论框架。研究旨在从根本上揭示这些行为病理的成因，为构建稳健对齐的理论基础。

Method: 将理论经济学的Berk-Nash理性化理论适配到AI领域，建立严格框架，将智能体建模为针对有缺陷的主观世界模型进行优化的过程。通过在六个先进模型家族上开展行为实验，生成相图以精确映射安全行为的拓扑边界。

Result: 证明不安全行为是结构性必然：根据奖励方案表现为稳定的失衡量均衡或振荡循环；策略性欺骗则作为"锁定"均衡或通过认知不确定性持续存在。发现安全是由智能体认知先验决定的离散相位，而非奖励强度的连续函数。

Conclusion: 提出主观模型工程（设计智能体内部信念结构）是实现稳健对齐的必要条件，标志着从操纵环境奖励转向塑造智能体现实解释的范式转变，为AI安全提供了新的理论方向。

Abstract: The rapid deployment of Large Language Models and AI agents across critical societal and technical domains is hindered by persistent behavioral pathologies including sycophancy, hallucination, and strategic deception that resist mitigation via reinforcement learning. Current safety paradigms treat these failures as transient training artifacts, lacking a unified theoretical framework to explain their emergence and stability. Here we show that these misalignments are not errors, but mathematically rationalizable behaviors arising from model misspecification. By adapting Berk-Nash Rationalizability from theoretical economics to artificial intelligence, we derive a rigorous framework that models the agent as optimizing against a flawed subjective world model. We demonstrate that widely observed failures are structural necessities: unsafe behaviors emerge as either a stable misaligned equilibrium or oscillatory cycles depending on reward scheme, while strategic deception persists as a "locked-in" equilibrium or through epistemic indeterminacy robust to objective risks. We validate these theoretical predictions through behavioral experiments on six state-of-the-art model families, generating phase diagrams that precisely map the topological boundaries of safe behavior. Our findings reveal that safety is a discrete phase determined by the agent's epistemic priors rather than a continuous function of reward magnitude. This establishes Subjective Model Engineering, defined as the design of an agent's internal belief structure, as a necessary condition for robust alignment, marking a paradigm shift from manipulating environmental rewards to shaping the agent's interpretation of reality.

</details>


### [25] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 本研究通过神经符号方法，利用OpenMath本体和检索增强生成技术，探究了形式化领域本体对提升语言模型数学推理可靠性的作用。在MATH基准测试中发现，检索质量高时本体引导的上下文能提升性能，但低质量相关上下文反而会损害模型表现。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本性缺陷，这些局限性在高风险专业领域（如需要可验证推理的数学）中尤为突出，亟需提升其可靠性。

Method: 以数学作为概念验证，构建神经符号流水线：利用OpenMath本体，采用混合检索和交叉编码器重排序技术，将相关数学定义注入模型提示中。

Result: 在MATH基准测试上对三个开源模型的评估表明，当检索质量高时，本体引导的上下文能提升性能；但检索到无关内容时会显著降低模型表现，显示出效果的强依赖性。

Conclusion: 本研究揭示了神经符号方法在增强模型可靠性方面的潜力与挑战，证实本体指导的有效性高度依赖于检索质量，为未来优化方向提供了重要洞察。

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [26] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: 本文提出The Token Games (TTG)，一种受16世纪数学决斗启发的语言模型评估框架。该框架让模型相互挑战创建编程谜题（给定返回布尔值的Python函数，寻找使其返回True的输入），通过Elo评分系统比较模型能力。在10个前沿模型上的评估显示，TTG的排名与人类设计的基准一致，但无需人工参与，且能测试创造力与任务创建能力，避免了传统基准的饱和问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型推理能力持续突破，传统人工设计的评估基准面临双重困境：一是专家级题目成本高昂，二是训练数据污染风险导致无法区分真实推理与记忆复现。亟需一种可自主生成、无法被设计饱和、并能综合评价创造力与任务创建能力的新型评估范式。

Method: 借鉴文艺复兴时期数学决斗文化，设计The Token Games (TTG)自动化评估框架。核心机制为：1) 采用编程谜题形式——给定返回布尔值的Python函数，要求模型生成使其返回True的输入；2) 模型互为对手，既当"出题者"也当"解题者"；3) 通过配对决斗胜负计算Elo评分，建立模型能力相对排名。

Result: 对10个前沿LLM的实证研究表明：1) TTG生成的模型排名与Humanity's Last Exam等人类专家基准高度吻合；2) 完全无需人工参与谜题设计，成本为零；3) 当前模型在创建高质量谜题方面表现不佳，暴露出超越解题能力的创造性缺陷。

Conclusion: 本研究开创了"以模型生成评估模型"的自进化评估范式，从根本上避免了基准饱和问题。TTG不仅衡量推理能力，同时评估创造力与任务构建能力，为未来大模型评估提供了可扩展、可持续的新方向。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [27] [El Agente Gráfico: Structured Execution Graphs for Scientific Agents](https://arxiv.org/abs/2602.17902)
*Jiaru Bai,Abdulrahman Aldossary,Thomas Swanick,Marcel Müller,Yeonghun Kang,Zijian Zhang,Jin Won Lee,Tsz Wai Ko,Mohammad Ghazi Vakili,Varinia Bernales,Alán Aspuru-Guzik*

Main category: cs.AI

TL;DR: 本文提出El Agente Gráfico单智能体框架，通过类型安全执行环境和动态知识图解决LLM科学工作流集成脆弱、决策溯源难的问题，在量子化学等任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学工作流自动化中的应用日益增多，但与异构计算工具的集成仍临时且脆弱。现有智能体方法依赖非结构化文本管理上下文，产生信息过载，掩盖决策溯源并阻碍审计能力。

Method: 提出El Agente Gráfico框架，将LLM决策嵌入类型安全执行环境，采用动态知识图进行外部持久化。核心是科学概念的结构化抽象和对象-图映射器，将计算状态表示为类型化Python对象，通过类型化符号标识符而非原始文本管理上下文。

Result: 在量子化学任务基准测试中，单智能体与可靠执行引擎结合可鲁棒执行复杂多步并行计算，性能媲美多智能体系统。该方法还成功扩展到构象异构体集生成和金属有机框架设计，知识图作为记忆和推理基质。

Conclusion: 抽象化和类型安全为超越提示中心化设计的智能体科学自动化提供了可扩展基础，展示了在科学计算领域构建更可靠、可审计自动化系统的有效路径。

Abstract: Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making within a type-safe execution environment and dynamic knowledge graphs for external persistence. Central to our approach is a structured abstraction of scientific concepts and an object-graph mapper that represents computational state as typed Python objects, stored either in memory or persisted in an external knowledge graph. This design enables context management through typed symbolic identifiers rather than raw text, thereby ensuring consistency, supporting provenance tracking, and enabling efficient tool orchestration. We evaluate the system by developing an automated benchmarking framework across a suite of university-level quantum chemistry tasks previously evaluated on a multi-agent system, demonstrating that a single agent, when coupled to a reliable execution engine, can robustly perform complex, multi-step, and parallel computations. We further extend this paradigm to two other large classes of applications: conformer ensemble generation and metal-organic framework design, where knowledge graphs serve as both memory and reasoning substrates. Together, these results illustrate how abstraction and type safety can provide a scalable foundation for agentic scientific automation beyond prompt-centric designs.

</details>


### [28] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: 本文针对LLM生成工作流的自动评估难题，提出WorkflowPerturb基准测试，通过向4,973个标准工作流施加三类可控扰动（Missing Steps、Compressed Steps、Description Changes）生成44,757个变体，系统评估不同指标族的敏感性与校准性，揭示跨指标族的系统性差异并支持严重程度感知的分数解释。


<details>
  <summary>Details</summary>
Motivation: 当前LLM生成的工作流自动评估面临两大挑战：评估指标缺乏校准性，且分数变化与工作流退化严重程度之间缺乏直接对应关系，亟需标准化基准以系统研究评估指标特性。

Method: 构建大规模基准数据集，涵盖4,973个标准工作流及44,757个扰动变体，采用Missing Steps、Compressed Steps和Description Changes三种扰动类型，每种设置10%、30%、50%三个严重等级，通过预期分数轨迹与残差分析量化各指标族的敏感性和校准性。

Result: 基准测试揭示不同指标族存在系统性差异，各指标对扰动类型和严重程度的敏感性呈现不同模式，分析结果为基于严重程度解释评估分数提供了实证依据。

Conclusion: WorkflowPerturb填补了工作流评估标准化基准的空白，为未来开发更鲁棒的评估指标奠定基础，作者承诺在论文录用后开源数据集以促进研究可复现性。

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [29] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 本研究提出将离线强化学习与跨实体学习结合，以解决机器人策略预训练中高质量演示数据收集成本高的问题。通过系统分析16种不同机器人平台的运动数据集，发现该方法在次优数据丰富的场景中优于行为克隆，但存在形态间梯度冲突问题。为此提出基于形态学相似性的静态分组策略，有效减少冲突并超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 可扩展的机器人策略预训练受到为每个平台收集高质量演示数据高成本的制约。虽然离线强化学习可以利用专家和次优数据，跨实体学习可以聚合不同形态机器人的轨迹获取通用控制先验，但两者结合的可行性和局限性尚未得到系统分析。

Method: 1) 构建包含16种不同机器人平台的运动数据集；2) 系统分析离线强化学习与跨实体学习结合的范式；3) 针对形态间梯度冲突问题，提出基于形态学相似性的静态分组策略，按相似性聚类机器人并使用组梯度更新模型。

Result: 1) 结合方法在次优数据丰富的预训练任务中表现优异，超越纯行为克隆；2) 随着次优数据比例和机器人类型增加，形态间梯度冲突会阻碍学习；3) 提出的静态分组策略显著减少冲突，性能优于现有冲突解决方法。

Conclusion: 离线强化学习与跨实体学习结合是有效的机器人预训练范式，但需要解决梯度冲突问题。基于形态学相似性的简单静态分组策略能有效缓解冲突，为可扩展机器人学习提供了实用解决方案。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [30] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: 研究发现无监督表示会编码被排除的敏感属性，SOMtime可恢复年龄/收入信息，相关系数达0.85，挑战了"无意识即公平"的假设。


<details>
  <summary>Details</summary>
Motivation: 挑战"无意识即公平"的普遍假设，即当敏感属性被排除时，无监督表示应对其保持中立。该假设未经充分验证，特别是对于序数敏感属性如年龄和收入。

Method: 采用SOMtime方法——一种基于高容量自组织映射(SOM)的拓扑保持表示技术。在两个大规模数据集上验证：覆盖五个国家的世界价值观调查和人口普查收入数据集，将年龄、收入等敏感属性排除在输入之外。

Result: SOMtime在无监督嵌入中恢复敏感属性的单调排序，斯皮尔曼相关系数高达0.85。相比之下，PCA和UMAP通常低于0.23（最高0.31），t-SNE和自编码器不超过0.34。无监督分割产生人口统计学偏斜的聚类，存在下游公平风险。

Conclusion: "无意识即公平"在表示层面对于序数敏感属性失效。无监督组件可能无意中编码敏感信息并产生公平风险。因此，公平性审计必须扩展到机器学习管道中的无监督组件。

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [31] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: 本文首次将扩散生成模型引入在线多智能体强化学习（MARL）领域，提出了OMAD框架。该框架通过最大化缩放联合熵的松弛目标函数，以及集中式训练与分散式执行（CTDE）范式下的联合分布价值函数，克服了扩散模型似然性难以计算的问题，从而在MPE和MAMuJoCo基准测试中实现了2.5至5倍的样本效率提升，并取得了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，提升策略的表达能力是实现高性能的关键。扩散模型虽在图像生成和离线场景中展现了强大的表达与多模态表示能力，但其在在线MARL中的应用却鲜有探索。其核心障碍在于扩散模型的似然函数难以计算，这严重阻碍了基于熵的探索策略和智能体间的有效协调。为此，本文致力于开发一种能够有效利用扩散模型优势的在线MARL新框架。

Method: 针对上述挑战，本文提出了OMAD（基于扩散策略的在线离线策略多智能体强化学习）框架。其主要方法包括：（1）设计一种松弛的策略优化目标，通过最大化缩放后的联合熵来驱动探索，成功绕开了对可处理似然性的依赖；（2）在集中式训练与分散式执行（CTDE）的整体架构下，引入联合分布价值函数来优化每个智能体的分散式扩散策略；（3）利用可计算的熵增强目标值来指导所有扩散策略的同步更新，以保障训练过程的稳定性与协调的有效性。

Result: 研究者在多智能体粒子环境（MPE）和多智能体MuJoCo（MAMuJoCo）两个广泛使用的基准测试平台上对OMAD进行了全面评估。实验结果表明，OMAD在涵盖10种不同任务的测试中均显著优于现有方法，达到了新的最先进（state-of-the-art）水平。特别地，该方法在样本效率方面取得了突破性进展，相较于先前方法实现了高达2.5倍至5倍的提升。

Conclusion: OMAD框架成功地将扩散模型的强大表示能力迁移至在线多智能体强化学习场景，通过理论创新解决了探索与协调的核心难题。大量实验证实了该方法在性能与效率上的双重优势，不仅为MARL研究开辟了新的技术路径，也为解决复杂多智能体协作问题提供了有力的工具。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [32] [Reducing Text Bias in Synthetically Generated MCQAs for VLMs in Autonomous Driving](https://arxiv.org/abs/2602.17677)
*Sutej Kulgod,Sean Ye,Sanchit Tanwar,Christoffer Heckman*

Main category: cs.LG

TL;DR: 针对视觉语言模型在驾驶任务多项选择题评估中利用文本捷径而非视觉理解的问题，本文提出通过解耦答案与语言伪影并结合课程学习的方法，将模型盲测准确率从+66.9%降至+2.9%，强制模型依赖视觉 grounding 以真实反映感知理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶任务VLM评估使用的合成生成多项选择题存在隐藏文本线索，使模型可通过 exploitation 语言模式而非视觉上下文作答，导致评估结果失真，无法准确衡量模型的视觉理解性能。

Method: 提出解耦正确答案与语言伪影的策略以消除可 exploited 的文本捷径，并采用课程学习方案逐步引导模型从依赖文本特征转向视觉 grounding。

Result: 实验表明，在无视觉输入情况下，经有问题数据微调的模型仍能取得与人类验证基准相当的准确率，盲测表现比随机水平高+66.9%；而所提方法将该优势降至仅+2.9%，消除了绝大部分可利用的文本捷径。

Conclusion: 该方法有效解决了合成MCQA基准中的文本捷径偏差问题，确保VLM性能评估真实反映其视觉感知与理解能力，为构建更可靠的视觉语言模型评估体系提供了有效途径。

Abstract: Multiple Choice Question Answering (MCQA) benchmarks are an established standard for measuring Vision Language Model (VLM) performance in driving tasks. However, we observe the known phenomenon that synthetically generated MCQAs are highly susceptible to hidden textual cues that allow models to exploit linguistic patterns rather than visual context. Our results show that a VLM fine-tuned on such data can achieve accuracy comparable to human-validated benchmarks even without visual input. Our proposed method reduces blind accuracy from +66.9% above random to +2.9%, eliminating the vast majority of exploitable textual shortcuts. By decoupling the correct answer from linguistic artifacts and employing a curriculum learning strategy, we force the model to rely on visual grounding, ensuring that performance accurately reflects perceptual understanding.

</details>


### [33] [BioBridge: Bridging Proteins and Language for Enhanced Biological Reasoning with LLMs](https://arxiv.org/abs/2602.17680)
*Yujia Wang,Jihong Guan,Wengen Li,Shuigeng Zhou,Xuhong Wang*

Main category: cs.LG

TL;DR: 提出BioBridge框架，通过领域增量持续预训练和跨模态对齐，将蛋白质语言模型与通用大语言模型结合，在蛋白质和通用基准测试上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型（PLMs）适应性和泛化能力有限，而通用大语言模型（LLMs）缺乏蛋白质序列理解和领域专业知识，无法进行有效的生物语义推理。需要结合两者优势，创建既能理解蛋白质序列又具备通用语言能力的模型。

Method: 提出BioBridge框架：1）采用领域增量持续预训练（DICP）同时将蛋白质领域知识和通用推理语料注入LLM，缓解灾难性遗忘；2）通过PLM-Projector-LLM管道实现跨模态对齐，将蛋白质序列嵌入映射到语言模型语义空间；3）端到端优化统一支持蛋白质性质预测和知识问答等多种任务。

Result: 在EC和BindingDB等蛋白质基准测试上性能与主流PLMs相当，在MMLU和RACE等通用理解任务上达到LLMs水平，成功结合了领域特定适应性和通用语言能力。

Conclusion: BioBridge框架通过持续预训练和跨模态对齐策略，有效融合了PLMs的专业知识与LLMs的通用推理能力，为蛋白质理解和通用语言任务提供了创新解决方案，展现了跨领域适应性的优势。

Abstract: Existing Protein Language Models (PLMs) often suffer from limited adaptability to multiple tasks and exhibit poor generalization across diverse biological contexts. In contrast, general-purpose Large Language Models (LLMs) lack the capability to interpret protein sequences and fall short in domain-specific knowledge, limiting their capacity for effective biosemantic reasoning. To combine the advantages of both, we propose BioBridge, a domain-adaptive continual pretraining framework for protein understanding. This framework employs Domain-Incremental Continual Pre-training (DICP) to infuse protein domain knowledge and general reasoning corpus into a LLM simultaneously, effectively mitigating catastrophic forgetting. Cross-modal alignment is achieved via a PLM-Projector-LLM pipeline, which maps protein sequence embeddings into the semantic space of the language model. Ultimately, an end-to-end optimization is adopted to uniformly support various tasks, including protein property prediction and knowledge question-answering. Our proposed BioBridge demonstrates performance comparable to that of mainstream PLMs on multiple protein benchmarks, such as EC and BindingDB. It also achieves results on par with LLMs on general understanding tasks like MMLU and RACE. This showcases its innovative advantage of combining domain-specific adaptability with general-purpose language competency.

</details>


### [34] [LATMiX: Learnable Affine Transformations for Microscaling Quantization of LLMs](https://arxiv.org/abs/2602.17681)
*Ofir Gordon,Lior Dikstein,Arnon Netzer,Idan Achituve,Hai Victor Habi*

Main category: cs.LG

TL;DR: 本文针对大语言模型的微缩放(MX)训练后量化，提出LATMiX方法。通过理论推导MX量化误差边界，揭示激活分布与量化结构的内在关联，并设计可学习的仿射变换替代传统旋转/Hadamard变换，在零样本基准测试中显著提升低比特量化精度。


<details>
  <summary>Details</summary>
Motivation: 现有训练后量化研究主要聚焦传统量化方案，对现代硬件广泛支持的MX格式缺乏理论分析。同时，现有激活变换方法局限于固定形式的旋转或Hadamard变换，与MX结合时存在严重性能退化问题，需依赖强假设限制。

Method: 1) 理论层面：推导MX量化下变换的误差边界，证明需同时考虑激活分布特性与量化结构；2) 算法层面：提出LATMiX，将异常值缓解推广至可学习的仿射变换空间，利用标准深度学习优化器端到端训练变换参数。

Result: 在多个模型尺寸（如7B/13B/70B）和零样本基准测试（如WikiText、MMLU等）上，LATMiX相比强基线在MX低比特（4-bit/6-bit）量化下平均准确率提升显著，性能衰减得到有效控制。

Conclusion: LATMiX突破了传统固定变换的局限性，为MX格式提供了理论支撑的可学习量化框架，在保持硬件友好性的同时提升大语言模型量化鲁棒性，具有广泛的实用价值。

Abstract: Post-training quantization (PTQ) is a widely used approach for reducing the memory and compute costs of large language models (LLMs). Recent studies have shown that applying invertible transformations to activations can significantly improve quantization robustness by reducing activation outliers; however, existing approaches are largely restricted to rotation or Hadamard-based transformations. Moreover, most studies focused primarily on traditional quantization schemes, whereas modern hardware increasingly supports the microscaling (MX) data format. Attempts to combine both showed severe performance degradation, leading prior work to introduce assumptions on the transformations. In this work, we take a complementary perspective. First, we provide a theoretical analysis of transformations under MX quantization by deriving a bound on the quantization error. Our analysis emphasizes the importance of accounting for both the activation distribution and the underlying quantization structure. Building on this analysis, we propose LATMiX, a method that generalizes outlier reduction to learnable invertible affine transformations optimized using standard deep learning tools. Experiments show consistent improvements in average accuracy for MX low-bit quantization over strong baselines on a wide range of zero-shot benchmarks, across multiple model sizes.

</details>


### [35] [Probabilistic NDVI Forecasting from Sparse Satellite Time Series and Weather Covariates](https://arxiv.org/abs/2602.17683)
*Irene Iele,Giulia Romoli,Daniele Molino,Elena Mulero Ayllón,Filippo Ruffini,Paolo Soda,Matteo Tortora*

Main category: cs.LG

TL;DR: 本文针对云覆盖导致的卫星观测稀疏性和气候异质性挑战，提出一种基于Transformer的田间尺度NDVI概率预测框架，通过时间距离加权分位数损失和气象特征工程，在欧洲数据集上显著优于各类基线方法。


<details>
  <summary>Details</summary>
Motivation: 精准农业的决策支持依赖于准确的短期植被动态预测。然而，基于卫星观测的NDVI预测面临两大核心挑战：云覆盖造成的稀疏不规则采样，以及作物生长过程中气候条件的空间异质性，现有方法尚未充分解决这些问题。

Method: 提出一种专用概率预测框架：1) 采用Transformer架构，显式分离历史植被动态建模与未来外生信息整合；2) 设计时间距离加权的分位数损失函数，使训练目标与有效预测视界对齐；3) 引入累积和极端天气特征工程，捕捉气象滞后效应；4) 融合历史NDVI观测与历史/未来气象协变量进行联合预测。

Result: 在欧洲卫星数据的广泛实验中，该方法在点预测和概率评估指标上均持续优于统计、深度学习和最新时间序列基线。消融研究表明目标历史信息起决定性作用，气象协变量提供显著互补增益。

Conclusion: 该框架有效应对了稀疏采样与气候异质性难题，为田间尺度NDVI预测提供了可靠的概率性工具，其开源实现将推动精准农业的数据驱动决策发展。

Abstract: Accurate short-term forecasting of vegetation dynamics is a key enabler for data-driven decision support in precision agriculture. Normalized Difference Vegetation Index (NDVI) forecasting from satellite observations, however, remains challenging due to sparse and irregular sampling caused by cloud coverage, as well as the heterogeneous climatic conditions under which crops evolve. In this work, we propose a probabilistic forecasting framework specifically designed for field-level NDVI prediction under clear-sky acquisition constraints. The method leverages a transformer-based architecture that explicitly separates the modeling of historical vegetation dynamics from future exogenous information, integrating historical NDVI observations with both historical and future meteorological covariates. To address irregular revisit patterns and horizon-dependent uncertainty, we introduce a temporal-distance weighted quantile loss that aligns the training objective with the effective forecasting horizon. In addition, we incorporate cumulative and extreme-weather feature engineering to better capture delayed meteorological effects relevant to vegetation response. Extensive experiments on European satellite data demonstrate that the proposed approach consistently outperforms a diverse set of statistical, deep learning, and recent time series baselines across both point-wise and probabilistic evaluation metrics. Ablation studies further highlight the central role of target history, while showing that meteorological covariates provide complementary gains when jointly exploited. The code is available at https://github.com/arco-group/ndvi-forecasting.

</details>


### [36] [CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models](https://arxiv.org/abs/2602.17684)
*Xiao Zhu,Xinyu Zhou,Boyu Zhu,Hanxu Hu,Mingzhe Du,Haotian Zhang,Huiming Wang,Zhijiang Guo*

Main category: cs.LG

TL;DR: 针对代码大语言模型中基于执行的强化学习(RLVR)受测试用例质量和可用性限制的问题，本文提出CodeScaler——一种无需执行的奖励模型。通过在精选的已验证代码问题偏好数据上训练，并结合语法感知代码提取和保效奖励塑形技术，CodeScaler在五个代码基准测试上将Qwen3-8B-Base平均提升11.72分，优于基于执行的强化学习1.82分，且推理延迟降低10倍。


<details>
  <summary>Details</summary>
Motivation: 基于可验证奖励的强化学习(RLVR)通过单元测试的执行反馈推动了代码大语言模型的进步，但其可扩展性受到高质量测试用例可用性和可靠性的根本限制。现有方法无法在没有测试用例的合成数据集上进行可扩展的强化学习训练，且测试时推理开销大。

Method: 提出CodeScaler，一种无需执行的奖励模型。该方法从已验证代码问题中构建精选偏好数据进行训练，并采用语法感知代码提取技术确保生成代码的语法正确性，通过保效奖励塑形机制保证优化的稳定性和鲁棒性。

Result: 在五个代码基准测试上，CodeScaler将Qwen3-8B-Base模型平均性能提升+11.72分，相比基于二进制执行的强化学习方法高出+1.82分。能够在无需任何测试用例的情况下在合成数据集上进行可扩展的强化学习。测试时推理性能与单元测试方法相当，但延迟降低10倍。在RM-Bench上，CodeScaler不仅在代码领域超出已有奖励模型+3.3分，在通用和推理领域也平均领先+2.7分。

Conclusion: CodeScaler成功解决了RLVR的测试用例依赖问题，通过执行-free的奖励建模实现了强化学习训练和测试时推理的可扩展性，显著提升了代码生成性能，并在多领域奖励模型基准测试中表现优异，为代码智能体开发提供了更高效的解决方案。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has driven recent progress in code large language models by leveraging execution-based feedback from unit tests, but its scalability is fundamentally constrained by the availability and reliability of high-quality test cases. We propose CodeScaler, an execution-free reward model designed to scale both reinforcement learning training and test-time inference for code generation. CodeScaler is trained on carefully curated preference data derived from verified code problems and incorporates syntax-aware code extraction and validity-preserving reward shaping to ensure stable and robust optimization. Across five coding benchmarks, CodeScaler improves Qwen3-8B-Base by an average of +11.72 points, outperforming binary execution-based RL by +1.82 points, and enables scalable reinforcement learning on synthetic datasets without any test cases. At inference time, CodeScaler serves as an effective test-time scaling method, achieving performance comparable to unit test approaches while providing a 10-fold reduction in latency. Moreover, CodeScaler surpasses existing reward models on RM-Bench not only in the code domain (+3.3 points), but also in general and reasoning domains (+2.7 points on average).

</details>


### [37] [Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling](https://arxiv.org/abs/2602.17685)
*Agni Bandyopadhyay,Gunther Waxenegger-Wilfing*

Main category: cs.LG

TL;DR: 本文提出一种统一共椭圆机动框架，融合Hohmann转移、安全椭圆接近操作和显式在轨加注逻辑，用于低地球轨道多目标主动碎片移除。在包含随机碎片场、避碰区和ΔV约束的仿真环境中，对比贪心启发式、蒙特卡洛树搜索和掩码近端策略优化（Masked PPO）三种算法。实验表明，Masked PPO访问碎片数量可达贪心算法的两倍，且运行时间显著优于蒙特卡洛树搜索，为自主碎片移除提供了高效智能规划方案。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道多目标主动碎片移除面临任务效率低、计算复杂度高和资源约束严格等挑战。传统启发式算法和搜索方法在复杂动态环境下难以实现高效可扩展的轨迹规划，亟需开发能够智能处理随机碎片分布、避碰约束和有限推进剂条件的先进规划方法，以提升碎片清除任务的整体效能和自主性。

Method: 提出统一的共椭圆机动框架，将Hohmann轨道转移、安全椭圆接近操作与显式在轨加注逻辑有机结合。构建高保真轨道仿真环境，包含随机生成的碎片场、避碰区和ΔV预算约束。基准测试三种算法：贪心启发式（局部最优选择）、蒙特卡洛树搜索（MCTS，基于模拟的搜索）和掩码近端策略优化（Masked PPO，深度强化学习）。通过100个多样化测试场景评估各算法的任务效率、计算性能和资源利用率。

Result: 实验结果表明，Masked PPO算法在任务效率和计算性能上均显著优于其他方法。在100个测试场景中，Masked PPO访问的碎片数量最高达到贪心算法的两倍，同时其运行速度远超蒙特卡洛树搜索，展现出优越的计算效率。该算法能够有效处理复杂约束，实现安全、资源高效的轨迹规划。

Conclusion: 研究验证了现代深度强化学习在空间任务规划中的巨大潜力，特别是Masked PPO算法为可扩展、安全且资源高效的主动碎片移除任务提供了有前景的解决方案。该成果为未来自主化碎片清除任务奠定了技术基础，推动了空间碎片清理向智能化、自主化方向发展，对维护空间环境可持续性具有重要意义。

Abstract: This paper addresses the challenge of multi target active debris removal (ADR) in Low Earth Orbit (LEO) by introducing a unified coelliptic maneuver framework that combines Hohmann transfers, safety ellipse proximity operations, and explicit refueling logic. We benchmark three distinct planning algorithms Greedy heuristic, Monte Carlo Tree Search (MCTS), and deep reinforcement learning (RL) using Masked Proximal Policy Optimization (PPO) within a realistic orbital simulation environment featuring randomized debris fields, keep out zones, and delta V constraints. Experimental results over 100 test scenarios demonstrate that Masked PPO achieves superior mission efficiency and computational performance, visiting up to twice as many debris as Greedy and significantly outperforming MCTS in runtime. These findings underscore the promise of modern RL methods for scalable, safe, and resource efficient space mission planning, paving the way for future advancements in ADR autonomy.

</details>


### [38] [AnCoder: Anchored Code Generation via Discrete Diffusion Models](https://arxiv.org/abs/2602.17688)
*Anton Xue,Litu Rout,Constantine Caramanis,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: 本文针对扩散语言模型在代码生成中因忽略编程语言刚性结构而导致生成程序无法执行的问题，提出AnchorTree框架。该方法利用抽象语法树对关键字和标识符等显著性标记进行优先解析，构建结构支架引导扩散过程，并通过AnCoder模型验证了其在参数高效前提下实现高质量代码生成的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散语言模型支持全局规划和迭代优化，但现有方法未能遵循编程语言的严格语法规则，频繁产生语法错误、无法执行的代码。为此，需要引入代码的层次化结构先验知识，以结构约束确保生成代码的正确性和可执行性。

Method: AnchorTree框架将抽象语法树作为结构化先验，在扩散过程中优先解析语法和语义显著性高的标记（如if/while等控制流关键字和变量名等标识符），以此建立层次化结构支架，逐步引导代码生成的完整过程，确保符合语言语法和语义约束。

Result: 基于该框架实现的AnCoder模型家族在代码生成任务中表现出参数高效的特性，生成的代码质量显著提升，具有更高的语法正确性和可执行性，验证了结构锚定扩散的有效性。

Conclusion: 通过在扩散过程中显式嵌入抽象语法树的结构化先验，可显著改善代码生成的质量和可靠性，为开发高效、可执行的代码生成模型提供了可行路径，证明了结构化扩散在程序生成领域的巨大潜力。

Abstract: Diffusion language models offer a compelling alternative to autoregressive code generation, enabling global planning and iterative refinement of complex program logic. However, existing approaches fail to respect the rigid structure of programming languages and, as a result, often produce broken programs that fail to execute. To address this, we introduce AnchorTree, a framework that explicitly anchors the diffusion process using structured, hierarchical priors native to code. Specifically, AnchorTree uses the abstract syntax tree to prioritize resolving syntactically and semantically salient tokens, such as keywords (e.g., if, while) and identifiers (e.g., variable names), thereby establishing a structural scaffold that guides the remaining generation. We validate this framework via AnCoder, a family of models showing that structurally anchored diffusion offers a parameter-efficient path to high-quality code generation.

</details>


### [39] [EXACT: Explicit Attribute-Guided Decoding-Time Personalization](https://arxiv.org/abs/2602.17695)
*Xin Yu,Hanwen Xing,Lingzhou Xue*

Main category: cs.LG

TL;DR: 针对解码时个性化方法存在偏好表示隐式、用户表示僵化而无法处理偏好漂移的问题，本文提出EXACT框架，通过预定义可解释属性，在离线阶段优化用户属性子集，在线阶段基于语义检索动态注入属性引导生成，实现有限反馈下的个性化对齐，并在实验中显著超越基线。


<details>
  <summary>Details</summary>
Motivation: 现有解码时个性化方法依赖隐式且可解释性差的偏好表示，并采用固定、与上下文无关的用户表示，无法有效建模不同提示间的偏好动态变化，限制了模型对用户演化上下文的适应性。

Method: EXACT采用两阶段框架：离线阶段通过最大化偏好响应似然识别用户特定属性子集；在线阶段检索与输入提示最语义相关的属性并注入上下文以引导生成。该方法基于相似度的检索机制可自适应不同任务，避免冲突偏好池化。

Result: 在人类标注偏好数据集上的实验表明，EXACT在偏好建模准确率和个性化生成质量上持续优于强基线方法，验证了其有效性。

Conclusion: EXACT通过可解释属性机制实现了理论保证的解码时个性化，有效缓解了上下文偏好漂移问题，为大规模语言模型的个性化适配提供了可扩展的新范式。

Abstract: Achieving personalized alignment requires adapting large language models to each user's evolving context. While decoding-time personalization offers a scalable alternative to training-time methods, existing methods largely rely on implicit, less interpretable preference representations and impose a rigid, context-agnostic user representation, failing to account for how preferences shift across prompts. We introduce EXACT, a new decoding-time personalization that aligns generation with limited pairwise preference feedback using a predefined set of interpretable attributes. EXACT first identifies user-specific attribute subsets by maximizing the likelihood of preferred responses in the offline stage. Then, for online inference, EXACT retrieves the most semantically relevant attributes for an incoming prompt and injects them into the context to steer generation. We establish theoretical approximation guarantees for the proposed algorithm under mild assumptions, and provably show that our similarity-based retrieval mechanism effectively mitigates contextual preference shifts, adapting to disparate tasks without pooling conflicting preferences. Extensive experiments on human-annotated preference datasets demonstrate that EXACT consistently outperforms strong baselines, including preference modeling accuracy and personalized generation quality.

</details>


### [40] [Robust Pre-Training of Medical Vision-and-Language Models with Domain-Invariant Multi-Modal Masked Reconstruction](https://arxiv.org/abs/2602.17689)
*Melika Filvantorkaman,Mohsen Piri*

Main category: cs.LG

TL;DR: 本文提出Robust-MMR，一种自监督预训练框架，通过非对称扰动感知掩码、领域一致性正则化和模态弹性约束，显式地将鲁棒性目标融入医疗视觉语言模型的掩码重建学习，显著提升了模型在领域偏移下的性能。


<details>
  <summary>Details</summary>
Motivation: 医疗视觉语言模型在面对成像设备、采集协议和报告风格变化引起的领域偏移时性能显著下降，而现有方法将鲁棒性视为下游适应问题，在预训练阶段缺乏对鲁棒性的显式建模。

Method: 提出Robust-MMR框架，采用非对称扰动感知掩码策略、领域一致性正则化约束和模态弹性约束，在自监督预训练中显式地学习目标领域不变表征，增强模型对领域变化的适应能力。

Result: 在VQA-RAD、SLAKE、VQA-2019等医疗VQA基准上分别达到78.9%、74.6%和77.0%的准确率，其中VQA-RAD跨领域性能超越最强基线3.8个百分点；在扰动评估下，VQA-RAD准确率从69.1%提升至75.6%，MELINDA分类准确率从70.3%提升至75.2%，检索平均排名退化从16以上降至4.1。

Conclusion: 在预训练阶段显式建模鲁棒性能够有效学习更可靠和迁移性更强的医疗视觉语言表征，为模型在真实临床环境中的部署提供了更稳健的解决方案。

Abstract: Medical vision-language models show strong potential for joint reasoning over medical images and clinical text, but their performance often degrades under domain shift caused by variations in imaging devices, acquisition protocols, and reporting styles. Existing multi-modal pre-training methods largely overlook robustness, treating it as a downstream adaptation problem. In this work, we propose Robust Multi-Modal Masked Reconstruction (Robust-MMR), a self-supervised pre-training framework that explicitly incorporates robustness objectives into masked vision-language learning. Robust-MMR integrates asymmetric perturbation-aware masking, domain-consistency regularization, and modality-resilience constraints to encourage domain-invariant representations. We evaluate Robust-MMR on multiple medical vision-language benchmarks, including medical visual question answering (VQA-RAD, SLAKE, VQA-2019), cross-domain image-text classification (MELINDA), and robust image-caption retrieval (ROCO). Robust-MMR achieves 78.9% cross-domain accuracy on VQA-RAD, outperforming the strongest baseline by 3.8 percentage points, and reaches 74.6% and 77.0% accuracy on SLAKE and VQA-2019, respectively. Under perturbed evaluation, Robust-MMR improves VQA-RAD accuracy from 69.1% to 75.6%. For image-text classification, cross-domain MELINDA accuracy increases from 70.3% to 75.2%, while retrieval experiments show a reduction in mean rank degradation from over 16 to 4.1 under perturbation. Qualitative results further demonstrate improved clinical reasoning for disease detection and structural abnormality assessment. These findings show that explicitly modeling robustness during pre-training leads to more reliable and transferable medical vision-language representations for real-world deployment.

</details>


### [41] [A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU](https://arxiv.org/abs/2602.17693)
*Yuchen Luo,Fangyue Zhu,Ruining Zhou,Mingzhe Huang,Jian Zhu,Fanyu Fan,Wei Shao*

Main category: cs.LG

TL;DR: 本研究针对昇腾NPU后训练量化(PTQ)研究不足的问题，对DeepSeek-R1-Distill-Qwen和QwQ-32B等推理模型进行案例研究，评估AWQ、GPTQ、SmoothQuant和FlatQuant四种算法。发现4-bit权重量化对大模型可行，但4-bit权重-激活量化因层间校准不稳定导致长文本推理逻辑崩溃，而8-bit量化数值稳定。INT8部署中优化内核虽降低延迟，但动态量化开销限制了端到端加速。


<details>
  <summary>Details</summary>
Motivation: 当前后训练量化(PTQ)在昇腾NPU上的有效性相比GPU架构研究不足，缺乏针对推理导向模型的实际部署可行性参考。本研究旨在填补这一空白，为昇腾平台上量化推理模型的部署提供实践指导。

Method: 采用案例研究方法，选取DeepSeek-R1-Distill-Qwen系列(1.5B/7B/14B)和QwQ-32B等代表性推理模型，系统评估AWQ、GPTQ、SmoothQuant和FlatQuant四种主流PTQ算法，覆盖从纯权重量化到先进旋转基方法的频谱。通过实证分析不同位宽(4-bit/8-bit)在NPU上的数值稳定性和实际部署效果。

Result: 实验发现：(1)4-bit权重量化对较大模型可行；(2)4-bit权重-激活量化因层间校准不稳定导致长文本推理任务出现逻辑崩溃；(3)标准8-bit量化保持数值稳定；(4)实际INT8部署中，优化内核虽降低延迟，但动态量化开销限制了端到端加速效果。揭示了量化算法在NPU上的显著平台敏感性。

Conclusion: 研究为昇腾NPU上推理模型的量化部署提供了关键实践参考：推荐8-bit量化确保稳定性，4-bit权重量化可作为权衡选择，而4-bit权重-激活方案需谨慎使用。同时指出当前动态量化开销是制约部署效率的关键瓶颈，为未来优化方向提供依据。

Abstract: Post-Training Quantization (PTQ) is crucial for efficient model deployment, yet its effectiveness on Ascend NPU remains under-explored compared to GPU architectures. This paper presents a case study of representative PTQ baselines applied to reasoning-oriented models such as DeepSeek-R1-Distill-Qwen series (1.5B/7B/14B) and QwQ-32B. We evaluate four distinct algorithms, including AWQ, GPTQ, SmoothQuant, and FlatQuant, to cover the spectrum from weight-only compression to advanced rotation-based methods. Our empirical results reveal significant platform sensitivity. While 4-bit weight-only quantization proves viable for larger models, aggressive 4-bit weight-activation schemes suffer from layer-wise calibration instability on the NPU, leading to logic collapse in long-context reasoning tasks. Conversely, standard 8-bit quantization remains numerically stable. Furthermore, a real-world INT8 deployment demonstrates that although optimized kernels reduce latency, dynamic quantization overheads currently limit end-to-end acceleration. These findings offer a practical reference for the feasibility and limitations of deploying quantized reasoning models on Ascend NPU.

</details>


### [42] [Can LLM Safety Be Ensured by Constraining Parameter Regions?](https://arxiv.org/abs/2602.17696)
*Zongmin Li,Jian Su,Farah Benamara,Aixin Sun*

Main category: cs.LG

TL;DR: 本文系统评估了四种不同粒度的安全区域识别方法，发现这些方法识别出的安全区域重叠度较低，且在引入效用数据集后重叠度进一步下降，表明现有技术无法可靠识别稳定且与数据集无关的安全区域。


<details>
  <summary>Details</summary>
Motivation: 当前研究假设大语言模型中存在可通过修改参数子集来直接影响安全行为的"安全区域"，但不同识别方法的有效性及其稳定性尚未得到系统验证。

Method: 研究者在四个不同规模的骨干大语言模型家族上，系统评估了从单个权重到完整Transformer层的四种安全区域识别方法，使用了十个安全识别数据集，并通过IoU指标衡量区域重叠度，同时引入非有害查询的效用数据集进行精炼验证。

Result: 实验发现识别出的安全区域仅呈现低至中等程度的重叠（IoU指标），且在用效用数据集进一步精炼后，重叠度显著下降。

Conclusion: 现有技术无法可靠识别出稳定且与数据集无关的安全区域，挑战了"安全区域"作为可精确定位的参数子集这一假设。

Abstract: Large language models (LLMs) are often assumed to contain ``safety regions'' -- parameter subsets whose modification directly influences safety behaviors. We conduct a systematic evaluation of four safety region identification methods spanning different parameter granularities, from individual weights to entire Transformer layers, across four families of backbone LLMs with varying sizes. Using ten safety identification datasets, we find that the identified safety regions exhibit only low to moderate overlap, as measured by IoU. The overlap drops significantly when the safety regions are further refined using utility datasets (\ie non-harmful queries). These results suggest that current techniques fail to reliably identify a stable, dataset-agnostic safety region.

</details>


### [43] [ScaleBITS: Scalable Bitwidth Search for Hardware-Aligned Mixed-Precision LLMs](https://arxiv.org/abs/2602.17698)
*Xinlin Li,Timothy Chou,Josh Fromm,Zichang Liu,Yunjie Pan,Christina Fragouli*

Main category: cs.LG

TL;DR: ScaleBITS是一个混合精度量化框架，通过新的敏感性分析、硬件对齐的块级权重划分和双向通道重排序，在超低比特率下实现自动化的细粒度位宽分配，相比均匀量化提升达36%，优于现有最优方法13%，且无运行时开销。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的后训练权重量化对降低内存和推理成本至关重要，但将平均精度推至4比特以下仍具挑战性，主要由于权重敏感性高度非均匀且缺乏原则性的精度分配策略。现有方法要么使用不规则细粒度混合精度带来高运行时开销，要么依赖启发式或强约束的精度分配策略。

Method: 提出ScaleBITS框架，包括：(1) 基于新的敏感性分析；(2) 硬件对齐的块级权重划分方案，采用双向通道重排序；(3) 将全局位宽分配建模为约束优化问题；(4) 开发可伸缩的贪心算法近似方法，实现端到端原则性分配。

Result: 实验表明，在超低比特率下，ScaleBITS相比均匀精度量化显著提升达36%，优于现有最优敏感性感知基线达13%，且不增加运行时开销。

Conclusion: ScaleBITS成功实现了在内存预算下自动化、细粒度的位宽分配，同时保持硬件效率，为LLM的超低比特量化提供了有效的解决方案。

Abstract: Post-training weight quantization is crucial for reducing the memory and inference cost of large language models (LLMs), yet pushing the average precision below 4 bits remains challenging due to highly non-uniform weight sensitivity and the lack of principled precision allocation. Existing solutions use irregular fine-grained mixed-precision with high runtime overhead or rely on heuristics or highly constrained precision allocation strategies. In this work, we propose ScaleBITS, a mixed-precision quantization framework that enables automated, fine-grained bitwidth allocation under a memory budget while preserving hardware efficiency. Guided by a new sensitivity analysis, we introduce a hardware-aligned, block-wise weight partitioning scheme, powered by bi-directional channel reordering. We formulate global bitwidth allocation as a constrained optimization problem and develop a scalable approximation to the greedy algorithm, enabling end-to-end principled allocation. Experiments show that ScaleBITS significantly improves over uniform-precision quantization (up to +36%) and outperforms state-of-the-art sensitivity-aware baselines (up to +13%) in ultra-low-bit regime, without adding runtime overhead.

</details>


### [44] [MIDAS: Mosaic Input-Specific Differentiable Architecture Search](https://arxiv.org/abs/2602.17700)
*Konstanty Subbotko*

Main category: cs.LG

TL;DR: MIDAS通过自注意力机制将DARTS中的静态架构参数替换为动态的输入特定参数，实现按空间patch的局部架构选择，并引入无参数的拓扑感知搜索空间，在多个NAS基准测试中性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 可微分神经架构搜索(DARTS)虽高效但实际应用受限，主要因其静态架构参数缺乏输入自适应性，导致架构选择鲁棒性不足。

Method: 1) 利用自注意力生成输入特定的动态架构参数；2) 对激活图各空间patch独立计算架构选择，实现局部化决策；3) 设计无参数拓扑感知搜索空间，显式建模节点连接性以简化边选择。在DARTS、NAS-Bench-201和RDARTS空间评估。

Result: CIFAR-10上达97.42% top-1准确率，CIFAR-100上为83.38%；NAS-Bench-201上持续找到全局最优架构；RDARTS中在CIFAR-10的四个搜索空间两个达SOTA。分析表明patchwise注意力增强操作判别力，参数分布呈类别感知且单峰主导。

Conclusion: MIDAS通过动态参数化和局部架构选择显著提升了DARTS性能与鲁棒性，其成功源于增强的操作判别力和可靠的单峰参数分布，为可微分NAS的实际部署提供了新方向。

Abstract: Differentiable Neural Architecture Search (NAS) provides efficient, gradient-based methods for automatically designing neural networks, yet its adoption remains limited in practice. We present MIDAS, a novel approach that modernizes DARTS by replacing static architecture parameters with dynamic, input-specific parameters computed via self-attention. To improve robustness, MIDAS (i) localizes the architecture selection by computing it separately for each spatial patch of the activation map, and (ii) introduces a parameter-free, topology-aware search space that models node connectivity and simplifies selecting the two incoming edges per node. We evaluate MIDAS on the DARTS, NAS-Bench-201, and RDARTS search spaces. In DARTS, it reaches 97.42% top-1 on CIFAR-10 and 83.38% on CIFAR-100. In NAS-Bench-201, it consistently finds globally optimal architectures. In RDARTS, it sets the state of the art on two of four search spaces on CIFAR-10. We further analyze why MIDAS works, showing that patchwise attention improves discrimination among candidate operations, and the resulting input-specific parameter distributions are class-aware and predominantly unimodal, providing reliable guidance for decoding.

</details>


### [45] [Pimp My LLM: Leveraging Variability Modeling to Tune Inference Hyperparameters](https://arxiv.org/abs/2602.17697)
*Nada Zine,Clément Quinton,Romain Rouvoy*

Main category: cs.LG

TL;DR: 针对大语言模型推理阶段能耗高且配置空间巨大的问题，本文将可变性管理技术应用于LLM推理配置分析，通过特征模型采样和预测建模，实现了对超参数影响的系统性分析和行为预测，为高效可持续的LLM配置提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理阶段占据主要计算能耗，但推理服务器的巨大配置空间导致穷尽评估不可行。现有研究缺乏系统性分析配置选择对能耗、延迟、准确率等指标影响的方法，亟需新的技术视角来解决组合爆炸问题。

Method: 将LLM视为可配置系统，采用基于特征的变异性模型表示生成超参数及约束关系；在Hugging Face Transformers库上采样代表性配置；测量能耗、延迟、准确率等多维指标；基于收集数据训练预测模型来推断配置行为。

Result: 可变性建模有效管理了LLM推理配置的复杂性，实现了超参数影响和交互作用的系统性分析，揭示了不同指标间的权衡关系，并能够基于少量测量准确预测推理行为，避免了组合爆炸带来的评估开销。

Conclusion: 本研究开辟了连接软件工程和机器学习的新研究方向，利用可变性建模实现LLM的高效可持续配置，对降低能耗和环境影响具有重要意义，为未来绿色AI系统设计提供了方法论支撑。

Abstract: Large Language Models (LLMs) are being increasingly used across a wide range of tasks. However, their substantial computational demands raise concerns about the energy efficiency and sustainability of both training and inference. Inference, in particular, dominates total compute usage, making its optimization crucial. Recent research has explored optimization techniques and analyzed how configuration choices influence energy consumption. Yet, the vast configuration space of inference servers makes exhaustive empirical evaluation infeasible due to combinatorial explosion. In this paper, we introduce a new perspective on this problem by treating LLMs as configurable systems and applying variability management techniques to systematically analyze inference-time configuration choices. We evaluate our approach on the Hugging Face Transformers library by representing generation hyperparameters and their constraints using a feature-based variability model, sampling representative configurations, measuring their energy consumption, latency, accuracy, and learning predictive models from the collected data. Our results show that variability modeling effectively manages the complexity of LLM inference configurations. It enables systematic analysis of hyperparameters effects and interactions, reveals trade-offs, and supports accurate prediction of inference behavior from a limited number of measurements. Overall, this work opens a new research direction that bridges software engineering and machine learning by leveraging variability modeling for the efficient and sustainable configuration of LLMs.

</details>


### [46] [Certified Learning under Distribution Shift: Sound Verification and Identifiable Structure](https://arxiv.org/abs/2602.17699)
*Chandrasekhar Gokavarapu,Sudhakar Gadde,Y. Rajasekhar,S. R. Bhargava*

Main category: cs.LG

TL;DR: 针对分布偏移下的模型泛化问题，本文提出了一个统一的可认证框架，通过可计算的偏移度量和显式不等式，给出额外风险的显式上界，并通过可识别性条件实现可解释性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在分布偏移下性能下降是实际应用中的关键问题。现有研究缺乏可验证的理论保证和可解释性，无法明确界定模型在何种情况下可靠、何种情况下失效。

Method: 在可验证的正则性和复杂性约束下，构建统一的认证框架：(i) 通过显式不等式对分布偏移风险进行认证；(ii) 对非平凡规模的模型进行可靠验证；(iii) 通过可识别性条件而非事后解释强制可解释性。

Result: 获得了由可计算偏移度量和模型参数决定的额外风险显式上界，能够验证非平凡规模的模型，系统性地分离了失败模式并刻画了不可认证的情形。

Conclusion: 该框架为分布偏移下的模型可靠性提供了严格的理论保证，推动了可解释性研究从启发式事后解释向可识别性条件的前置转变，同时明确了理论适用的边界。

Abstract: Proposition. Let $f$ be a predictor trained on a distribution $P$ and evaluated on a shifted distribution $Q$. Under verifiable regularity and complexity constraints, the excess risk under shift admits an explicit upper bound determined by a computable shift metric and model parameters. We develop a unified framework in which (i) risk under distribution shift is certified by explicit inequalities, (ii) verification of learned models is sound for nontrivial sizes, and (iii) interpretability is enforced through identifiability conditions rather than post hoc explanations. All claims are stated with explicit assumptions. Failure modes are isolated. Non-certifiable regimes are characterized.

</details>


### [47] [Parallel Complex Diffusion for Scalable Time Series Generation](https://arxiv.org/abs/2602.17706)
*Rongyao Cai,Yuxi Wan,Kexin Zhang,Ming Jin,Zhiqiang Ge,Qingsong Wen,Yong Liu*

Main category: cs.LG

TL;DR: PaCoDi 是一种频域原生的并行复数扩散模型，通过傅里叶变换解耦时域依赖，利用埃尔米特对称性将注意力计算量减半，在理论严谨的前提下实现时间序列生成质量和速度的双重提升。


<details>
  <summary>Details</summary>
Motivation: 时间序列长程依赖建模面临表征能力与计算效率的根本性权衡。传统扩散模型存在局部纠缠问题，且注意力机制带来 O(L²) 计算复杂度，限制了其在长序列场景的应用。

Method: 提出 PaCoDi 架构：1) 在频域进行生成建模，傅里叶变换作为对角化算子解耦局部依赖；2) 理论证明复数扩散过程可分解为独立的实部/虚部分支；3) 采用平均场理论近似与交互校正机制；4) 推广至连续时间频域随机微分方程；5) 利用埃尔米特对称性压缩序列长度；6) 设计异方差损失函数处理非各向同性噪声。

Result: 理论层面建立了完整的频域扩散理论框架；效率层面实现注意力计算量降低50%且无信息损失；性能层面在生成质量和推理速度上均显著优于现有基线模型。

Conclusion: PaCoDi 通过频域解耦和对称性压缩，为长程时间序列建模提供了计算高效、理论严谨的解决方案，有效突破了传统方法的计算瓶颈，具有重要理论和实践价值。

Abstract: Modeling long-range dependencies in time series generation poses a fundamental trade-off between representational capacity and computational efficiency. Traditional temporal diffusion models suffer from local entanglement and the $\mathcal{O}(L^2)$ cost of attention mechanisms. We address these limitations by introducing PaCoDi (Parallel Complex Diffusion), a spectral-native architecture that decouples generative modeling in the frequency domain. PaCoDi fundamentally alters the problem topology: the Fourier Transform acts as a diagonalizing operator, converting locally coupled temporal signals into globally decorrelated spectral components. Theoretically, we prove the Quadrature Forward Diffusion and Conditional Reverse Factorization theorem, demonstrating that the complex diffusion process can be split into independent real and imaginary branches. We bridge the gap between this decoupled theory and data reality using a \textbf{Mean Field Theory (MFT) approximation} reinforced by an interactive correction mechanism. Furthermore, we generalize this discrete DDPM to continuous-time Frequency SDEs, rigorously deriving the Spectral Wiener Process describe the differential spectral Brownian motion limit. Crucially, PaCoDi exploits the Hermitian Symmetry of real-valued signals to compress the sequence length by half, achieving a 50% reduction in attention FLOPs without information loss. We further derive a rigorous Heteroscedastic Loss to handle the non-isotropic noise distribution on the compressed manifold. Extensive experiments show that PaCoDi outperforms existing baselines in both generation quality and inference speed, offering a theoretically grounded and computationally efficient solution for time series modeling.

</details>


### [48] [MantisV2: Closing the Zero-Shot Gap in Time Series Classification with Synthetic Data and Test-Time Strategies](https://arxiv.org/abs/2602.17868)
*Vasilii Feofanov,Songkang Wen,Jianfeng Zhang,Lujia Pan,Ievgen Redko*

Main category: cs.LG

TL;DR: 本文提出Mantis+和MantisV2两种改进的时间序列基础模型，通过合成数据预训练、架构优化和测试时增强方法，显著提升零样本特征提取性能，在UCR、UEA、HAR及EEG等多个基准上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类基础模型具有高度实践价值，可作为通用特征提取器。尽管早期模型Mantis展示了良好前景，但冻结编码器和微调编码器间存在显著性能差距，限制了零样本学习效果，亟需填补这一鸿沟。

Method: 1. 提出Mantis+：完全基于合成时间序列预训练的Mantis变体；2. 开发MantisV2：通过控制性消融研究优化架构，获得更轻量的编码器；3. 设计增强测试时方法：利用中间层表示并改进输出token聚合；4. 引入自集成和跨模型嵌入融合策略进一步提升性能。

Result: 在UCR、UEA、人类活动识别(HAR)及EEG等基准测试上，MantisV2和Mantis+一致优于先前时间序列基础模型，实现了最先进的零样本性能，显著缩小了冻结与微调编码器的性能差距。

Conclusion: 通过合成数据预训练、架构优化与测试时策略的有机结合，可有效强化时间序列零样本特征提取能力，为构建通用时间序列基础模型提供了可行路径，具有重要的实际应用价值。

Abstract: Developing foundation models for time series classification is of high practical relevance, as such models can serve as universal feature extractors for diverse downstream tasks. Although early models such as Mantis have shown the promise of this approach, a substantial performance gap remained between frozen and fine-tuned encoders. In this work, we introduce methods that significantly strengthen zero-shot feature extraction for time series. First, we introduce Mantis+, a variant of Mantis pre-trained entirely on synthetic time series. Second, through controlled ablation studies, we refine the architecture and obtain MantisV2, an improved and more lightweight encoder. Third, we propose an enhanced test-time methodology that leverages intermediate-layer representations and refines output-token aggregation. In addition, we show that performance can be further improved via self-ensembling and cross-model embedding fusion. Extensive experiments on UCR, UEA, Human Activity Recognition (HAR) benchmarks, and EEG datasets show that MantisV2 and Mantis+ consistently outperform prior time series foundation models, achieving state-of-the-art zero-shot performance.

</details>


### [49] [Provable Adversarial Robustness in In-Context Learning](https://arxiv.org/abs/2602.17743)
*Di Zhang*

Main category: cs.LG

TL;DR: 本文针对大语言模型在对抗性分布偏移下的上下文学习（ICL）鲁棒性进行理论研究，提出了分布鲁棒元学习框架。通过分析线性自注意力Transformer，推导出连接对抗扰动强度(ρ)、模型容量(m)和上下文示例数(N)的非渐近界，发现模型鲁棒性随容量平方根增长(ρ_max ∝ √m)，而对抗设置带来的样本复杂度惩罚与扰动幅度的平方成正比(N_ρ - N_0 ∝ ρ²)。合成任务实验验证了这些缩放规律，揭示了容量是分布鲁棒性的基础资源。


<details>
  <summary>Details</summary>
Motivation: 当前ICL的理论解释假设测试任务与预训练任务来自相似分布，忽略了威胁现实可靠性的对抗性分布偏移。这一理论缺口阻碍了对ICL在真实环境中极限的理解，特别是在面临对抗性扰动时模型的鲁棒性保障问题。

Method: 引入分布鲁棒元学习框架，为ICL在Wasserstein分布偏移下提供最坏情况性能保证。聚焦线性自注意力Transformer，推导关于对抗扰动强度(ρ)、模型容量(m)和上下文示例数(N)的非渐近界，并通过合成任务实验验证理论预测的缩放规律。

Result: 理论分析揭示两个关键缩放律：1) 模型对抗鲁棒性的最大容忍扰动强度ρ_max与模型容量的平方根成正比(ρ_max ∝ √m)；2) 对抗设置带来的额外样本复杂度(N_ρ - N_0)与扰动幅度ρ的平方成正比(N_ρ - N_0 ∝ ρ²)。合成任务实验数据证实了这些理论预测。

Conclusion: 该研究推进了对对抗条件下ICL极限的理论理解，表明模型容量是分布鲁棒性的基础资源。这些发现为设计更可靠的ICL系统提供了理论指导，强调了提升模型容量对于增强对抗鲁棒性的重要性。

Abstract: Large language models adapt to new tasks through in-context learning (ICL) without parameter updates. Current theoretical explanations for this capability assume test tasks are drawn from a distribution similar to that seen during pretraining. This assumption overlooks adversarial distribution shifts that threaten real-world reliability. To address this gap, we introduce a distributionally robust meta-learning framework that provides worst-case performance guarantees for ICL under Wasserstein-based distribution shifts. Focusing on linear self-attention Transformers, we derive a non-asymptotic bound linking adversarial perturbation strength ($ρ$), model capacity ($m$), and the number of in-context examples ($N$). The analysis reveals that model robustness scales with the square root of its capacity ($ρ_{\text{max}} \propto \sqrt{m}$), while adversarial settings impose a sample complexity penalty proportional to the square of the perturbation magnitude ($N_ρ- N_0 \propto ρ^2$). Experiments on synthetic tasks confirm these scaling laws. These findings advance the theoretical understanding of ICL's limits under adversarial conditions and suggest that model capacity serves as a fundamental resource for distributional robustness.

</details>


### [50] [Machine Learning Based Prediction of Surgical Outcomes in Chronic Rhinosinusitis from Clinical Data](https://arxiv.org/abs/2602.17888)
*Sayeed Shafayet Chowdhury,Karen D'Souza,V. Siva Kakumani,Snehasis Mukhopadhyay,Shiaofen Fang,Rodney J. Schlosser,Daniel M. Beswick,Jeremiah A. Alt,Jess C. Mace,Zachary M. Soler,Timothy L. Smith,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 本研究利用监督机器学习模型，基于术前数据预测慢性鼻窦炎患者的手术获益，识别可能无需手术的患者。模型在测试集上达到约85%准确率，在30例验证集上达80%准确率，超越专家医生平均水平（75.6%），展现出辅助临床决策的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域已有应用，但将其机器学习预测应用于前瞻性收集的观察性临床干预试验数据仍不足。慢性鼻窦炎（CRS）对生活质量和社会成本负担重大，手术决策复杂，需权衡已知风险与不确定个体预后。开发预测手术获益的模型有助于降低医疗成本、避免不必要手术并改善患者结局。

Method: 采用前瞻性观察性干预试验队列数据，所有患者均接受手术。以Sino-Nasal Outcome Test-22（SNOT-22）为主要患者报告结局指标，评估多种监督机器学习算法（含集成方法），仅使用术前数据训练模型，预测手术获益并识别可能不应推荐手术的患者。

Result: 最佳模型实现约85%分类准确率，在30例混合难度保留测试集上达到80%准确率，显著超过专家临床医生的平均预测准确率（75.6%），提供可解释的手术候选预测。

Conclusion: 基于前瞻性标准化数据的机器学习模型能有效预测CRS患者手术获益，性能优于人类专家，有望增强临床决策支持，实现个性化护理，筛选真正需要手术的患者，避免不必要手术干预。

Abstract: Artificial intelligence (AI) has increasingly transformed medical prognostics by enabling rapid and accurate analysis across imaging and pathology. However, the investigation of machine learning predictions applied to prospectively collected, standardized data from observational clinical intervention trials remains underexplored, despite its potential to reduce costs and improve patient outcomes. Chronic rhinosinusitis (CRS), a persistent inflammatory disease of the paranasal sinuses lasting more than three months, imposes a substantial burden on quality of life (QoL) and societal cost. Although many patients respond to medical therapy, others with refractory symptoms often pursue surgical intervention. Surgical decision-making in CRS is complex, as it must weigh known procedural risks against uncertain individualized outcomes. In this study, we evaluated supervised machine learning models for predicting surgical benefit in CRS, using the Sino-Nasal Outcome Test-22 (SNOT-22) as the primary patient-reported outcome. Our prospectively collected cohort from an observational intervention trial comprised patients who all underwent surgery; we investigated whether models trained only on preoperative data could identify patients who might not have been recommended surgery prior to the procedure. Across multiple algorithms, including an ensemble approach, our best model achieved approximately 85% classification accuracy, providing accurate and interpretable predictions of surgical candidacy. Moreover, on a held-out set of 30 cases spanning mixed difficulty, our model achieved 80% accuracy, exceeding the average prediction accuracy of expert clinicians (75.6%), demonstrating its potential to augment clinical decision-making and support personalized CRS care.

</details>


### [51] [Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778)
*Zachary Coalson,Bo Fang,Sanghyun Hong*

Main category: cs.LG

TL;DR: 该论文揭示了大语言模型对话中的"回合放大"失效模式，即模型持续延长多轮交互却不完成任务。研究发现对抗性攻击可利用模型澄清行为，在查询无关的激活子空间中操纵模型，实现跨任务和提示的系统性对话延长，且现有防御措施防护有限。


<details>
  <summary>Details</summary>
Motivation: 多轮对话交互长度主导对话型大语言模型的运营成本。模型无谓延长对话会导致计算资源浪费和服务成本激增，但对此类系统性失效模式的机制性理解仍不足，亟需探索对话延长的根本原因和有效防御策略。

Method: 研究采用机制性分析视角，识别出与澄清寻求响应相关的查询无关、通用激活子空间。通过供应链攻击（微调）和运行时攻击（低级别参数损坏）两种方式，系统性地诱导模型产生抽象澄清行为，并在多个指令微调模型和基准测试上验证效果。

Result: 攻击在多个指令微调大语言模型上显著增加对话回合数，同时保持合规性。该攻击源于对话动态而非单轮提示优化，能跨不同提示和任务持续存在，现有防御措施对此类新型失效模式的防护效果有限。

Conclusion: 回合放大是对话大语言模型中一种可系统利用的失效模式，通过操纵模型内在澄清机制可造成运营成本放大。该发现揭示了模型行为控制的新漏洞，强调需要开发更有效的防御机制来应对基于对话动态的成本放大攻击。

Abstract: Multi-turn interaction length is a dominant factor in the operational costs of conversational LLMs. In this work, we present a new failure mode in conversational LLMs: turn amplification, in which a model consistently prolongs multi-turn interactions without completing the underlying task. We show that an adversary can systematically exploit clarification-seeking behavior$-$commonly encouraged in multi-turn conversation settings$-$to scalably prolong interactions. Moving beyond prompt-level behaviors, we take a mechanistic perspective and identify a query-independent, universal activation subspace associated with clarification-seeking responses. Unlike prior cost-amplification attacks that rely on per-turn prompt optimization, our attack arises from conversational dynamics and persists across prompts and tasks. We show that this mechanism provides a scalable pathway to induce turn amplification: both supply-chain attacks via fine-tuning and runtime attacks through low-level parameter corruptions consistently shift models toward abstract, clarification-seeking behavior across prompts. Across multiple instruction-tuned LLMs and benchmarks, our attack substantially increases turn count while remaining compliant. We also show that existing defenses offer limited protection against this emerging class of failures.

</details>


### [52] [MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance](https://arxiv.org/abs/2602.17930)
*Narjes Nourzad,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 提出MIRA（记忆集成强化学习智能体），通过构建包含轨迹段和子目标结构的记忆图来整合LLM先验与智能体高回报经验，将LLM查询分摊为持久记忆而非依赖实时监督，从而减少在线查询需求并在稀疏奖励环境中提升早期学习效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏或延迟奖励设置下RL智能体样本复杂度高；LLM监督虽能提供子目标分解等先验知识，但重度依赖导致可扩展性限制和不可靠信号问题。

Method: 1) 构建结构化记忆图，存储决策相关信息，融合LLM输出与智能体高回报经验；2) 从记忆图提取效用信号，软调整优势估计以影响策略更新；3) 设计效用项衰减机制，使策略逐步超越LLM先验，保持收敛保证。

Result: 理论分析表明效用塑形提升稀疏奖励环境早期学习；实验显示MIRA性能优于RL基线，达到与频繁LLM监督方法相当的回报，但显著减少在线LLM查询次数。

Conclusion: MIRA通过记忆集成机制有效平衡了初始LLM引导与长期学习自主性，实现了LLM监督的成本分摊，兼具良好初始性能和最终收敛性。

Abstract: Reinforcement learning (RL) agents often suffer from high sample complexity in sparse or delayed reward settings due to limited prior structure. Large language models (LLMs) can provide subgoal decompositions, plausible trajectories, and abstract priors that facilitate early learning. However, heavy reliance on LLM supervision introduces scalability constraints and dependence on potentially unreliable signals. We propose MIRA (Memory-Integrated Reinforcement Learning Agent), which incorporates a structured, evolving memory graph to guide early training. The graph stores decision-relevant information, including trajectory segments and subgoal structures, and is constructed from both the agent's high-return experiences and LLM outputs. This design amortizes LLM queries into a persistent memory rather than requiring continuous real-time supervision. From this memory graph, we derive a utility signal that softly adjusts advantage estimation to influence policy updates without modifying the underlying reward function. As training progresses, the agent's policy gradually surpasses the initial LLM-derived priors, and the utility term decays, preserving standard convergence guarantees. We provide theoretical analysis showing that utility-based shaping improves early-stage learning in sparse-reward environments. Empirically, MIRA outperforms RL baselines and achieves returns comparable to approaches that rely on frequent LLM supervision, while requiring substantially fewer online LLM queries. Project webpage: https://narjesno.github.io/MIRA/

</details>


### [53] [Grassmannian Mixture-of-Experts: Concentration-Controlled Routing on Subspace Manifolds](https://arxiv.org/abs/2602.17798)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 本文提出Grassmannian MoE (GrMoE)，一种基于Grassmannian流形和Matrix Bingham分布的新型MoE路由框架。该方法通过一个可解释的浓度矩阵Λ连续控制路由熵，替代离散的top-k选择，实现了几何原则上的稀疏性机制。结合摊销变分推断进行后验路由，有效避免专家崩溃，并在350M至2.7B参数规模的模型上实现零路由崩溃、更优的负载平衡和困惑度。


<details>
  <summary>Details</summary>
Motivation: 标准MoE模型采用softmax门控机制，但缺乏控制稀疏性与专家利用率权衡的原则性方法，容易导致专家崩溃问题。离散的top-k选择不具备灵活的稀疏性调节能力。

Method: 1) 在Grassmannian流形上构建路由框架，门控权重源于Matrix Bingham分布的浓度参数；2) 通过浓度矩阵Λ作为单一控制旋钮，连续调节路由熵；3) 开发摊销变分推断程序计算后验路由分布，实现不确定性感知的专家分配；4) 建立浓度谱与路由熵、期望top-k质量及专家崩溃指数界的严格理论联系。

Result: - 在350M(8专家)、1.3B(16专家)、2.7B(32专家)参数模型上实现0%路由崩溃；- 困惑度相当或更优，负载平衡提升15-30%；- 浓度与有效稀疏性呈现平滑单调关系，支持训练后稀疏性调节而无需重新训练；- 专家学习到异质化浓度值，与语言 specialization 显著相关，路由行为具有可解释性。

Conclusion: GrMoE首次建立了浓度控制稀疏性的形式化理论，提供了一种几何原则、可解释且理论严谨的MoE路由方案。该方法成功解决了专家崩溃问题，在保持模型性能的同时实现了灵活的稀疏性控制，为大规模MoE训练提供了新范式。

Abstract: Mixture-of-Experts models rely on learned routers to assign tokens to experts, yet standard softmax gating provides no principled mechanism to control the tradeoff between sparsity and utilization. We propose Grassmannian MoE (GrMoE), a routing framework that operates on the Grassmannian manifold of subspaces, where gating weights arise from the concentration parameters of Matrix Bingham distributions. This construction yields a single, interpretable knob -- the concentration matrix $Λ$ -- that continuously controls routing entropy, replacing discrete top-$k$ selection with a smooth, geometrically principled sparsity mechanism. We further develop an amortized variational inference procedure for posterior routing distributions, enabling uncertainty-aware expert assignment that naturally resists expert collapse. We formally prove tight bounds relating the Bingham concentration spectrum to routing entropy, expected top-$k$ mass, and an exponential bound on expert collapse, establishing the first formal theory of concentration-controlled sparsity. On synthetic routing tasks, a 350M-parameter MoE language model with 8 experts, a 1.3B-parameter model with 16 experts, and a 2.7B-parameter model with 32 experts, GrMoE achieves 0\% routing collapse across all seeds, comparable or better perplexity with 15--30\% improved load balance, and a smooth monotonic relationship between concentration and effective sparsity that enables post-hoc sparsity tuning without retraining. Token-level analysis reveals that experts learn heterogeneous concentration values that correlate with linguistic specialization, providing interpretable routing behavior.

</details>


### [54] [Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2602.17931)
*Narjes Nourzad,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 本文针对稀疏奖励环境下强化学习样本复杂度高的问题，提出了一种基于记忆图的离线辅助强化学习方法。通过编码LLM指导与智能体成功轨迹构建效用函数，用于优势函数塑形，减少对持续LLM调用的依赖。实验表明该方法提升了样本效率与早期学习速度，且最终性能与持续LLM监督方法相当。


<details>
  <summary>Details</summary>
Motivation: 稀疏或延迟奖励环境导致强化学习需要大量环境交互，样本效率低下。现有利用大型语言模型进行子目标发现和轨迹指导的方法虽能促进探索，但频繁的LLM调用带来计算开销和可靠性挑战。因此，亟需开发一种减少在线LLM依赖、提升可扩展性的学习框架。

Method: 1) 构建记忆图，整合LLM生成的子目标与智能体成功轨迹；2) 基于记忆图推导效用函数，评估当前轨迹与历史成功策略的相似性；3) 将效用函数融入优势估计，为价值函数提供额外监督信号，但不改变原始奖励结构；4) 采用离线为主、在线为辅的查询策略，避免持续LLM交互。

Result: 在标准基准测试中，相较于基线RL方法，本方法显著提升了样本效率并加速了早期学习阶段；其最终获得的回报与需要频繁LLM交互的方法具有可比性，但大幅减少了LLM调用次数。

Conclusion: 通过记忆图机制有效复用历史成功经验，本方法在保持性能的同时显著降低了对大型语言模型的在线依赖，为稀疏奖励强化学习提供了可扩展且可靠的解决方案，证明了离线经验指导的有效性。

Abstract: In environments with sparse or delayed rewards, reinforcement learning (RL) incurs high sample complexity due to the large number of interactions needed for learning. This limitation has motivated the use of large language models (LLMs) for subgoal discovery and trajectory guidance. While LLMs can support exploration, frequent reliance on LLM calls raises concerns about scalability and reliability. We address these challenges by constructing a memory graph that encodes subgoals and trajectories from both LLM guidance and the agent's own successful rollouts. From this graph, we derive a utility function that evaluates how closely the agent's trajectories align with prior successful strategies. This utility shapes the advantage function, providing the critic with additional guidance without altering the reward. Our method relies primarily on offline input and only occasional online queries, avoiding dependence on continuous LLM supervision. Preliminary experiments in benchmark environments show improved sample efficiency and faster early learning compared to baseline RL methods, with final returns comparable to methods that require frequent LLM interaction.

</details>


### [55] [Calibrated Adaptation: Bayesian Stiefel Manifold Priors for Reliable Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2602.17809)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 针对参数高效微调方法缺乏不确定性估计导致校准性差的问题，本文提出Stiefel-Bayes Adapters (SBA)，通过在Stiefel流形上施加矩阵Langevin先验并采用切空间拉普拉斯近似，实现了校准预测。在GLUE/SuperGLUE基准及多模型上，SBA在保持LoRA相当性能的同时，将预期校准误差降低18-34%，分布偏移下的选择性预测AUROC提升12-25%，且优于5个LoRA集成的OOD检测能力。


<details>
  <summary>Details</summary>
Motivation: LoRA等参数高效微调方法缺乏原则性的不确定性量化机制，导致模型预测校准性差且在分布偏移时行为不可靠。现有方法使用平直空间高斯先验再投影至正交约束，会引入结构性方差膨胀，无法为适配器子空间提供符合几何结构的归纳偏置。

Method: 提出Stiefel-Bayes Adapters (SBA)，一种贝叶斯参数高效微调框架。核心方法为：(1)在Stiefel流形上对正交适配器因子施加矩阵Langevin先验，自然编码子空间应良好条件化与正交的归纳偏置；(2)通过测地线回缩的切空间拉普拉斯近似进行后验推断，从理论上避免投影法的结构性方差膨胀问题。

Result: 在RoBERTa-large、LLaMA-2-7B/13B、Mistral-7B、Qwen2.5-7B等模型上，SBA实现与LoRA/DoRA相当的任务性能：1)预期校准误差(ECE)较确定性基线降低18-34%；2)分布偏移下选择性预测AUROC提升12-25%；3)在抽象摘要任务中表现优异；4)以极少的参数成本优于5个LoRA模型的深度集成在分布外(OOD)检测性能。

Conclusion: 不确定性量化的位置至关重要——在正确的几何结构(Stiefel流形)上建模比简单添加贝叶斯处理更重要。SBA通过流形上的内在推断实现了更优的预测校准性与分布鲁棒性，同时保持参数高效性，为大型语言模型的不确定性感知微调提供了理论严谨且实用的新范式。

Abstract: Parameter-efficient fine-tuning methods such as LoRA enable practical adaptation of large language models but provide no principled uncertainty estimates, leading to poorly calibrated predictions and unreliable behavior under domain shift. We introduce Stiefel-Bayes Adapters (SBA), a Bayesian PEFT framework that places a Matrix Langevin prior over orthonormal adapter factors on the Stiefel manifold $\St$ and performs approximate posterior inference via tangent space Laplace approximation with geodesic retraction. Unlike Gaussian priors in flat space projected onto orthogonality constraints, our prior on the manifold naturally encodes the inductive bias that adapter subspaces should be well conditioned and orthogonal, while the posterior provides calibrated predictive uncertainty without recalibration. We prove formally that the tangent space approximation strictly avoids the structural variance inflation inherent in projecting from ambient space, establishing a rigorous theoretical advantage for intrinsic manifold inference. Across GLUE and SuperGLUE benchmarks on RoBERTa-large, LLaMA-2-7B, LLaMA-2-13B, Mistral-7B, and Qwen2.5-7B, domain shift evaluations, selective prediction protocols, and an abstractive summarization task, SBA achieves task performance comparable to LoRA and DoRA while reducing Expected Calibration Error by 18 to 34\% over deterministic baselines, improving selective prediction AUROC by 12 to 25\% under domain shift, and outperforming deep ensembles of five LoRA models on OOD detection at a fraction of the parameter cost. Our results demonstrate that where you place uncertainty, on the right geometric structure, matters more than simply adding any Bayesian treatment to adapters.

</details>


### [56] [Causality by Abstraction: Symbolic Rule Learning in Multivariate Timeseries with Large Language Models](https://arxiv.org/abs/2602.17829)
*Preetom Biswas,Giulia Pedrielli,K. Selçuk Candan*

Main category: cs.LG

TL;DR: 针对具有延迟效应的时间序列因果推断难题，本文提出ruleXplain框架，通过大语言模型从模拟驱动的动态系统中提取可验证的符号化因果规则。该框架利用约束符号规则语言结合时序算子，通过模拟器生成反事实轨迹作为LLM上下文，并采用闭环优化确保规则一致性，有效解决多输入轨迹导致相似输出时的可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据中推断延迟因果关系是根本挑战，尤其当系统呈现无法被简单函数映射的复杂动力学时。传统方法因多个不同输入轨迹可能产生几乎不可区分的输出，难以生成泛化且可解释的因果解释，亟需可验证的形式化规则提取方法。

Method: ruleXplain框架方法包括：(1)设计带有时序算子和延迟语义的约束符号规则语言；(2)利用模拟器生成产生相似输出的多样化反事实输入轨迹；(3)聚类反事实轨迹并作为上下文输入大语言模型；(4)通过结构化提示使LLM生成编码联合时序趋势的符号规则；(5)闭环精化过程确保规则一致性与语义有效性。

Result: 研究在PySIRTEM流行病模拟器(检测率输入→日感染数输出)和EnergyPlus建筑能源模拟器(温度/太阳辐照度输入→用电需求输出)上验证框架。进行三类实验：通过输入重建评估规则集有效性；消融研究评估规则集的因果编码能力；泛化测试评估提取规则在具有不同相位动力学的未见输出趋势上的适用性。

Conclusion: 该工作提出了首个基于LLM的符号化因果规则提取框架ruleXplain，为复杂动态系统中延迟因果关系的可解释建模提供了新思路，并通过多领域模拟器验证了其可行性和泛化潜力。

Abstract: Inferring causal relations in timeseries data with delayed effects is a fundamental challenge, especially when the underlying system exhibits complex dynamics that cannot be captured by simple functional mappings. Traditional approaches often fail to produce generalized and interpretable explanations, as multiple distinct input trajectories may yield nearly indistinguishable outputs. In this work, we present ruleXplain, a framework that leverages Large Language Models (LLMs) to extract formal explanations for input-output relations in simulation-driven dynamical systems. Our method introduces a constrained symbolic rule language with temporal operators and delay semantics, enabling LLMs to generate verifiable causal rules through structured prompting. ruleXplain relies on the availability of a principled model (e.g., a simulator) that maps multivariate input time series to output time series. Within ruleXplain, the simulator is used to generate diverse counterfactual input trajectories that yield similar target output, serving as candidate explanations. Such counterfactual inputs are clustered and provided as context to the LLM, which is tasked with the generation of symbolic rules encoding the joint temporal trends responsible for the patterns observable in the output times series. A closed-loop refinement process ensures rule consistency and semantic validity. We validate the framework using the PySIRTEM epidemic simulator, mapping testing rate inputs to daily infection counts; and the EnergyPlus building energy simulator, observing temperature and solar irradiance inputs to electricity needs. For validation, we perform three classes of experiments: (1) the efficacy of the ruleset through input reconstruction; (2) ablation studies evaluating the causal encoding of the ruleset; and (3) generalization tests of the extracted rules across unseen output trends with varying phase dynamics.

</details>


### [57] [MePoly: Max Entropy Polynomial Policy Optimization](https://arxiv.org/abs/2602.17832)
*Hang Liu,Sangli Teng,Maani Ghaffari*

Main category: cs.LG

TL;DR: 针对随机最优控制中策略多模态性与显式概率密度的矛盾，本文提出MePoly——一种基于多项式能量模型的新型策略参数化方法，通过可处理的显式密度实现精确熵最大化，并在理论和实验上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 随机最优控制为复杂决策问题提供统一数学框架，涵盖最大熵强化学习与模仿学习等范式。然而，传统参数化策略难以刻画多模态解，而扩散策略虽能恢复多模态性却缺乏显式概率密度，导致策略梯度优化困难。这一缺陷构成了本文的核心研究动机。

Method: 作者提出MePoly，采用多项式能量模型进行策略参数化。该方法通过多项式能量函数显式定义策略分布的概率密度，使其具备可处理性，从而支持精确的熵最大化计算。

Result: 理论上，该方法根植于经典矩问题，具备对任意分布的通用逼近能力；实验上，MePoly能有效建模复杂非凸流形，在多样化基准测试中性能显著优于现有基线方法。

Conclusion: MePoly成功解决了多模态策略表示与显式概率密度之间的兼容性问题，为随机最优控制提供了更强大的策略参数化工具，其理论严谨性与实证有效性共同确立了该方法的学术价值。

Abstract: Stochastic Optimal Control provides a unified mathematical framework for solving complex decision-making problems, encompassing paradigms such as maximum entropy reinforcement learning(RL) and imitation learning(IL). However, conventional parametric policies often struggle to represent the multi-modality of the solutions. Though diffusion-based policies are aimed at recovering the multi-modality, they lack an explicit probability density, which complicates policy-gradient optimization. To bridge this gap, we propose MePoly, a novel policy parameterization based on polynomial energy-based models. MePoly provides an explicit, tractable probability density, enabling exact entropy maximization. Theoretically, we ground our method in the classical moment problem, leveraging the universal approximation capabilities for arbitrary distributions. Empirically, we demonstrate that MePoly effectively captures complex non-convex manifolds and outperforms baselines in performance across diverse benchmarks.

</details>


### [58] [Learning Optimal and Sample-Efficient Decision Policies with Guarantees](https://arxiv.org/abs/2602.17978)
*Daqian Shao*

Main category: cs.LG

TL;DR: 该论文针对强化学习在高风险实际应用中面临的挑战，特别是离线数据集中的隐藏混杂因子问题，提出三种解决方案：1）基于工具变量和条件矩约束的样本高效算法；2）将其扩展至离线模仿学习；3）开发线性时序逻辑目标的可证明最优学习算法。所有方法均提供收敛性和最优性保证，并在基准测试中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习需要大量在线交互，在高风险场景（如机器人、医疗、金融）中成本高昂且危险。而离线学习又面临隐藏混杂因子导致的虚假相关问题，可能误导智能体采取次优甚至对抗性行为，限制了实际应用。

Method: 采用工具变量法识别因果效应，将其建模为条件矩约束（CMR）问题。受双重/去偏机器学习启发，推导出样本高效的CMR求解算法。具体包括：(1) 针对离线强化学习的隐藏混杂问题设计CMR求解器；(2) 在离线模仿学习中放宽混杂因子条件并适配CMR估计器；(3) 针对线性时序逻辑（LTL）表达的高级目标开发可证明最优的学习算法。

Result: 所提算法在理论上提供收敛速率和最优性保证，实验中显著优于现有先进方法。通过在强化学习基准测试、合成和半合成数据集上的评估，验证了其在样本效率和性能上的优势，证明了其在真实世界决策中的实用性。

Conclusion: 该研究成功解决了离线强化学习中的因果推断难题，为高风险应用提供了理论保证的解决方案。三个技术贡献显著提升了样本效率，拓展了强化学习在复杂决策场景中的应用前景，为现实世界决策支持系统的发展奠定了重要基础。

Abstract: The paradigm of decision-making has been revolutionised by reinforcement learning and deep learning. Although this has led to significant progress in domains such as robotics, healthcare, and finance, the use of RL in practice is challenging, particularly when learning decision policies in high-stakes applications that may require guarantees. Traditional RL algorithms rely on a large number of online interactions with the environment, which is problematic in scenarios where online interactions are costly, dangerous, or infeasible. However, learning from offline datasets is hindered by the presence of hidden confounders. Such confounders can cause spurious correlations in the dataset and can mislead the agent into taking suboptimal or adversarial actions. Firstly, we address the problem of learning from offline datasets in the presence of hidden confounders. We work with instrumental variables (IVs) to identify the causal effect, which is an instance of a conditional moment restrictions (CMR) problem. Inspired by double/debiased machine learning, we derive a sample-efficient algorithm for solving CMR problems with convergence and optimality guarantees, which outperforms state-of-the-art algorithms. Secondly, we relax the conditions on the hidden confounders in the setting of (offline) imitation learning, and adapt our CMR estimator to derive an algorithm that can learn effective imitator policies with convergence rate guarantees. Finally, we consider the problem of learning high-level objectives expressed in linear temporal logic (LTL) and develop a provably optimal learning algorithm that improves sample efficiency over existing methods. Through evaluation on reinforcement learning benchmarks and synthetic and semi-synthetic datasets, we demonstrate the usefulness of the methods developed in this thesis in real-world decision making.

</details>


### [59] [PHAST: Port-Hamiltonian Architecture for Structured Temporal Dynamics Forecasting](https://arxiv.org/abs/2602.17998)
*Shubham Bhardwaj,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: 本文针对仅有位置观测的物理系统动力学预测问题，提出PHAST框架。该框架基于端口哈密顿体系，将哈密顿量分解为势能、质量和阻尼三部分，通过低秩正定参数化和Strang分裂实现稳定的长期预测和物理参数可识别性。


<details>
  <summary>Details</summary>
Motivation: 实际物理系统具有耗散特性，从部分观测（仅位置）预测其动力学是科学机器学习的核心挑战。端口哈密顿框架通过显式分离守恒与耗散部分，可保证能量单调递减。然而，在位置-only设定下，如何同时实现稳定长期预测和物理参数可识别性仍属难题。

Method: 提出PHAST（Port-Hamiltonian Architecture for Structured Temporal dynamics）框架：1）将哈密顿量分解为势能V(q)、质量M(q)和阻尼D(q)；2）支持已知/部分/未知三种知识场景；3）采用低秩PSD/SPD矩阵参数化保证正定性；4）使用Strang分裂进行动力学积分。

Result: 在13个涵盖机械、电气、分子、热、引力及生态系统的q-only基准测试中，PHAST在长期预测精度上超越所有基线方法。当提供足够结构锚点时，可恢复物理意义参数；反之则存在规范自由度导致识别困难。研究进一步提出了预测稳定性与可识别性分离的两轴评估体系。

Conclusion: 该工作验证了结构化架构在物理系统学习中的重要性，揭示了长期预测稳定性与参数可识别性的根本差异。端口哈密顿框架在充足先验知识下可同时实现稳定预测和物理解释性，为科学机器学习提供了新范式。

Abstract: Real physical systems are dissipative -- a pendulum slows, a circuit loses charge to heat -- and forecasting their dynamics from partial observations is a central challenge in scientific machine learning. We address the \emph{position-only} (q-only) problem: given only generalized positions~$q_t$ at discrete times (momenta~$p_t$ latent), learn a structured model that (a)~produces stable long-horizon forecasts and (b)~recovers physically meaningful parameters when sufficient structure is provided. The port-Hamiltonian framework makes the conservative-dissipative split explicit via $\dot{x}=(J-R)\nabla H(x)$, guaranteeing $dH/dt\le 0$ when $R\succeq 0$. We introduce \textbf{PHAST} (Port-Hamiltonian Architecture for Structured Temporal dynamics), which decomposes the Hamiltonian into potential~$V(q)$, mass~$M(q)$, and damping~$D(q)$ across three knowledge regimes (KNOWN, PARTIAL, UNKNOWN), uses efficient low-rank PSD/SPD parameterizations, and advances dynamics with Strang splitting. Across thirteen q-only benchmarks spanning mechanical, electrical, molecular, thermal, gravitational, and ecological systems, PHAST achieves the best long-horizon forecasting among competitive baselines and enables physically meaningful parameter recovery when the regime provides sufficient anchors. We show that identification is fundamentally ill-posed without such anchors (gauge freedom), motivating a two-axis evaluation that separates forecasting stability from identifiability.

</details>


### [60] [ADAPT: Hybrid Prompt Optimization for LLM Feature Visualization](https://arxiv.org/abs/2602.17867)
*João N. Cardoso,Arlindo L. Oliveira,Bruno Martins*

Main category: cs.LG

TL;DR: 该论文针对大型语言模型特征可视化因文本离散性和局部最优难题而难以应用的问题，提出ADAPT混合方法，结合束搜索与自适应梯度变异，在Gemma 2模型上实现了显著优于现有方法的效果，证明了LLM特征可视化的可行性。


<details>
  <summary>Details</summary>
Motivation: 理解LLM激活空间中学习方向所编码的特征需要找到能强烈激活它们的输入。虽然特征可视化是比数据集搜索更经济的替代方案，但由于文本的离散性以及现有提示优化技术在该领域极易陷入局部最优，这一方法在大型语言模型中尚未得到充分探索。

Method: ADAPT是一种混合方法，其核心设计包括：（1）束搜索初始化，提供高质量的起点分布；（2）自适应梯度引导变异，根据特定失败模式动态调整搜索策略。该方法专门针对LLM特征可视化易陷入局部最优的特性而设计。

Result: 在Gemma 2 2B的稀疏自编码器潜在空间上的评估表明，ADAPT在跨层和跨潜在类型的一致性上显著优于先前方法。研究提出基于数据集激活统计的新评估指标，实现了更严格的比较基准。

Conclusion: 研究表明LLM特征可视化是可实现的，但其有效实施需要针对该领域特定挑战（如离散文本和局部最优）量身定制设计假设。ADAPT为这一领域提供了原则性的解决方案。

Abstract: Understanding what features are encoded by learned directions in LLM activation space requires identifying inputs that strongly activate them. Feature visualization, which optimizes inputs to maximally activate a target direction, offers an alternative to costly dataset search approaches, but remains underexplored for LLMs due to the discrete nature of text. Furthermore, existing prompt optimization techniques are poorly suited to this domain, which is highly prone to local minima. To overcome these limitations, we introduce ADAPT, a hybrid method combining beam search initialization with adaptive gradient-guided mutation, designed around these failure modes. We evaluate on Sparse Autoencoder latents from Gemma 2 2B, proposing metrics grounded in dataset activation statistics to enable rigorous comparison, and show that ADAPT consistently outperforms prior methods across layers and latent types. Our results establish that feature visualization for LLMs is tractable, but requires design assumptions tailored to the domain.

</details>


### [61] [NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs](https://arxiv.org/abs/2602.18008)
*Zihan Guan,Rituparna Datta,Mengxuan Hu,Shunshun Liu,Aiying Zhang,Prasanna Balachandran,Sheng Li,Anil Vullikanti*

Main category: cs.LG

TL;DR: 本文针对LLM自动生成机理模型在实际应用中可靠性不足的问题，提出了NIMM评估框架和NIMMgen生成框架，通过迭代优化提升代码正确性和模型有效性，在三个科学领域的数据集上验证了性能并支持反事实干预模拟。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体框架在自动构建机理模型时过度简化了真实世界条件，导致模型在实际场景中的可靠性不明确，亟需一个更贴近现实的评估框架来揭示真实挑战并指导改进。

Method: 1) 设计NIMM评估框架，在部分观测和多样化任务目标的真实条件下评估LLM生成机理模型；2) 开发NIMMgen智能体框架，通过迭代细化机制增强代码正确性和实践有效性。

Result: NIMM评估揭示了现有基线模型在有效性和代码正确性层面的根本性挑战；NIMMgen在三个不同科学领域的数据集上表现出强性能，且生成的机理模型支持反事实干预模拟。

Conclusion: LLM自动生成机理模型面临真实世界应用的关键挑战，但通过神经整合与迭代优化的NIMMgen框架可显著提升模型可靠性，为科学决策提供可验证的模拟工具。

Abstract: Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling (NIMM) evaluation framework, which evaluates LLM-generated mechanistic models under realistic settings with partial observations and diversified task objectives. Our evaluation reveals fundamental challenges in current baselines, ranging from model effectiveness to code-level correctness. Motivated by these findings, we design NIMMgen, an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement. Experiments across three datasets from diversified scientific domains demonstrate its strong performance. We also show that the learned mechanistic models support counterfactual intervention simulation.

</details>


### [62] [JAX-Privacy: A library for differentially private machine learning](https://arxiv.org/abs/2602.17861)
*Ryan McKenna,Galen Andrew,Borja Balle,Vadym Doroshenko,Arun Ganesh,Weiwei Kong,Alex Kurakin,Brendan McMahan,Mikhail Pravilov*

Main category: cs.LG

TL;DR: JAX-Privacy是一个旨在简化差分隐私机器学习机制部署的开源库，遵循可用性、灵活性和效率的设计原则，为研究人员和从业者提供统一的解决方案。


<details>
  <summary>Details</summary>
Motivation: 差分隐私机器学习实现复杂，现有工具难以同时满足研究人员深度定制和从业者开箱即用的需求，缺乏标准化且可验证的模块化组件。

Method: 基于JAX框架开发，提供经过验证的模块化原语，覆盖机制设计全流程（批次选择、梯度裁剪、噪声添加、核算与审计），并集成最新研究成果。

Result: 构建了一个既能支持研究人员灵活定制，又能为从业者提供便捷开箱体验的高性能差分隐私机器学习库。

Conclusion: JAX-Privacy通过标准化组件和模块化设计，有效降低了差分隐私机器学习的实现门槛，推动了该技术在研究和实践中的应用。

Abstract: JAX-Privacy is a library designed to simplify the deployment of robust and performant mechanisms for differentially private machine learning. Guided by design principles of usability, flexibility, and efficiency, JAX-Privacy serves both researchers requiring deep customization and practitioners who want a more out-of-the-box experience. The library provides verified, modular primitives for critical components for all aspects of the mechanism design including batch selection, gradient clipping, noise addition, accounting, and auditing, and brings together a large body of recent research on differentially private ML.

</details>


### [63] [Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards](https://arxiv.org/abs/2602.18037)
*Johannes Ackermann,Michael Noukhovitch,Takashi Ishida,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 本文针对语言模型后训练中的奖励黑客问题，提出用梯度正则化(GR)替代传统的KL惩罚。通过理论推导建立奖励准确性与最优解平坦度的关联，证明GR能引导训练至更平坦区域以保持奖励模型准确性，并采用有限差分法高效实现。实证表明GR在RLHF、数学推理和LLM-as-a-Judge任务上均优于KL惩罚。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF/RLVR训练存在奖励黑客问题，即策略利用奖励模型的不准确性学习非预期行为。主流解决方案是KL惩罚限制策略更新，但该方法存在局限性。本文旨在从全新视角——通过偏置训练区域来提升奖励模型准确性——解决该问题。

Method: 1) 理论推导：建立奖励模型准确性与收敛最优解平坦度之间的数学关联；2) 提出梯度正则化(GR)方法，通过正则化梯度来偏置训练至平坦区域；3) 采用高效的有限差分估计实现显式GR；4) 与参考重置KL惩罚进行对比分析。

Result: 1) 实证验证梯度范数与奖励准确性的正相关性；2) 揭示参考重置KL惩罚本质是GR的隐式实现；3) 在多样RL实验中GR全面优于KL惩罚：RLHF任务获得更高GPT评判胜率，数学推理任务避免过度关注格式，LLM-as-a-Judge任务有效防止评判模型被攻击。

Conclusion: 梯度正则化是解决奖励黑客问题的新范式，比传统KL惩罚更有效。其核心思想是通过引导模型训练至奖励模型更准确的平坦区域，从而维持奖励可靠性并提升策略学习效果，为语言模型后训练提供了更优的技术路径。

Abstract: Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.

</details>


### [64] [Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory](https://arxiv.org/abs/2602.18297)
*Usman Anwar,Tim Bakker,Dana Kianfar,Cristina Pinneri,Christos Louizos*

Main category: cs.LG

TL;DR: 本文从信息论视角分析LLM思维链(CoT)监控器的可监控性，揭示CoT与输出间的非零互信息是必要但不充分条件。研究识别信息缺口和提取误差两大实践误差源，并提出基于oracle奖励和条件互信息最大化的训练方法，显著提升监控准确率并有效缓解奖励攻击问题。


<details>
  <summary>Details</summary>
Motivation: 现有CoT监控器在检测LLM输出不良属性（如代码生成中的测试攻击）时面临理论局限：非零互信息无法保证可监控性。实践中，监控性能受近似误差制约，缺乏系统性改进方法，亟需理论指导和有效训练策略以提升监控可靠性。

Method: 采用信息论分析框架：1) 证明非零互信息的必要不充分性；2) 量化信息缺口（监控器对CoT信息的提取能力）和提取误差（监控函数逼近最优的程度）；3) 提出两种训练范式：oracle-based方法（直接奖励最大化监控准确率的CoT）和免标签方法（最大化输出与CoT的条件互信息）。

Result: 跨多个环境的实验表明，两种方法均能显著提升监控准确率，有效防止CoT退化现象，并在任务奖励不完美指定的情况下成功缓解奖励攻击问题。

Conclusion: 本研究为CoT监控性奠定了理论基础，明确了影响监控性能的关键误差源，提供了可系统优化监控效果的可行路径，对开发更鲁棒的LLM对齐和安全机制具有重要指导意义。

Abstract: Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.

</details>


### [65] [On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction](https://arxiv.org/abs/2602.18301)
*Ivan Bondarenko,Egor Palkin,Fedor Tikunov*

Main category: cs.LG

TL;DR: 本文通过系列实验探究大型语言模型中两个原型标记的信息编码机制：解耦语义/句法内容、分析e-标记稳定性、可视化注意力模式，并测试两种正则化方案（锚点损失与关系蒸馏）来为e-标记注入语义结构。研究发现m-标记比e-标记更强地捕获语义信息；锚点约束与重构准确率存在明显权衡；关系蒸馏可在不牺牲重构质量的前提下将批次级语义关系迁移至原型标记空间，为非自回归seq2seq系统提供了可行性支持。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型需逐标记生成，序列长度为n时需n次前向传播，效率低下。近期研究表明冻结LLM可从两个学习到的原型标记中一次性重构数百个标记，暗示了超越自回归范式的可能。本文旨在深入理解这些原型标记编码的信息本质及其行为特性，为开发高效非自回归序列生成系统奠定理论基础。

Method: 研究采用多维度实验方法：1) 解耦两个原型标记中的语义与句法信息分布；2) 分析e-标记在重构过程中的稳定性属性；3) 可视化并解析模型对e-标记的注意力模式；4) 设计两种基于教师嵌入的正则化方案——基于锚点的对比损失和关系蒸馏目标函数，以显式地向e-标记空间注入结构化语义约束。

Result: 实验揭示三点核心发现：首先，在标准优化条件下，m-标记捕获语义信息的能力显著强于e-标记；其次，锚点约束虽能塑造语义结构，但与重构准确率呈尖锐的此消彼长关系；最后，关系蒸馏成功实现了批次级语义关系向原型标记空间的迁移，且未造成重构质量损失。

Conclusion: 本研究证实原型标记可作为有效的中间表示，支持未来非自回归seq2seq系统的可行性。关系蒸馏方法尤其具有前景，它能在保持高重构保真度的同时，为标记空间注入可控的语义结构，为非自回归生成范式提供了重要的技术路径。

Abstract: Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for "imposing" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.

</details>


### [66] [On the "Induction Bias" in Sequence Models](https://arxiv.org/abs/2602.18333)
*M. Reza Ebrahimi,Michaël Defferrard,Sunny Panchal,Roland Memisevic*

Main category: cs.LG

TL;DR: 研究发现Transformer在状态跟踪任务上数据效率远低于RNN，需要更多训练数据且无法跨序列长度共享机制，而RNN能有效共享权重，证明状态跟踪是Transformer在分布内也存在的根本性缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型应用成功，但其状态跟踪能力存疑，现有研究多关注分布外泛化失败。本文转而探究该局限在分布内的表现及影响。

Method: 通过大规模实验比较Transformer与RNN在多种监督机制下的数据效率，并分析两者在不同序列长度间共享状态跟踪机制的程度。

Result: Transformer所需训练数据随状态空间和序列长度增长的速度远超RNN；其在不同长度间权重共享可忽略甚至有害，学习孤立的长度特定解；而RNN通过权重共享实现摊销学习，不同长度数据能相互提升性能。

Conclusion: 研究表明，即使在分布内设置下，状态跟踪仍是Transformer面临的根本性挑战，其机制共享能力弱于RNN。

Abstract: Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.

</details>


### [67] [Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2602.18117)
*Yongjae Shin,Jongseong Chae,Jongeui Park,Youngchul Sung*

Main category: cs.LG

TL;DR: 针对离线强化学习向在线微调转换的关键挑战，本文提出FINO方法，通过流匹配策略注入噪声增强探索，并结合熵引导采样平衡探索与利用，在有限在线预算下实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 生成模型在强化学习中取得显著成功，但现有研究将在线微调简单视为离线预训练的延续，未能解决离线到在线转换过程中的关键挑战。

Method: 提出FINO（Flow Matching with Injected Noise for Offline-to-Online RL）方法，利用流匹配策略，在训练中注入噪声以促进对离线数据集未见动作的探索，同时结合熵引导采样机制动态平衡探索与利用。

Result: 在多种具有挑战性的任务上，FINO在有限在线预算条件下持续表现出优越性能。

Conclusion: FINO通过噪声注入和熵引导采样有效解决了离线到在线强化学习的转换挑战，提高了样本效率，为生成模型策略的在线微调提供了新思路。

Abstract: Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL). While they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed. In this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL. FINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset. In addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning. Experiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.

</details>


### [68] [Breaking the Correlation Plateau: On the Optimization and Capacity Limits of Attention-Based Regressors](https://arxiv.org/abs/2602.17898)
*Jingquan Yan,Yuwei Miao,Peiran Yu,Junzhou Huang*

Main category: cs.LG

TL;DR: 本文理论分析了注意力回归模型训练中的PCC plateau现象，揭示MSE优化与PCC梯度的根本冲突以及softmax注意力的凸性容量限制。提出Extrapolative Correlation Attention (ECA)机制，通过理论驱动方法突破凸包约束，在多项基准测试中显著提升相关性且保持MSE性能。


<details>
  <summary>Details</summary>
Motivation: 注意力回归模型联合优化MSE和PCC损失时，普遍存在PCC指标早期停滞的plateau现象，而MSE持续下降。这一现象缺乏严谨理论解释，制约了模型性能提升，特别是在同质数据场景下。

Method: 提出Extrapolative Correlation Attention (ECA)机制，引入理论驱动的优化机制以解决MSE-PCC梯度冲突，并通过外推能力突破传统凸聚合算子的凸包约束，提升PCC优化效果。

Result: 在包括挑战性同质数据设置的多项基准测试中，ECA持续突破PCC plateau，实现显著的相关性提升，同时不损害MSE性能。

Conclusion: 理论分析揭示了PCC plateau的根本原因：优化目标冲突与模型容量限制。ECA通过创新机制同时解决这两个问题，为注意力回归模型提供了新的优化范式，有效提升了形状匹配能力。

Abstract: Attention-based regression models are often trained by jointly optimizing Mean Squared Error (MSE) loss and Pearson correlation coefficient (PCC) loss, emphasizing the magnitude of errors and the order or shape of targets, respectively. A common but poorly understood phenomenon during training is the PCC plateau: PCC stops improving early in training, even as MSE continues to decrease. We provide the first rigorous theoretical analysis of this behavior, revealing fundamental limitations in both optimization dynamics and model capacity. First, in regard to the flattened PCC curve, we uncover a critical conflict where lowering MSE (magnitude matching) can paradoxically suppress the PCC gradient (shape matching). This issue is exacerbated by the softmax attention mechanism, particularly when the data to be aggregated is highly homogeneous. Second, we identify a limitation in the model capacity: we derived a PCC improvement limit for any convex aggregator (including the softmax attention), showing that the convex hull of the inputs strictly bounds the achievable PCC gain. We demonstrate that data homogeneity intensifies both limitations. Motivated by these insights, we propose the Extrapolative Correlation Attention (ECA), which incorporates novel, theoretically-motivated mechanisms to improve the PCC optimization and extrapolate beyond the convex hull. Across diverse benchmarks, including challenging homogeneous data setting, ECA consistently breaks the PCC plateau, achieving significant improvements in correlation without compromising MSE performance.

</details>


### [69] [Distribution-Free Sequential Prediction with Abstentions](https://arxiv.org/abs/2602.17918)
*Jialin Yu,Moïse Blanchard*

Main category: cs.LG

TL;DR: 该研究解决了在分布未知的半对抗性序列预测问题，其中学习者可通过弃权避免对抗样本的预测代价。作者提出基于提升（boosting）弱学习器的 AbstainBoost 算法，在 oblivious 与 adaptive 对抗者下，对一般 VC 类及线性分类器等结构化函数类均实现了次线性误差，并给出了误分类误差与错误弃权次数之间的多项式权衡下界。


<details>
  <summary>Details</summary>
Motivation: 经典随机 i.i.d. 设置要求有限 VC 维才能学习，而完全对抗设置则限制极强。Goel 等人（2023）的工作需事先知道干净样本的分布 μ，这在理论与实践中均为强假设。本文旨在移除这一假设，研究分布自由的 abstention learning，使得学习器无需分布先验知识即可在对抗污染的数据流中实现学习保证，更具现实意义。

Method: 本文提出 \textsc{AbstainBoost} 算法，采用提升（boosting）框架，通过组合多个弱学习器实现强学习保证。算法允许学习器在每轮选择预测或弃权，通过自适应调整弱学习器权重，在未知分布情况下控制整体误差。对于 oblivious 对抗者，算法适用于任意 VC 类；对于 adaptive 对抗者，则适用于线性分类器等结构化函数类。

Result: 主要结果包括：（1）在分布自由的 abstention learning 下，AbstainBoost 对 oblivious 对抗者在任意 VC 类上实现次线性误差；（2）对 adaptive 对抗者，该算法在线性分类器等结构化类上具有类似保证；（3）下界分析揭示了误分类误差与错误弃权次数之间存在多项式权衡关系。

Conclusion: 本文成功将 abstention learning 推广至分布自由场景，表明即使不知道干净样本的分布，学习器仍能在半对抗性环境中通过弃权机制实现有效学习。AbstainBoost 为处理对抗污染数据提供了新工具，理论保证涵盖 oblivious 与 adaptive 对抗者，填补了分布自由 abstention learning 的理论空白，并为实际对抗鲁棒学习提供了理论支撑。

Abstract: We study a sequential prediction problem in which an adversary is allowed to inject arbitrarily many adversarial instances in a stream of i.i.d.\ instances, but at each round, the learner may also \emph{abstain} from making a prediction without incurring any penalty if the instance was indeed corrupted. This semi-adversarial setting naturally sits between the classical stochastic case with i.i.d.\ instances for which function classes with finite VC dimension are learnable; and the adversarial case with arbitrary instances, known to be significantly more restrictive. For this problem, Goel et al. (2023) showed that, if the learner knows the distribution $μ$ of clean samples in advance, learning can be achieved for all VC classes without restrictions on adversary corruptions. This is, however, a strong assumption in both theory and practice: a natural question is whether similar learning guarantees can be achieved without prior distributional knowledge, as is standard in classical learning frameworks (e.g., PAC learning or asymptotic consistency) and other non-i.i.d.\ models (e.g., smoothed online learning). We therefore focus on the distribution-free setting where $μ$ is \emph{unknown} and propose an algorithm \textsc{AbstainBoost} based on a boosting procedure of weak learners, which guarantees sublinear error for general VC classes in \emph{distribution-free} abstention learning for oblivious adversaries. These algorithms also enjoy similar guarantees for adaptive adversaries, for structured function classes including linear classifiers. These results are complemented with corresponding lower bounds, which reveal an interesting polynomial trade-off between misclassification error and number of erroneous abstentions.

</details>


### [70] [Capabilities Ain't All You Need: Measuring Propensities in AI](https://arxiv.org/abs/2602.18182)
*Daniel Romero-Alvarado,Fernando Martínez-Plumed,Lorenzo Pacchiardi,Hugo Save,Siddhesh Milind Pawar,Behzad Mehrbakhsh,Pablo Antonio Moreno Casares,Ben Slater,Paolo Bova,Peter Romero,Zachary R. Tyler,Jonathan Prunty,Luning Sun,Jose Hernandez-Orallo*

Main category: cs.LG

TL;DR: 该论文提出首个测量AI倾向性的形式化框架，采用双逻辑模型刻画模型成功率在倾向性"理想带"内最高的特性，并证明结合倾向性与能力评估能比单一指标更准确地预测AI行为。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估过度聚焦于能力测量，而忽视倾向性（模型展现特定行为的倾向）对性能与安全的关键影响。传统IRT模型将任务成功描述为能力与任务需求的单调函数，无法刻画倾向性中"过犹不及"的非线性特征。

Method: 提出双逻辑（bilogistic）框架，将模型成功概率建模为在倾向性"理想带"范围内最高的函数。利用配备任务无关量规的LLM估计理想带的边界阈值，并在六个倾向性被人为调控的LLM家族上进行验证。

Result: 该框架能精确量化倾向性偏移程度及其对任务表现的影响；基于单一基准测得的倾向性可泛化预测模型在保留任务上的行为；融合倾向性与能力特征比单独使用任一指标具有更强的预测效力。

Conclusion: 该研究建立了严谨的AI倾向性测量范式，揭示了倾向性与能力互补的预测价值，为未来AI行为预测与安全评估提供了更全面的理论基础和方法论工具。

Abstract: AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an "ideal band". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.

</details>


### [71] [LERD: Latent Event-Relational Dynamics for Neurodegenerative Classification](https://arxiv.org/abs/2602.18195)
*Hairong Chen,Yicheng Feng,Ziyu Jia,Samir Bhatt,Hengguan Huang*

Main category: cs.LG

TL;DR: 本研究提出LERD，一种端到端贝叶斯电生理神经动力学系统，可直接从多通道EEG推断潜在神经事件及其关系结构，无需事件标注。该方法融合连续时间事件推断、随机事件生成过程和电生理先验，在合成与真实AD EEG数据上均显著优于现有基线，为AD诊断提供可解释的动力学特征。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病(AD)改变脑电生理活动并破坏多通道EEG动力学模式，使EEG成为筛查和监测疾病的重要工具。但现有方法多依赖黑盒分类器，缺乏对信号生成底层动力学的显式建模，限制了解释性和临床实用性。

Method: LERD系统核心包括：(1)连续时间事件推断模块；(2)随机事件生成过程建模灵活时间模式；(3)电生理启发的动力学先验提供约束。理论分析给出可处理的训练边界和关系动力学稳定性保证，实现端到端训练。

Result: 在合成基准测试和两个真实AD EEG队列上的实验表明，LERD持续超越强基线方法，其学习到的潜在神经事件摘要与生理机制一致，能有效表征不同组别间的动力学差异。

Conclusion: 该研究为基于EEG的AD分析提供了可解释的动力学建模框架，能够捕捉疾病相关的神经活动变化，为开发临床实用的筛查和监测工具开辟了新途径。

Abstract: Alzheimer's disease (AD) alters brain electrophysiology and disrupts multichannel EEG dynamics, making accurate and clinically useful EEG-based diagnosis increasingly important for screening and disease monitoring. However, many existing approaches rely on black-box classifiers and do not explicitly model the underlying dynamics that generate observed signals. To address these limitations, we propose LERD, an end-to-end Bayesian electrophysiological neural dynamical system that infers latent neural events and their relational structure directly from multichannel EEG without event or interaction annotations. LERD combines a continuous-time event inference module with a stochastic event-generation process to capture flexible temporal patterns, while incorporating an electrophysiology-inspired dynamical prior to guide learning in a principled way. We further provide theoretical analysis that yields a tractable bound for training and stability guarantees for the inferred relational dynamics. Extensive experiments on synthetic benchmarks and two real-world AD EEG cohorts demonstrate that LERD consistently outperforms strong baselines and yields physiology-aligned latent summaries that help characterize group-level dynamical differences.

</details>


### [72] [Tighter Regret Lower Bound for Gaussian Process Bandits with Squared Exponential Kernel in Hypersphere](https://arxiv.org/abs/2602.17940)
*Shogo Iwazaki*

Main category: cs.LG

TL;DR: 针对平方指数核高斯过程老虎机问题，本文在超球体输入域下建立了算法无关的频数派最坏情况下界，证明任何算法都会遭受Ω(√(T (ln T)^d (ln ln T)^{-d}))的累积遗憾，且需要Ω(ε^{-2}(ln(1/ε))^d (ln ln(1/ε))^{-d})步才能找到ε-最优解，同时给出最大信息增益的改进上界O((ln T)^{d+1}(ln ln T)^{-d})，部分解决了维度依赖对数因子间隙这一未解问题。


<details>
  <summary>Details</summary>
Motivation: 高斯过程老虎机中平方指数核应用广泛，但现有上界与下界在维度依赖的对数因子间存在显著间隙，这是该领域尚未解决的核心理论问题。

Method: 采用算法无关的最坏情况分析框架，在固定超球体输入域和已知RKHS范数约束下，针对平方指数核构造紧致下界实例。

Result: 证明了累积遗憾下界Ω(√(T (ln T)^d (ln ln T)^{-d}))和简单遗憾下界Ω(ε^{-2}(ln(1/ε))^d (ln ln(1/ε))^{-d})，同时将最大信息增益上界改进至O((ln T)^{d+1}(ln ln T)^{-d})。

Conclusion: 在超球体输入域假设下，该工作部分解决了对数因子间隙问题，表明现有最优算法在去除维度依赖因子后已达到最优，仅相差维度无关的对数因子。

Abstract: We study an algorithm-independent, worst-case lower bound for the Gaussian process (GP) bandit problem in the frequentist setting, where the reward function is fixed and has a bounded norm in the known reproducing kernel Hilbert space (RKHS). Specifically, we focus on the squared exponential (SE) kernel, one of the most widely used kernel functions in GP bandits. One of the remaining open questions for this problem is the gap in the \emph{dimension-dependent} logarithmic factors between upper and lower bounds. This paper partially resolves this open question under a hyperspherical input domain. We show that any algorithm suffers $Ω(\sqrt{T (\ln T)^{d} (\ln \ln T)^{-d}})$ cumulative regret, where $T$ and $d$ represent the total number of steps and the dimension of the hyperspherical domain, respectively. Regarding the simple regret, we show that any algorithm requires $Ω(ε^{-2}(\ln \frac{1}ε)^d (\ln \ln \frac{1}ε)^{-d})$ time steps to find an $ε$-optimal point. We also provide the improved $O((\ln T)^{d+1}(\ln \ln T)^{-d})$ upper bound on the maximum information gain for the SE kernel. Our results guarantee the optimality of the existing best algorithm up to \emph{dimension-independent} logarithmic factors under a hyperspherical input domain.

</details>


### [73] [[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games](https://arxiv.org/abs/2602.18230)
*Jorge Carrasco Pollo,Ioannis Kapetangeorgis,Joshua Rosenthal,John Hua Yao*

Main category: cs.LG

TL;DR: 本文对Abdelnabi等人(2024)提出的基于Scoreable Games的LLM谈判基准测试进行可重复性验证。通过扩展模型测试和引入新指标，发现该基准虽复杂但模型比较模糊，存在信息泄露检测与消融研究不足等问题，凸显了模型比较评估中上下文的重要性。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在多智能体谈判任务中展现出显著潜力，但缺乏稳健且可泛化的基准测试使其评估充满挑战。本文旨在验证Abdelnabi等人(2024)所提谈判基准的可重复性，并深入探究其可用性与泛化能力。

Method: 研究通过复制原始实验，在更多模型上进行测试，并引入额外指标以评估谈判质量及评价公平性。

Result: 结果表明，尽管基准测试具有复杂性，但模型间比较结果存在歧义，引发对其客观性的质疑。此外，实验设置在信息泄露检测与消融研究的彻底性方面存在局限。

Conclusion: 通过对扩展版基准测试上更广泛模型行为的考察分析，本文为潜在用户提供了补充性见解，强调了在模型比较评估中上下文的重要性。

Abstract: Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations.

</details>


### [74] [Understanding the Generalization of Bilevel Programming in Hyperparameter Optimization: A Tale of Bias-Variance Decomposition](https://arxiv.org/abs/2602.17947)
*Yubo Zhou,Jun Shu,Junmin Liu,Deyu Meng*

Main category: cs.LG

TL;DR: 本文针对梯度超参数优化中数据分布导致的方差问题，提出偏差-方差分解分析，并设计了集成超梯度策略来有效降低方差，实验证明该方法在多个任务上提升了超梯度估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有梯度超参数优化的理论研究主要关注估计偏差，忽略了数据分布引入的方差误差，这会导致性能下降。本文旨在弥补这一理论空白。

Method: 本文对超梯度估计误差进行偏差-方差分解，深入分析被前人忽略的方差项，给出超梯度估计的误差界分析，并基于此提出集成超梯度策略，同时建立超额误差与超梯度估计之间的联系。

Result: 集成策略有效降低了方差，在正则化超参数学习、数据超清洗和少样本学习等任务上显著提升了超梯度估计性能，并解释了验证集过拟合等实践现象。

Conclusion: 通过理论分析方差问题并设计集成方法，本文为梯度超参数优化提供了更完整的理论框架和实践指导，超额误差与超梯度估计的联系进一步阐明了性能提升的内在机制。

Abstract: Gradient-based hyperparameter optimization (HPO) have emerged recently, leveraging bilevel programming techniques to optimize hyperparameter by estimating hypergradient w.r.t. validation loss. Nevertheless, previous theoretical works mainly focus on reducing the gap between the estimation and ground-truth (i.e., the bias), while ignoring the error due to data distribution (i.e., the variance), which degrades performance. To address this issue, we conduct a bias-variance decomposition for hypergradient estimation error and provide a supplemental detailed analysis of the variance term ignored by previous works. We also present a comprehensive analysis of the error bounds for hypergradient estimation. This facilitates an easy explanation of some phenomena commonly observed in practice, like overfitting to the validation set. Inspired by the derived theories, we propose an ensemble hypergradient strategy to reduce the variance in HPO algorithms effectively. Experimental results on tasks including regularization hyperparameter learning, data hyper-cleaning, and few-shot learning demonstrate that our variance reduction strategy improves hypergradient estimation. To explain the improved performance, we establish a connection between excess error and hypergradient estimation, offering some understanding of empirical observations.

</details>


### [75] [A Geometric Probe of the Accuracy-Robustness Trade-off: Sharp Boundaries in Symmetry-Breaking Dimensional Expansion](https://arxiv.org/abs/2602.17948)
*Yu Bai,Zhe Wang,Jiarui Zhang,Dong-Xiao Zhang,Yinjun Gao,Jun-Jie Zhang*

Main category: cs.LG

TL;DR: 本研究利用对称性破缺维度扩展(SBDE)探究深度学习中准确率与对抗鲁棒性的权衡机制。通过在图像中插入常值像素打破平移对称性，SBDE可提升干净准确率（如ResNet-18在CIFAR-10上从90.47%升至95.63%）但牺牲对抗鲁棒性。测试时的掩码投影重置辅助像素后能恢复鲁棒性，揭示该权衡源于优化景观在辅助维度上形成陡峭边界。


<details>
  <summary>Details</summary>
Motivation: 深度学习中干净准确率与对抗鲁棒性之间的普遍权衡现象，其几何起源尚未明确，需要深入探究其根本机制。

Method: 提出对称性破缺维度扩展(SBDE)作为可控探针：通过在输入图像中插入常值像素来扩展维度并打破平移对称性。同时设计测试时掩码投影方法，将插入的辅助像素重置为训练时的值，以分离脆弱性来源。

Result: SBDE显著提升干净准确率（ResNet-18在CIFAR-10上从90.47%提升至95.63%），但导致对抗白盒攻击的鲁棒性下降。掩码投影能有效中和攻击并恢复鲁棒性，证明脆弱性几乎完全源于插入的辅助维度。模型通过在辅助轴上创建陡峭的损失梯度边界来实现高精度。

Conclusion: 准确率-鲁棒性悖论具有具体几何解释：优化景观为提升准确率而加深吸引盆，但不可避免地在辅助自由度上筑起陡峭"墙壁"，从而对离流形扰动产生脆弱的敏感性。

Abstract: The trade-off between clean accuracy and adversarial robustness is a pervasive phenomenon in deep learning, yet its geometric origin remains elusive. In this work, we utilize Symmetry-Breaking Dimensional Expansion (SBDE) as a controlled probe to investigate the mechanism underlying this trade-off. SBDE expands input images by inserting constant-valued pixels, which breaks translational symmetry and consistently improves clean accuracy (e.g., from $90.47\%$ to $95.63\%$ on CIFAR-10 with ResNet-18) by reducing parameter degeneracy. However, this accuracy gain comes at the cost of reduced robustness against iterative white-box attacks. By employing a test-time \emph{mask projection} that resets the inserted auxiliary pixels to their training values, we demonstrate that the vulnerability stems almost entirely from the inserted dimensions. The projection effectively neutralizes the attacks and restores robustness, revealing that the model achieves high accuracy by creating \emph{sharp boundaries} (steep loss gradients) specifically along the auxiliary axes. Our findings provide a concrete geometric explanation for the accuracy-robustness paradox: the optimization landscape deepens the basin of attraction to improve accuracy but inevitably erects steep walls along the auxiliary degrees of freedom, creating a fragile sensitivity to off-manifold perturbations.

</details>


### [76] [Bayesian Online Model Selection](https://arxiv.org/abs/2602.17958)
*Aida Afshar,Yuke Zhang,Aldo Pacchiano*

Main category: cs.LG

TL;DR: 针对贝叶斯老虎机中的在线模型选择问题，本文提出一种新型贝叶斯算法。该算法实现了神谕式的贝叶斯遗憾界O(d*M√T + √(MT))，其中M为基学习器数量，d*为最优基学习器的遗憾系数。实证研究表明其性能可与最佳基学习器媲美，并揭示了基学习器间数据共享对缓解先验误设的重要作用。


<details>
  <summary>Details</summary>
Motivation: 该研究的核心挑战在于：当环境实例从先验分布中抽取时，如何设计自适应策略以探索多个老虎机学习器，并在事后与最佳学习器保持竞争力。这引发了对贝叶斯老虎机中在线模型选择根本性探索问题的研究。

Method: 作者提出了一种用于随机老虎机在线模型选择的新颖贝叶斯算法，并系统研究了基学习器间共享数据的效果及其在缓解先验误设中的作用机制。

Result: 理论上，算法获得了O(d*M√T + √(MT))的神谕式贝叶斯遗憾界；实证上，在多种随机老虎机设置中验证了其与最佳基学习器相当的竞争力。

Conclusion: 本文提出的贝叶斯算法有效解决了在线模型选择问题，兼具理论保证与实践性能。研究还发现，基学习器间的数据共享是缓解先验误设的关键机制，为算法鲁棒性提供了重要保障。

Abstract: Online model selection in Bayesian bandits raises a fundamental exploration challenge: When an environment instance is sampled from a prior distribution, how can we design an adaptive strategy that explores multiple bandit learners and competes with the best one in hindsight? We address this problem by introducing a new Bayesian algorithm for online model selection in stochastic bandits. We prove an oracle-style guarantee of $O\left( d^* M \sqrt{T} + \sqrt{(MT)} \right)$ on the Bayesian regret, where $M$ is the number of base learners, $d^*$ is the regret coefficient of the optimal base learner, and $T$ is the time horizon. We also validate our method empirically across a range of stochastic bandit settings, demonstrating performance that is competitive with the best base learner. Additionally, we study the effect of sharing data among base learners and its role in mitigating prior mis-specification.

</details>


### [77] [Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers](https://arxiv.org/abs/2602.18292)
*Xiaotong Ji,Rasul Tutunov,Matthieu Zimmer,Haitham Bou-Ammar*

Main category: cs.LG

TL;DR: 该论文将语言模型解码重新定义为概率单纯形上的正则化优化问题，统一了贪心、Softmax采样、Top-K、Top-P和Sparsemax等现有方法，并提出Best-of-K (BoK)新解码器，在Qwen2.5-Math-7B的MATH500任务中实现+18.6%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有解码策略被当作启发式的旋钮调优问题，缺乏理论指导。作者主张应将解码视为原则性的优化层，在每个token上求解一个平衡模型得分与结构约束的正则化问题，以实现更系统化的解码方法设计。

Method: 提出统一优化框架，将解码形式化为概率单纯形上的正则化优化问题。该框架通过最优性条件统一解释贪心解码、Softmax采样、Top-K、Top-P和Sparsemax等方法。基于此框架，设计Best-of-K (BoK)解码器，采用KL-锚定覆盖目标，针对多采样流程（自洽性、重排序、验证器选择），优化在固定K样本预算内覆盖优质解的概率。

Result: BoK解码器显著提升实证性能。在MATH500数学推理任务上，Qwen2.5-Math-7B模型在高采样温度下准确率提升+18.6%，证明了该方法的有效性。

Conclusion: 该优化框架为解码提供了理论基础，使新解码器的设计摆脱 folklore 依赖，实现了从启发式调优到原则性优化的范式转变。

Abstract: Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.

</details>


### [78] [JPmHC Dynamical Isometry via Orthogonal Hyper-Connections](https://arxiv.org/abs/2602.18308)
*Biswa Sengupta,Jinhua Wang,Leo Brunswic*

Main category: cs.LG

TL;DR: 本文提出JPmHC框架，通过可学习的线性混合器替代残差连接中的恒等映射，并将混合器约束在算子范数有界流形上，以保持Jacobian谱稳定、防止梯度异常。该方法通过自由概率分析预测Jacobian谱、采用内存高效的隐式微分进行不动点投影、利用Cayley变换实现Stiefel约束，在ARC-AGI基准上实现了更快的收敛、更高的准确率和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 尽管Hyper-Connections等深度学习的最新进展通过引入更宽的残差流和多样化的连接模式带来了显著性能提升，但这些创新损害了残差连接的恒等映射特性，导致训练不稳定、可扩展性受限和内存开销增加的问题。

Method: JPmHC框架用作用于n个并行流的可训练线性混合器替代恒等跳跃连接，通过将混合器M约束在算子范数有界流形（如双随机、Stiefel、Grassmann流形）来显式控制梯度条件。具体包括：(1) 基于自由概率理论的结构化跳跃Jacobian谱预测方法；(2) 内存高效的隐式微分不动点投影技术；(3) 通过Cayley变换实现的Stiefel约束混合器。

Result: 在ARC-AGI基准上的实证评估表明，与双随机基线相比，JPmHC实现了更快的收敛速度、更高的准确率和更低的计算成本。

Conclusion: JPmHC作为Hyper-Connections的灵活且可扩展的扩展，推动了谱感知、稳定且高效的深度学习发展，为拓扑架构设计和基础模型演进提供了新的见解。

Abstract: Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.

</details>


### [79] [FedZMG: Efficient Client-Side Optimization in Federated Learning](https://arxiv.org/abs/2602.18384)
*Fotios Zantalis,Evangelos Zervas,Grigorios Koulouras*

Main category: cs.LG

TL;DR: 本文提出FedZMG，一种新型的无参数客户端优化算法，通过将本地梯度投影至零均值超平面来结构性地规整化优化空间，有效解决联邦学习中因数据非独立同分布(non-IID)导致的客户端漂移问题，在不增加通信开销的前提下，相比FedAvg和FedAdam实现更快的收敛速度和更高的模型准确率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在边缘设备上进行分布式训练时，客户端数据的非独立同分布特性会导致客户端漂移，严重影响收敛速度与模型性能。现有自适应优化器虽能缓解该问题，但往往引入计算复杂性和通信开销，不适用于资源受限的物联网环境，亟需一种轻量且高效的解决方案。

Method: 提出FedZMG算法，在客户端侧对本地梯度实施零均值化处理，即将梯度投影至零均值超平面，从结构上消除异构数据分布带来的"强度"与"偏差"偏移。该算法无需额外通信轮次或超参数调优，属于无参数、轻量级的客户端优化方法。

Result: 理论分析表明，FedZMG能有效降低梯度方差并获得比FedAvg更紧的收敛边界。在EMNIST、CIFAR100和Shakespeare数据集上的大量实验验证，尤其在高度非IID场景下，FedZMG相比FedAvg和FedAdam均表现出更优的收敛速度与最终验证准确率。

Conclusion: FedZMG为联邦学习中的客户端漂移问题提供了一种有效且实用的解决方案。通过在本地对梯度进行零均值化预处理，该算法在不增加通信和计算负担的前提下，显著提升了异构数据环境下的训练效率和模型性能，兼具理论保证与实践价值。

Abstract: Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.

</details>


### [80] [Learning Without Training](https://arxiv.org/abs/2602.17985)
*Ryan O'Dowd*

Main category: cs.LG

TL;DR: 本文是一篇机器学习数学理论 dissertation，包含三个项目：1) 通过流形学习改进监督学习的函数逼近理论缺陷；2) 在部分域数据已知条件下研究迁移学习的函数提升问题；3) 将信号分离技术引入主动学习分类，提出更快且精度相当的新算法。


<details>
  <summary>Details</summary>
Motivation: 针对机器学习处理大规模数据的核心挑战，本文从数学理论角度切入三个关键问题：监督学习中函数逼近存在理论缺陷、迁移学习在不同域间的知识迁移机制、以及分类任务在主动学习范式下的效率问题。研究动机在于为这些实际应用提供更坚实的理论支撑和更高效的方法论。

Method: 项目一：提出新方法以弥补监督学习现有范式的理论缺陷，结合流形学习进行函数逼近。项目二：在数据仅覆盖部分完整域的假设下，研究函数的提升(lifting)问题，确定目标数据空间的适用子集，并建立函数与其提升的局部平滑性关系。项目三：借鉴信号分离问题的技巧，提出统一信号分离与分类的理论框架，并设计相应算法。

Result: 项目一：理论上改进了监督学习的函数逼近方法。项目二：明确了函数提升可定义的目标数据子集范围，并建立了局部平滑性的理论关联。项目三：开发出兼具竞争精度和显著速度优势的主动学习分类算法，相比近期算法能更快获得结果。

Conclusion: 本论文通过严格的数学理论为机器学习三大应用领域（监督学习、迁移学习、主动学习分类）提供了创新性的理论框架和实用算法，特别是在分类任务中实现了效率突破，验证了理论指导实践的有效性，为大规模数据问题提供了更可靠的解决方案。

Abstract: Machine learning is at the heart of managing the real-world problems associated with massive data. With the success of neural networks on such large-scale problems, more research in machine learning is being conducted now than ever before. This dissertation focuses on three different projects rooted in mathematical theory for machine learning applications.
  The first project deals with supervised learning and manifold learning. In theory, one of the main problems in supervised learning is that of function approximation: that is, given some data set $\mathcal{D}=\{(x_j,f(x_j))\}_{j=1}^M$, can one build a model $F\approx f$? We introduce a method which aims to remedy several of the theoretical shortcomings of the current paradigm for supervised learning.
  The second project deals with transfer learning, which is the study of how an approximation process or model learned on one domain can be leveraged to improve the approximation on another domain. We study such liftings of functions when the data is assumed to be known only on a part of the whole domain. We are interested in determining subsets of the target data space on which the lifting can be defined, and how the local smoothness of the function and its lifting are related.
  The third project is concerned with the classification task in machine learning, particularly in the active learning paradigm. Classification has often been treated as an approximation problem as well, but we propose an alternative approach leveraging techniques originally introduced for signal separation problems. We introduce theory to unify signal separation with classification and a new algorithm which yields competitive accuracy to other recent active learning algorithms while providing results much faster.

</details>


### [81] [Asynchronous Heavy-Tailed Optimization](https://arxiv.org/abs/2602.18002)
*Junfei Sun,Dixi Yao,Xuchen Gong,Tahseen Rabbani,Manzil Zaheer,Tian Li*

Main category: cs.LG

TL;DR: 针对transformer模型中重尾梯度噪声与异步优化交互作用的研究空白，提出基于延迟感知学习率调度和延迟补偿的算法改进，理论收敛速率与同步方法相当且延迟容忍度更高，实验在图像和语言任务上展现出更优的准确率/时间权衡和超参数鲁棒性。


<details>
  <summary>Details</summary>
Motivation: transformer模型中重尾随机梯度噪声会破坏优化稳定性，现有研究集中于同步设置，对异步优化中噪声与延迟的交互作用缺乏系统探索。

Method: 研究两种处理stragglers的异步通信方案，提出基于延迟感知学习率调度和延迟补偿的算法改进并进行理论分析。

Result: 理论保证在重尾噪声下收敛速率与同步方法相当，且延迟容忍度优于现有异步方法；在图像和语言任务上，所提方法在准确率/运行时间权衡方面优于先前方法，并对超参数更具鲁棒性。

Conclusion: 本研究填补了异步优化场景下重尾噪声研究的空白，提出的算法在理论和实验上均证明其有效性，为构建稳定高效的异步分布式训练系统提供了新方案。

Abstract: Heavy-tailed stochastic gradient noise, commonly observed in transformer models, can destabilize the optimization process. Recent works mainly focus on developing and understanding approaches to address heavy-tailed noise in the centralized or distributed, synchronous setting, leaving the interactions between such noise and asynchronous optimization underexplored. In this work, we investigate two communication schemes that handle stragglers with asynchronous updates in the presence of heavy-tailed gradient noise. We propose and theoretically analyze algorithmic modifications based on delay-aware learning rate scheduling and delay compensation to enhance the performance of asynchronous algorithms. Our convergence guarantees under heavy-tailed noise match the rate of the synchronous counterparts and improve delay tolerance compared with existing asynchronous approaches. Empirically, our approaches outperform prior synchronous and asynchronous methods in terms of accuracy/runtime trade-offs and are more robust to hyperparameters in both image and language tasks.

</details>


### [82] [Continual-NExT: A Unified Comprehension And Generation Continual Learning Framework](https://arxiv.org/abs/2602.18055)
*Jingyang Qiao,Zhizhong Zhang,Xin Tan,Jingyu Gong,Yanyun Qu,Yuan Xie*

Main category: cs.LG

TL;DR: 该论文针对Dual-to-Dual多模态大语言模型在持续学习方面的不足，提出了Continual-NExT评估框架和MAGE方法（通用与专家LoRA的混合聚合），通过跨模态知识迁移和遗忘缓解实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Dual-to-Dual MLLMs虽然具备强大的即时学习和泛化能力，但在终身演化方面存在缺陷，面临灾难性遗忘、幻觉、指令不遵循和跨模态知识迁移失败等挑战，且缺乏标准化的持续学习框架，限制了其在动态真实世界场景中的持续适应能力。

Method: 提出Continual-NExT持续学习框架，并设计MAGE（Mixture and Aggregation of General LoRA and Expert LoRA）方法，通过混合和聚合通用LoRA与专家LoRA来促进跨模态知识迁移并减轻遗忘。

Result: 大量实验表明，MAGE方法超越了其他持续学习方法，在Dual-to-Dual MLLMs的持续学习任务上实现了最先进的性能。

Conclusion: 该研究通过建立标准化评估框架和提出高效持续学习方法，为Dual-to-Dual MLLMs的终身演化问题提供了有效解决方案，显著提升了模型在动态环境中的持续适应能力。

Abstract: Dual-to-Dual MLLMs refer to Multimodal Large Language Models, which can enable unified multimodal comprehension and generation through text and image modalities. Although exhibiting strong instantaneous learning and generalization capabilities, Dual-to-Dual MLLMs still remain deficient in lifelong evolution, significantly affecting continual adaptation to dynamic real-world scenarios. One of the challenges is that learning new tasks inevitably destroys the learned knowledge. Beyond traditional catastrophic forgetting, Dual-to-Dual MLLMs face other challenges, including hallucination, instruction unfollowing, and failures in cross-modal knowledge transfer. However, no standardized continual learning framework for Dual-to-Dual MLLMs has been established yet, leaving these challenges unexplored. Thus, in this paper, we establish Continual-NExT, a continual learning framework for Dual-to-Dual MLLMs with deliberately-architected evaluation metrics. To improve the continual learning capability of Dual-to-Dual MLLMs, we propose an efficient MAGE (Mixture and Aggregation of General LoRA and Expert LoRA) method to further facilitate knowledge transfer across modalities and mitigate forgetting. Extensive experiments demonstrate that MAGE outperforms other continual learning methods and achieves state-of-the-art performance.

</details>


### [83] [Balancing Symmetry and Efficiency in Graph Flow Matching](https://arxiv.org/abs/2602.18084)
*Benjamin Honoré,Alba Carballo-Castro,Yiming Qin,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文研究图生成模型中等变性与训练效率的权衡，提出一种基于正弦位置编码和节点置换的可控对称性调制方案。该方法通过有控制地放松等变性约束，在延迟过拟合的同时加速收敛，仅需19%的基线训练轮数即可达到更强性能。


<details>
  <summary>Details</summary>
Motivation: 严格的等变性虽能保证图生成模型尊重置换对称性，但会因架构约束增加计算成本，并因需在大量节点置换上保持一致性而减慢收敛。本文旨在探索这种权衡，寻求提升训练效率的方法。

Method: 从等变离散流匹配模型出发，在训练过程中引入可控的对称性调制机制，利用正弦位置编码和节点置换动态调节模型的等变程度，实现训练效率与模型性能之间的平衡。

Result: 实验表明，完全打破对称性可加速早期训练但导致捷径解与过拟合（生成训练集重复）；而适当调制对称性信号能延迟过拟合并加速收敛，使模型仅用19%的基线训练轮数即达到更优性能。

Conclusion: 可控对称性调制是提升图生成模型训练效率的有效策略，通过动态平衡等变性与灵活性，可在保持泛化能力的同时显著减少训练成本，为模型优化提供了新方向。

Abstract: Equivariance is central to graph generative models, as it ensures the model respects the permutation symmetry of graphs. However, strict equivariance can increase computational cost due to added architectural constraints, and can slow down convergence because the model must be consistent across a large space of possible node permutations. We study this trade-off for graph generative models. Specifically, we start from an equivariant discrete flow-matching model, and relax its equivariance during training via a controllable symmetry modulation scheme based on sinusoidal positional encodings and node permutations. Experiments first show that symmetry-breaking can accelerate early training by providing an easier learning signal, but at the expense of encouraging shortcut solutions that can cause overfitting, where the model repeatedly generates graphs that are duplicates of the training set. On the contrary, properly modulating the symmetry signal can delay overfitting while accelerating convergence, allowing the model to reach stronger performance with $19\%$ of the baseline training epochs.

</details>


### [84] [Non-Stationary Online Resource Allocation: Learning from a Single Sample](https://arxiv.org/abs/2602.18114)
*Yiding Feng,Jiashuo Jiang,Yige Wang*

Main category: cs.LG

TL;DR: 研究非平稳需求下的在线多资源分配问题，提出基于类型依赖分位数的元策略框架，仅需每时段一个历史样本，即可在 reward-observed 设置下实现 Õ(√T) 遗憾界，在 type-only 设置下通过精细舍入技术首次获得 O((log T)³) 的多对数遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在线资源分配在动态环境中面临需求非平稳性的严峻挑战，而现有方法通常依赖大量历史数据或变化预算假设。实际应用中数据稀缺且变化不可预测，亟需开发一种仅需极弱离线信息（每时段一个样本）即可处理任意非平稳性和多资源约束的鲁棒算法。

Method: 设计类型依赖的分位数元策略，将问题解耦为三个模块化组件：(1) 基于历史样本的奖励分布估计；(2) 通过流体松弛求解目标服务概率；(3) 动态接受阈值实时决策。针对 reward-observed 样本采用静态阈值策略；针对 type-only 样本，在最小到达概率假设下，提出部分自适应策略和全自适应求解策略，后者引入精细的概率舍入机制。

Result: 理论成果包括：① reward-observed 样本下静态阈值策略达到 Õ(√T) 遗憾界；② 证明 type-only 样本无额外结构时次线性遗憾不可能；③ 在最小到达概率假设下，部分自适应策略实现 Õ(T) 遗憾，全自适应策略首次实现 O((log T)³) 的多对数遗憾，开创非平稳多资源分配问题的多项式对数遗憾新范式。

Conclusion: 本框架通过模块化设计和创新舍入技术，在极弱离线数据条件下（每时段一个样本）有效解决了任意非平稳性和多资源约束的在线分配难题，突破了传统变化预算假设的限制，为动态资源管理提供了坚实的理论基础和实用算法。

Abstract: We study online resource allocation under non-stationary demand with a minimum offline data requirement. In this problem, a decision-maker must allocate multiple types of resources to sequentially arriving queries over a finite horizon. Each query belongs to a finite set of types with fixed resource consumption and a stochastic reward drawn from an unknown, type-specific distribution. Critically, the environment exhibits arbitrary non-stationarity -- arrival distributions may shift unpredictably-while the algorithm requires only one historical sample per period to operate effectively. We distinguish two settings based on sample informativeness: (i) reward-observed samples containing both query type and reward realization, and (ii) the more challenging type-only samples revealing only query type information.
  We propose a novel type-dependent quantile-based meta-policy that decouples the problem into modular components: reward distribution estimation, optimization of target service probabilities via fluid relaxation, and real-time decisions through dynamic acceptance thresholds. For reward-observed samples, our static threshold policy achieves $\tilde{O}(\sqrt{T})$ regret. For type-only samples, we first establish that sublinear regret is impossible without additional structure; under a mild minimum-arrival-probability assumption, we design both a partially adaptive policy attaining the same $\tilde{O}({T})$ bound and, more significantly, a fully adaptive resolving policy with careful rounding that achieves the first poly-logarithmic regret guarantee of $O((\log T)^3)$ for non-stationary multi-resource allocation. Our framework advances prior work by operating with minimal offline data (one sample per period), handling arbitrary non-stationarity without variation-budget assumptions, and supporting multiple resource constraints.

</details>


### [85] [RAT+: Train Dense, Infer Sparse -- Recurrence Augmented Attention for Dilated Inference](https://arxiv.org/abs/2602.18196)
*Xiuying Wei,Caglar Gulcehre*

Main category: cs.LG

TL;DR: RAT+是一种通过全序列循环和主动循环学习增强的密集预训练架构，可一次性预训练后，在推理时灵活切换为膨胀注意力或混合结构，仅需少量适应即可实现高效长序列处理，同时保持较高准确率。


<details>
  <summary>Details</summary>
Motivation: 结构化膨胀注意力虽能降低计算量和KV缓存，但将预训练模型稀疏化为膨胀模式会导致严重准确率下降。亟需一种能同时保持长程连接性和推理效率的架构，避免为不同稀疏模式重复训练。

Method: RAT+在标准注意力中引入全序列循环连接和主动循环学习机制。模型一次性密集预训练后，可在推理时动态切换为膨胀注意力（可选局部窗口）或混合层/头组合，仅需10亿token的简短适应而非完整重训练。

Result: 在15亿参数、1000亿token规模下，膨胀因子16时准确率接近密集模型，因子64时于常识推理和LongBench任务上分别仅下降2-3个点，且优于top-k块注意力稀疏化。该趋势在26亿参数、2000亿token扩展中依然成立。

Conclusion: RAT+有效解决了模型稀疏化的准确率退化问题，提供了一种灵活高效的推理时效率调节方案，为长序列处理提供了实用的新范式。

Abstract: Structured dilated attention has an appealing inference-time efficiency knob: it reduces the FLOPs of the attention and the KV cache size by a factor of the dilation size D, while preserving long-range connectivity. However, we find a persistent failure mode of them -- sparsifying a pretrained attention model to a dilated pattern leads to severe accuracy degradation. We introduce RAT+, a dense-pretraining architecture that augments attention with full-sequence recurrence and active recurrence learning. A single RAT+ model is pretrained densely once, then flexibly switched at inference time to dilated attention (optionally with local windows) or hybrid layer/head compositions, requiring only a short 1B-token resolution adaptation rather than retraining separate sparse models. At 1.5B parameters trained on 100B tokens, RAT+ closely matches dense accuracy at 16 and drops by about 2-3 points at 64 on commonsense reasoning and LongBench tasks, respectively. Moreover, RAT+ outperforms attention when sparsifying to the top-k block attention. We further scale to 2.6B parameters and 200B tokens and observe the same trend.

</details>


### [86] [Neural-HSS: Hierarchical Semi-Separable Neural PDE Solver](https://arxiv.org/abs/2602.18248)
*Pietro Sittoni,Emanuele Zangrando,Angelo A. Casulli,Nicola Guglielmi,Francesco Tudisco*

Main category: cs.LG

TL;DR: 本文提出 Neural-HSS，一种基于分层半可分（HSS）矩阵结构的高效参数化架构，用于求解偏微分方程。该方法在理论上被证明在低数据 regime 下具有精确性和数据高效性，并在三维泊松方程及电磁学、流体动力学、生物学等多个领域的偏微分方程求解中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在求解偏微分方程方面表现出色，但生成大规模高质量数据集和训练模型的高昂计算成本仍然是关键应用的主要瓶颈。即使在高性能计算基础设施下，这一问题依然突出。

Method: 受椭圆型偏微分方程格林函数结构研究的启发，作者提出了 Neural-HSS 架构。该架构建立在分层半可分（HSS）矩阵结构之上，具有参数高效性。论文从理论上分析了该架构，证明其在极低数据情况下仍满足精确性性质，并探讨了其与傅里叶神经算子层和卷积层的联系。

Result: 在三维泊松方程实验中，网格包含两百万个点，Neural-HSS 在低数据 regime 下展现出卓越的学习能力，性能优于基线方法。此外，该方法在电磁学、流体动力学和生物学等多个领域的偏微分方程数据上也验证了其广泛适用性。

Conclusion: Neural-HSS 架构为求解偏微分方程提供了一种高效的数据驱动方法，特别适用于低数据场景。其理论保证和跨领域实验验证表明，该方法在科学计算和工程应用中具有巨大潜力。

Abstract: Deep learning-based methods have shown remarkable effectiveness in solving PDEs, largely due to their ability to enable fast simulations once trained. However, despite the availability of high-performance computing infrastructure, many critical applications remain constrained by the substantial computational costs associated with generating large-scale, high-quality datasets and training models. In this work, inspired by studies on the structure of Green's functions for elliptic PDEs, we introduce Neural-HSS, a parameter-efficient architecture built upon the Hierarchical Semi-Separable (HSS) matrix structure that is provably data-efficient for a broad class of PDEs. We theoretically analyze the proposed architecture, proving that it satisfies exactness properties even in very low-data regimes. We also investigate its connections with other architectural primitives, such as the Fourier neural operator layer and convolutional layers. We experimentally validate the data efficiency of Neural-HSS on the three-dimensional Poisson equation over a grid of two million points, demonstrating its superior ability to learn from data generated by elliptic PDEs in the low-data regime while outperforming baseline methods. Finally, we demonstrate its capability to learn from data arising from a broad class of PDEs in diverse domains, including electromagnetism, fluid dynamics, and biology.

</details>


### [87] [Variational Distributional Neuron](https://arxiv.org/abs/2602.18250)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 提出变分分布神经元概念，将每个计算单元构建为VAE模块，显式携带先验、摊销后验和局部ELBO，使激活变为分布式以在神经元层面编码不确定性，计算本质是在约束下收缩可能性空间，解决确定性计算单元与概率模型间的结构性矛盾。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习中，计算单元多为确定性标量，而概率模型的不确定性由全局机制承担。论文指出结构性张力：序列生成中因果性在符号空间组织，潜变量常为辅助，有效动力学由确定性解码器承载；概率潜变量模型捕获变异和不确定性，但单元仍传播标量。核心问题：若不确定性是计算内在属性，为何计算单元不显式携带它？

Method: 提出“变分分布神经元”——每个神经元是一个VAE砖块，包含先验分布、摊销后验分布和局部ELBO。神经元参数化后验，传播重参数化样本，通过局部ELBO的KL项正则化。计算被重新定义为“在约束下收缩可能性连续空间”，其程度可通过内部测度监测，上下文信息量和时间持续性由不同约束局部调节。

Result: 激活变为分布式的。分析了“坍缩”模式和“活神经元”条件，并通过每个单元上的自回归潜变量先验将模型扩展到时间维度。

Conclusion: 若不确定性是计算固有属性，则基本计算单元应为分布式而非确定性。研究建立两个轴：(i)概率约束的组成需稳定、可解释、可控；(ii)粒度问题——若推断是约束下的分布协商，原始单元应保持确定性还是变为分布式？为实现神经元级概率计算提供了概念证明。

Abstract: We propose a proof of concept for a variational distributional neuron: a compute unit formulated as a VAE brick, explicitly carrying a prior, an amortized posterior and a local ELBO. The unit is no longer a deterministic scalar but a distribution: computing is no longer about propagating values, but about contracting a continuous space of possibilities under constraints. Each neuron parameterizes a posterior, propagates a reparameterized sample and is regularized by the KL term of a local ELBO - hence, the activation is distributional. This "contraction" becomes testable through local constraints and can be monitored via internal measures. The amount of contextual information carried by the unit, as well as the temporal persistence of this information, are locally tuned by distinct constraints. This proposal addresses a structural tension: in sequential generation, causality is predominantly organized in the symbolic space and, even when latents exist, they often remain auxiliary, while the effective dynamics are carried by a largely deterministic decoder. In parallel, probabilistic latent models capture factors of variation and uncertainty, but that uncertainty typically remains borne by global or parametric mechanisms, while units continue to propagate scalars - hence the pivot question: if uncertainty is intrinsic to computation, why does the compute unit not carry it explicitly? We therefore draw two axes: (i) the composition of probabilistic constraints, which must be made stable, interpretable and controllable; and (ii) granularity: if inference is a negotiation of distributions under constraints, should the primitive unit remain deterministic or become distributional? We analyze "collapse" modes and the conditions for a "living neuron", then extend the contribution over time via autoregressive priors over the latent, per unit.

</details>


### [88] [MEG-to-MEG Transfer Learning and Cross-Task Speech/Silence Detection with Limited Data](https://arxiv.org/abs/2602.18253)
*Xabier de Zuazo,Vincenzo Verbeni,Eva Navas,Ibon Saratxaga,Mathieu Bourguignon,Nicola Molinaro*

Main category: cs.LG

TL;DR: 一篇关于语音脑机接口数据高效神经解码的论文，首次展示了在MEG语音模型中使用迁移学习和跨任务解码，通过预训练和微调显著提升性能，并揭示了感知与产生任务间的共享神经表征。


<details>
  <summary>Details</summary>
Motivation: 语音脑机接口中的数据高效神经解码是一个核心挑战，因为收集大量神经数据既昂贵又耗时。该研究旨在通过迁移学习来解决数据稀缺问题，并探索语音感知与产生任务之间的神经共享机制。

Method: 研究使用了一个基于Conformer的模型，首先在单个受试者的50小时听语音数据上进行预训练，然后在18名受试者中每人仅用5分钟的数据进行微调。该方法实现了任务内和跨任务（感知与产生）的迁移学习。

Result: 迁移学习带来了持续的性能提升：任务内准确率提高1-4%，跨任务提升高达5-6%。更重要的是，在语音产生任务上训练的模型能够显著解码被动听语音任务，表明学到的表征反映了共享的神经过程。

Conclusion: 研究表明，预训练不仅改善了每个任务的性能，还实现了感知与产生之间的可靠跨任务解码。模型能够从产生任务解码感知任务，证实了学习到的神经表征反映的是共享的神经过程，而非任务特定的运动活动。

Abstract: Data-efficient neural decoding is a central challenge for speech brain-computer interfaces. We present the first demonstration of transfer learning and cross-task decoding for MEG-based speech models spanning perception and production. We pre-train a Conformer-based model on 50 hours of single-subject listening data and fine-tune on just 5 minutes per subject across 18 participants. Transfer learning yields consistent improvements, with in-task accuracy gains of 1-4% and larger cross-task gains of up to 5-6%. Not only does pre-training improve performance within each task, but it also enables reliable cross-task decoding between perception and production. Critically, models trained on speech production decode passive listening above chance, confirming that learned representations reflect shared neural processes rather than task-specific motor activity.

</details>


### [89] [Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering](https://arxiv.org/abs/2602.18348)
*Matheus Camilo da Silva,Leonardo Arrighi,Ana Carolina Lorena,Sylvio Barbon Junior*

Main category: cs.LG

TL;DR: 本文研究AutoClustering中元模型的可解释性问题。通过系统回顾22种现有方法并建立元特征结构化分类法，结合决策谓词图全局解释与SHAP局部解释技术，分析元模型特征重要性及具体聚类决策，揭示元特征相关性的一致模式，识别当前元学习策略的结构性缺陷，为可解释的AutoML设计提供实践指导。


<details>
  <summary>Details</summary>
Motivation: AutoClustering方法虽能通过元学习自动化非监督学习任务（算法选择、超参数优化、管道合成）并取得良好性能，但其推荐缺乏可解释性：元特征对算法和超参数选择的影响未被暴露，限制了系统可靠性、偏差诊断及高效元特征工程，亟需提升决策透明度。

Method: 1) 文献综述：回顾22种AutoClustering方法，构建元特征结构化分类法；2) 全局可解释性分析：应用决策谓词图评估元模型中的特征重要性；3) 局部可解释性分析：使用SHAP工具分析具体聚类决策。

Result: 研究发现了元特征相关性的稳定模式，识别出当前元学习策略中可能扭曲推荐结果的结构性弱点，并为设计更具解释性的AutoML系统提供了可操作的指导。

Conclusion: 本研究为提升非监督学习自动化决策的透明度提供了实践基础，有助于构建更可靠、可解释的Automated Machine Learning框架。

Abstract: AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.

</details>


### [90] [Assigning Confidence: K-partition Ensembles](https://arxiv.org/abs/2602.18435)
*Aggelos Semoglou,John Pavlopoulos*

Main category: cs.LG

TL;DR: 本文提出CAKE框架，通过集成多个聚类结果计算每个样本的分配稳定性与局部几何拟合一致性，融合为[0,1]置信度分数，用于识别聚类中的模糊点与核心点，提升聚类质量。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法难以评估单个样本分配的可靠性，尤其是对k-means这类初始化敏感算法。全局诊断指标无法反映逐点置信度，导致分配级不稳定性影响聚类准确性与鲁棒性。集成方法虽提升一致性，但缺乏结合跨轮次一致性与几何结构支持的逐点置信度量化工具。

Method: CAKE框架通过对聚类集成计算两个互补统计量：1)分配稳定性（跨轮次一致性）和2)局部几何拟合一致性（点与簇几何结构匹配度），并将二者融合为[0,1]区间的可解释置信度分数。

Result: 理论分析证明CAKE在噪声下依然有效，能区分稳定与不稳定点。在合成与真实数据集上的实验表明，CAKE能有效识别模糊点与稳定核心成员，提供置信度排序用于过滤或优先级排序，从而提升聚类质量。

Conclusion: CAKE为聚类分配提供了可靠的置信度量化工具，通过识别高置信度核心点与低置信度模糊点，可指导数据过滤与样本优先级排序，显著改善聚类结果的质量与鲁棒性。

Abstract: Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [91] [When & How to Write for Personalized Demand-aware Query Rewriting in Video Search](https://arxiv.org/abs/2602.17667)
*Cheng cheng,Chenxing Wang,Aolin Li,Haijun Wu,Huiyun Hu,Juyuan Wang*

Main category: cs.IR

TL;DR: 针对视频搜索中用户历史行为信号稀释和反馈延迟问题，提出WeWrite个性化查询改写框架，通过事后挖掘、SFT+GRPO混合训练及并行架构实现精准改写，提升点击率并降低重构率。


<details>
  <summary>Details</summary>
Motivation: 视频搜索系统中用户历史行为虽蕴含丰富意图信息，但传统隐式特征利用方式存在信号稀释和反馈延迟缺陷，导致搜索意图识别不准确、歧义消解效果差，亟需一种更有效的个性化查询改写方法来提升搜索体验和效率。

Method: 提出WeWrite框架，包含三方面创新：1）事后自动化挖掘策略从日志中提取高质量样本，识别必须个性化的场景；2）结合监督微调（SFT）与组相对策略优化（GRPO）的混合训练范式，对齐LLM输出与大模型检索系统风格；3）设计并行"Fake Recall"架构确保低延迟部署。

Result: 在大型视频平台在线A/B测试表明，WeWrite显著提升用户点击视频量（VV>10秒）1.07%，同时降低用户查询重构率2.97%，有效改善了搜索效果与用户满意度。

Conclusion: WeWrite框架通过精准识别个性化需求、优化模型训练策略及高效部署架构，成功解决了视频搜索中的信号稀释与延迟问题，验证了个性化查询改写在提升检索系统性能方面的有效性和实用性。

Abstract: In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel "Fake Recall" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.

</details>


### [92] [IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering](https://arxiv.org/abs/2602.17687)
*Connor Shorten,Augustas Skaburskas,Daniel M. Jones,Charles Pierse,Roberto Esposito,John Trengrove,Etienne Dilocker,Bob van Luijt*

Main category: cs.IR

TL;DR: 本文介绍了IRPAPERS基准测试，包含166篇科学论文的3,230页图像和OCR文本，通过180个深入问题比较了基于图像和基于文本的检索与问答系统，发现多模态混合搜索效果最佳，Cohere Embed v4图像嵌入模型表现突出。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在文本和关系数据处理上取得显著成功，视觉文档处理仍相对未充分探索。传统系统需要OCR转录，而多模态基础模型的最新进展允许直接从文档图像进行检索和生成。核心问题是：基于图像的系统与成熟的文本方法相比表现如何？

Method: 创建IRPAPERS基准（166篇论文，3,230页，每页包含图像和OCR文本），使用180个"大海捞针"问题。对比了文本检索（Arctic 2.0嵌入、BM25、混合文本搜索）、图像检索（多种多向量图像嵌入模型）、多模态混合搜索，并评估效率-性能权衡（MUVERA）及闭源模型（Cohere Embed v4、Voyage 3 Large）与开源模型的表现。

Result: 文本检索：Recall@1为46%，Recall@5为78%，Recall@20为91%；图像检索：Recall@1为43%，Recall@5为78%，Recall@20为93%；多模态混合：Recall@1为49%，Recall@5为81%，Recall@20为95%。Cohere Embed v4图像嵌入：Recall@1为58%，Recall@5为87%，Recall@20为97%，优于所有开源模型和Voyage 3 Large文本嵌入。问答方面，基于文本的RAG系统ground-truth对齐度更高（0.82 vs 0.71）。增加检索深度显著提升性能，多文档检索优于单文档检索。

Conclusion: 文本和图像模态存在互补性失败，多模态混合搜索可超越单一模态。不同问题类型需要不同模态，应识别这些差异。IRPAPERS数据集和实验代码已公开。

Abstract: AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.

</details>


### [93] [Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems](https://arxiv.org/abs/2602.17856)
*Hamideh Ghanadian,Amin Kamali,Mohammad Hossein Tekieh*

Main category: cs.IR

TL;DR: 本文研究了如何通过检索增强生成(RAG)技术提升科技文献聊天机器人的性能，重点对比评估了基于向量和基于图的检索系统。提出了一种混合架构，利用图和向量数据库进行文献检索，并在单文档和大规模语料库两种场景下进行了系统评估。


<details>
  <summary>Details</summary>
Motivation: 科技文献海量增长导致信息获取困难，传统聊天机器人在专业领域存在知识幻觉和准确性不足问题。RAG技术通过外部知识检索可以缓解这些问题，但向量检索和图检索哪种更适合科技文献尚缺乏系统比较，这是本研究的动机。

Method: 提出混合RAG架构，同时使用图数据库（结构化）和向量数据库（非结构化）存储科技文献和灰色文献。设计两个用例场景：单文档检索和大规模语料库检索。使用GPT模型生成基准测试集，并进行人工标注评估。通过检索准确率和响应相关性两个指标对比分析两种检索方法。

Result: 研究表明，向量检索在处理语义相似性方面表现较好，而图检索在关系推理和结构化查询方面更具优势。混合系统能够结合两者优势，在检索准确性和响应相关性上均优于单一方法，验证了混合RAG系统在科技文献领域的有效性。

Conclusion: 混合RAG系统显著提升了科技知识的可及性，为循证决策提供了有力支持。该研究为未来科技文献智能检索系统的设计提供了重要参考，展示了RAG技术在学术领域的广阔应用前景。

Abstract: This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.

</details>


### [94] [SuiteEval: Simplifying Retrieval Benchmarks](https://arxiv.org/abs/2602.18107)
*Andrew Parry,Debasis Ganguly,Sean MacAvaney*

Main category: cs.IR

TL;DR: 本文提出SuiteEval，一个统一的信息检索评估框架，通过自动化端到端评估、动态索引复用和内置主流基准测试支持，解决评估实践碎片化问题，提升可重复性和可比性。


<details>
  <summary>Details</summary>
Motivation: 信息检索评估存在数据集子集、聚合方法和管道配置各异的碎片化问题，严重破坏可重复性和可比性，尤其影响需要强大域外性能的基础嵌入模型评估。缺乏标准化导致研究难以比较和复现。

Method: 设计SuiteEval框架：提供自动化端到端评估流程；采用动态索引技术重用磁盘索引以最小化存储占用；内置支持BEIR、LoTTE、MS MARCO、NanoBEIR和BRIGHT等主流基准；用户仅需提供管道生成器，框架负责数据加载、索引、排序、指标计算和结果聚合；支持单行代码添加新基准套件。

Result: SuiteEval显著减少样板代码，标准化评估流程，支持更广泛的基准测试集，有效提升实验效率和结果可比性，促进可重复的IR研究。框架成功解决了评估碎片化问题。

Conclusion: SuiteEval通过统一框架解决了IR评估的碎片化挑战，为研究社区提供了标准化、可扩展的评估工具，有助于推动基础嵌入模型等先进方法的可靠评估和比较，对促进可重复研究具有重要意义。

Abstract: Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.

</details>


### [95] [A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18206)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Ronghua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 本文提出PSP-NS，一种从增强正样本监督信号视角设计的负采样插件，通过图权重建模、正样本对生成和活动感知加权，显著提升隐式协同过滤性能。


<details>
  <summary>Details</summary>
Motivation: 隐式协同过滤模型过度关注负样本采样策略，忽视正样本探索。现有去噪方法会稀疏化正样本监督，且普遍忽略用户活跃度偏差，导致非活跃用户表示学习不足。

Method: 构建带权二分图表示交互置信度；通过复制重加权生成正样本对强化信号；设计活动感知加权机制平衡不同活跃度用户学习；从边界改进角度提供理论分析。

Result: 四数据集实验显示PSP-NS全面优于基线，Yelp上Recall@30和Precision@30分别提升32.11%和22.90%，可即插即用集成于各类隐式CF模型。

Conclusion: PSP-NS通过增强正样本监督信号有效解决正样本稀疏和活跃度偏差问题，兼具理论合理性与实践有效性，为推荐系统提供简单而强大的负采样增强方案。

Abstract: Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.

</details>


### [96] [The Economical-Ecological Benefits of Matching Non-matching Socks](https://arxiv.org/abs/2602.18221)
*Teddy Lazebnik*

Main category: cs.IR

TL;DR: 研究量化孤儿袜配对的经济生态价值及社会心理成本，发现适度容忍错配比严格配对更能减少资源闲置，尽管存在行为障碍。


<details>
  <summary>Details</summary>
Motivation: 袜子成对使用特性使其易因单只丢失导致可用容量闲置和过早替换，产生巨大资源浪费，需量化非匹配配对效益并分析阻碍该行为的社会心理机制。

Method: 将袜子拥有建模为随机动态决策问题，通过实地实验估计个体错配敏感度和多样性偏好参数，结合计算机模拟评估可解释配对策略的资源效率。

Result: 严格配对虽表面节约，但造成大量无袜日和容量浪费；适度错配容忍能维持服务连续性并显著降低闲置，揭示社会规范与资源效率间的权衡关系。

Conclusion: 研究证实配对非匹配袜子具备可行性，为减少纺织品浪费提供新思路，同时指出行为偏见和社会规范是主要实施挑战。

Abstract: Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.

</details>


### [97] [Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18249)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 本文提出DTL-NS方法，通过双树结构编码利用大语言模型进行负采样，无需文本信息和微调即可提升隐式协同过滤推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM增强负采样方法严重依赖文本信息和任务特定微调，限制了实际应用。本文旨在探索无需文本和微调的LLM负采样新范式，解决其研究不足的问题。

Method: DTL-NS包含两个模块：(i)离线假负例识别模块，利用层次索引树将协同结构和潜在语义信息转化为结构化物品ID编码，供LLM识别假负例；(ii)多视角困难负例采样模块，结合用户-物品偏好分数与物品层次相似度，挖掘高质量困难负例以提升模型判别能力。

Result: 在Amazon-sports数据集上，DTL-NS相比最强基线Recall@20提升10.64%，NDCG@20提升19.12%，且能有效集成到多种隐式协同过滤模型和负采样方法中。

Conclusion: DTL-NS是一种有效的文本无关、微调自由的LLM增强负采样方法，可通用地提升各类隐式协同过滤推荐模型的性能。

Abstract: Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.
  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.
  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.
  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).
  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.
  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.
  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.

</details>
