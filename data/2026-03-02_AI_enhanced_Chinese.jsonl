{"id": "2602.23369", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23369", "abs": "https://arxiv.org/abs/2602.23369", "authors": ["Xuanming Cui", "Hong-You Chen", "Hao Yu", "Hao Yuan", "Zihao Wang", "Shlok Kumar Mishra", "Hanchao Yu", "Yonghuan Yang", "Jun Xiao", "Ser-Nam Lim", "Jianpeng Cheng", "Qi Guo", "Xiangjun Fan"], "title": "Reason to Contrast: A Cascaded Multimodal Retrieval Framework", "comment": null, "summary": "Traditional multimodal retrieval systems rely primarily on bi-encoder architectures, where performance is closely tied to embedding dimensionality. Recent work, Think-Then-Embed (TTE), shows that incorporating multimodal reasoning to elicit additional informative tokens before embedding can further improve retrieval. In this paper, we extend this paradigm with TTE-v2, a hybrid multimodal retrieval framework that introduces reasoning-driven performance scaling based on additional input token budget rather than model or embedding size. Our approach augments the initial multimodal retrieval with additional reasoning steps for reranking, enabling more expressive query-candidate interactions at test time. The reranking stage further provides fine-grained supervision for hard negative mining and false negative filtering, creating a feedback loop that effectively strengthens the upstream retriever. This cascaded design delivers substantial test-time improvements based on intermediate reasoning token scaling. Experiments on the MMEB-V2 benchmark demonstrate that TTE-v2-7B achieves a new state-of-the-art accuracy of 75.7%, and that TTE-v2-2B matches or surpasses leading 7B models trained with significantly larger external data. Our results highlight the promise of token-wise scaling as an alternative scaling paradigm for multimodal retrieval.", "AI": {"tldr": "TTE-v2\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u591a\u6a21\u6001\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u63a8\u7406token\u9884\u7b97\uff08\u800c\u975e\u6a21\u578b/\u5d4c\u5165\u5927\u5c0f\uff09\u7684\u6027\u80fd\u6269\u5c55\u673a\u5236\uff0c\u5728\u6d4b\u8bd5\u65f6\u5229\u7528\u989d\u5916\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u589e\u5f3a\u67e5\u8be2-\u5019\u9009\u9879\u4ea4\u4e92\u3002\u5728MMEB-V2\u57fa\u51c6\u4e0a\uff0c7B\u6a21\u578b\u8fbe\u523075.7% SOTA\u51c6\u786e\u7387\uff0c2B\u6a21\u578b\u5ab2\u7f8e\u4f7f\u7528\u66f4\u5927\u5916\u90e8\u6570\u636e\u8bad\u7ec3\u76847B\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86token\u7ea7\u6269\u5c55\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u53cc\u7f16\u7801\u5668\u67b6\u6784\u7684\u6027\u80fd\u74f6\u9888\u5728\u4e8e\u5d4c\u5165\u7ef4\u5ea6\uff0c\u5c3d\u7ba1TTE\u901a\u8fc7\u9884\u5d4c\u5165\u63a8\u7406\u6709\u6240\u6539\u8fdb\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u6d4b\u8bd5\u65f6token\u9884\u7b97\u548c\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u4e0e\u53cd\u9988\u4f18\u5316\u3002", "method": "TTE-v2\u91c7\u7528\u7ea7\u8054\u67b6\u6784\uff1a1) \u521d\u59cb\u591a\u6a21\u6001\u68c0\u7d22\uff1b2) \u57fa\u4e8e\u989d\u5916\u63a8\u7406token\u7684\u91cd\u6392\u5e8f\u9636\u6bb5\uff0c\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u6d4b\u8bd5\u65f6\u67e5\u8be2-\u5019\u9009\u9879\u4ea4\u4e92\uff1b3) \u91cd\u6392\u5e8f\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\u4fe1\u53f7\uff0c\u7528\u4e8e\u56f0\u96be\u8d1f\u6837\u672c\u6316\u6398\u548c\u5047\u9634\u6027\u8fc7\u6ee4\uff0c\u5f62\u6210\u5f3a\u5316\u4e0a\u6e38\u68c0\u7d22\u5668\u7684\u53cd\u9988\u5faa\u73af\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u589e\u52a0\u63a8\u7406token\u5b9e\u73b0\u6027\u80fd\u6269\u5c55\u3002", "result": "MMEB-V2\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0cTTE-v2-7B\u8fbe\u523075.7%\u7684SOTA\u51c6\u786e\u7387\uff1bTTE-v2-2B\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4f7f\u7528\u663e\u8457\u66f4\u5927\u5916\u90e8\u6570\u636e\u8bad\u7ec3\u7684\u9886\u51487B\u6a21\u578b\uff0c\u8bc1\u660etoken\u7ea7\u6269\u5c55\u7684\u6548\u7387\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8etoken\u9884\u7b97\u7684\u63a8\u7406\u9a71\u52a8\u6269\u5c55\u53ef\u4f5c\u4e3a\u4f20\u7edf\u6a21\u578b/\u5d4c\u5165\u5927\u5c0f\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u65b0\u8303\u5f0f\uff0c\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.23372", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23372", "abs": "https://arxiv.org/abs/2602.23372", "authors": ["Qizhi Wang"], "title": "Democratizing GraphRAG: Linear, CPU-Only Graph Retrieval for Multi-Hop QA", "comment": "13 pages, 14 figures, 26 tables", "summary": "GraphRAG systems improve multi-hop retrieval by modeling structure, but many approaches rely on expensive LLM-based graph construction and GPU-heavy inference. We present SPRIG (Seeded Propagation for Retrieval In Graphs), a CPU-only, linear-time, token-free GraphRAG pipeline that replaces LLM graph building with lightweight NER-driven co-occurrence graphs and uses Personalized PageRank (PPR) for 28% with negligible Recall@10 changes. The results characterize when CPU-friendly graph retrieval helps multi-hop recall and when strong lexical hybrids (RRF) are sufficient, outlining a realistic path to democratizing GraphRAG without token costs or GPU requirements.", "AI": {"tldr": "SPRIG\u662f\u4e00\u79cdCPU-only\u3001\u7ebf\u6027\u65f6\u95f4\u3001\u65e0token\u6210\u672c\u7684GraphRAG\u65b9\u6848\uff0c\u4ee5\u8f7b\u91cf\u7ea7NER\u5171\u73b0\u56fe\u53d6\u4ee3LLM\u5efa\u56fe\uff0c\u7ed3\u5408\u4e2a\u6027\u5316PageRank\u5b9e\u73b028%\u7684\u6210\u672c\u4f18\u5316\u4e14Recall@10\u51e0\u4e4e\u4e0d\u53d8\uff0c\u4e3aGraphRAG\u666e\u53ca\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002", "motivation": "\u73b0\u6709GraphRAG\u7cfb\u7edf\u4f9d\u8d56\u6602\u8d35\u7684LLM\u5efa\u56fe\u548cGPU\u63a8\u7406\uff0c\u5bfc\u81f4\u90e8\u7f72\u6210\u672c\u9ad8\u3001\u96be\u4ee5\u666e\u53ca\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u6613\u90e8\u7f72\u7684GraphRAG\u65b9\u6848\uff0c\u6d88\u9664token\u8d39\u7528\u548cGPU\u4f9d\u8d56\uff0c\u5b9e\u73b0\u6280\u672f\u6c11\u4e3b\u5316\u3002", "method": "\u63d0\u51faSPRIG\u6846\u67b6\uff1a\u91c7\u7528CPU-only\u67b6\u6784\uff0c\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff1b\u4f7f\u7528\u547d\u540d\u5b9e\u4f53\u8bc6\u522b(NER)\u6784\u5efa\u8f7b\u91cf\u7ea7\u5171\u73b0\u56fe\uff0c\u66ff\u4ee3LLM\u56fe\u6784\u5efa\uff1b\u91c7\u7528\u4e2a\u6027\u5316PageRank(PPR)\u8fdb\u884c\u591a\u8df3\u68c0\u7d22\uff1b\u5168\u7a0b\u65e0\u9700token\u3002", "result": "\u7cfb\u7edf\u5728\u4fdd\u6301Recall@10\u51e0\u4e4e\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b028%\u7684\u6210\u672c/\u6548\u7387\u4f18\u5316\u3002\u7814\u7a76\u8fd8\u660e\u786e\u4e86CPU\u53cb\u597d\u56fe\u68c0\u7d22\u5728\u4f55\u65f6\u80fd\u63d0\u5347\u591a\u8df3\u53ec\u56de\u7387\uff0c\u4ee5\u53ca\u7eaf\u8bcd\u6cd5\u6df7\u5408(RRF)\u4f55\u65f6\u5df2\u8db3\u591f\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e\u3002", "conclusion": "SPRIG\u901a\u8fc7\u6d88\u9664token\u6210\u672c\u548cGPU\u9700\u6c42\uff0c\u5728\u7ef4\u6301\u68c0\u7d22\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u90e8\u7f72\u95e8\u69db\uff0c\u4e3aGraphRAG\u6280\u672f\u7684\u6c11\u4e3b\u5316\u548c\u5927\u89c4\u6a21\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u63d0\u4f9b\u4e86\u73b0\u5b9e\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2602.23370", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23370", "abs": "https://arxiv.org/abs/2602.23370", "authors": ["Kaifeng Wu", "Junyan Wu", "Qiang Liu", "Jiarui Zhang", "Wen Xu"], "title": "Toward General Semantic Chunking: A Discriminative Framework for Ultra-Long Documents", "comment": null, "summary": "Long-document topic segmentation plays an important role in information retrieval and document understanding, yet existing methods still show clear shortcomings in ultra-long text settings. Traditional discriminative models are constrained by fixed windows and cannot model document-level semantics; generative large language models can output paragraph boundaries, but inference is expensive and long inputs are difficult to support. To address these issues, we propose a discriminative segmentation model based on Qwen3-0.6B. On top of the backbone network, we add a cross-window context fusion layer and a boundary classification head, and combine them with an overlapping sliding-window strategy. Our model supports single-pass inputs of up to 13k tokens and can be extended to ultra-long documents for paragraph boundary detection. To further enhance downstream retrieval efficiency, we derive a vector fusion method with scalar correction, which compresses the representation of ultra-long segments into a single vector without semantic loss. Experiments on the Wikipedia long-document topic segmentation dataset WIKI-727K show that, compared with three generative models based on Qwen2-0.5B released by Jina, our method achieves a better macro-averaged F1 and delivers two orders of magnitude faster inference, substantially improving the practicality and scalability of long-document processing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u8d85\u957f\u6587\u6863\u4e3b\u9898\u5206\u5272\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eQwen3-0.6B\u7684\u5224\u522b\u5f0f\u5206\u5272\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u7a97\u53e3\u4e0a\u4e0b\u6587\u878d\u5408\u5c42\u548c\u91cd\u53e0\u6ed1\u52a8\u7a97\u53e3\u7b56\u7565\uff0c\u652f\u630113k tokens\u7684\u5355\u6b21\u8f93\u5165\uff0c\u5e76\u7ed3\u5408\u6807\u91cf\u4fee\u6b63\u7684\u5411\u91cf\u878d\u5408\u65b9\u6cd5\u63d0\u5347\u4e0b\u6e38\u68c0\u7d22\u6548\u7387\uff0c\u5728WIKI-727K\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u5b8f\u5e73\u5747F1\u503c\u4e14\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u6709\u957f\u6587\u6863\u4e3b\u9898\u5206\u5272\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u4f20\u7edf\u5224\u522b\u5f0f\u6a21\u578b\u53d7\u9650\u4e8e\u56fa\u5b9a\u7a97\u53e3\uff0c\u65e0\u6cd5\u5efa\u6a21\u6587\u6863\u7ea7\u8bed\u4e49\uff1b\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u8f93\u51fa\u6bb5\u843d\u8fb9\u754c\uff0c\u4f46\u63a8\u7406\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u652f\u6301\u8d85\u957f\u8f93\u5165\u3002\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8d85\u957f\u6587\u672c\u5206\u5272\u65b9\u6848\u3002", "method": "1) \u57fa\u4e8eQwen3-0.6B\u6784\u5efa\u5224\u522b\u5f0f\u5206\u5272\u6a21\u578b\uff0c\u589e\u52a0\u8de8\u7a97\u53e3\u4e0a\u4e0b\u6587\u878d\u5408\u5c42\u548c\u8fb9\u754c\u5206\u7c7b\u5934\uff1b2) \u91c7\u7528\u91cd\u53e0\u6ed1\u52a8\u7a97\u53e3\u7b56\u7565\uff0c\u652f\u6301\u5355\u6b21\u8f93\u5165\u9ad8\u8fbe13k tokens\uff1b3) \u63d0\u51fa\u6807\u91cf\u4fee\u6b63\u7684\u5411\u91cf\u878d\u5408\u65b9\u6cd5\uff0c\u5c06\u8d85\u957f\u6bb5\u843d\u8868\u793a\u538b\u7f29\u4e3a\u5355\u5411\u91cf\u4e14\u4e0d\u635f\u5931\u8bed\u4e49\u3002", "result": "\u5728WIKI-727K\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4Jina\u53d1\u5e03\u7684\u4e09\u79cd\u57fa\u4e8eQwen2-0.5B\u7684\u751f\u6210\u5f0f\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u4f18\u7684\u5b8f\u5e73\u5747F1\u503c\uff0c\u4e14\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u957f\u6587\u6863\u5904\u7406\u7684\u5b9e\u7528\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u8d85\u957f\u6587\u672c\u7684\u6bb5\u843d\u8fb9\u754c\u68c0\u6d4b\u4e0e\u4e0b\u6e38\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23367", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23367", "abs": "https://arxiv.org/abs/2602.23367", "authors": ["Shubh Laddha", "Lucas Changbencharoen", "Win Kuptivej", "Surya Shringla", "Archana Vaidheeswaran", "Yash Bhaskar"], "title": "HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance", "comment": "4 pages, 2 figures, 3 tables", "summary": "Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.", "AI": {"tldr": "\u9488\u5bf9MCP\u670d\u52a1\u5668\u5de5\u5177\u8bc4\u4f30\u7f3a\u4e4f\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u7684\u95ee\u9898\uff0c\u672c\u6587\u57fa\u4e8eMCP Zero\u6570\u636e\u96c6\uff0c\u9996\u6b21\u6784\u5efa\u4e86\u8986\u76d6308\u4e2a\u670d\u52a1\u5668\u30012800\u4e2a\u5de5\u5177\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4e3a\u6bcf\u4e2a\u5de5\u5177\u751f\u6210\u591a\u4e2a\u4e0d\u540c\u7528\u6237\u753b\u50cf\u7684\u67e5\u8be2\uff0c\u6db5\u76d6\u4ece\u7cbe\u786e\u4efb\u52a1\u5230\u6a21\u7cca\u63a2\u7d22\u7684\u591a\u6837\u5316\u610f\u56fe\u3002", "motivation": "\u73b0\u6709MCP\u670d\u52a1\u5668\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u771f\u5b9e\u3001\u7c7b\u4eba\u7684\u7528\u6237\u67e5\u8be2\uff0c\u65e0\u6cd5\u53cd\u6620\u4e0d\u540c\u7528\u6237\u8868\u8fbe\u8bf7\u6c42\u7684\u65b9\u5f0f\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u6cdb\u5316\u6027\u5dee\u4e14\u53ef\u9760\u6027\u865a\u9ad8\uff0c\u6210\u4e3a\u8bc4\u4ef7\u5de5\u5177\u4f7f\u7528\u548c\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u7684\u5173\u952e\u74f6\u9888\u3002", "method": "\u5728MCP Zero\u6570\u636e\u96c6\u57fa\u7840\u4e0a\uff0c\u4e3a2800\u4e2a\u5de5\u5177\u5f00\u53d1\u591a\u4e2a\u72ec\u7279\u7684\u7528\u6237\u753b\u50cf\uff0c\u751f\u6210\u4ece\u7cbe\u786e\u4efb\u52a1\u8bf7\u6c42\u5230\u6a21\u7cca\u63a2\u7d22\u547d\u4ee4\u7684\u591a\u6837\u5316\u7528\u6237\u67e5\u8be2\uff0c\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u6a21\u5f0f\u7684\u590d\u6742\u6027\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21MCP\u6570\u636e\u96c6\uff0c\u6db5\u76d6308\u4e2aMCP\u670d\u52a1\u5668\u76842800\u4e2a\u5de5\u5177\uff0c\u6bcf\u4e2a\u5de5\u5177\u914d\u5bf9\u591a\u4e2a\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u7684\u7528\u6237\u67e5\u8be2\uff0c\u771f\u5b9e\u53cd\u6620\u4e0d\u540c\u7528\u6237\u7684\u610f\u56fe\u5c42\u6b21\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u586b\u8865\u4e86MCP\u670d\u52a1\u5668\u5de5\u5177\u8bc4\u4f30\u9886\u57df\u7f3a\u4e4f\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u8bc4\u4ef7\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u6027\u3002"}}
{"id": "2602.23391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23391", "abs": "https://arxiv.org/abs/2602.23391", "authors": ["Nazanin Mohammadi Sepahvand", "Eleni Triantafillou", "Hugo Larochelle", "Doina Precup", "Daniel M. Roy", "Gintare Karolina Dziugaite"], "title": "Detoxifying LLMs via Representation Erasure-Based Preference Optimization", "comment": null, "summary": "Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful \"directions\" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6613\u4ea7\u751f\u6bd2\u6027\u8f93\u51fa\uff0c\u73b0\u6709DPO/NPO\u7b49\u9632\u5fa1\u65b9\u6cd5\u9c81\u68d2\u6027\u4e0d\u8db3\uff1a\u6613\u53d7\u5bf9\u6297\u63d0\u793a\u653b\u51fb\uff0c\u4e14\u53ef\u901a\u8fc7\u5fae\u8c03\u91cd\u5b66\u4e60\u653b\u51fb\u8f7b\u6613\u64a4\u9500\u3002\u673a\u5236\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u7f16\u8f91\u4ec5\u505c\u7559\u5728\u8868\u9762\uff0c\u6709\u5bb3\u8868\u793a\"\u65b9\u5411\"\u4f9d\u7136\u5b58\u5728\u3002\u4e3a\u6b64\uff0c\u672c\u6587\u63d0\u51faREPO\uff08\u8868\u793a\u64e6\u9664\u504f\u597d\u4f18\u5316\uff09\uff0c\u5c06\u53bb\u6bd2\u5316\u91cd\u6784\u4e3atoken\u7ea7\u504f\u597d\u95ee\u9898\uff0c\u5f3a\u5236\u6709\u6bd2\u8868\u793a\u5411\u826f\u6027\u8868\u793a\u6536\u655b\uff0c\u5b9e\u73b0\u6df1\u5c42\u3001\u9c81\u68d2\u7684\u6bd2\u6027\u795e\u7ecf\u5143\u7f16\u8f91\uff0c\u5728\u91cd\u5b66\u4e60\u653b\u51fb\u548c\u589e\u5f3aGCG\u8d8a\u72f1\u7b49\u9ad8\u7ea7\u5a01\u80c1\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eDPO\u3001NPO\u7b49\u7b97\u6cd5\u7684\u9632\u5fa1\u80fd\u964d\u4f4e\u6bd2\u6027\u8f93\u51fa\u6982\u7387\uff0c\u4f46\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u7f16\u8f91\u662f\u8868\u9762\u7684\uff1a\u7ebf\u6027\u63a2\u6d4b\u63ed\u793a\u6709\u5bb3\"\u65b9\u5411\"\u4ecd\u5b58\u5728\u4e8e\u8868\u793a\u4e2d\u3002\u6b64\u7c7b\u65b9\u6cd5\u6613\u53d7\u5bf9\u6297\u63d0\u793a\u653b\u51fb\uff0c\u4e14\u53ef\u901a\u8fc7\u5fae\u8c03\u91cd\u5b66\u4e60\u653b\u51fb\u8f7b\u6613\u64a4\u9500\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u6df1\u5c42\u7f16\u8f91\u6bd2\u6027\u7f16\u7801\u3001\u4fdd\u6301\u6a21\u578b\u6548\u7528\u7684\u9c81\u68d2\u53bb\u6bd2\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRepresentation Erasure-based Preference Optimization (REPO)\uff0c\u5c06\u53bb\u6bd2\u5316\u91cd\u65b0\u5b9a\u4e49\u4e3atoken\u7ea7\u504f\u597d\u95ee\u9898\u3002\u901a\u8fc7\u65b0\u9896\u7684\u504f\u597d\u4f18\u5316\u76ee\u6807\uff0c\u5229\u7528\u504f\u597d\u6570\u636e\u5f3a\u5236\u6709\u6bd2\u7eed\u4f53\u7684\u8868\u793a\u5411\u5176\u826f\u6027\u5bf9\u5e94\u4f53\u6536\u655b\uff0c\u4ece\u800c\u5728\u8868\u793a\u5c42\u9762\u5bf9\u6bd2\u6027\u7f16\u7801\u795e\u7ecf\u5143\u8fdb\u884c\u6df1\u5c42\u3001\u5c40\u90e8\u5316\u7f16\u8f91\u3002", "result": "\u8be6\u5c3d\u8bc4\u4f30\u663e\u793a\uff0cREPO\u5b9e\u73b0\u6700\u5148\u8fdb\u9c81\u68d2\u6027\uff1a\u6210\u529f\u963b\u6b62\u5305\u62ec\u91cd\u5b66\u4e60\u653b\u51fb\u548c\u589e\u5f3aGCG\u8d8a\u72f1\u5728\u5185\u7684\u590d\u6742\u5a01\u80c1\uff0c\u800c\u8fd9\u4e9b\u653b\u51fb\u53ef\u4f7f\u73b0\u6709\u8868\u793a\u7ea7\u548c\u8f93\u51fa\u7ea7\u65b9\u6cd5\u5931\u6548\u3002\u673a\u5236\u5206\u6790\u8bc1\u5b9e\uff0cREPO\u5bf9\u6bd2\u6027\u7f16\u7801\u795e\u7ecf\u5143\u8fdb\u884c\u6df1\u5c42\u7f16\u8f91\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u901a\u7528\u6548\u7528\u3002", "conclusion": "REPO\u901a\u8fc7\u8868\u793a\u64e6\u9664\u548ctoken\u7ea7\u504f\u597d\u4f18\u5316\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9c81\u68d2\u3001\u66f4\u6df1\u5c42\u7684LLM\u53bb\u6bd2\u5316\u65b9\u6848\uff0c\u80fd\u6c38\u4e45\u7f16\u8f91\u6bd2\u6027\u7f16\u7801\u795e\u7ecf\u5143\uff0c\u62b5\u5fa1\u9ad8\u7ea7\u653b\u51fb\uff0c\u4e3a\u5b89\u5168\u90e8\u7f72LLMs\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.23374", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23374", "abs": "https://arxiv.org/abs/2602.23374", "authors": ["Weixi Lin"], "title": "Higress-RAG: A Holistic Optimization Framework for Enterprise Retrieval-Augmented Generation via Dual Hybrid Retrieval, Adaptive Routing, and CRAG", "comment": "7 pages,5 figures, our submissions are not yet published", "summary": "The integration of Large Language Models (LLMs) into enterprise knowledge management systems has been catalyzed by the Retrieval-Augmented Generation (RAG) paradigm, which augments parametric memory with non-parametric external data. However, the transition from proof-of-concept to production-grade RAG systems is hindered by three persistent challenges: low retrieval precision for complex queries, high rates of hallucination in the generation phase, and unacceptable latency for real-time applications. This paper presents a comprehensive analysis of the Higress RAG MCP Server, a novel, enterprise-centric architecture designed to resolve these bottlenecks through a \"Full-Link Optimization\" strategy. Built upon the Model Context Protocol (MCP), the system introduces a layered architecture that orchestrates a sophisticated pipeline of Adaptive Routing, Semantic Caching, Hybrid Retrieval, and Corrective RAG (CRAG). We detail the technical implementation of key innovations, including the Higress-Native Splitter for structure-aware data ingestion, the application of Reciprocal Rank Fusion (RRF) for merging dense and sparse retrieval signals, and a 50ms-latency Semantic Caching mechanism with dynamic thresholding. Experimental evaluations on domain-specific Higress technical documentation and blogs verify the system's architectural robustness. The results demonstrate that by optimizing the entire retrieval lifecycle - from pre-retrieval query rewriting to post-retrieval corrective evaluation - the Higress RAG system offers a scalable, hallucination-resistant solution for enterprise AI deployment.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4f01\u4e1aRAG\u7cfb\u7edf\u4ece\u6982\u5ff5\u9a8c\u8bc1\u5230\u751f\u4ea7\u90e8\u7f72\u9762\u4e34\u7684\u68c0\u7d22\u7cbe\u5ea6\u4f4e\u3001\u5e7b\u89c9\u7387\u9ad8\u548c\u5ef6\u8fdf\u4e0d\u53ef\u63a5\u53d7\u4e09\u5927\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684Higress RAG MCP Server\u67b6\u6784\u3002\u8be5\u67b6\u6784\u91c7\u7528\"\u5168\u94fe\u8def\u4f18\u5316\"\u7b56\u7565\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8def\u7531\u3001\u8bed\u4e49\u7f13\u5b58\u3001\u6df7\u5408\u68c0\u7d22\u548c\u7ea0\u9519RAG\uff08CRAG\uff09\u7b49\u521b\u65b0\u6280\u672f\uff0c\u5728Higress\u6280\u672f\u6587\u6863\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u6297\u5e7b\u89c9\u80fd\u529b\uff0c\u4e3a\u4f01\u4e1aAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u751f\u4ea7\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u8303\u5f0f\u901a\u8fc7\u7ed3\u5408\u53c2\u6570\u5316\u8bb0\u5fc6\u4e0e\u975e\u53c2\u6570\u5316\u5916\u90e8\u6570\u636e\u4fc3\u8fdb\u4e86LLM\u5728\u4f01\u4e1a\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\uff0c\u4f46\u4ece\u6982\u5ff5\u9a8c\u8bc1\u5411\u751f\u4ea7\u7ea7RAG\u7cfb\u7edf\u8fc7\u6e21\u4ecd\u9762\u4e34\u4e09\u5927\u74f6\u9888\uff1a\u590d\u6742\u67e5\u8be2\u68c0\u7d22\u7cbe\u5ea6\u4e0d\u8db3\u3001\u751f\u6210\u9636\u6bb5\u5e7b\u89c9\u7387\u9ad8\uff0c\u4ee5\u53ca\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u4e0d\u53ef\u63a5\u53d7\u3002\u8fd9\u4e9b\u6311\u6218\u4e25\u91cd\u5236\u7ea6\u4e86\u4f01\u4e1a\u7ea7AI\u5e94\u7528\u7684\u53ef\u884c\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u7684\u67b6\u6784\u521b\u65b0\u6765\u89e3\u51b3\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684Higress RAG MCP Server\u4f01\u4e1a\u67b6\u6784\uff0c\u91c7\u7528\"\u5168\u94fe\u8def\u4f18\u5316\"\u7b56\u7565\u3002\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5206\u5c42\u67b6\u6784\u7f16\u6392\u81ea\u9002\u5e94\u8def\u7531\u3001\u8bed\u4e49\u7f13\u5b58\u3001\u6df7\u5408\u68c0\u7d22\u548c\u7ea0\u9519RAG\uff08CRAG\uff09\u6d41\u6c34\u7ebf\uff1b2\uff09\u5f00\u53d1Higress-Native Splitter\u5b9e\u73b0\u7ed3\u6784\u611f\u77e5\u6570\u636e ingestion\uff1b3\uff09\u5e94\u7528\u4e92\u53cd\u6392\u5e8f\u878d\u5408\uff08RRF\uff09\u5408\u5e76\u7a20\u5bc6\u4e0e\u7a00\u758f\u68c0\u7d22\u4fe1\u53f7\uff1b4\uff09\u8bbe\u8ba1\u52a8\u6001\u9608\u503c50ms\u7ea7\u8bed\u4e49\u7f13\u5b58\u673a\u5236\u3002\u901a\u8fc7\u4f18\u5316\u4ece\u67e5\u8be2\u91cd\u5199\u5230\u68c0\u7d22\u540e\u7ea0\u9519\u7684\u5b8c\u6574\u751f\u547d\u5468\u671f\u6765\u7cfb\u7edf\u6027\u89e3\u51b3\u751f\u4ea7\u74f6\u9888\u3002", "result": "\u5728Higress\u6280\u672f\u6587\u6863\u548c\u535a\u5ba2\u7684\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u67b6\u6784\u7684\u9c81\u68d2\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u67b6\u6784\u901a\u8fc7\u5168\u94fe\u8def\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u7cbe\u5ea6\uff0c\u964d\u4f4e\u4e86\u5e7b\u89c9\u7387\uff0c\u5e76\u5b9e\u73b0\u4e8650ms\u7ea7\u7684\u4f4e\u5ef6\u8fdf\u54cd\u5e94\u3002\u7cfb\u7edf\u5c55\u73b0\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u4f01\u4e1aAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u6297\u5e7b\u89c9\u3001\u9ad8\u6027\u80fd\u7684\u751f\u4ea7\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Higress RAG MCP Server\u901a\u8fc7\u5168\u94fe\u8def\u4f18\u5316\u7b56\u7565\u6210\u529f\u89e3\u51b3\u4e86\u751f\u4ea7\u7ea7RAG\u7cfb\u7edf\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5176\u521b\u65b0\u7684\u5206\u5c42\u67b6\u6784\u548c\u5173\u952e\u6280\u672f\u7ec4\u4ef6\uff08\u81ea\u9002\u5e94\u8def\u7531\u3001\u8bed\u4e49\u7f13\u5b58\u3001\u6df7\u5408\u68c0\u7d22\u3001CRAG\uff09\u6709\u6548\u5e73\u8861\u4e86\u7cbe\u5ea6\u3001\u5e7b\u89c9\u548c\u5ef6\u8fdf\u4e09\u8005\u95f4\u7684\u6743\u8861\u3002\u8be5\u67b6\u6784\u4e3a\u4f01\u4e1a\u90e8\u7f72\u53ef\u6269\u5c55\u3001\u53ef\u9760\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\uff0c\u6807\u5fd7\u7740RAG\u6280\u672f\u4ece\u5b9e\u9a8c\u5ba4\u6982\u5ff5\u5411\u4f01\u4e1a\u751f\u4ea7\u73af\u5883\u7684\u91cd\u8981\u8fc8\u8fdb\u3002"}}
{"id": "2602.23388", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.23388", "abs": "https://arxiv.org/abs/2602.23388", "authors": ["Swati Sharma", "Divya V. Sharma", "Anubha Gupta"], "title": "Task-Lens: Cross-Task Utility Based Speech Dataset Profiling for Low-Resource Indian Languages", "comment": "Accepted at LREC 2026", "summary": "The rising demand for inclusive speech technologies amplifies the need for multilingual datasets for Natural Language Processing (NLP) research. However, limited awareness of existing task-specific resources in low-resource languages hinders research. This challenge is especially acute in linguistically diverse countries, such as India. Cross-task profiling of existing Indian speech datasets can alleviate the data scarcity challenge. This involves investigating the utility of datasets across multiple downstream tasks rather than focusing on a single task. Prior surveys typically catalogue datasets for a single task, leaving comprehensive cross-task profiling as an open opportunity. Therefore, we propose Task-Lens, a cross-task survey that assesses the readiness of 50 Indian speech datasets spanning 26 languages for nine downstream speech tasks. First, we analyze which datasets contain metadata and properties suitable for specific tasks. Next, we propose task-aligned enhancements to unlock datasets to their full downstream potential. Finally, we identify tasks and Indian languages that are critically underserved by current resources. Our findings reveal that many Indian speech datasets contain untapped metadata that can support multiple downstream tasks. By uncovering cross-task linkages and gaps, Task-Lens enables researchers to explore the broader applicability of existing datasets and to prioritize dataset creation for underserved tasks and languages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTask-Lens\u6846\u67b6\uff0c\u5bf950\u4e2a\u5370\u5ea6\u8bed\u97f3\u6570\u636e\u96c6\uff08\u6db5\u76d626\u79cd\u8bed\u8a00\uff09\u57289\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u9002\u7528\u6027\u8fdb\u884c\u8de8\u4efb\u52a1\u5206\u6790\uff0c\u53d1\u73b0\u8bb8\u591a\u6570\u636e\u96c6\u8574\u542b\u672a\u5145\u5206\u5229\u7528\u7684\u5143\u6570\u636e\u53ef\u652f\u6301\u591a\u4efb\u52a1\u5e94\u7528\uff0c\u4e3a\u8d44\u6e90\u532e\u4e4f\u8bed\u8a00\u7684\u7814\u7a76\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5305\u5bb9\u6027\u8bed\u97f3\u6280\u672f\u9700\u6c42\u7684\u589e\u957f\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u591a\u8bed\u79cd\u6570\u636e\u96c6\u9700\u6c42\u65e5\u76ca\u51f8\u663e\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5bf9\u8fd9\u4e9b\u8bed\u8a00\u4e2d\u7279\u5b9a\u4efb\u52a1\u7684\u8d44\u6e90\u8ba4\u77e5\u6709\u9650\uff0c\u5c24\u5176\u5728\u5370\u5ea6\u8fd9\u6837\u8bed\u8a00\u591a\u6837\u6027\u6781\u9ad8\u7684\u56fd\u5bb6\u3002\u4f20\u7edf\u8c03\u67e5\u4ec5\u5173\u6ce8\u5355\u4e00\u4efb\u52a1\uff0c\u7f3a\u4e4f\u8de8\u4efb\u52a1\u5206\u6790\uff0c\u65e0\u6cd5\u6709\u6548\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8de8\u4efb\u52a1\u5206\u6790\u73b0\u6709\u5370\u5ea6\u8bed\u97f3\u6570\u636e\u96c6\uff0c\u6316\u6398\u5176\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u8bc6\u522b\u8d44\u6e90\u4e25\u91cd\u4e0d\u8db3\u7684\u4efb\u52a1\u548c\u8bed\u8a00\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51faTask-Lens\u6846\u67b6\uff0c\u5bf950\u4e2a\u5370\u5ea6\u8bed\u97f3\u6570\u636e\u96c6\uff08\u8986\u76d626\u79cd\u8bed\u8a00\uff09\u57289\u4e2a\u4e0b\u6e38\u8bed\u97f3\u4efb\u52a1\u4e0a\u7684\u51c6\u5907\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002\u9996\u5148\u5206\u6790\u54ea\u4e9b\u6570\u636e\u96c6\u5305\u542b\u9002\u5408\u7279\u5b9a\u4efb\u52a1\u7684\u5143\u6570\u636e\u548c\u5c5e\u6027\uff1b\u5176\u6b21\u63d0\u51fa\u4efb\u52a1\u5bf9\u9f50\u7684\u589e\u5f3a\u65b9\u6848\u4ee5\u91ca\u653e\u6570\u636e\u96c6\u7684\u5b8c\u6574\u4e0b\u6e38\u6f5c\u529b\uff1b\u6700\u540e\u8bc6\u522b\u5f53\u524d\u8d44\u6e90\u4e25\u91cd\u4e0d\u8db3\u7684\u4efb\u52a1\u548c\u5370\u5ea6\u8bed\u8a00\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8bb8\u591a\u5370\u5ea6\u8bed\u97f3\u6570\u636e\u96c6\u5305\u542b\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u5143\u6570\u636e\uff0c\u53ef\u652f\u6301\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u3002\u901a\u8fc7\u63ed\u793a\u8de8\u4efb\u52a1\u5173\u8054\u548c\u7f3a\u53e3\uff0cTask-Lens\u4f7f\u7814\u7a76\u8005\u80fd\u591f\u63a2\u7d22\u73b0\u6709\u6570\u636e\u96c6\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\uff0c\u5e76\u4f18\u5148\u4e3a\u8d44\u6e90\u4e0d\u8db3\u7684\u4efb\u52a1\u548c\u8bed\u8a00\u521b\u5efa\u65b0\u6570\u636e\u96c6\u3002", "conclusion": "Task-Lens\u901a\u8fc7\u8de8\u4efb\u52a1\u5206\u6790\u6846\u67b6\uff0c\u4e0d\u4ec5\u63ed\u793a\u4e86\u5370\u5ea6\u8bed\u97f3\u6570\u636e\u96c6\u5728\u591a\u4efb\u52a1\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u8fd8\u8bc6\u522b\u4e86\u5173\u952e\u7684\u8bed\u8a00\u548c\u4efb\u52a1\u7f3a\u53e3\u3002\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\uff0c\u4ee5\u6700\u5927\u5316\u73b0\u6709\u6570\u636e\u96c6\u7684\u6548\u7528\uff0c\u5e76\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6570\u636e\u96c6\u521b\u5efa\u4f18\u5148\u7ea7\u63d0\u4f9b\u6307\u5bfc\uff0c\u4ece\u800c\u63a8\u52a8\u5305\u5bb9\u6027\u8bed\u97f3\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.23440", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23440", "abs": "https://arxiv.org/abs/2602.23440", "authors": ["Chris Samarinas", "Haw-Shiuan Chang", "Hamed Zamani"], "title": "Truncated Step-Level Sampling with Process Rewards for Retrieval-Augmented Reasoning", "comment": null, "summary": "Training large language models to reason with search engines via reinforcement learning is hindered by a fundamental credit assignment problem: existing methods such as Search-R1 provide only a sparse outcome reward after an entire multi-step trajectory, making it infeasible to attribute success or failure to individual reasoning and retrieval decisions. Process-reward methods like StepSearch alleviate this by introducing step-level supervision, but rely on heuristic rewards such as TF-IDF overlap with gold documents, and still sample k complete trajectories per example, retaining high gradient variance. We propose SLATE, a framework built on two complementary ideas: (1) truncated step-level sampling, which generates k trajectories that share a common prefix and differ only at the next step, and (2) dense LLM-as-judge rewards, which replace heuristic scoring with a capable LLM evaluator that assesses the quality of each reasoning step, search query, and answer, providing richer and more reliable supervision. We theoretically prove that under the same dense reward structure, truncated sampling reduces the variance of advantage estimates by up to a factor of T compared to full-trajectory sampling for T-step trajectories, yielding lower-variance, better-targeted policy gradients. Experiments on seven QA benchmarks confirm that SLATE consistently outperforms both sparse-reward and process-reward baselines, with the largest gains on harder multi-hop tasks and smaller models.", "AI": {"tldr": "SLATE\u6846\u67b6\u901a\u8fc7\u622a\u65ad\u6b65\u9aa4\u91c7\u6837\u548cLLM-as-judge\u5bc6\u96c6\u5956\u52b1\uff0c\u89e3\u51b3\u4e86LLM\u4e0e\u641c\u7d22\u5f15\u64ce\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u964d\u4f4e\u4e86\u68af\u5ea6\u65b9\u5dee\u5e76\u5728\u591a\u8df3QA\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8bad\u7ec3LLM\u4e0e\u641c\u7d22\u5f15\u64ce\u8fdb\u884c\u591a\u6b65\u63a8\u7406\u65f6\u9762\u4e34\u4fe1\u7528\u5206\u914d\u96be\u9898\u2014\u2014\u7a00\u758f\u5956\u52b1\u65e0\u6cd5\u5f52\u56e0\u5230\u5177\u4f53\u6b65\u9aa4\uff0c\u800c\u8fc7\u7a0b\u5956\u52b1\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u8bc4\u5206\u4e14\u91c7\u6837\u5b8c\u6574\u8f68\u8ff9\u5bfc\u81f4\u9ad8\u65b9\u5dee\u3002", "method": "\u63d0\u51faSLATE\u6846\u67b6\uff0c\u7ed3\u5408\u622a\u65ad\u6b65\u9aa4\u7ea7\u91c7\u6837\uff08\u751f\u6210\u5171\u4eab\u524d\u7f00\u3001\u4ec5\u4e0b\u4e00\u6b65\u4e0d\u540c\u7684k\u4e2a\u8f68\u8ff9\uff09\u548c\u5bc6\u96c6LLM-as-judge\u5956\u52b1\uff08\u7528LLM\u8bc4\u4f30\u6bcf\u4e00\u6b65\u63a8\u7406\u3001\u67e5\u8be2\u548c\u7b54\u6848\u8d28\u91cf\uff09\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u5176\u53ef\u5c06\u4f18\u52bf\u4f30\u8ba1\u65b9\u5dee\u964d\u4f4eT\u500d\u3002", "result": "\u5728\u4e03\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cSLATE\u6301\u7eed\u4f18\u4e8e\u7a00\u758f\u5956\u52b1\u548c\u8fc7\u7a0b\u5956\u52b1\u57fa\u7ebf\uff0c\u5728\u591a\u8df3\u4efb\u52a1\u548c\u8f83\u5c0f\u6a21\u578b\u4e0a\u63d0\u5347\u6700\u663e\u8457\u3002", "conclusion": "SLATE\u901a\u8fc7\u622a\u65ad\u91c7\u6837\u548c\u5bc6\u96c6LLM\u8bc4\u4f30\u6709\u6548\u89e3\u51b3\u4e86\u4fe1\u7528\u5206\u914d\u548c\u65b9\u5dee\u95ee\u9898\uff0c\u4e3aLLM\u4e0e\u5de5\u5177\u7ed3\u5408\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u8303\u5f0f\u3002"}}
{"id": "2602.23541", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23541", "abs": "https://arxiv.org/abs/2602.23541", "authors": ["Arvind Raghavan", "Elias Bareinboim"], "title": "Causal Identification from Counterfactual Data: Completeness and Bounding Results", "comment": null, "summary": "Previous work establishing completeness results for $\\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\\textit{counterfactual realizabilty}$. This leaves open the question of what $\\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.", "AI": {"tldr": "\u672c\u7814\u7a76\u7a81\u7834\u56e0\u679c\u5c42\u6b21\u7b2c\u4e09\u5c42\u6570\u636e\u4e0d\u53ef\u83b7\u5f97\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u5f00\u53d1CTFIDU+\u7b97\u6cd5\u5e76\u8bc1\u660e\u5176\u5b8c\u5907\u6027\uff0c\u9996\u6b21\u7cfb\u7edf\u523b\u753b\u4e86\u6df7\u5408\u89c2\u6d4b\u3001\u5e72\u9884\u4e0e\u90e8\u5206\u53cd\u4e8b\u5b9e\u6570\u636e\u4e0b\u53cd\u4e8b\u5b9e\u8bc6\u522b\u7684\u7406\u8bba\u8fb9\u754c\uff0c\u786e\u7acb\u4e86\u975e\u53c2\u6570\u56e0\u679c\u63a8\u65ad\u7684\u57fa\u672c\u6781\u9650\uff0c\u5e76\u4e3a\u4e0d\u53ef\u8bc6\u522b\u91cf\u63d0\u4f9b\u4e86\u57fa\u4e8e\u53ef\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u6570\u636e\u7684\u65b0\u8fb9\u754c\u3002", "motivation": "\u4f20\u7edf\u53cd\u4e8b\u5b9e\u8bc6\u522b\u5b8c\u5907\u6027\u7814\u7a76\u5c40\u9650\u4e8e\u56e0\u679c\u5c42\u6b21\u7684\u524d\u4e24\u5c42\uff08\u89c2\u6d4b\u4e0e\u5e72\u9884\u5206\u5e03\uff09\uff0c\u56e0\u5047\u8bbe\u7b2c\u4e09\u5c42\u53cd\u4e8b\u5b9e\u5206\u5e03\u65e0\u6cd5\u83b7\u5f97\u3002\u5c3d\u7ba1Raghavan & Bareinboim (2025)\u63d0\u51fa\u4e86\"\u53cd\u4e8b\u5b9e\u53ef\u5b9e\u73b0\u6027\"\u6982\u5ff5\uff0c\u5f62\u5f0f\u5316\u4e86\u4e00\u7c7b\u53ef\u76f4\u63a5\u4f30\u8ba1\u7684\u7b2c\u4e09\u5c42\u5206\u5e03\uff0c\u4f46\u5173\u952e\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\uff1a\u5728\u53ef\u83b7\u53d6\u90e8\u5206\u7b2c\u4e09\u5c42\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u54ea\u4e9b\u989d\u5916\u53cd\u4e8b\u5b9e\u91cf\u53d8\u5f97\u53ef\u8bc6\u522b\uff1f\u6b64\u95ee\u9898\u7b54\u6848\u5c06\u754c\u5b9a\u56e0\u679c\u63a8\u65ad\u80fd\u529b\u7684\u6839\u672c\u8fb9\u754c\u3002", "method": "\u63d0\u51faCTFIDU+\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4efb\u610f\u7b2c\u4e09\u5c42\u53cd\u4e8b\u5b9e\u5206\u5e03\u96c6\u5408\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u67e5\u8be2\uff0c\u5e76\u4e25\u683c\u8bc1\u660e\u5176\u5b8c\u5907\u6027\u3002\u8be5\u7b97\u6cd5\u7edf\u4e00\u5904\u7406\u89c2\u6d4b\u3001\u5e72\u9884\u4e0e\u53ef\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u6570\u636e\u7684\u6df7\u5408\u573a\u666f\u3002\u9488\u5bf9\u4e0d\u53ef\u7cbe\u786e\u8bc6\u522b\u7684\u53cd\u4e8b\u5b9e\u91cf\uff0c\u8fdb\u4e00\u6b65\u63a8\u5bfc\u51fa\u57fa\u4e8e\u53ef\u5b9e\u73b0\u6570\u636e\u7684\u65b0\u578b\u89e3\u6790\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "(1) CTFIDU+\u7b97\u6cd5\u5bf9\u4efb\u610f\u53ef\u5b9e\u73b0\u7b2c\u4e09\u5c42\u5206\u5e03\u4e0b\u7684\u53cd\u4e8b\u5b9e\u8bc6\u522b\u5177\u6709\u5b8c\u5907\u6027\uff1b(2) \u786e\u7acb\u4e86\u4ece\u7269\u7406\u53ef\u5b9e\u73b0\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u91cf\u7684\u7406\u8bba\u6781\u9650\uff0c\u63ed\u793a\u4e86\u975e\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7cbe\u786e\u56e0\u679c\u63a8\u65ad\u7684\u6839\u672c\u9650\u5236\uff1b(3) \u4e3a\u4e0d\u53ef\u8bc6\u522b\u7684\u5173\u952e\u53cd\u4e8b\u5b9e\u91cf\u63a8\u5bfc\u51fa\u65b0\u89e3\u6790\u8fb9\u754c\uff0c\u6a21\u62df\u8bc1\u5b9e\u53cd\u4e8b\u5b9e\u6570\u636e\u80fd\u663e\u8457\u6536\u7d27\u8fd9\u4e9b\u8fb9\u754c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u5f62\u5f0f\u5316\u7b2c\u4e09\u5c42\u6570\u636e\u7684\u53ef\u83b7\u5f97\u6027\uff0c\u5b8c\u6574\u523b\u753b\u4e86\u6df7\u5408\u6570\u636e\u73af\u5883\u4e0b\u7684\u53cd\u4e8b\u5b9e\u8bc6\u522b\u80fd\u529b\u8fb9\u754c\uff0c\u5c06\u56e0\u679c\u63a8\u65ad\u7406\u8bba\u524d\u6cbf\u63a8\u8fdb\u81f3\u65b0\u5c42\u6b21\u3002CTFIDU+\u7b97\u6cd5\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u5b8c\u5907\u5de5\u5177\uff0c\u540c\u65f6\u63ed\u793a\u7cbe\u786e\u63a8\u65ad\u7684\u57fa\u672c\u9650\u5236\u3002\u5bf9\u4e8e\u4e0d\u53ef\u8bc6\u522b\u91cf\uff0c\u5229\u7528\u53ef\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u6570\u636e\u53ef\u83b7\u5f97\u66f4\u7d27\u8fb9\u754c\uff0c\u517c\u5177\u7406\u8bba\u6df1\u5ea6\u4e0e\u5b9e\u8df5\u6307\u5bfc\u4ef7\u503c\u3002"}}
{"id": "2602.23409", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.23409", "abs": "https://arxiv.org/abs/2602.23409", "authors": ["Michael Poppel", "Jonas Stein", "Sebastian W\u00f6lckert", "Markus Baumann", "Claudia Linnhoff-Popien"], "title": "Long Range Frequency Tuning for QML", "comment": null, "summary": "Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).", "AI": {"tldr": "\u9488\u5bf9\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u53ef\u8bad\u7ec3\u9891\u7387\u7f16\u7801\u7684\u68af\u5ea6\u4f18\u5316\u5b58\u5728\u9891\u7387\u53ef\u8fbe\u6027\u9650\u5236\uff08\u4ec5\u80fd\u79fb\u52a8\u7ea6\u00b11\u5355\u4f4d\uff09\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4e09\u5143\u7f16\u7801\u7684\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4ee5O(log\u2083(\u03c9_max))\u7684\u7535\u8def\u6df1\u5ea6\u786e\u4fdd\u76ee\u6807\u9891\u7387\u4f4d\u4e8e\u5c40\u90e8\u53ef\u5230\u8fbe\u8303\u56f4\u5185\uff0c\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u822a\u73ed\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b00.9969\u548c0.9671\u7684\u4e2d\u4f4dR\u00b2\u5f97\u5206\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u53ef\u8bad\u7ec3\u9891\u7387\u7f16\u7801\u7406\u8bba\u4e0a\u80fd\u5c06\u91cf\u5b50\u7535\u8def\u6df1\u5ea6\u4f18\u5316\u81f3\u4e0e\u76ee\u6807\u9891\u8c31\u5927\u5c0f\u5339\u914d\uff0c\u4f46\u5b9e\u9645\u8bad\u7ec3\u4e2d\u68af\u5ea6\u4e0b\u964d\u65e0\u6cd5\u6709\u6548\u8c03\u8282\u9891\u7387\u9884\u56e0\u5b50\uff0c\u5bfc\u81f4\u9891\u7387\u53ef\u8fbe\u6027\u53d7\u9650\uff0c\u5f53\u76ee\u6807\u9891\u7387\u8d85\u51fa\u53ef\u79fb\u52a8\u8303\u56f4\u65f6\u4f18\u5316\u5931\u8d25\uff0c\u5236\u7ea6\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u7f51\u683c\u521d\u59cb\u5316\u7b56\u7565\u7ed3\u5408\u4e09\u5143\u7f16\u7801\u65b9\u6848\uff0c\u751f\u6210\u5bc6\u96c6\u7684\u6574\u6570\u9891\u7387\u8c31\uff0c\u4f7f\u76ee\u6807\u9891\u7387\u81ea\u52a8\u843d\u5165\u68af\u5ea6\u4f18\u5316\u53ef\u8fbe\u8303\u56f4\u5185\uff0c\u5728\u4fdd\u6301\u6307\u6570\u7ea7\u4f18\u4e8e\u56fa\u5b9a\u9891\u7387\u65b9\u6cd5\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u9891\u7387\u8bad\u7ec3\u96be\u9898\u3002", "result": "\u5728\u5408\u6210\u9ad8\u9891\u79fb\u4f4d\u6570\u636e\u96c6\u4e0a\uff0c\u4e09\u5143\u7f51\u683c\u521d\u59cb\u5316\u4e2d\u4f4dR\u00b2\u8fbe0.9969\uff0c\u8f83\u57fa\u7ebf0.1841\u63d0\u5347\u663e\u8457\uff1b\u5728Flight Passengers\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u4e2d\u4f4dR\u00b2\u4e3a0.9671\uff0c\u8f83\u57fa\u7ebf0.7876\u63d0\u534722.8%\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u7a81\u7834\u4e86\u53ef\u8bad\u7ec3\u9891\u7387\u7f16\u7801\u7684\u9891\u7387\u53ef\u8fbe\u6027\u74f6\u9888\uff0c\u5728\u4fdd\u6301\u7535\u8def\u6548\u7387\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23530", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23530", "abs": "https://arxiv.org/abs/2602.23530", "authors": ["Aditya Gaydhani", "Guangyue Xu", "Dhanush Kamath", "Ankit Singh", "Alex Li"], "title": "Unified Learning-to-Rank for Multi-Channel Retrieval in Large-Scale E-Commerce Search", "comment": null, "summary": "Large-scale e-commerce search must surface a broad set of items from a vast catalog, ranging from bestselling products to new, trending, or seasonal items. Modern systems therefore rely on multiple specialized retrieval channels to surface products, each designed to satisfy a specific objective. A key challenge is how to effectively merge documents from these heterogeneous channels into a single ranked list under strict latency constraints while optimizing for business KPIs such as user conversion. Rank-based fusion methods such as Reciprocal Rank Fusion (RRF) and Weighted Interleaving rely on fixed global channel weights and treat channels independently, failing to account for query-specific channel utility and cross-channel interactions. We observe that multi-channel fusion can be reformulated as a query-dependent learning-to-rank problem over heterogeneous candidate sources. In this paper, we propose a unified ranking model that learns to merge and rank documents from multiple retrieval channels. We formulate the problem as a channel-aware learning-to-rank task that jointly optimizes clicks, add-to-carts, and purchases while incorporating channel-specific objectives. We further incorporate recent user behavioral signals to capture short-term intent shifts that are critical for improving conversion in multi-channel ranking. Our online A/B experiments show that the proposed approach outperforms rank-based fusion methods, leading to a +2.85\\% improvement in user conversion. The model satisfies production latency requirements, achieving a p95 latency of under 50\\,ms, and is deployed on Target.com.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u7535\u5546\u591a\u901a\u9053\u68c0\u7d22\u7684\u7edf\u4e00\u6392\u5e8f\u6a21\u578b\uff0c\u5c06\u878d\u5408\u95ee\u9898\u91cd\u6784\u4e3a\u67e5\u8be2\u611f\u77e5\u7684\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\u3002\u8be5\u6a21\u578b\u52a8\u6001\u5b66\u4e60\u901a\u9053\u6743\u91cd\u4e0e\u4ea4\u4e92\uff0c\u8054\u5408\u4f18\u5316\u70b9\u51fb\u3001\u52a0\u8d2d\u3001\u8d2d\u4e70\u7b49\u76ee\u6807\uff0c\u5e76\u5229\u7528\u7528\u6237\u884c\u4e3a\u4fe1\u53f7\u6355\u6349\u77ed\u671f\u610f\u56fe\u3002\u5b9e\u9a8c\u663e\u793a\u8f6c\u5316\u7387\u63d0\u53472.85%\uff0c\u5ef6\u8fdf\u4f4e\u4e8e50\u6beb\u79d2\uff0c\u5df2\u5728Target.com\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u7535\u5546\u641c\u7d22\u9700\u4ece\u6d77\u91cf\u5546\u54c1\u5e93\u4e2d\u5448\u73b0\u591a\u6837\u5316\u5546\u54c1\uff0c\u73b0\u4ee3\u7cfb\u7edf\u4f9d\u8d56\u591a\u4e2a\u4e13\u7528\u68c0\u7d22\u901a\u9053\u3002\u7136\u800c\uff0c\u4f20\u7edf\u6392\u540d\u878d\u5408\u65b9\u6cd5\uff08\u5982RRF\u548c\u52a0\u6743\u4ea4\u9519\uff09\u91c7\u7528\u56fa\u5b9a\u5168\u5c40\u6743\u91cd\u4e14\u72ec\u7acb\u5904\u7406\u901a\u9053\uff0c\u65e0\u6cd5\u9002\u5e94\u67e5\u8be2\u7279\u5b9a\u7684\u901a\u9053\u6548\u7528\u548c\u8de8\u901a\u9053\u4ea4\u4e92\uff0c\u5728\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u96be\u4ee5\u6709\u6548\u4f18\u5316\u7528\u6237\u8f6c\u5316\u7b49\u4e1a\u52a1\u6307\u6807\u3002", "method": "\u672c\u6587\u5c06\u591a\u901a\u9053\u878d\u5408\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u67e5\u8be2\u4f9d\u8d56\u7684\u5f02\u8d28\u6e90\u5b66\u4e60\u6392\u5e8f\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u9053\u611f\u77e5\u7684\u7edf\u4e00\u6392\u5e8f\u6846\u67b6\u3002\u8be5\u6a21\u578b\u8054\u5408\u4f18\u5316\u70b9\u51fb\u3001\u52a0\u8d2d\u548c\u8d2d\u4e70\u7b49\u591a\u76ee\u6807\uff0c\u5e76\u878d\u5165\u901a\u9053\u7279\u5b9a\u76ee\u6807\uff0c\u540c\u65f6\u5f15\u5165\u8fd1\u671f\u7528\u6237\u884c\u4e3a\u4fe1\u53f7\u4ee5\u6355\u83b7\u5f71\u54cd\u8f6c\u5316\u7387\u7684\u5173\u952e\u77ed\u671f\u610f\u56fe\u53d8\u5316\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6392\u540d\u878d\u5408\u65b9\u6cd5\uff0c\u4f7f\u7528\u6237\u8f6c\u5316\u7387\u63d0\u53472.85%\u3002\u6a21\u578b\u6ee1\u8db3\u751f\u4ea7\u73af\u5883\u5ef6\u8fdf\u8981\u6c42\uff0cp95\u5ef6\u8fdf\u4f4e\u4e8e50\u6beb\u79d2\uff0c\u5e76\u6210\u529f\u90e8\u7f72\u4e8eTarget.com\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06\u591a\u901a\u9053\u68c0\u7d22\u878d\u5408\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u5b66\u4e60\u7684\u6392\u5e8f\u4efb\u52a1\uff0c\u901a\u8fc7\u67e5\u8be2\u611f\u77e5\u7684\u52a8\u6001\u6743\u91cd\u5b66\u4e60\u548c\u8de8\u901a\u9053\u4ea4\u4e92\u5efa\u6a21\uff0c\u5728\u63d0\u5347\u5546\u4e1a\u6307\u6807\u7684\u540c\u65f6\u4fdd\u8bc1\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u5927\u578b\u7535\u5546\u5e73\u53f0\u7684\u6392\u5e8f\u67b6\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23452", "categories": ["cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.23452", "abs": "https://arxiv.org/abs/2602.23452", "authors": ["Zhengqing Yuan", "Kaiwen Shi", "Zheyuan Zhang", "Lichao Sun", "Nitesh V. Chawla", "Yanfang Ye"], "title": "CiteAudit: You Cited It, But Did You Read It? A Benchmark for Verifying Scientific References in the LLM Era", "comment": null, "summary": "Scientific research relies on accurate citation for attribution and integrity, yet large language models (LLMs) introduce a new risk: fabricated references that appear plausible but correspond to no real publications. Such hallucinated citations have already been observed in submissions and accepted papers at major machine learning venues, exposing vulnerabilities in peer review. Meanwhile, rapidly growing reference lists make manual verification impractical, and existing automated tools remain fragile to noisy and heterogeneous citation formats and lack standardized evaluation. We present the first comprehensive benchmark and detection framework for hallucinated citations in scientific writing. Our multi-agent verification pipeline decomposes citation checking into claim extraction, evidence retrieval, passage matching, reasoning, and calibrated judgment to assess whether a cited source truly supports its claim. We construct a large-scale human-validated dataset across domains and define unified metrics for citation faithfulness and evidence alignment. Experiments with state-of-the-art LLMs reveal substantial citation errors and show that our framework significantly outperforms prior methods in both accuracy and interpretability. This work provides the first scalable infrastructure for auditing citations in the LLM era and practical tools to improve the trustworthiness of scientific references.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u865a\u5047\u4f46\u770b\u4f3c\u5408\u7406\u7684\u5b66\u672f\u5f15\u7528\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u7efc\u5408\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u68c0\u6d4b\u6846\u67b6\u3002\u8be5\u6846\u67b6\u91c7\u7528\u591a\u667a\u80fd\u4f53\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u901a\u8fc7\u58f0\u660e\u63d0\u53d6\u3001\u8bc1\u636e\u68c0\u7d22\u3001\u6bb5\u843d\u5339\u914d\u3001\u63a8\u7406\u548c\u6821\u51c6\u5224\u65ad\u6765\u8bc4\u4f30\u5f15\u7528\u771f\u5b9e\u6027\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u4eba\u5de5\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3aLLM\u65f6\u4ee3\u7684\u5b66\u672f\u5f15\u7528\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u865a\u5047\u5f15\u7528\u5df2\u51fa\u73b0\u5728\u9876\u7ea7\u673a\u5668\u5b66\u4e60\u4f1a\u8bae\u7684\u6295\u7a3f\u548c\u5f55\u7528\u8bba\u6587\u4e2d\uff0c\u66b4\u9732\u4e86\u540c\u884c\u8bc4\u5ba1\u7684\u6f0f\u6d1e\uff1b\u540c\u65f6\u53c2\u8003\u6587\u732e\u5217\u8868\u5feb\u901f\u589e\u957f\u4f7f\u4eba\u5de5\u6838\u67e5\u4e0d\u53ef\u884c\uff0c\u800c\u73b0\u6709\u81ea\u52a8\u5316\u5de5\u5177\u5bf9\u566a\u58f0\u548c\u5f02\u6784\u5f15\u7528\u683c\u5f0f\u8106\u5f31\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u9a8c\u8bc1\u6d41\u6c34\u7ebf\uff0c\u5c06\u5f15\u7528\u68c0\u67e5\u5206\u89e3\u4e3a\u58f0\u660e\u63d0\u53d6\u3001\u8bc1\u636e\u68c0\u7d22\u3001\u6bb5\u843d\u5339\u914d\u3001\u63a8\u7406\u548c\u6821\u51c6\u5224\u65ad\u4e94\u4e2a\u6b65\u9aa4\uff1b\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u8de8\u9886\u57df\u4eba\u5de5\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5e76\u5b9a\u4e49\u4e86\u7edf\u4e00\u7684\u5f15\u7528\u5fe0\u5b9e\u5ea6\u548c\u8bc1\u636e\u5bf9\u9f50\u5ea6\u91cf\u6807\u51c6\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5927\u91cf\u5f15\u7528\u9519\u8bef\uff0c\u4e14\u672c\u6846\u67b6\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3aLLM\u65f6\u4ee3\u7684\u5b66\u672f\u5f15\u7528\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u53ca\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u79d1\u5b66\u53c2\u8003\u6587\u732e\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.23545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23545", "abs": "https://arxiv.org/abs/2602.23545", "authors": ["Matteo Ceriscioli", "Karthika Mohan"], "title": "Planning under Distribution Shifts with Causal POMDPs", "comment": "To appear at the 36th International Conference on Automated Planning and Scheduling (ICAPS-26)", "summary": "In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $\u03b1$-vector-based POMDP methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u77e5\u8bc6\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u6f02\u79fb\u4e0b\u8fdb\u884c\u89c4\u5212\u3002\u5c06\u73af\u5883\u53d8\u5316\u8868\u793a\u4e3a\u5bf9\u56e0\u679cPOMDP\u7684\u5e72\u9884\uff0c\u4ece\u800c\u8bc4\u4f30\u5047\u8bbe\u53d8\u5316\u4e0b\u7684\u8ba1\u5212\u5e76\u4e3b\u52a8\u8bc6\u522b\u73af\u5883\u5df2\u6539\u53d8\u7684\u7ec4\u4ef6\u3002\u8bc1\u660e\u5728\u589e\u5f3a\u7684\u4fe1\u5ff5\u7a7a\u95f4\u4e2d\u4ef7\u503c\u51fd\u6570\u4fdd\u6301\u5206\u6bb5\u7ebf\u6027\u4e14\u51f8\uff08PWLC\uff09\uff0c\u7ef4\u6301\u4e86\u03b1\u2011\u5411\u91cfPOMDP\u65b9\u6cd5\u7684\u53ef\u5904\u7406\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u89c4\u5212\u5e38\u53d7\u5230\u5206\u5e03\u6f02\u79fb\u7684\u6311\u6218\uff1a\u5728\u4e00\u79cd\u6761\u4ef6\u4e0b\u83b7\u5f97\u7684\u6a21\u578b\u5728\u72b6\u6001\u5206\u5e03\u6216\u73af\u5883\u52a8\u6001\u53d1\u751f\u53d8\u5316\u65f6\u53ef\u80fd\u5931\u6548\uff0c\u5bfc\u81f4\u5148\u524d\u5b66\u4e60\u7684\u7b56\u7565\u5931\u8d25\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u4e14\u5206\u5e03\u6f02\u79fb\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u9c81\u68d2\u89c4\u5212\u7684\u6846\u67b6\u3002", "method": "1. \u5c06\u56e0\u679c\u77e5\u8bc6\u5f15\u5165POMDP\uff0c\u6784\u5efa\u56e0\u679cPOMDP\u6a21\u578b\u3002  \n2. \u5c06\u73af\u5883\u6f02\u79fb\u5efa\u6a21\u4e3a\u8be5\u6a21\u578b\u4e0a\u7684\u5e72\u9884\uff08intervention\uff09\uff0c\u4ece\u800c\u80fd\u591f\u5728\u5047\u8bbe\u7684\u53d8\u5316\u4e0b\u8bc4\u4f30\u8ba1\u5212\u5e76\u4e3b\u52a8\u8bc6\u522b\u54ea\u4e9b\u73af\u5883\u7ec4\u4ef6\u53d1\u751f\u4e86\u6539\u53d8\u3002  \n3. \u7ef4\u62a4\u5e76\u66f4\u65b0\u5bf9\u9690\u72b6\u6001\u548c\u5e95\u5c42\u9886\u57df\u7684\u4fe1\u5ff5\uff08belief\uff09\uff0c\u5e76\u8bc1\u660e\u5728\u589e\u5f3a\u7684\u4fe1\u5ff5\u7a7a\u95f4\u4e2d\u4ef7\u503c\u51fd\u6570\u4ecd\u4fdd\u6301\u5206\u6bb5\u7ebf\u6027\u4e14\u51f8\uff08PWLC\uff09\u3002", "result": "\u5728\u589e\u5f3a\u7684\u4fe1\u5ff5\u7a7a\u95f4\u4e2d\uff0c\u4ef7\u503c\u51fd\u6570\u4fdd\u6301PWLC\u6027\u8d28\u3002\u8fd9\u4f7f\u5f97\u53ef\u4ee5\u4f7f\u7528\u03b1\u2011\u5411\u91cf\u65b9\u6cd5\u8fdb\u884c\u6709\u6548\u7684POMDP\u89c4\u5212\uff0c\u4ece\u800c\u5728\u5206\u5e03\u6f02\u79fb\u4e0b\u4ecd\u7136\u4fdd\u6301\u8ba1\u7b97\u7684\u53ef\u5904\u7406\u6027\u3002", "conclusion": "\u8be5\u56e0\u679cPOMDP\u6846\u67b6\u80fd\u591f\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u4e14\u5b58\u5728\u5206\u5e03\u6f02\u79fb\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u89c4\u5212\u3002\u901a\u8fc7\u4fdd\u6301PWLC\u7ed3\u6784\uff0c\u4fdd\u7559\u4e86\u03b1\u2011\u5411\u91cf\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u4e3a\u5b9e\u73b0\u53ef\u5904\u7406\u7684\u9002\u5e94\u6027\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.23620", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23620", "abs": "https://arxiv.org/abs/2602.23620", "authors": ["Gui Ling", "Weiyuan Li", "Yue Jiang", "Wenjun Peng", "Xingxian Liu", "Dongshuai Li", "Fuyu Lv", "Dan Ou", "Haihong Tang"], "title": "Synthetic Data Powers Product Retrieval for Long-tail Knowledge-Intensive Queries in E-commerce Search", "comment": null, "summary": "Product retrieval is the backbone of e-commerce search: for each user query, it identifies a high-recall candidate set from billions of items, laying the foundation for high-quality ranking and user experience. Despite extensive optimization for mainstream queries, existing systems still struggle with long-tail queries, especially knowledge-intensive ones. These queries exhibit diverse linguistic patterns, often lack explicit purchase intent, and require domain-specific knowledge reasoning for accurate interpretation. They also suffer from a shortage of reliable behavioral logs, which makes such queries a persistent challenge for retrieval optimization. To address these issues, we propose an efficient data synthesis framework tailored to retrieval involving long-tail, knowledge-intensive queries. The key idea is to implicitly distill the capabilities of a powerful offline query-rewriting model into an efficient online retrieval system. Leveraging the strong language understanding of LLMs, we train a multi-candidate query rewriting model with multiple reward signals and capture its rewriting capability in well-curated query-product pairs through a powerful offline retrieval pipeline. This design mitigates distributional shift in rewritten queries, which might otherwise limit incremental recall or introduce irrelevant products. Experiments demonstrate that without any additional tricks, simply incorporating this synthetic data into retrieval model training leads to significant improvements. Online Side-By-Side (SBS) human evaluation results indicate a notable enhancement in user search experience.", "AI": {"tldr": "\u9488\u5bf9\u7535\u5546\u641c\u7d22\u4e2d\u77e5\u8bc6\u5bc6\u96c6\u578b\u957f\u5c3e\u67e5\u8be2\u7684\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u79bb\u7ebf\u67e5\u8be2\u91cd\u5199\u6a21\u578b\u7684\u80fd\u529b\u84b8\u998f\u81f3\u5728\u7ebf\u68c0\u7d22\u7cfb\u7edf\uff0c\u5229\u7528LLM\u8bad\u7ec3\u591a\u5019\u9009\u91cd\u5199\u6a21\u578b\u5e76\u751f\u6210\u9ad8\u8d28\u91cf\u67e5\u8be2-\u5546\u54c1\u5bf9\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6548\u679c\u4e0e\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u7535\u5546\u4ea7\u54c1\u68c0\u7d22\u7cfb\u7edf\u5728\u5904\u7406\u957f\u5c3e\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e9b\u67e5\u8be2\u8bed\u8a00\u6a21\u5f0f\u591a\u6837\u3001\u7f3a\u4e4f\u660e\u786e\u8d2d\u4e70\u610f\u56fe\u3001\u9700\u9886\u57df\u77e5\u8bc6\u63a8\u7406\uff0c\u4e14\u884c\u4e3a\u65e5\u5fd7\u7a00\u5c11\uff0c\u9020\u6210\u68c0\u7d22\u4f18\u5316\u7684\u6301\u7eed\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u9690\u5f0f\u84b8\u998f\u79bb\u7ebf\u67e5\u8be2\u91cd\u5199\u6a21\u578b\u80fd\u529b\u81f3\u5728\u7ebf\u68c0\u7d22\u7cfb\u7edf\u3002\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u8bad\u7ec3\u878d\u5408\u591a\u91cd\u5956\u52b1\u4fe1\u53f7\u7684\u591a\u5019\u9009\u67e5\u8be2\u91cd\u5199\u6a21\u578b\uff0c\u901a\u8fc7\u79bb\u7ebf\u68c0\u7d22\u7ba1\u9053\u751f\u6210\u7cbe\u9009\u7684\u67e5\u8be2-\u5546\u54c1\u5bf9\uff0c\u4ee5\u7f13\u89e3\u91cd\u5199\u67e5\u8be2\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u65e0\u9700\u989d\u5916\u6280\u5de7\uff0c\u4ec5\u5c06\u8be5\u5408\u6210\u6570\u636e\u52a0\u5165\u68c0\u7d22\u6a21\u578b\u8bad\u7ec3\u5373\u53ef\u5e26\u6765\u663e\u8457\u63d0\u5347\u3002\u5728\u7ebfSide-By-Side\u4eba\u5de5\u8bc4\u4f30\u8868\u660e\u7528\u6237\u641c\u7d22\u4f53\u9a8c\u663e\u8457\u589e\u5f3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u77e5\u8bc6\u5bc6\u96c6\u578b\u957f\u5c3e\u67e5\u8be2\u7684\u68c0\u7d22\u96be\u9898\uff0c\u901a\u8fc7\u6a21\u578b\u84b8\u998f\u4e0e\u6570\u636e\u5408\u6210\u7b56\u7565\u663e\u8457\u6539\u5584\u53ec\u56de\u8d28\u91cf\uff0c\u4e3a\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u65b0\u8def\u5f84\u3002"}}
{"id": "2602.23479", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23479", "abs": "https://arxiv.org/abs/2602.23479", "authors": ["Michael Frew", "Nishit Bheda", "Bryan Tripp"], "title": "FHIRPath-QA: Executable Question Answering over FHIR Electronic Health Records", "comment": "Submitted to LREC 2026 CL4Health Workshop", "summary": "Though patients are increasingly granted digital access to their electronic health records (EHRs), existing interfaces may not support precise, trustworthy answers to patient-specific questions. Large language models (LLM) show promise in clinical question answering (QA), but retrieval-based approaches are computationally inefficient, prone to hallucination, and difficult to deploy over real-life EHRs. In this work, we introduce FHIRPath-QA, the first open dataset and benchmark for patient-specific QA that includes open-standard FHIRPath queries over real-world clinical data. We propose a text-to-FHIRPath QA paradigm that shifts reasoning from free-text generation to FHIRPath query synthesis, significantly reducing LLM usage. Built on MIMIC-IV on FHIR Demo, the dataset pairs over 14k natural language questions in patient and clinician phrasing with validated FHIRPath queries and answers. Further, we demonstrate that state-of-the-art LLMs struggle to deal with ambiguity in patient language and perform poorly in FHIRPath query synthesis. However, they benefit strongly from supervised fine-tuning. Our results highlight that text-to-FHIRPath synthesis has the potential to serve as a practical foundation for safe, efficient, and interoperable consumer health applications, and our dataset and benchmark serve as a starting point for future research on the topic. The full dataset and generation code is available at: https://github.com/mooshifrew/fhirpath-qa.", "code_url": "https://github.com/mooshifrew/fhirpath-qa", "code_stars": 0, "code_last_update": "2026-02-25", "AI": {"tldr": "\u672c\u7814\u7a76\u521b\u5efaFHIRPath-QA\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u5c06\u60a3\u8005\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u4e3aFHIRPath\u67e5\u8be2\u7684\u8303\u5f0f\uff0c\u66ff\u4ee3\u4f20\u7edf\u81ea\u7531\u6587\u672c\u751f\u6210\uff0c\u51cf\u5c11LLM\u4f9d\u8d56\u4e0e\u5e7b\u89c9\u98ce\u9669\uff0c\u63ed\u793aLLM\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u77ed\u677f\u53ca\u5fae\u8c03\u7684\u6709\u6548\u6027\uff0c\u4e3aEHR\u7cbe\u51c6\u95ee\u7b54\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "motivation": "\u73b0\u6709EHR\u60a3\u8005\u95e8\u6237\u867d\u63d0\u4f9b\u8bb0\u5f55\u8bbf\u95ee\uff0c\u4f46\u7f3a\u4e4f\u7cbe\u51c6\u56de\u7b54\u4e2a\u6027\u5316\u95ee\u9898\u7684\u80fd\u529b\u3002\u57fa\u4e8eLLM\u7684\u4e34\u5e8a\u95ee\u7b54\u9762\u4e34\u6548\u7387\u4f4e\u3001\u5e7b\u89c9\u98ce\u9669\u9ad8\u53ca\u90e8\u7f72\u96be\u7b49\u6311\u6218\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u5f00\u653e\u7684\u60a3\u8005\u7279\u5f02\u6027QA\u6570\u636e\u96c6\u4e0e\u57fa\u51c6\uff0c\u5236\u7ea6\u4e86\u76f8\u5173\u7b97\u6cd5\u7814\u7a76\u4e0e\u5e94\u7528\u53d1\u5c55\u3002", "method": "\u57fa\u4e8eMIMIC-IV FHIR\u6f14\u793a\u6570\u636e\u6784\u5efaFHIRPath-QA\u6570\u636e\u96c6\uff0c\u5305\u542b1.4\u4e07\u4f59\u5bf9\u60a3\u8005/\u4e34\u5e8a\u533b\u751f\u8868\u8ff0\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u4e0e\u5df2\u9a8c\u8bc1\u7684FHIRPath\u67e5\u8be2\u53ca\u6807\u51c6\u7b54\u6848\u3002\u63d0\u51fatext-to-FHIRPath\u8303\u5f0f\uff0c\u5c06\u63a8\u7406\u4ece\u6587\u672c\u751f\u6210\u8f6c\u4e3a\u67e5\u8be2\u5408\u6210\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u8bc4\u4f30SOTA LLM\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5f53\u524dSOTA LLM\u5728\u5904\u7406\u60a3\u8005\u8bed\u8a00\u6b67\u4e49\u53caFHIRPath\u67e5\u8be2\u751f\u6210\u65b9\u9762\u8868\u73b0\u6b20\u4f73\uff0c\u9519\u8bef\u7387\u8f83\u9ad8\u3002\u4f46\u7ecf\u76d1\u7763\u5fae\u8c03\u540e\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u8303\u5f0f\u5728\u964d\u4f4eLLM\u4f7f\u7528\u6210\u672c\u7684\u540c\u65f6\u5177\u5907\u53ef\u884c\u6027\u3002", "conclusion": "text-to-FHIRPath\u5408\u6210\u8303\u5f0f\u4e3a\u5f00\u53d1\u5b89\u5168\u3001\u9ad8\u6548\u3001\u4e92\u64cd\u4f5c\u7684EHR\u60a3\u8005\u95ee\u7b54\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002FHIRPath-QA\u6570\u636e\u96c6\u4e0e\u57fa\u51c6\u53ef\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u7684\u91cd\u8981\u8d77\u70b9\uff0c\u63a8\u52a8\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u4e34\u5e8a\u843d\u5730\u3002"}}
{"id": "2602.23579", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23579", "abs": "https://arxiv.org/abs/2602.23579", "authors": ["Guillem Rodr\u00edguez-Corominas", "Maria J. Blesa", "Christian Blum"], "title": "Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem", "comment": null, "summary": "The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u6df7\u5408\u7b97\u6cd5 RL-CMSA\uff0c\u7528\u4e8e\u5bf9\u79f0\u5355\u4ed3\u5e93\u6700\u5c0f\u5316\u6700\u5927\u8def\u5f84\u7684\u591a\u65c5\u884c\u5546\u95ee\u9898 (min-max mTSP)\u3002\u7b97\u6cd5\u901a\u8fc7 Q \u503c\u5f15\u5bfc\u7684\u6982\u7387\u805a\u7c7b\u6784\u5efa\u591a\u6837\u89e3\uff0c\u5408\u5e76\u8def\u5f84\u5f62\u6210\u7d27\u51d1\u6c60\uff0c\u6c42\u89e3\u53d7\u9650\u96c6\u5408\u8986\u76d6 MILP\uff0c\u5e76\u5229\u7528\u8de8\u8def\u5f84\u79fb\u9664\u3001\u79fb\u52a8\u3001\u4ea4\u6362\u64cd\u4f5c\u8fdb\u884c\u5c40\u90e8\u4f18\u5316\uff1bQ \u503c\u6839\u636e\u9ad8\u8d28\u91cf\u89e3\u4e2d\u7684\u57ce\u5e02\u5171\u73b0\u8fdb\u884c\u589e\u5f3a\uff0c\u6c60\u901a\u8fc7\u8001\u5316\u548c\u526a\u679d\u81ea\u9002\u5e94\u66f4\u65b0\u3002\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0cRL-CMSA \u5728\u968f\u673a\u548c TSPLIB \u5b9e\u4f8b\u4e0a\u5747\u80fd\u6301\u7eed\u83b7\u5f97\uff08\u8fd1\uff09\u6700\u4f18\u89e3\uff0c\u5e76\u5728\u53ef\u6bd4\u65f6\u95f4\u9650\u5236\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\uff0c\u5c24\u5176\u5728\u5b9e\u4f8b\u89c4\u6a21\u548c\u65c5\u884c\u5546\u6570\u91cf\u589e\u5927\u65f6\u4f18\u52bf\u66f4\u660e\u663e\u3002", "motivation": "\u591a\u65c5\u884c\u5546\u95ee\u9898\u5728\u5b9e\u9645\u7269\u6d41\u914d\u9001\u3001\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u800c\u6700\u5c0f\u5316\u6700\u957f\u8def\u5f84\uff08min\u2011max\uff09\u80fd\u6709\u6548\u5e73\u8861\u5404 salesman \u7684\u5de5\u4f5c\u8d1f\u8377\uff0c\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6548\u7387\u3002\u968f\u7740\u95ee\u9898\u89c4\u6a21\u589e\u5927\uff0c\u4f20\u7edf\u7cbe\u786e\u7b97\u6cd5\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u6c42\u89e3\u901f\u5ea6\u548c\u89e3\u8d28\u91cf\u4e0a\u5747\u9762\u4e34\u6311\u6218\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u5728\u8f83\u77ed\u65f6\u95f4\u5185\u83b7\u5f97\u9ad8\u8d28\u91cf\u89e3\u7684\u65b0\u65b9\u6cd5\u3002", "method": "RL\u2011CMSA \u65b9\u6cd5\u5305\u62ec\u4ee5\u4e0b\u6b65\u9aa4\uff1a1\uff09\u6784\u9020\u9636\u6bb5\uff1a\u5229\u7528\u5df2\u5b66\u4e60\u7684\u914d\u5bf9 Q \u503c\u6307\u5bfc\u6982\u7387\u805a\u7c7b\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u521d\u59cb\u8def\u5f84\uff1b2\uff09\u5408\u5e76\u9636\u6bb5\uff1a\u5c06\u6784\u9020\u51fa\u7684\u8def\u5f84\u5408\u5e76\u4e3a\u4e00\u4e2a\u7d27\u51d1\u7684\u5019\u9009\u6c60\uff1b3\uff09\u6c42\u89e3\u9636\u6bb5\uff1a\u57fa\u4e8e\u53d7\u9650\u96c6\u5408\u8986\u76d6\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u4ece\u6c60\u4e2d\u9009\u62e9\u6700\u4f18\u8def\u5f84\u7ec4\u5408\uff1b4\uff09\u81ea\u9002\u5e94\u9636\u6bb5\uff1a\u5bf9\u9009\u51fa\u7684\u89e3\u8fdb\u884c\u8de8\u8def\u5f84\u7684\u79fb\u9664\u3001\u79fb\u52a8\u3001\u4ea4\u6362\u7b49\u5c40\u90e8\u641c\u7d22\uff0c\u63d0\u5347\u89e3\u8d28\u91cf\uff1b5\uff09\u5f3a\u5316\u5b66\u4e60\u66f4\u65b0\uff1a\u6839\u636e\u9ad8\u8d28\u91cf\u89e3\u4e2d\u57ce\u5e02\u5bf9\u7684\u5171\u73b0\u9891\u7387\u66f4\u65b0 Q \u503c\uff0c\u5f3a\u5316\u4f18\u79c0\u914d\u5bf9\u7684\u6743\u91cd\uff1b6\uff09\u6c60\u7ba1\u7406\uff1a\u91c7\u7528\u8001\u5316\u548c\u526a\u679d\u7b56\u7565\u52a8\u6001\u7ef4\u62a4\u6c60\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf\uff0c\u9632\u6b62\u65e9\u719f\u6536\u655b\u3002\u8be5\u65b9\u6cd5\u5c06\u7cbe\u786e\u4f18\u5316\u4e0e\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6784\u9020\u76f8\u7ed3\u5408\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u968f\u673a\u751f\u6210\u548c TSPLIB \u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRL\u2011CMSA \u80fd\u591f\u5728\u89c4\u5b9a\u65f6\u95f4\u5185\u6301\u7eed\u627e\u5230\uff08\u8fd1\uff09\u6700\u4f18\u89e3\uff0c\u4e14\u5728\u6240\u6709\u5bf9\u6bd4\u5b9e\u4f8b\u4e2d\u5747\u4f18\u4e8e\u6216\u4e0e\u6700\u5148\u8fdb\u7684\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\u76f8\u5f53\u3002\u5c24\u5176\u5728\u5b9e\u4f8b\u89c4\u6a21\u66f4\u5927\u3001\u65c5\u884c\u5546\u6570\u91cf\u66f4\u591a\u65f6\uff0cRL\u2011CMSA \u7684\u6027\u80fd\u4f18\u52bf\u66f4\u52a0\u663e\u8457\uff0c\u4f53\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "RL\u2011CMSA \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6784\u9020\u4e0e\u7cbe\u786e\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u4e3a\u6700\u5c0f\u5316\u6700\u5927\u8def\u5f84\u7684\u591a\u65c5\u884c\u5546\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6c42\u89e3\u6846\u67b6\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u89e3\u8d28\u91cf\u3001\u6536\u655b\u901f\u5ea6\u53ca\u5927\u89c4\u6a21\u5b9e\u4f8b\u5904\u7406\u80fd\u529b\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u7b97\u6cd5\uff0c\u5177\u5907\u5728\u5b9e\u9645\u7269\u6d41\u4e0e\u8def\u5f84\u89c4\u5212\u7cfb\u7edf\u4e2d\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.23413", "categories": ["cs.LG", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.23413", "abs": "https://arxiv.org/abs/2602.23413", "authors": ["Shu Liu", "Shubham Agarwal", "Monishwaran Maheswaran", "Mert Cemri", "Zhifei Li", "Qiuyang Mang", "Ashwin Naren", "Ethan Boneh", "Audrey Cheng", "Melissa Z. Pan", "Alexander Du", "Kurt Keutzer", "Alexandros G. Dimakis", "Koushik Sen", "Matei Zaharia", "Ion Stoica"], "title": "EvoX: Meta-Evolution for Automated Discovery", "comment": null, "summary": "Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEvoX\uff0c\u4e00\u79cd\u81ea\u9002\u5e94\u8fdb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u6f14\u5316\u5019\u9009\u89e3\u4e0e\u641c\u7d22\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u6574\u4f18\u5316\u8fc7\u7a0b\u3002\u5728200\u4e2a\u771f\u5b9e\u4efb\u52a1\u4e0a\uff0cEvoX\u5728\u591a\u6570\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709AI\u8fdb\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u8fdb\u5316\u65b9\u6cd5\u91c7\u7528\u56fa\u5b9a\u641c\u7d22\u7b56\u7565\u548c\u9759\u6001\u53c2\u6570\uff08\u5982\u63a2\u7d22-\u5229\u7528\u6bd4\u7387\uff09\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u6216\u5728\u4efb\u52a1\u5185\u968f\u641c\u7d22\u7a7a\u95f4\u53d8\u5316\u800c\u8c03\u6574\uff0c\u5bfc\u81f4\u4f18\u5316\u6548\u679c\u53d7\u9650\u3002", "method": "EvoX\u5c06\u641c\u7d22\u7b56\u7565\u672c\u8eab\u4f5c\u4e3a\u8fdb\u5316\u5bf9\u8c61\uff0c\u91c7\u7528\u53cc\u5c42\u6f14\u5316\u673a\u5236\uff1a\u5728\u6f14\u5316\u5019\u9009\u89e3\u7684\u540c\u65f6\uff0c\u6839\u636e\u5386\u53f2\u8bc4\u4f30\u7ed3\u679c\u52a8\u6001\u8c03\u6574\u5148\u9a8c\u89e3\u7684\u9009\u62e9\u4e0e\u53d8\u5f02\u7b56\u7565\uff0c\u5b9e\u73b0\u641c\u7d22\u7b56\u7565\u7684\u81ea\u9002\u5e94\u5207\u6362\u3002", "result": "\u5728\u8fd1200\u4e2a\u6db5\u76d6\u7a0b\u5e8f\u3001\u63d0\u793a\u548c\u7b97\u6cd5\u4f18\u5316\u7684\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e0a\uff0cEvoX\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e2d\u6027\u80fd\u4f18\u4e8eAlphaEvolve\u3001OpenEvolve\u3001GEPA\u548cShinkaEvolve\u3002", "conclusion": "EvoX\u901a\u8fc7\u81ea\u6211\u4f18\u5316\u7684\u8fdb\u5316\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9759\u6001\u641c\u7d22\u7b56\u7565\u7684\u9002\u5e94\u6027\u95ee\u9898\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u8fdb\u5316\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2602.23639", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23639", "abs": "https://arxiv.org/abs/2602.23639", "authors": ["Haibo Xing", "Hao Deng", "Lingyu Mu", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "Learning to Reflect and Correct: Towards Better Decoding Trajectories for Large-Scale Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) has become a promising paradigm for large-scale recommendation systems. However, existing GR models typically perform single-pass decoding without explicit refinement, causing early deviations to accumulate and ultimately degrade recommendation quality. To tackle this problem, we propose GRC, which is, to our knowledge, the first structured reflection-correction framework for GR that extends standard decoding into a Generation-Reflection-Correction (GRC) process. Concretely, GRC introduces a supervised reflection-correction template that decomposes the decoding process into initial draft generation, multi-granular reflection, and reflection-guided correction, thereby enabling structured reflection and correction in the semantic token space. To further explore the enlarged refinement space introduced by the GRC process, we optimize the entire GRC trajectory with GRPO-based reinforcement learning, under a carefully designed reward function with token-level and trajectory-level signals. For efficient online serving, we propose an Entropy-Guided Reflection Scheduling (EGRS) strategy that dynamically allocates more correction budget to high-uncertainty decoding trajectories during beam search. Extensive experiments on real-world datasets show that GRC consistently outperforms six state-of-the-art baselines by up to 15.74%, and online A/B tests demonstrate its substantial practical value in large-scale industrial recommendation, delivering a 1.79% lift in advertising revenue with only modest latency overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u751f\u6210\u5f0f\u63a8\u8350\u7684\u7ed3\u6784\u5316\u53cd\u601d-\u4fee\u6b63\u6846\u67b6GRC\uff0c\u901a\u8fc7\u751f\u6210-\u53cd\u601d-\u4fee\u6b63\u4e09\u9636\u6bb5\u6d41\u7a0b\u548cGRPO\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u548c\u5546\u4e1a\u6536\u76ca\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u91c7\u7528\u5355\u6b65\u89e3\u7801\u4e14\u7f3a\u4e4f\u663e\u5f0f\u4f18\u5316\u673a\u5236\uff0c\u5bfc\u81f4\u65e9\u671f\u504f\u5dee\u7d2f\u79ef\u5e76\u964d\u4f4e\u63a8\u8350\u8d28\u91cf\uff0c\u4e9f\u9700\u7ed3\u6784\u5316\u53cd\u601d\u548c\u4fee\u6b63\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faGRC\u6846\u67b6\uff0c\u5c06\u6807\u51c6\u89e3\u7801\u6269\u5c55\u4e3a\u751f\u6210-\u53cd\u601d-\u4fee\u6b63\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1b\u5f15\u5165\u76d1\u7763\u5f0f\u53cd\u601d-\u4fee\u6b63\u6a21\u677f\uff0c\u5b9e\u73b0\u8bed\u4e49token\u7a7a\u95f4\u7684\u7ed3\u6784\u5316\u53cd\u601d\u548c\u4fee\u6b63\uff1b\u91c7\u7528GRPO\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6574\u4e2aGRC\u8f68\u8ff9\uff0c\u8bbe\u8ba1token\u7ea7\u548c\u8f68\u8ff9\u7ea7\u5956\u52b1\u51fd\u6570\uff1b\u63d0\u51fa\u71b5\u5f15\u5bfc\u7684\u53cd\u601d\u8c03\u5ea6\u7b56\u7565EGRS\uff0c\u5728beam\u641c\u7d22\u4e2d\u52a8\u6001\u5206\u914d\u4fee\u6b63\u8d44\u6e90\u7ed9\u9ad8\u4e0d\u786e\u5b9a\u6027\u8f68\u8ff9\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0cGRC\u76f8\u6bd4\u516d\u79cdSOTA\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe15.74%\uff1b\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0c\u4ec5\u5e26\u6765\u9002\u5ea6\u5ef6\u8fdf\u5f00\u9500\u7684\u540c\u65f6\uff0c\u5e7f\u544a\u6536\u5165\u63d0\u53471.79%\u3002", "conclusion": "GRC\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u601d\u4fee\u6b63\u673a\u5236\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u504f\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u5728\u63d0\u5347\u63a8\u8350\u8d28\u91cf\u7684\u540c\u65f6\u521b\u9020\u4e86\u663e\u8457\u5546\u4e1a\u4ef7\u503c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5de5\u4e1a\u7ea7\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.23481", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23481", "abs": "https://arxiv.org/abs/2602.23481", "authors": ["Md Mofijul Islam", "Md Sirajus Salekin", "Joe King", "Priyashree Roy", "Vamsi Thilak Gudi", "Spencer Romo", "Akhil Nooney", "Boyi Xie", "Bob Strahan", "Diego A. Socolinsky"], "title": "IDP Accelerator: Agentic Document Intelligence from Extraction to Compliance Validation", "comment": null, "summary": "Understanding and extracting structured insights from unstructured documents remains a foundational challenge in industrial NLP. While Large Language Models (LLMs) enable zero-shot extraction, traditional pipelines often fail to handle multi-document packets, complex reasoning, and strict compliance requirements. We present IDP (Intelligent Document Processing) Accelerator, a framework enabling agentic AI for end-to-end document intelligence with four key components: (1) DocSplit, a novel benchmark dataset and multimodal classifier using BIO tagging to segment complex document packets; (2) configurable Extraction Module leveraging multimodal LLMs to transform unstructured content into structured data; (3) Agentic Analytics Module, compliant with the Model Context Protocol (MCP) providing data access through secure, sandboxed code execution; and (4) Rule Validation Module replacing deterministic engines with LLM-driven logic for complex compliance checks. The interactive demonstration enables users to upload document packets, visualize classification results, and explore extracted data through an intuitive web interface. We demonstrate effectiveness across industries, highlighting a production deployment at a leading healthcare provider achieving 98% classification accuracy, 80% reduced processing latency, and 77% lower operational costs over legacy baselines. IDP Accelerator is open-sourced with a live demonstration available to the community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIDP Accelerator\u667a\u80fd\u6587\u6863\u5904\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u56db\u5927\u6838\u5fc3\u7ec4\u4ef6\uff08DocSplit\u6570\u636e\u96c6/\u5206\u7c7b\u5668\u3001\u591a\u6a21\u6001LLM\u63d0\u53d6\u3001MCP\u5408\u89c4\u5206\u6790\u3001LLM\u9a8c\u8bc1\uff09\uff0c\u5728\u533b\u7597\u884c\u4e1a\u751f\u4ea7\u90e8\u7f72\u4e2d\u5b9e\u73b098%\u5206\u7c7b\u51c6\u786e\u7387\u3001\u5904\u7406\u5ef6\u8fdf\u964d\u4f4e80%\u3001\u8fd0\u8425\u6210\u672c\u51cf\u5c1177%\u3002", "motivation": "\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u5de5\u4e1aNLP\u4e2d\u4ece\u65e0\u7ed3\u6784\u6587\u6863\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u7684\u57fa\u7840\u6027\u6311\u6218\uff0c\u6307\u51fa\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u652f\u6301\u96f6\u6837\u672c\u63d0\u53d6\uff0c\u4f46\u4f20\u7edf\u6d41\u6c34\u7ebf\u65e0\u6cd5\u5904\u7406\u591a\u6587\u6863\u5305\u3001\u590d\u6742\u63a8\u7406\u548c\u4e25\u683c\u5408\u89c4\u8981\u6c42\u3002", "method": "\u4f5c\u8005\u63d0\u51faIDP Accelerator\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1\uff09DocSplit\u57fa\u51c6\u6570\u636e\u96c6\u53ca\u91c7\u7528BIO\u6807\u8bb0\u7684\u591a\u6a21\u6001\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u590d\u6742\u6587\u6863\u5305\u5206\u5272\uff1b2\uff09\u57fa\u4e8e\u591a\u6a21\u6001LLM\u7684\u53ef\u914d\u7f6e\u63d0\u53d6\u6a21\u5757\uff1b3\uff09\u7b26\u5408\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684Agentic\u5206\u6790\u6a21\u5757\uff0c\u901a\u8fc7\u5b89\u5168\u6c99\u7bb1\u5316\u4ee3\u7801\u6267\u884c\u63d0\u4f9b\u6570\u636e\u8bbf\u95ee\uff1b4\uff09\u89c4\u5219\u9a8c\u8bc1\u6a21\u5757\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u903b\u8f91\u66ff\u4ee3\u786e\u5b9a\u6027\u5f15\u64ce\u8fdb\u884c\u590d\u6742\u5408\u89c4\u68c0\u67e5\u3002", "result": "\u5728\u9886\u5148\u533b\u7597\u63d0\u4f9b\u8005\u7684\u751f\u4ea7\u90e8\u7f72\u4e2d\uff0c\u8be5\u7cfb\u7edf\u5b9e\u73b098%\u5206\u7c7b\u51c6\u786e\u7387\u3001\u5904\u7406\u5ef6\u8fdf\u964d\u4f4e80%\u3001\u8fd0\u8425\u6210\u672c\u8f83\u4f20\u7edf\u57fa\u7ebf\u51cf\u5c1177%\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ea4\u4e92\u5f0fWeb\u754c\u9762\u4f9b\u7528\u6237\u4e0a\u4f20\u6587\u6863\u5305\u3001\u53ef\u89c6\u5316\u5206\u7c7b\u7ed3\u679c\u548c\u63a2\u7d22\u63d0\u53d6\u6570\u636e\u3002", "conclusion": "IDP Accelerator\u6210\u529f\u5c55\u793a\u4e86\u7aef\u5230\u7aefAgentic AI\u6587\u6863\u667a\u80fd\u89e3\u51b3\u65b9\u6848\u7684\u5de5\u4e1a\u53ef\u884c\u6027\uff0c\u8de8\u884c\u4e1a\u6709\u6548\u4e14\u533b\u7597\u90e8\u7f72\u6210\u679c\u663e\u8457\uff0c\u6846\u67b6\u5df2\u5f00\u6e90\u5e76\u63d0\u4f9b\u5728\u7ebf\u6f14\u793a\u3002"}}
{"id": "2602.23605", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23605", "abs": "https://arxiv.org/abs/2602.23605", "authors": ["Zongzhe Xu", "Zitao Shuai", "Eideen Mozaffari", "Ravi S. Aysola", "Rajesh Kumar", "Yuzhe Yang"], "title": "SleepLM: Natural-Language Intelligence for Human Sleep", "comment": null, "summary": "We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.", "AI": {"tldr": "\u63d0\u51faSleepLM\u7761\u7720\u8bed\u8a00\u57fa\u7840\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5b9e\u73b0\u7761\u7720\u5bf9\u9f50\u3001\u89e3\u91ca\u4e0e\u4ea4\u4e92\u3002\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5c40\u9650\u4e8e\u5c01\u95ed\u6807\u7b7e\u7a7a\u95f4\u3001\u65e0\u6cd5\u6cdb\u5316\u81f3\u65b0\u7761\u7720\u73b0\u8c61\u7684\u95ee\u9898\u3002\u6784\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u7761\u7720\u6587\u672c\u6570\u636e\u96c6\uff0810\u4e07+\u5c0f\u65f6\uff0c1\u4e07+\u4e2a\u4f53\uff09\uff0c\u91c7\u7528\u5bf9\u6bd4\u5bf9\u9f50\u3001\u5b57\u5e55\u751f\u6210\u4e0e\u4fe1\u53f7\u91cd\u5efa\u7684\u7edf\u4e00\u9884\u8bad\u7ec3\u76ee\u6807\u3002\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u96f6/\u5c11\u6837\u672c\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u7761\u7720\u5b57\u5e55\u751f\u6210\u4e0a\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6280\u672f\uff0c\u5e76\u5177\u5907\u8bed\u8a00\u5f15\u5bfc\u4e8b\u4ef6\u5b9a\u4f4d\u3001\u6d1e\u5bdf\u751f\u6210\u548c\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u7761\u7720\u5206\u6790\u7cfb\u7edf\u53ea\u80fd\u5728\u5c01\u95ed\u6807\u7b7e\u7a7a\u95f4\uff08\u5982\u9884\u5b9a\u4e49\u7761\u7720\u9636\u6bb5\u6216\u4e8b\u4ef6\uff09\u4e2d\u8fd0\u884c\uff0c\u65e0\u6cd5\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u3001\u67e5\u8be2\u6216\u6cdb\u5316\u5230\u65b0\u7684\u7761\u7720\u73b0\u8c61\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u7761\u7720\u751f\u7406\u5b66\u7684\u6df1\u5165\u7406\u89e3\u548c\u4e34\u5e8a\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6865\u63a5\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u5bfc\u7761\u7720\u56fe\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u7075\u6d3b\u3001\u53ef\u89e3\u91ca\u548c\u4e2a\u6027\u5316\u7684\u7761\u7720\u5206\u6790\u3002", "method": "1. \u63d0\u51faSleepLM\u6a21\u578b\u5bb6\u65cf\uff0c\u6865\u63a5\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u591a\u5bfc\u7761\u7720\u56fe\u6570\u636e\uff0c\u6784\u5efa\u8bed\u8a00\u63a5\u5730\u7684\u7761\u7720\u751f\u7406\u8868\u5f81\u30022. \u8bbe\u8ba1\u591a\u7ea7\u7761\u7720\u5b57\u5e55\u751f\u6210\u6d41\u6c34\u7ebf\uff0c\u521b\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u7761\u7720-\u6587\u672c\u914d\u5bf9\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u8d8510,000\u540d\u4e2a\u4f53\u7684100,000\u591a\u5c0f\u65f6\u7761\u7720\u8bb0\u5f55\u30023. \u91c7\u7528\u7edf\u4e00\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u8054\u5408\u4f18\u5316\u5bf9\u6bd4\u5bf9\u9f50\u3001\u5b57\u5e55\u751f\u6210\u548c\u4fe1\u53f7\u91cd\u5efa\u4e09\u4e2a\u4efb\u52a1\uff0c\u4ee5\u589e\u5f3a\u751f\u7406\u4fdd\u771f\u5ea6\u4e0e\u8de8\u6a21\u6001\u4ea4\u4e92\u80fd\u529b\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7761\u7720\u7406\u89e3\u4efb\u52a1\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cSleepLM\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u68c0\u7d22\u3001\u7761\u7720\u5b57\u5e55\u751f\u6210\u7b49\u5173\u952e\u6307\u6807\u4e0a\u5747\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u8bed\u8a00\u5f15\u5bfc\u7684\u4e8b\u4ef6\u5b9a\u4f4d\u3001\u9488\u5bf9\u6027\u6d1e\u5bdf\u751f\u6210\u4ee5\u53ca\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u96f6\u6837\u672c\u6cdb\u5316\u7b49\u9ad8\u7ea7\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u7edf\u4e00\u9884\u8bad\u7ec3\u76ee\u6807\u7684\u6709\u6548\u6027\u3002\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u5c06\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002", "conclusion": "SleepLM\u9996\u6b21\u5c06\u57fa\u7840\u6a21\u578b\u5f15\u5165\u7761\u7720\u9886\u57df\uff0c\u6210\u529f\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u4e0e\u7761\u7720\u751f\u7406\u5b66\u7684\u5bf9\u9f50\uff0c\u4e3a\u7761\u7720\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u65b0\u7684\u4ea4\u4e92\u8303\u5f0f\u3002\u901a\u8fc7\u5f00\u6e90\uff0c\u8be5\u5de5\u4f5c\u5c06\u4fc3\u8fdb\u7761\u7720\u533b\u5b66\u7684\u6c11\u4e3b\u5316\u548c\u4e2a\u6027\u5316\u53d1\u5c55\uff0c\u672a\u6765\u6709\u671b\u5e94\u7528\u4e8e\u4e34\u5e8a\u8bca\u65ad\u3001\u5065\u5eb7\u76d1\u6d4b\u548c\u79d1\u7814\u6559\u80b2\u7b49\u591a\u4e2a\u573a\u666f\uff0c\u63a8\u52a8\u7761\u7720\u5065\u5eb7\u9886\u57df\u7684\u667a\u80fd\u5316\u8f6c\u578b\u3002"}}
{"id": "2602.23446", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23446", "abs": "https://arxiv.org/abs/2602.23446", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning", "comment": "Proceedings from IEEE CAI 2026, Conference on Artificial Intelligence, 8-10 May, Granada, Spain. 8 Pages, 3 Figures, 7 Tables", "summary": "Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\"\u4eba\u7c7b\u9650\u5b9a\u667a\u80fd\u6781\u9650\"\u7406\u8bba\uff0c\u8bba\u8bc1\u4eba\u7c7b\u76d1\u7763\u901a\u9053\u7684\u7ed3\u6784\u6027\u4e0d\u5145\u5206\uff08\u6807\u6ce8\u566a\u58f0\u3001\u504f\u597d\u626d\u66f2\u3001\u8bed\u4e49\u538b\u7f29\uff09\u5bfc\u81f4\u4efb\u4f55\u5b66\u4e60\u8005\u90fd\u5b58\u5728\u4e25\u683c\u6b63\u7684\u8d85\u989d\u98ce\u9669\u4e0b\u754c\uff0c\u4ec5\u9760\u6a21\u578b\u6269\u5c55\u65e0\u6cd5\u6d88\u9664\u6301\u4e45\u9519\u8bef\uff0c\u4f46\u8f85\u52a9\u975e\u4eba\u7c7b\u4fe1\u53f7\u53ef\u63d0\u5347\u76d1\u7763\u5bb9\u91cf\u5e76\u7a81\u7834\u8be5\u6781\u9650\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5728\u4eba\u7c7b\u751f\u6210\u6570\u636e\u548c\u53cd\u9988\u4e0a\u8bad\u7ec3\uff0c\u4f46\u4ecd\u5b58\u5728\u6e90\u4e8e\u6807\u6ce8\u566a\u58f0\u3001\u4e3b\u89c2\u504f\u597d\u548c\u8bed\u8a00\u8868\u8fbe\u5e26\u5bbd\u9650\u5236\u7684\u6301\u4e45\u9519\u8bef\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e9b\u9650\u5236\u53cd\u6620\u4e86\u76d1\u7763\u901a\u9053\u7684\u7ed3\u6784\u6027\u5c5e\u6027\uff0c\u800c\u975e\u6a21\u578b\u89c4\u6a21\u6216\u4f18\u5316\u95ee\u9898\uff0c\u65e8\u5728\u89e3\u91ca\u4e3a\u4f55\u5355\u7eaf\u6269\u5c55\u65e0\u6cd5\u6d88\u9664\u8fd9\u4e9b\u5bf9\u9f50\u9519\u8bef\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7406\u8bba\uff0c\u8bc1\u660e\u5f53\u4eba\u7c7b\u76d1\u7763\u901a\u9053\u5bf9\u6f5c\u5728\u8bc4\u4f30\u76ee\u6807\u4e0d\u5145\u5206\u65f6\uff0c\u4f1a\u4f5c\u4e3a\u4fe1\u606f\u538b\u7f29\u901a\u9053\uff0c\u4e3a\u4efb\u4f55\u53d7\u5176\u4e3b\u5bfc\u7684\u5b66\u4e60\u8005\u8bf1\u5bfc\u4e25\u683c\u6b63\u7684\u8d85\u989d\u98ce\u9669\u4e0b\u9650\u3002\u901a\u8fc7\u7b97\u5b50\u7406\u8bba\u3001PAC-Bayes\u3001\u4fe1\u606f\u8bba\u3001\u56e0\u679c\u63a8\u65ad\u3001\u8303\u7574\u8bba\u548cRLHF\u535a\u5f08\u8bba\u5206\u6790\u516d\u79cd\u6846\u67b6\u5f62\u5f0f\u5316\u8be5\u6781\u9650\uff0c\u5e76\u4ece\u6807\u6ce8\u566a\u58f0\u3001\u504f\u597d\u626d\u66f2\u3001\u8bed\u4e49\u538b\u7f29\u8fdb\u884c\u7ed3\u6784\u5206\u89e3\u3002\u5728\u771f\u5b9e\u504f\u597d\u6570\u636e\u3001\u5408\u6210\u4efb\u52a1\u548c\u5916\u90e8\u53ef\u9a8c\u8bc1\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u7684\u7ed3\u6784\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\uff1a\u7eaf\u4eba\u7c7b\u76d1\u7763\u5b58\u5728\u6301\u4e45\u9519\u8bef\u5e73\u53f0\uff0c\u800c\u5145\u5206\u7684\u4fe1\u606f\u8f85\u52a9\u901a\u9053\uff08\u68c0\u7d22\u3001\u7a0b\u5e8f\u6267\u884c\u3001\u5de5\u5177\uff09\u80fd\u4e25\u683c\u964d\u4f4e\u6216\u6d88\u9664\u8d85\u989d\u9519\u8bef\u3002\u8be5\u7406\u8bba\u89e3\u91ca\u4e86\u6269\u5c55\u672c\u8eab\u65e0\u6cd5\u6d88\u9664\u4eba\u7c7b\u5bf9\u9f50\u9519\u8bef\u7684\u6839\u672c\u539f\u56e0\u3002", "conclusion": "\u4eba\u7c7b\u76d1\u7763\u7684\u7ed3\u6784\u6027\u9650\u5236\u6784\u6210\u6027\u80fd\u7684\u6839\u672c\u8fb9\u754c\uff0c\u6269\u5c55\u4e0d\u8db3\u4ee5\u7a81\u7834\uff0c\u9700\u501f\u52a9\u975e\u4eba\u7c7b\u8f85\u52a9\u4fe1\u53f7\u63d0\u5347\u76d1\u7763\u5bb9\u91cf\u624d\u80fd\u7a81\u7834\u4eba\u7c7b\u9650\u5b9a\u667a\u80fd\u6781\u9650\u3002"}}
{"id": "2602.23546", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23546", "abs": "https://arxiv.org/abs/2602.23546", "authors": ["Gaurav Kamath", "Sreenath Madathil", "Sebastian Schuster", "Marie-Catherine de Marneffe", "Siva Reddy"], "title": "Humans and LLMs Diverge on Probabilistic Inferences", "comment": null, "summary": "Human reasoning often involves working over limited information to arrive at probabilistic conclusions. In its simplest form, this involves making an inference that is not strictly entailed by a premise, but rather only likely given the premise. While reasoning LLMs have demonstrated strong performance on logical and mathematical tasks, their behavior on such open-ended, non-deterministic inferences remains largely unexplored. We introduce ProbCOPA, a dataset of 210 handcrafted probabilistic inferences in English, each annotated for inference likelihood by 25--30 human participants. We find that human responses are graded and varied, revealing probabilistic judgments of the inferences in our dataset. Comparing these judgments with responses from eight state-of-the-art reasoning LLMs, we show that models consistently fail to produce human-like distributions. Finally, analyzing LLM reasoning chains, we find evidence of a common reasoning pattern used to evaluate such inferences. Our findings reveal persistent differences between humans and LLMs, and underscore the need to evaluate reasoning beyond deterministic settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4eba\u7c7b\u6982\u7387\u63a8\u7406\u4e0eLLM\u8868\u73b0\u7684\u5dee\u8ddd\u3002\u4f5c\u8005\u521b\u5efaProbCOPA\u6570\u636e\u96c6\uff08210\u4e2a\u6982\u7387\u63a8\u7406\u95ee\u9898\uff0c\u6bcf\u989825-30\u4eba\u6807\u6ce8\uff09\uff0c\u53d1\u73b0\u4eba\u7c7b\u5224\u65ad\u5448\u73b0\u5206\u7ea7\u53d8\u5316\uff0c\u800c8\u4e2a\u5148\u8fdbLLM\u65e0\u6cd5\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6982\u7387\u5206\u5e03\uff0c\u63ed\u793a\u4e86\u4eba\u673a\u63a8\u7406\u7684\u672c\u8d28\u5dee\u5f02\u3002", "motivation": "\u4eba\u7c7b\u63a8\u7406\u5e38\u9700\u57fa\u4e8e\u6709\u9650\u4fe1\u606f\u4f5c\u51fa\u6982\u7387\u6027\u63a8\u65ad\uff0c\u8fd9\u4e0e\u786e\u5b9a\u6027\u903b\u8f91\u63a8\u7406\u4e0d\u540c\u3002\u5c3d\u7ba1LLM\u5728\u903b\u8f91\u6570\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u5f00\u653e\u6027\u3001\u975e\u786e\u5b9a\u6027\u63a8\u7406\u4e2d\u7684\u884c\u4e3a\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u7cfb\u7edf\u8bc4\u4f30LLM\u7684\u6982\u7387\u63a8\u7406\u80fd\u529b\uff0c\u5bf9\u7406\u89e3\u5176\u8ba4\u77e5\u5c40\u9650\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "1) \u6784\u5efaProbCOPA\uff1a210\u4e2a\u4eba\u5de5\u8bbe\u8ba1\u7684\u82f1\u8bed\u6982\u7387\u63a8\u7406\u95ee\u9898\uff0c\u6bcf\u9898\u753125-30\u540d\u53c2\u4e0e\u8005\u6807\u6ce8\u53ef\u80fd\u6027\uff1b2) \u6d4b\u8bd58\u4e2a\u5148\u8fdb\u63a8\u7406LLM\uff1b3) \u5bf9\u6bd4\u4eba\u7c7b\u4e0e\u6a21\u578b\u7684\u54cd\u5e94\u5206\u5e03\uff1b4) \u5206\u6790LLM\u63a8\u7406\u94fe\uff0c\u8bc6\u522b\u901a\u7528\u63a8\u7406\u6a21\u5f0f\u3002", "result": "1) \u4eba\u7c7b\u54cd\u5e94\u5448\u73b0\u5206\u7ea7\u4e14\u591a\u6837\u7684\u6982\u7387\u5224\u65ad\uff1b2) \u6240\u6709\u6d4b\u8bd5LLM\u5747\u672a\u80fd\u4ea7\u751f\u4eba\u7c7b\u7c7b\u4f3c\u7684\u6982\u7387\u5206\u5e03\uff1b3) \u63a8\u7406\u94fe\u5206\u6790\u53d1\u73b0LLM\u4f7f\u7528\u7279\u5b9a\u6a21\u5f0f\u8bc4\u4f30\u6982\u7387\u63a8\u7406\uff1b4) \u4eba\u673a\u5728\u6982\u7387\u63a8\u7406\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u6982\u7387\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u65e0\u6cd5\u6a21\u62df\u4eba\u7c7b\u7684\u6982\u7387\u6027\u5224\u65ad\u5206\u5e03\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u975e\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.23632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23632", "abs": "https://arxiv.org/abs/2602.23632", "authors": ["Lun Zhan", "Feng Xiong", "Huanyong Liu", "Feng Zhang", "Yuhui Yin"], "title": "MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs", "comment": null, "summary": "Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS", "code_url": "https://github.com/360AILAB-NLP/MMKG-RDS", "code_stars": 1, "code_last_update": "2026-02-27", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u6846\u67b6MMKG-RDS\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63d0\u53d6\u3001\u53ef\u5b9a\u5236\u8def\u5f84\u91c7\u6837\u548c\u591a\u7ef4\u5ea6\u8d28\u91cf\u8bc4\u5206\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u5c3e\u77e5\u8bc6\u8986\u76d6\u3001\u53ef\u89e3\u91ca\u6027\u7b49\u65b9\u9762\u7684\u5c40\u9650\u3002\u5728\u6db5\u76d6\u4e94\u4e2a\u9886\u57df14,950\u4e2a\u6837\u672c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4ec5\u7528\u5c11\u91cf\u5408\u6210\u6570\u636e\u5fae\u8c03Qwen3\u6a21\u578b\u5373\u5b9e\u73b09.2%\u7684\u63a8\u7406\u51c6\u786e\u7387\u63d0\u5347\uff0c\u751f\u6210\u7684\u6570\u636e\u5bf9\u8868\u683c\u548c\u516c\u5f0f\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u4e3a\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u6784\u5efa\u63d0\u4f9b\u65b0\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u5408\u6210\u65b9\u6cd5\u5728\u957f\u5c3e\u77e5\u8bc6\u8986\u76d6\u3001\u6548\u679c\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u5728\u529f\u80fd\u6027\u3001\u7c92\u5ea6\u7cbe\u7ec6\u5ea6\u3001\u53ef\u5b9a\u5236\u6027\u548c\u8bc4\u4f30\u4f53\u7cfb\u65b9\u9762\u4ecd\u6709\u6b20\u7f3a\uff0c\u96be\u4ee5\u6ee1\u8db3\u9886\u57df\u6a21\u578b\u63a8\u7406\u80fd\u529b\u589e\u5f3a\u7684\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u63d0\u51faMMKG-RDS\u6846\u67b6\uff0c\u91c7\u7528\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u6838\u5fc3\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63d0\u53d6\u3001\u7528\u6237\u53ef\u5b9a\u5236\u7684\u8def\u5f84\u91c7\u6837\u7b56\u7565\uff0c\u4ee5\u53ca\u591a\u7ef4\u5ea6\u7684\u6570\u636e\u8d28\u91cf\u8bc4\u5206\u673a\u5236\uff0c\u63d0\u4f9b\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u65b9\u6848\u3002", "result": "\u6784\u5efaMMKG-RDS-Bench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8986\u76d6\u4e94\u4e2a\u9886\u57df\u300117\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u517114,950\u4e2a\u6837\u672c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u5c11\u91cf\u8be5\u6846\u67b6\u5408\u6210\u7684\u6570\u636e\u5fae\u8c03Qwen3\u7cfb\u5217\u6a21\u578b\uff080.6B/8B/32B\u53c2\u6570\uff09\u53ef\u4f7f\u63a8\u7406\u51c6\u786e\u7387\u663e\u8457\u63d0\u53479.2%\u3002\u6b64\u5916\uff0c\u751f\u6210\u7684\u6570\u636e\u5728\u6d89\u53ca\u8868\u683c\u548c\u516c\u5f0f\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u72ec\u7279\u6027\uff0c\u5bf9\u73b0\u6709\u6a21\u578b\u6784\u6210\u6311\u6218\uff0c\u9002\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "MMKG-RDS\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u5408\u6210\u9762\u4e34\u7684\u591a\u91cd\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u3001\u53ef\u5b9a\u5236\u5316\u7684\u6570\u636e\u751f\u6210\u4e0e\u8bc4\u4f30\u3002\u8be5\u65b9\u6cd5\u4e3a\u63d0\u5347\u9886\u57df\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u5176\u751f\u6210\u7684\u6311\u6218\u6027\u6570\u636e\u5bf9\u63a8\u52a8\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u7684\u53d1\u5c55\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.23459", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23459", "abs": "https://arxiv.org/abs/2602.23459", "authors": ["Eric V. Strobl"], "title": "Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires", "comment": null, "summary": "Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.", "AI": {"tldr": "\u9488\u5bf9\u7cbe\u795e\u75be\u75c5\u95ee\u5377\u9884\u6d4b\u4e2d\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u7684\u6743\u8861\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51faREFINE\u4e24\u9636\u6bb5\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5c06\u975e\u7ebf\u6027\u80fd\u529b\u9650\u5236\u5728\u57fa\u7ebf\u9884\u5904\u7406\u6a21\u5757\u4ee5\u4f30\u8ba1\u7a33\u5b9a\u9879\u76ee\u503c\uff0c\u968f\u540e\u7528\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u672a\u6765\u75c7\u72b6\u4e25\u91cd\u7a0b\u5ea6\uff0c\u5b9e\u73b0\u4e86\u9884\u6d4b\u6027\u80fd\u4e0e\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u7684\u7edf\u4e00\u3002", "motivation": "\u7cbe\u795e\u75be\u75c5\u95ee\u5377\u9ad8\u5ea6\u4f9d\u8d56\u4e0a\u4e0b\u6587\u4e14\u9884\u6d4b\u6548\u5ea6\u6709\u9650\uff0c\u4f20\u7edf\u975e\u7ebf\u6027\u6a21\u578b\u867d\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u4f46\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e34\u5e8a\u4fe1\u4efb\u3002\u9700\u8981\u501f\u9274\u5f71\u50cf\u5b66\u548c\u7ec4\u5b66\u9886\u57df\u7684\u7a33\u5b9a\u4fe1\u53f7\u63d0\u53d6\u7b56\u7565\uff0c\u5f00\u53d1\u65e2\u51c6\u786e\u53c8\u900f\u660e\u7684\u7cbe\u795e\u75be\u75c5\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u89e3\u8026\u9884\u5904\u7406\u4e0e\u9884\u6d4b\u7684\u4e24\u9636\u6bb5\u6846\u67b6REFINE\uff08\u5197\u4f59\u5229\u7528\u968f\u8bbf\u4fe1\u606f\u975e\u7ebf\u6027\u589e\u5f3a\uff09\uff1a\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u975e\u7ebf\u6027\u6a21\u5757\u4ece\u7eb5\u5411\u95ee\u5377\u6570\u636e\u4e2d\u63d0\u53d6\u7a33\u5b9a\u7684\u57fa\u7ebf\u9879\u76ee\u503c\uff0c\u6d88\u9664\u8bbf\u89c6\u548c\u5de5\u5177\u7279\u5f02\u6027\u4f2a\u5f71\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u7ebf\u6027\u6620\u5c04\u6a21\u578b\u5c06\u7a33\u5b9a\u5316\u9879\u76ee\u503c\u4e0e\u672a\u6765\u4e25\u91cd\u7a0b\u5ea6\u5173\u8054\uff0c\u901a\u8fc7\u7cfb\u6570\u77e9\u9635\u5b9e\u73b0\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u591a\u9879\u7cbe\u795e\u53ca\u975e\u7cbe\u795e\u75be\u75c5\u7eb5\u5411\u9884\u6d4b\u5b9e\u9a8c\u4e2d\uff0cREFINE\u5728\u4fdd\u6301\u6e05\u6670\u5168\u5c40\u5f52\u56e0\u7684\u540c\u65f6\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5728\u9884\u5904\u7406\u9636\u6bb5\u96c6\u4e2d\u975e\u7ebf\u6027\u5efa\u6a21\u3001\u9884\u6d4b\u9636\u6bb5\u4fdd\u6301\u7ebf\u6027\u7684\u7b56\u7565\uff0cREFINE\u6709\u6548\u89e3\u51b3\u4e86\u7cbe\u795e\u75be\u75c5\u9884\u6d4b\u7684\"\u51c6\u786e\u6027-\u53ef\u89e3\u91ca\u6027\"\u56f0\u5883\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u4e86\u65e2\u53ef\u9760\u53c8\u900f\u660e\u7684\u5de5\u5177\u3002"}}
{"id": "2602.23671", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23671", "abs": "https://arxiv.org/abs/2602.23671", "authors": ["Yufei Ye", "Wei Guo", "Hao Wang", "Luankang Zhang", "Heng Chang", "Hong Zhu", "Yuyang Ye", "Yong Liu", "Defu Lian", "Enhong Chen"], "title": "FuXi-Linear: Unleashing the Power of Linear Attention in Long-term Time-aware Sequential Recommendation", "comment": null, "summary": "Modern recommendation systems primarily rely on attention mechanisms with quadratic complexity, which limits their ability to handle long user sequences and slows down inference. While linear attention is a promising alternative, existing research faces three critical challenges: (1) temporal signals are often overlooked or integrated via naive coupling that causes mutual interference between temporal and semantic signals while neglecting behavioral periodicity; (2) insufficient positional information provided by existing linear frameworks; and (3) a primary focus on short sequences and shallow architectures. To address these issues, we propose FuXi-Linear, a linear-complexity model designed for efficient long-sequence recommendation. Our approach introduces two key components: (1) a Temporal Retention Channel that independently computes periodic attention weights using temporal data, preventing crosstalk between temporal and semantic signals; (2) a Linear Positional Channel that integrates positional information through learnable kernels within linear complexity. Moreover, we demonstrate that FuXi-Linear exhibits a robust power-law scaling property at a thousand-length scale, a characteristic largely unexplored in prior linear recommendation studies. Extensive experiments on sequences of several thousand tokens demonstrate that FuXi-Linear outperforms state-of-the-art models in recommendation quality, while achieving up to 10$\\times$ speedup in the prefill stage and up to 21$\\times$ speedup in the decode stage compared to competitive baselines. Our code has been released in a public repository https://github.com/USTC-StarTeam/fuxi-linear.", "code_url": "https://github.com/USTC-StarTeam/fuxi-linear", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFuXi-Linear\uff0c\u4e00\u79cd\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u957f\u5e8f\u5217\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u65f6\u95f4\u4fdd\u7559\u901a\u9053\u72ec\u7acb\u5904\u7406\u5468\u671f\u6027\u4fe1\u53f7\u5e76\u9632\u6b62\u4e32\u6270\uff0c\u4ee5\u53ca\u7ebf\u6027\u4f4d\u7f6e\u901a\u9053\u589e\u5f3a\u4f4d\u7f6e\u7f16\u7801\uff0c\u5728\u5343\u7ea7\u5e8f\u5217\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u5206\u522b\u83b7\u5f97\u6700\u9ad810\u500d\u548c21\u500d\u52a0\u901f\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u6ce8\u610f\u529b\u673a\u5236\u9650\u5236\u4e86\u5bf9\u957f\u7528\u6237\u5e8f\u5217\u7684\u5904\u7406\u80fd\u529b\u548c\u63a8\u7406\u901f\u5ea6\u3002\u73b0\u6709\u7ebf\u6027\u6ce8\u610f\u529b\u7814\u7a76\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u65f6\u95f4\u4fe1\u53f7\u88ab\u5ffd\u89c6\u6216\u7b80\u5355\u8026\u5408\u5bfc\u81f4\u76f8\u4e92\u5e72\u6270\u3001\u5468\u671f\u6027\u884c\u4e3a\u672a\u88ab\u5229\u7528\uff1b\u73b0\u6709\u7ebf\u6027\u6846\u67b6\u4f4d\u7f6e\u4fe1\u606f\u4e0d\u8db3\uff1b\u7814\u7a76\u96c6\u4e2d\u4e8e\u77ed\u5e8f\u5217\u548c\u6d45\u5c42\u67b6\u6784\u3002", "method": "\u63d0\u51faFuXi-Linear\u6a21\u578b\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a(1)\u65f6\u95f4\u4fdd\u7559\u901a\u9053\uff0c\u5229\u7528\u65f6\u5e8f\u6570\u636e\u72ec\u7acb\u8ba1\u7b97\u5468\u671f\u6027\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u907f\u514d\u65f6\u95f4\u4e0e\u8bed\u4e49\u4fe1\u53f7\u4e32\u6270\uff1b(2)\u7ebf\u6027\u4f4d\u7f6e\u901a\u9053\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u6838\u51fd\u6570\u5728\u5e38\u6570\u590d\u6742\u5ea6\u5185\u96c6\u6210\u4f4d\u7f6e\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5c55\u73b0\u4e86\u5343\u7ea7\u5e8f\u5217\u5c3a\u5ea6\u4e0b\u7684\u7a33\u5065\u5e42\u5f8b\u7f29\u653e\u7279\u6027\u3002", "result": "\u5728\u957f\u8fbe\u6570\u5343token\u7684\u5e8f\u5217\u4e0a\uff0cFuXi-Linear\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u6a21\u578b\uff0c\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u5728\u9884\u586b\u5145\u9636\u6bb5\u5b9e\u73b0\u6700\u9ad810\u500d\u52a0\u901f\uff0c\u5728\u89e3\u7801\u9636\u6bb5\u5b9e\u73b0\u6700\u9ad821\u500d\u52a0\u901f\u3002", "conclusion": "FuXi-Linear\u901a\u8fc7\u5206\u79bb\u65f6\u5e8f\u4e0e\u8bed\u4e49\u4fe1\u53f7\u5904\u7406\u7684\u521b\u65b0\u67b6\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u6548\u7387\u4e0e\u6548\u679c\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u6709\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23643", "abs": "https://arxiv.org/abs/2602.23643", "authors": ["Judah Goldfeder", "Philippe Wyder", "Yann LeCun", "Ravid Shwartz Ziv"], "title": "AI Must Embrace Specialization via Superhuman Adaptable Intelligence", "comment": null, "summary": "Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u5ba1\u89c6\u4e86\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u6982\u5ff5\uff0c\u8ba4\u4e3a\u5c3d\u7ba1\u5404\u754c\u5bf9\u5176\u5b9a\u4e49\u7f3a\u4e4f\u5171\u8bc6\uff0c\u4f46\u5373\u4fbf\u5728\u6700\u6e05\u6670\u7684\u8868\u8ff0\u4e0b\uff0cAGI\u4ecd\u662f\u4e00\u4e2a\u63cf\u8ff0AI\u672a\u6765\u7684\u6709\u7f3a\u9677\u6846\u67b6\u3002\u8bba\u6587\u8bba\u8bc1\u4e86\u4eba\u7c7b\u5e76\u975e\u771f\u6b63\"\u901a\u7528\"\uff0c\u4e3b\u5f20AI\u5e94\u62e5\u62b1\u4e13\u4e1a\u5316\u800c\u975e\u8ffd\u6c42\u901a\u7528\u6027\uff0c\u5e76\u63d0\u51fa\"\u8d85\u4eba\u7c7b\u9002\u5e94\u667a\u80fd\uff08SAI\uff09\"\u4f5c\u4e3a\u66ff\u4ee3\u6982\u5ff5\u2014\u2014\u6307\u80fd\u5728\u4eba\u7c7b\u80fd\u505a\u7684\u91cd\u8981\u4e8b\u60c5\u4e0a\u8d85\u8d8a\u4eba\u7c7b\uff0c\u5e76\u586b\u8865\u4eba\u7c7b\u80fd\u529b\u7a7a\u767d\u7684\u667a\u80fd\u3002SAI\u65e8\u5728\u4e3a\u88abAGI\u8fc7\u8f7d\u5b9a\u4e49\u6a21\u7cca\u5316\u7684AI\u8ba8\u8bba\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u6307\u5bfc\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u4eceAI\u4ece\u4e1a\u8005\u5230\u653f\u7b56\u5236\u5b9a\u8005\u3001\u6d3b\u52a8\u5bb6\u90fd\u5728\u8ba8\u8bbaAGI\uff0c\u4f46\u5bf9\u5176\u5b9a\u4e49\u7f3a\u4e4f\u5171\u8bc6\u3002\u6838\u5fc3\u95ee\u9898\u5728\u4e8e\uff1a\u4ee5\"\u80fd\u505a\u4eba\u7c7b\u6240\u80fd\u505a\u7684\u4e00\u5207\"\u6765\u5b9a\u4e49AGI\u662f\u5426\u5408\u7406\uff1f\u4eba\u7c7b\u662f\u5426\u771f\u7684\u5177\u6709\"\u901a\u7528\u6027\"\uff1f\u8fd9\u79cd\u6a21\u7cca\u4e14\u53ef\u80fd\u9519\u8bef\u7684\u6982\u5ff5\u6846\u67b6\u4f1a\u8bef\u5bfc\u5bf9AI\u672a\u6765\u7684\u8ba8\u8bba\u548c\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\u73b0\u6709\u4e3b\u6d41AGI\u5b9a\u4e49\u7684\u5408\u7406\u6027\u3001\u5b9e\u7528\u6027\u548c\u771f\u6b63\u901a\u7528\u6027\uff0c\u6307\u51fa\u5176\u6982\u5ff5\u7f3a\u9677\u3002\u8fdb\u800c\u63d0\u51fa\u5e94\u653e\u5f03\u5bf9\u901a\u7528\u6027\u7684\u8ffd\u6c42\uff0c\u8f6c\u5411\u4e13\u4e1a\u5316\u8def\u5f84\uff0c\u5e76\u5f15\u5165\"\u8d85\u4eba\u7c7b\u9002\u5e94\u667a\u80fd\uff08SAI\uff09\"\u4f5c\u4e3a\u65b0\u7684\u6982\u5ff5\u6846\u67b6\u3002SAI\u5b9a\u4e49\u4e3a\u80fd\u591f\u5b66\u4e60\u5e76\u5728\u4eba\u7c7b\u80fd\u505a\u7684\u4efb\u4f55\u91cd\u8981\u4e8b\u60c5\u4e0a\u8d85\u8d8a\u4eba\u7c7b\uff0c\u540c\u65f6\u586b\u8865\u4eba\u7c7b\u80fd\u529b\u7a7a\u767d\u7684\u667a\u80fd\u5f62\u5f0f\u3002", "result": "\u8bba\u8bc1\u4e86AGI\u6982\u5ff5\u7684\u6839\u672c\u7f3a\u9677\uff0c\u6210\u529f\u63d0\u51fa\u4e86SAI\u4f5c\u4e3a\u66ff\u4ee3\u6027\u6982\u5ff5\u6846\u67b6\u3002SAI\u5f3a\u8c03\u5728\u4e13\u4e1a\u5316\u57fa\u7840\u4e0a\u8ffd\u6c42\u8d85\u4eba\u7c7b\u8868\u73b0\uff0c\u800c\u975e\u4eba\u7c7b\u6c34\u5e73\u7684\u901a\u7528\u6027\u3002\u8fd9\u4e00\u65b0\u6982\u5ff5\u80fd\u591f\u6f84\u6e05\u88abAGI\u8fc7\u8f7d\u5b9a\u4e49\u6240\u6a21\u7cca\u7684AI\u8ba8\u8bba\uff0c\u4e3a\u672a\u6765AI\u53d1\u5c55\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u6307\u5bfc\u65b9\u5411\u3002", "conclusion": "AGI\u662f\u4e00\u4e2a\u6709\u7f3a\u9677\u7684\u6982\u5ff5\uff0c\u4e0d\u5e94\u4f5c\u4e3aAI\u672a\u6765\u7684\u63cf\u8ff0\u6846\u67b6\u3002AI\u53d1\u5c55\u5e94\u62e5\u62b1\u4e13\u4e1a\u5316\u5e76\u5728\u4e13\u4e1a\u5316\u4e2d\u8ffd\u6c42\u8d85\u4eba\u7c7b\u8868\u73b0\u3002SAI\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u6982\u5ff5\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u9886\u57df\u7684\u7406\u6027\u8ba8\u8bba\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\u89c4\u5212\u3002\u8fd9\u4e00\u6982\u5ff5\u8f6c\u6362\u5bf9AI\u7814\u7a76\u548c\u653f\u7b56\u5236\u5b9a\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.23495", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23495", "abs": "https://arxiv.org/abs/2602.23495", "authors": ["Yangyi Li", "Mengdi Huai"], "title": "Uncertainty-aware Language Guidance for Concept Bottleneck Models", "comment": null, "summary": "Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff0c\u901a\u8fc7\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\u6982\u5ff5\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u878d\u5165\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6LLM\u5e7b\u89c9\u98ce\u9669\u4e14\u7f3a\u4e4f\u5206\u5e03\u65e0\u5173\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\uff0c\u6210\u672c\u9ad8\u6602\uff1b\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u6807\u6ce8\u65b9\u6cd5\u5ffd\u89c6\u6982\u5ff5\u4e0d\u786e\u5b9a\u6027\u4e14\u672a\u5c06\u5176\u7eb3\u5165\u8bad\u7ec3\uff0c\u5bfc\u81f4\u6a21\u578b\u6613\u53d7LLM\u5e7b\u89c9\u5f71\u54cd\uff0c\u53ef\u9760\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5CBM\u6846\u67b6\uff1a1\uff09\u91c7\u7528\u5206\u5e03\u65e0\u5173\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u4e25\u683c\u91cf\u5316LLM\u6807\u6ce8\u6982\u5ff5\u6807\u7b7e\u7684\u4e0d\u786e\u5b9a\u6027\uff1b2\uff09\u5c06\u91cf\u5316\u540e\u7684\u4e0d\u786e\u5b9a\u6027\u878d\u5165\u6a21\u578b\u8bad\u7ec3\uff0c\u901a\u8fc7\u533a\u5206\u4e0d\u540c\u6982\u5ff5\u6807\u6ce8\u7684\u53ef\u9760\u6027\u6765\u4f18\u5316\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u6027\u4e0e\u53ef\u9760\u6027\u4fdd\u8bc1\uff1b\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u6982\u5ff5\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u6210\u529f\u5c06\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u673a\u5236\u5f15\u5165\u57fa\u4e8eLLM\u7684CBM\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5173\u952e\u7f3a\u9677\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684AI\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4fc3\u8fdb\u4e86CBM\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.23717", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23717", "abs": "https://arxiv.org/abs/2602.23717", "authors": ["Hao Li", "Kedar Bellare", "Siyu Yang", "Sherry Chen", "Liwei He", "Stephanie Moyerman", "Sanjeev Katariya"], "title": "Recommending Search Filters To Improve Conversions At Airbnb", "comment": null, "summary": "Airbnb, a two-sided online marketplace connecting guests and hosts, offers a diverse and unique inventory of accommodations, experiences, and services. Search filters play an important role in helping guests navigate this variety by refining search results to align with their needs. Yet, while search filters are designed to facilitate conversions in online marketplaces, their direct impact on driving conversions remains underexplored in the existing literature.\n  This paper bridges this gap by presenting a novel application of machine learning techniques to recommend search filters aimed at improving booking conversions. We introduce a modeling framework that directly targets lower-funnel conversions (bookings) by recommending intermediate tools, i.e. search filters. Leveraging the framework, we designed and built the filter recommendation system at Airbnb from the ground up, addressing challenges like cold start and stringent serving requirements.\n  The filter recommendation system we developed has been successfully deployed at Airbnb, powering multiple user interfaces and driving incremental booking conversion lifts, as validated through online A/B testing. An ablation study further validates the effectiveness of our approach and key design choices. By focusing on conversion-oriented filter recommendations, our work ensures that search filters serve their ultimate purpose at Airbnb - helping guests find and book their ideal accommodations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\uff0c\u5f00\u53d1\u4e86\u641c\u7d22\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\u4ee5\u76f4\u63a5\u63d0\u5347Airbnb\u7684\u9884\u8ba2\u8f6c\u5316\u7387\u3002\u8be5\u7cfb\u7edf\u4ece\u96f6\u6784\u5efa\uff0c\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u548c\u9ad8\u5e76\u53d1\u670d\u52a1\u6311\u6218\uff0c\u7ecfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u5728\u591a\u754c\u9762\u90e8\u7f72\u540e\u5e26\u6765\u663e\u8457\u8f6c\u5316\u7387\u63d0\u5347\u3002", "motivation": "\u641c\u7d22\u8fc7\u6ee4\u5668\u867d\u5728\u5728\u7ebf\u5e73\u53f0\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u5176\u5bf9\u9a71\u52a8\u8f6c\u5316\u7684\u76f4\u63a5\u6548\u679c\u5728\u5b66\u672f\u7814\u7a76\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002Airbnb\u4f5c\u4e3a\u8fde\u63a5\u623f\u5ba2\u4e0e\u623f\u4e1c\u7684\u53cc\u8fb9\u5e02\u573a\uff0c\u62e5\u6709\u5927\u91cf\u591a\u6837\u5316\u4f4f\u5bbf\u5e93\u5b58\uff0c\u8fc7\u6ee4\u5668\u662f\u7528\u6237\u51b3\u7b56\u7684\u5173\u952e\u5de5\u5177\uff0c\u4f46\u5982\u4f55\u4e3b\u52a8\u4f18\u5316\u8fc7\u6ee4\u5668\u63a8\u8350\u4ee5\u6700\u5927\u5316\u9884\u8ba2\u8f6c\u5316\u7387\u4ecd\u662f\u4e00\u4e2a\u91cd\u8981\u4e14\u672a\u88ab\u7cfb\u7edf\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u6f0f\u6597\u4e0b\u6e38\u8f6c\u5316\uff08\u9884\u8ba2\uff09\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u8350\u4e2d\u95f4\u5de5\u5177\uff08\u641c\u7d22\u8fc7\u6ee4\u5668\uff09\u6765\u4f18\u5316\u6700\u7ec8\u8f6c\u5316\u7387\u3002\u7cfb\u7edf\u4ece0\u52301\u6784\u5efa\uff0c\u91c7\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\u5e76\u6ee1\u8db3\u4e25\u683c\u7684\u7ebf\u4e0a\u670d\u52a1\u5ef6\u8fdf\u8981\u6c42\uff0c\u8bbe\u8ba1\u4e86\u5b8c\u6574\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\u5f15\u64ce\u67b6\u6784\u3002", "result": "\u6240\u5f00\u53d1\u7684\u7cfb\u7edf\u5df2\u5728Airbnb\u751f\u4ea7\u73af\u5883\u6210\u529f\u90e8\u7f72\uff0c\u652f\u6301\u591a\u4e2a\u7528\u6237\u754c\u9762\uff0c\u5e76\u901a\u8fc7\u4e25\u683c\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u5e26\u6765\u4e86\u7edf\u8ba1\u663e\u8457\u7684\u589e\u91cf\u9884\u8ba2\u8f6c\u5316\u7387\u63d0\u5347\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u91cf\u5316\u4e86\u5404\u8bbe\u8ba1\u9009\u62e9\u5bf9\u6548\u679c\u7684\u8d21\u732e\uff0c\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u805a\u7126\u8f6c\u5316\u5bfc\u5411\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\uff0c\u786e\u4fdd\u641c\u7d22\u8fc7\u6ee4\u5668\u53d1\u6325\u5176\u7ec8\u6781\u4ef7\u503c\u3002\u6210\u679c\u4e0d\u4ec5\u586b\u8865\u4e86\u5b66\u672f\u754c\u5728\u8fc7\u6ee4\u5668\u63a8\u8350\u4e0e\u8f6c\u5316\u7387\u5173\u7cfb\u65b9\u9762\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e5f\u4e3a\u5728\u7ebf\u5e02\u573a\u5e73\u53f0\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u4f18\u5316\u6846\u67b6\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2602.23577", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23577", "abs": "https://arxiv.org/abs/2602.23577", "authors": ["Jun Li", "Xiangmeng Wang", "Haoyang Li", "Yifei Yan", "Shijie Zhang", "Hong Va Leong", "Ling Feng", "Nancy Xiaonan Yu", "Qing Li"], "title": "Multi-Agent Causal Reasoning for Suicide Ideation Detection Through Online Conversations", "comment": null, "summary": "Suicide remains a pressing global public health concern. While social media platforms offer opportunities for early risk detection through online conversation trees, existing approaches face two major limitations: (1) They rely on predefined rules (e.g., quotes or relies) to log conversations that capture only a narrow spectrum of user interactions, and (2) They overlook hidden influences such as user conformity and suicide copycat behavior, which can significantly affect suicidal expression and propagation in online communities. To address these limitations, we propose a Multi-Agent Causal Reasoning (MACR) framework that collaboratively employs a Reasoning Agent to scale user interactions and a Bias-aware Decision-Making Agent to mitigate harmful biases arising from hidden influences. The Reasoning Agent integrates cognitive appraisal theory to generate counterfactual user reactions to posts, thereby scaling user interactions. It analyses these reactions through structured dimensions, i.e., cognitive, emotional, and behavioral patterns, with a dedicated sub-agent responsible for each dimension. The Bias-aware Decision-Making Agent mitigates hidden biases through a front-door adjustment strategy, leveraging the counterfactual user reactions produced by the Reasoning Agent. Through the collaboration of reasoning and bias-aware decision making, the proposed MACR framework not only alleviates hidden biases, but also enriches contextual information of user interactions with counterfactual knowledge. Extensive experiments on real-world conversational datasets demonstrate the effectiveness and robustness of MACR in identifying suicide risk.", "AI": {"tldr": "\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u81ea\u6740\u98ce\u9669\u68c0\u6d4b\u4e2d\u73b0\u6709\u65b9\u6cd5\u4e92\u52a8\u6355\u6349\u5c40\u9650\u4e0e\u5ffd\u89c6\u9690\u85cf\u504f\u89c1\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u56e0\u679c\u63a8\u7406\uff08MACR\uff09\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u63a8\u7406\u667a\u80fd\u4f53\u751f\u6210\u53cd\u4e8b\u5b9e\u7528\u6237\u53cd\u5e94\u4ee5\u6269\u5c55\u4e92\u52a8\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u504f\u89c1\u611f\u77e5\u51b3\u7b56\u667a\u80fd\u4f53\u91c7\u7528\u524d\u95e8\u8c03\u6574\u7b56\u7565\u7f13\u89e3\u4ece\u4f17\u4e0e\u6a21\u4eff\u81ea\u6740\u7b49\u9690\u85cf\u5f71\u54cd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u771f\u5b9e\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u6709\u6548\u4e14\u9c81\u68d2\u3002", "motivation": "\u81ea\u6740\u662f\u5168\u7403\u91cd\u5927\u516c\u5171\u536b\u751f\u6311\u6218\uff0c\u793e\u4ea4\u5a92\u4f53\u867d\u4e3a\u65e9\u671f\u98ce\u9669\u68c0\u6d4b\u63d0\u4f9b\u673a\u9047\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u53cc\u91cd\u7f3a\u9677\uff1a\u4f9d\u8d56\u9884\u5b9a\u4e49\u89c4\u5219\u5bfc\u81f4\u4e92\u52a8\u6355\u6349\u8303\u56f4\u72ed\u7a84\uff0c\u4e14\u5ffd\u89c6\u7528\u6237\u4ece\u4f17\u4e0e\u81ea\u6740\u6a21\u4eff\u884c\u4e3a\u7b49\u9690\u85cf\u5f71\u54cd\uff0c\u8fd9\u4e9b\u56e0\u7d20\u663e\u8457\u5f71\u54cd\u5728\u7ebf\u793e\u533a\u7684\u81ea\u6740\u8868\u8fbe\u4e0e\u4f20\u64ad\u3002", "method": "\u63d0\u51faMACR\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u63a8\u7406\u667a\u80fd\u4f53\uff1a\u57fa\u4e8e\u8ba4\u77e5\u8bc4\u4f30\u7406\u8bba\u751f\u6210\u53cd\u4e8b\u5b9e\u7528\u6237\u53cd\u5e94\uff0c\u901a\u8fc7\u8ba4\u77e5\u3001\u60c5\u611f\u3001\u884c\u4e3a\u4e09\u7ef4\u5ea6\u7ed3\u6784\u5316\u5206\u6790\u6269\u5c55\u4e92\u52a8\uff0c\u5404\u7ef4\u5ea6\u8bbe\u4e13\u95e8\u5b50\u667a\u80fd\u4f53\uff1b2\uff09\u504f\u89c1\u611f\u77e5\u51b3\u7b56\u667a\u80fd\u4f53\uff1a\u5229\u7528\u53cd\u4e8b\u5b9e\u53cd\u5e94\u5b9e\u65bd\u524d\u95e8\u8c03\u6574\u7b56\u7565\u4ee5\u7f13\u89e3\u9690\u85cf\u504f\u89c1\u3002\u53cc\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u504f\u89c1\u6291\u5236\u4e0e\u4e0a\u4e0b\u6587\u589e\u5f3a\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MACR\u6846\u67b6\u5728\u8bc6\u522b\u81ea\u6740\u98ce\u9669\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "MACR\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u4e0e\u504f\u89c1\u611f\u77e5\u7684\u534f\u540c\u673a\u5236\uff0c\u6709\u6548\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u4e92\u52a8\u89c4\u6a21\u4e0e\u9690\u85cf\u504f\u89c1\u4e0a\u7684\u5c40\u9650\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u81ea\u6740\u98ce\u9669\u65e9\u671f\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u516c\u5171\u536b\u751f\u4ef7\u503c\u3002"}}
{"id": "2602.23504", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23504", "abs": "https://arxiv.org/abs/2602.23504", "authors": ["Anik Pramanik", "Murat Kantarcioglu", "Vincent Oria", "Shantanu Sharma"], "title": "FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments", "comment": "This paper has been accepted in ICLR 2026", "summary": "Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.", "AI": {"tldr": "FedDAG\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u6570\u636e\u548c\u68af\u5ea6\u4fe1\u606f\u7684\u52a0\u6743\u7c7b\u7ea7\u76f8\u4f3c\u6027\u5ea6\u91cf\u8fdb\u884c\u66f4\u5168\u9762\u7684\u5ba2\u6237\u7aef\u805a\u7c7b\uff0c\u5e76\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5b9e\u73b0\u8de8\u96c6\u7fa4\u7279\u5f81\u8fc1\u79fb\uff0c\u5728\u591a\u6837\u5316\u5f02\u6784\u6570\u636e\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u6784\u65f6\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u6570\u636e\u76f8\u4f3c\u6027\u6216\u68af\u5ea6\u76f8\u4f3c\u6027\u4e4b\u4e00\uff0c\u8bc4\u4f30\u4e0d\u5168\u9762\uff1b\u540c\u65f6\u9650\u5236\u77e5\u8bc6\u5171\u4eab\u4ec5\u5728\u96c6\u7fa4\u5185\u90e8\uff0c\u65e0\u6cd5\u5229\u7528\u8de8\u96c6\u7fa4\u7684\u591a\u6837\u6027\u4fe1\u606f\u3002", "method": "FedDAG\u6846\u67b6\u63d0\u51fa\uff1a(1)\u4e00\u79cd\u52a0\u6743\u7c7b\u7ea7\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u878d\u5408\u6570\u636e\u548c\u68af\u5ea6\u4fe1\u606f\u8fdb\u884c\u66f4\u5168\u9762\u7684\u805a\u7c7b\uff1b(2)\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u4e3b\u7f16\u7801\u5668\u5728\u81ea\u8eab\u5ba2\u6237\u7aef\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u8f85\u52a9\u7f16\u7801\u5668\u5229\u7528\u4e92\u8865\u96c6\u7fa4\u7684\u68af\u5ea6\u8fdb\u884c\u4f18\u5316\uff0c\u5b9e\u73b0\u8de8\u96c6\u7fa4\u7279\u5f81\u8fc1\u79fb\u540c\u65f6\u4fdd\u6301\u96c6\u7fa4\u7279\u5f02\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u548c\u6570\u636e\u5f02\u6784\u6027\u8bbe\u7f6e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedDAG\u5728\u51c6\u786e\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "FedDAG\u901a\u8fc7\u5168\u9762\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u548c\u8de8\u96c6\u7fa4\u7279\u5f81\u8fc1\u79fb\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u4e3a\u5f02\u6784\u73af\u5883\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23766", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23766", "abs": "https://arxiv.org/abs/2602.23766", "authors": ["Zheng Dou", "Zhao Zhang", "Deqing Wang", "Yikun Ban", "Fuzhen Zhuang"], "title": "UniFAR: A Unified Facet-Aware Retrieval Framework for Scientific Documents", "comment": null, "summary": "Existing scientific document retrieval (SDR) methods primarily rely on document-centric representations learned from inter-document relationships for document-document (doc-doc) retrieval. However, the rise of LLMs and RAG has shifted SDR toward question-driven retrieval, where documents are retrieved in response to natural-language questions (q-doc). This change has led to systematic mismatches between document-centric models and question-driven retrieval, including (1) input granularity (long documents vs. short questions), (2) semantic focus (scientific discourse structure vs. specific question intent), and (3) training signals (citation-based similarity vs. question-oriented relevance). To this end, we propose UniFAR, a Unified Facet-Aware Retrieval framework to jointly support doc-doc and q-doc SDR within a single architecture. UniFAR reconciles granularity differences through adaptive multi-granularity aggregation, aligns document structure with question intent via learnable facet anchors, and unifies doc-doc and q-doc supervision through joint training. Experimental results show that UniFAR consistently outperforms prior methods across multiple retrieval tasks and base models, confirming its effectiveness and generality.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u4ece\u6587\u6863-\u6587\u6863\u68c0\u7d22\u5411\u95ee\u9898-\u6587\u6863\u68c0\u7d22\u7684\u8f6c\u53d8\uff0c\u63d0\u51faUniFAR\u7edf\u4e00\u6846\u67b6\u6765\u89e3\u51b3\u7c92\u5ea6\u3001\u8bed\u4e49\u548c\u8bad\u7ec3\u4fe1\u53f7\u4e09\u65b9\u9762\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7c92\u5ea6\u805a\u5408\u3001\u53ef\u5b66\u4e60\u65b9\u9762\u951a\u70b9\u548c\u8054\u5408\u8bad\u7ec3\u5b9e\u73b0\u53cc\u4efb\u52a1\u7edf\u4e00\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6587\u6863\u4e2d\u5fc3\u8868\u793a\u5b66\u4e60\uff0c\u9002\u7528\u4e8e\u6587\u6863-\u6587\u6863\u68c0\u7d22\u3002\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u548cRAG\u7684\u5174\u8d77\u4f7f\u68c0\u7d22\u573a\u666f\u8f6c\u5411\u95ee\u9898\u9a71\u52a8\u7684\u95ee\u7b54\u5f0f\u68c0\u7d22\uff0c\u5bfc\u81f4\u73b0\u6709\u65b9\u6cd5\u5728\u8f93\u5165\u7c92\u5ea6\uff08\u957f\u6587\u6863vs\u77ed\u95ee\u9898\uff09\u3001\u8bed\u4e49\u7126\u70b9\uff08\u79d1\u5b66\u8bba\u8ff0\u7ed3\u6784vs\u7279\u5b9a\u95ee\u9898\u610f\u56fe\uff09\u548c\u8bad\u7ec3\u4fe1\u53f7\uff08\u5f15\u7528\u76f8\u4f3c\u5ea6vs\u95ee\u9898\u76f8\u5173\u6027\uff09\u4e09\u65b9\u9762\u51fa\u73b0\u7cfb\u7edf\u6027\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faUniFAR\uff08\u7edf\u4e00\u65b9\u9762\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff09\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u591a\u7c92\u5ea6\u805a\u5408\u89e3\u51b3\u7c92\u5ea6\u5dee\u5f02\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u65b9\u9762\u951a\u70b9\u5bf9\u9f50\u6587\u6863\u7ed3\u6784\u4e0e\u95ee\u9898\u610f\u56fe\uff0c\u5e76\u5229\u7528\u8054\u5408\u8bad\u7ec3\u7edf\u4e00\u6587\u6863-\u6587\u6863\u548c\u95ee\u7b54\u5f0f\u68c0\u7d22\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u5728\u5355\u4e00\u67b6\u6784\u4e2d\u540c\u65f6\u652f\u6301\u4e24\u79cd\u68c0\u7d22\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUniFAR\u5728\u591a\u4e2a\u68c0\u7d22\u4efb\u52a1\u548c\u57fa\u7840\u6a21\u578b\u4e0a\u5747\u6301\u7eed\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u8de8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "UniFAR\u6210\u529f\u5f25\u5408\u4e86\u6587\u6863\u4e2d\u5fc3\u6a21\u578b\u4e0e\u95ee\u7b54\u5f0f\u68c0\u7d22\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u73b0\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2602.23580", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23580", "abs": "https://arxiv.org/abs/2602.23580", "authors": ["Yun Wang", "Xuansheng Wu", "Jingyuan Huang", "Lei Liu", "Xiaoming Zhai", "Ninghao Liu"], "title": "BRIDGE the Gap: Mitigating Bias Amplification in Automated Scoring of English Language Learners via Inter-group Data Augmentation", "comment": "15 pages, 1 figure", "summary": "In the field of educational assessment, automated scoring systems increasingly rely on deep learning and large language models (LLMs). However, these systems face significant risks of bias amplification, where model prediction gaps between student groups become larger than those observed in training data. This issue is especially severe for underrepresented groups such as English Language Learners (ELLs), as models may inherit and further magnify existing disparities in the data. We identify that this issue is closely tied to representation bias: the scarcity of minority (high-scoring ELL) samples makes models trained with empirical risk minimization favor majority (non-ELL) linguistic patterns. Consequently, models tend to under-predict ELL students who even demonstrate comparable domain knowledge but use different linguistic patterns, thereby undermining the fairness of automated scoring outcomes. To mitigate this, we propose BRIDGE, a Bias-Reducing Inter-group Data GEneration framework designed for low-resource assessment settings. Instead of relying on the limited minority samples, BRIDGE synthesizes high-scoring ELL samples by \"pasting\" construct-relevant (i.e., rubric-aligned knowledge and evidence) content from abundant high-scoring non-ELL samples into authentic ELL linguistic patterns. We further introduce a discriminator model to ensure the quality of synthetic samples. Experiments on California Science Test (CAST) datasets demonstrate that BRIDGE effectively reduces prediction bias for high-scoring ELL students while maintaining overall scoring performance. Notably, our method achieves fairness gains comparable to using additional real human data, offering a cost-effective solution for ensuring equitable scoring in large-scale assessments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faBRIDGE\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u9ad8\u8d28\u91cf\u82f1\u8bed\u5b66\u4e60\u8005\uff08ELL\uff09\u6837\u672c\uff0c\u6709\u6548\u51cf\u5c11\u81ea\u52a8\u5316\u8bc4\u5206\u7cfb\u7edf\u4e2d\u7684\u9884\u6d4b\u504f\u5dee\uff0c\u5728\u4fdd\u6301\u6574\u4f53\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e0e\u771f\u5b9e\u6570\u636e\u76f8\u5f53\u7684\u516c\u5e73\u6027\u63d0\u5347\uff0c\u4e3a\u5927\u89c4\u6a21\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u9ad8\u6548\u7684\u516c\u5e73\u6027\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5728\u6559\u80b2\u8bc4\u4f30\u9886\u57df\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8bc4\u5206\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u7684\u504f\u89c1\u653e\u5927\u98ce\u9669\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u82f1\u8bed\u5b66\u4e60\u8005\uff08ELL\uff09\u7b49\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u7fa4\u4f53\u3002\u7531\u4e8e\u5c11\u6570\u7fa4\u4f53\uff08\u9ad8\u5206ELL\uff09\u6837\u672c\u7a00\u7f3a\uff0c\u91c7\u7528\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u8bad\u7ec3\u7684\u6a21\u578b\u4f1a\u504f\u5411\u591a\u6570\u7fa4\u4f53\uff08\u975eELL\uff09\u7684\u8bed\u8a00\u6a21\u5f0f\uff0c\u5bfc\u81f4\u5373\u4f7f\u638c\u63e1\u76f8\u5f53\u9886\u57df\u77e5\u8bc6\u7684ELL\u5b66\u751f\u4e5f\u88ab\u4f4e\u4f30\u5206\u6570\uff0c\u635f\u5bb3\u8bc4\u5206\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51faBRIDGE\uff08Bias-Reducing Inter-group Data GEneration\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4e30\u5bcc\u7684\u9ad8\u5206\u975eELL\u6837\u672c\u4e2d\u7684\u6784\u5ff5\u76f8\u5173\uff08\u5373\u7b26\u5408\u8bc4\u5206\u6807\u51c6\uff09\u5185\u5bb9\"\u7c98\u8d34\"\u5230\u771f\u5b9e\u7684ELL\u8bed\u8a00\u6a21\u5f0f\u4e2d\uff0c\u5408\u6210\u9ad8\u8d28\u91cfELL\u6837\u672c\u3002\u540c\u65f6\u5f15\u5165\u5224\u522b\u5668\u6a21\u578b\u786e\u4fdd\u5408\u6210\u6837\u672c\u8d28\u91cf\uff0c\u4e13\u95e8\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bc4\u4f30\u573a\u666f\u8bbe\u8ba1\u3002", "result": "\u5728\u52a0\u5dde\u79d1\u5b66\u6d4b\u8bd5\uff08CAST\uff09\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBRIDGE\u5728\u4fdd\u6301\u6574\u4f53\u8bc4\u5206\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u9ad8\u5206ELL\u5b66\u751f\u7684\u9884\u6d4b\u504f\u5dee\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u7684\u516c\u5e73\u6027\u63d0\u5347\u4e0e\u4f7f\u7528\u989d\u5916\u771f\u5b9e\u4eba\u7c7b\u6570\u636e\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u786e\u4fdd\u5927\u89c4\u6a21\u8bc4\u4f30\u4e2d\u7684\u516c\u5e73\u8bc4\u5206\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u663e\u8457\u589e\u52a0\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6559\u80b2\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u76ee\u6807\u3002"}}
{"id": "2602.23681", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23681", "abs": "https://arxiv.org/abs/2602.23681", "authors": ["Siyuan Ma", "Bo Gao", "Xiaojun Jia", "Simeng Qin", "Tianlin Li", "Ke Ma", "Xiaoshuang Jia", "Wenqi Ren", "Yang Liu"], "title": "ODAR: Principled Adaptive Routing for LLM Reasoning via Active Inference", "comment": null, "summary": "The paradigm of large language model (LLM) reasoning is shifting from parameter scaling to test-time compute scaling, yet many existing approaches still rely on uniform brute-force sampling (for example, fixed best-of-N or self-consistency) that is costly, hard to attribute, and can trigger overthinking with diminishing returns. We propose ODAR-Expert, an adaptive routing framework that optimizes the accuracy-efficiency trade-off via principled resource allocation. ODAR uses a difficulty estimator grounded in amortized active inference to dynamically route queries between a heuristic Fast Agent and a deliberative Slow Agent. We further introduce a free-energy-principled, risk-sensitive fusion mechanism that selects answers by minimizing a variational free energy objective, balancing log-likelihood with epistemic uncertainty (varentropy) as a principled alternative to ad hoc voting over heterogeneous candidates. Extensive evaluation across 23 benchmarks shows strong and consistent gains, including 98.2% accuracy on MATH and 54.8% on Humanity's Last Exam (HLE), while improving the compute-accuracy frontier under compute-matched settings. We also validate reproducibility on a fully open-source stack (Llama 4 + DeepSeek), where ODAR surpasses homogeneous sampling strategies while reducing computational costs by 82%. Overall, our results suggest that thinking-optimal scaling requires adaptive resource allocation with free-energy-based decision-making rather than simply increasing test-time compute.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faODAR-Expert\u81ea\u9002\u5e94\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u539f\u5219\u6027\u8d44\u6e90\u5206\u914d\u4f18\u5316\u51c6\u786e\u7387-\u6548\u7387\u6743\u8861\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u644a\u9500\u4e3b\u52a8\u63a8\u7406\u96be\u5ea6\u4f30\u8ba1\u5668\u52a8\u6001\u8c03\u5ea6\u67e5\u8be2\u81f3\u542f\u53d1\u5f0f\u5feb\u667a\u80fd\u4f53\u548c\u6df1\u601d\u5f0f\u6162\u667a\u80fd\u4f53\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u81ea\u7531\u80fd\u539f\u7406\u7684\u98ce\u9669\u654f\u611f\u878d\u5408\u673a\u5236\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u53d8\u5206\u81ea\u7531\u80fd\u76ee\u6807\uff08\u5e73\u8861\u5bf9\u6570\u4f3c\u7136\u4e0e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff09\u9009\u62e9\u7b54\u6848\uff0c\u800c\u975e\u542f\u53d1\u5f0f\u6295\u7968\u3002\u572823\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff08MATH\u8fbe98.2%\uff0cHLE\u8fbe54.8%\uff09\uff0c\u5728\u5339\u914d\u8ba1\u7b97\u91cf\u4e0b\u63d0\u5347\u8ba1\u7b97-\u51c6\u786e\u7387\u524d\u6cbf\uff0c\u5e76\u5728\u5f00\u6e90\u6808\u4e0a\u964d\u4f4e82%\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u867d\u4ece\u53c2\u6570\u6269\u5c55\u8f6c\u5411\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\uff0c\u4f46\u591a\u6570\u65b9\u6cd5\u4ecd\u4f9d\u8d56\u7edf\u4e00\u7684\u66b4\u529b\u91c7\u6837\u7b56\u7565\uff08\u5982\u56fa\u5b9abest-of-N\u6216\u81ea\u6d3d\u6027\uff09\uff0c\u5b58\u5728\u6210\u672c\u9ad8\u3001\u53ef\u5f52\u56e0\u6027\u5dee\u3001\u6613\u5f15\u53d1\u6536\u76ca\u9012\u51cf\u7684\u8fc7\u5ea6\u601d\u8003\u7b49\u95ee\u9898\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u8d44\u6e90\u5206\u914d\u673a\u5236\u6765\u4f18\u5316\u51c6\u786e\u7387\u4e0e\u6548\u7387\u7684\u6743\u8861\uff0c\u800c\u975e\u5355\u7eaf\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u3002", "method": "\u63d0\u51faODAR-Expert\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u644a\u9500\u4e3b\u52a8\u63a8\u7406\u7684\u96be\u5ea6\u4f30\u8ba1\u5668\uff0c\u52a8\u6001\u8def\u7531\u67e5\u8be2\u81f3\u542f\u53d1\u5f0fFast Agent\u548c\u6df1\u601d\u5f0fSlow Agent\uff1b2\uff09\u5f15\u5165\u81ea\u7531\u80fd\u539f\u7406\u7684\u98ce\u9669\u654f\u611f\u878d\u5408\u673a\u5236\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u53d8\u5206\u81ea\u7531\u80fd\u76ee\u6807\u51fd\u6570\uff0c\u5c06\u5bf9\u6570\u4f3c\u7136\u4e0e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff08varentropy\uff09\u76f8\u7ed3\u5408\uff0c\u4f5c\u4e3a\u5f02\u6784\u5019\u9009\u7b54\u6848\u7684\u51b3\u7b56\u539f\u5219\uff0c\u66ff\u4ee3\u4e34\u65f6\u6027\u7684\u6295\u7968\u7b56\u7565\u3002", "result": "\u572823\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u5f3a\u5927\u4e14\u4e00\u81f4\u7684\u589e\u76ca\uff1aMATH\u51c6\u786e\u738798.2%\uff0cHumanity's Last Exam\uff08HLE\uff09\u8fbe54.8%\uff1b\u5728\u8ba1\u7b97\u91cf\u5339\u914d\u8bbe\u7f6e\u4e0b\u6539\u5584\u4e86\u8ba1\u7b97-\u51c6\u786e\u7387\u524d\u6cbf\uff1b\u5728\u5b8c\u5168\u5f00\u6e90\u6808\uff08Llama 4 + DeepSeek\uff09\u4e0a\u590d\u73b0\u5e76\u8d85\u8d8a\u540c\u8d28\u91c7\u6837\u7b56\u7565\uff0c\u540c\u65f6\u964d\u4f4e82%\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6700\u4f18\u601d\u8003\u6269\u5c55\u9700\u8981\u57fa\u4e8e\u81ea\u7531\u80fd\u7684\u9002\u5e94\u6027\u8d44\u6e90\u5206\u914d\u4e0e\u51b3\u7b56\u673a\u5236\uff0c\u800c\u975e\u7b80\u5355\u5730\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u3002\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2602.23507", "categories": ["cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.23507", "abs": "https://arxiv.org/abs/2602.23507", "authors": ["Diana Shamsutdinova", "Felix Zimmer", "Oyebayo Ridwan Olaniran", "Sarah Markham", "Daniel Stahl", "Gordon Forbes", "Ewan Carr"], "title": "Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package", "comment": "26 pages, 4 figures, 1 table, preprint", "summary": "Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u5f00\u53d1\u4e2d\u7684\u6837\u672c\u91cf\u786e\u5b9a\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5b66\u4e60\u66f2\u7ebf\u3001\u9ad8\u65af\u8fc7\u7a0b\u4f18\u5316\u548c\u4fdd\u8bc1\u539f\u5219\u7684\u6a21\u62df\u65b9\u6cd5(pmsims R\u5305)\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u6700\u5c0f\u6837\u672c\u91cf\u786e\u5b9a\u4ecd\u662f\u5173\u952e\u4e14\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002\u6837\u672c\u91cf\u4e0d\u8db3\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u9884\u6d4b\u504f\u5dee\u3002\u73b0\u6709\u65b9\u6cd5(\u542f\u53d1\u5f0f\u89c4\u5219\u3001\u95ed\u5f0f\u516c\u5f0f\u3001\u6a21\u62df\u65b9\u6cd5)\u5728\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u51c6\u786e\u6027\u5dee\u5f02\u8f83\u5927\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u73b0\u6709\u6837\u672c\u91cf\u4f30\u7b97\u65b9\u6cd5\uff0c\u63d0\u51fa\u533a\u5206\u5747\u503c\u578b\u4e0e\u4fdd\u8bc1\u578b\u6807\u51c6\u7684\u7406\u8bba\u6846\u67b6\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1\u65b0\u578b\u6a21\u62df\u65b9\u6cd5\uff0c\u6574\u5408\u5b66\u4e60\u66f2\u7ebf\u3001\u9ad8\u65af\u8fc7\u7a0b\u4f18\u5316\u548c\u4fdd\u8bc1\u539f\u5219\uff0c\u4ee5\u8bc6\u522b\u4ee5\u9ad8\u6982\u7387\u8fbe\u5230\u76ee\u6807\u6027\u80fd\u7684\u6837\u672c\u91cf\uff1b\u5c06\u6b64\u65b9\u6cd5\u5b9e\u73b0\u4e3a\u5f00\u6e90\u3001\u6a21\u578b\u65e0\u5173\u7684R\u5305pmsims\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u6837\u672c\u91cf\u4f30\u8ba1\u5728\u4e0d\u540c\u65b9\u6cd5\u3001\u6027\u80fd\u6307\u6807\u548c\u5efa\u6a21\u7b56\u7565\u95f4\u5dee\u5f02\u663e\u8457\u3002\u76f8\u6bd4\u73b0\u6709\u5de5\u5177\uff0cpmsims\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u5bb9\u7eb3\u591a\u6837\u6a21\u578b\u548c\u7528\u6237\u81ea\u5b9a\u4e49\u6307\u6807\uff0c\u5e76\u663e\u5f0f\u8003\u8651\u6a21\u578b\u6027\u80fd\u7684\u53d8\u5f02\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u8f6f\u4ef6\u901a\u8fc7\u7ed3\u5408\u7075\u6d3b\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u63a8\u8fdb\u4e86\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u7684\u6837\u672c\u91cf\u65b9\u6cd5\u8bba\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u6269\u5c55\u81f3\u5c42\u6b21\u5316\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u7eb3\u5165\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\u6307\u6807\uff0c\u5e76\u89e3\u51b3\u7f3a\u5931\u6570\u636e\u548c\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\u7b49\u6311\u6218\u3002"}}
{"id": "2602.23949", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23949", "abs": "https://arxiv.org/abs/2602.23949", "authors": ["Guy Hadad", "Shadi Iskander", "Oren Kalinsky", "Sofia Tolmach", "Ran Levy", "Haggai Roitman"], "title": "HotelQuEST: Balancing Quality and Efficiency in Agentic Search", "comment": "To be published in EACL 2026", "summary": "Agentic search has emerged as a promising paradigm for adaptive retrieval systems powered by large language models (LLMs). However, existing benchmarks primarily focus on quality, overlooking efficiency factors that are critical for real-world deployment. Moreover, real-world user queries often contain underspecified preferences, a challenge that remains largely underexplored in current agentic search evaluation. As a result, many agentic search systems remain impractical despite their impressive performance. In this work, we introduce HotelQuEST, a benchmark comprising 214 hotel search queries that range from simple factual requests to complex queries, enabling evaluation across the full spectrum of query difficulty. We further address the challenge of evaluating underspecified user preferences by collecting clarifications that make annotators' implicit preferences explicit for evaluation. We find that LLM-based agents achieve higher accuracy than traditional retrievers, but at substantially higher costs due to redundant tool calls and suboptimal routing that fails to match query complexity to model capability. Our analysis exposes inefficiencies in current agentic search systems and demonstrates substantial potential for cost-aware optimization.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u667a\u80fd\u4f53\u641c\u7d22\u57fa\u51c6\u5ffd\u89c6\u6548\u7387\u4e0e\u672a\u660e\u786e\u504f\u597d\u7684\u95ee\u9898\uff0c\u63d0\u51faHotelQuEST\u57fa\u51c6\uff08214\u4e2a\u9152\u5e97\u67e5\u8be2\uff09\uff0c\u63ed\u793a\u5927\u6a21\u578b\u667a\u80fd\u4f53\u867d\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u56e0\u5197\u4f59\u5de5\u5177\u8c03\u7528\u548c\u6b21\u4f18\u8def\u7531\u5bfc\u81f4\u6210\u672c\u6fc0\u589e\uff0c\u6307\u51fa\u6210\u672c\u611f\u77e5\u4f18\u5316\u6f5c\u529b\u5de8\u5927\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u641c\u7d22\u57fa\u51c6\u8fc7\u5ea6\u5173\u6ce8\u8d28\u91cf\u800c\u5ffd\u7565\u5b9e\u9645\u90e8\u7f72\u5173\u952e\u7684\u6548\u7387\u56e0\u7d20\uff0c\u4e14\u5bf9\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u4e2d\u666e\u904d\u5b58\u5728\u7684\u672a\u660e\u786e\u504f\u597d\u95ee\u9898\u7f3a\u4e4f\u63a2\u7d22\uff0c\u81f4\u4f7f\u8bb8\u591a\u9ad8\u6027\u80fd\u7cfb\u7edf\u5728\u73b0\u5b9e\u4e2d\u96be\u4ee5\u5e94\u7528\u3002", "method": "\u6784\u5efaHotelQuEST\u57fa\u51c6\uff0c\u5305\u542b214\u4e2a\u4ece\u7b80\u5355\u4e8b\u5b9e\u5230\u590d\u6742\u67e5\u8be2\u7684\u9152\u5e97\u641c\u7d22\u4efb\u52a1\uff0c\u8986\u76d6\u5168\u96be\u5ea6\u8c31\u7cfb\uff1b\u901a\u8fc7\u6536\u96c6\u6f84\u6e05\u4fe1\u606f\u5c06\u6807\u6ce8\u8005\u9690\u5f0f\u504f\u597d\u663e\u5f0f\u5316\uff0c\u4ee5\u8bc4\u4f30\u667a\u80fd\u4f53\u5904\u7406\u672a\u660e\u786e\u504f\u597d\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u667a\u80fd\u4f53\u51c6\u786e\u7387\u4f18\u4e8e\u4f20\u7edf\u68c0\u7d22\u5668\uff0c\u4f46\u6210\u672c\u663e\u8457\u66f4\u9ad8\uff0c\u4e3b\u8981\u6e90\u4e8e\u5197\u4f59\u5de5\u5177\u8c03\u7528\u548c\u672a\u80fd\u6309\u67e5\u8be2\u590d\u6742\u5ea6\u5339\u914d\u6a21\u578b\u80fd\u529b\u7684\u6b21\u4f18\u8def\u7531\u7b56\u7565\u3002", "conclusion": "\u5206\u6790\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u641c\u7d22\u7cfb\u7edf\u7684\u6548\u7387\u74f6\u9888\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u6210\u672c\u611f\u77e5\u4f18\u5316\u63d0\u5347\u5b9e\u7528\u6027\u7684\u5de8\u5927\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2602.23603", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23603", "abs": "https://arxiv.org/abs/2602.23603", "authors": ["Rafid Ishrak Jahan", "Fahmid Shahriar Iqbal", "Sagnik Ray Choudhury"], "title": "LFQA-HP-1M: A Large-Scale Human Preference Dataset for Long-Form Question Answering", "comment": "LREC 2026 Accepted. https://huggingface.co/datasets/nlpatunt/LFQA-HP-1M", "summary": "Long-form question answering (LFQA) demands nuanced evaluation of multi-sentence explanatory responses, yet existing metrics often fail to reflect human judgment. We present LFQA-HP-1M, a large-scale dataset comprising 1.3M human pairwise preference annotations for LFQA. We propose nine rubrics for answer quality evaluation, and show that simple linear models based on these features perform comparably to state-of-the-art LLM evaluators. We further examine transitivity consistency, positional bias, and verbosity biases in LLM evaluators and demonstrate their vulnerability to adversarial perturbations. Overall, this work provides one of the largest public LFQA preference datasets and a rubric-driven framework for transparent and reliable evaluation.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u957f\u6587\u672c\u95ee\u7b54(LFQA)\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u5de5\u5224\u65ad\u8131\u8282\u7684\u95ee\u9898\uff0c\u63a8\u51fa\u5305\u542b130\u4e07\u6761\u4eba\u5de5\u6210\u5bf9\u504f\u597d\u6807\u6ce8\u7684\u6570\u636e\u96c6LFQA-HP-1M\u53ca\u4e5d\u4e2a\u8d28\u91cf\u8bc4\u4f30\u6807\u51c6\u3002\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u6807\u51c6\u7684\u7b80\u5355\u7ebf\u6027\u6a21\u578b\u6027\u80fd\u5ab2\u7f8e\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5668\uff0c\u540c\u65f6\u63ed\u793a\u4e86LLM\u8bc4\u4f30\u5668\u5b58\u5728\u4f20\u9012\u6027\u4e0d\u4e00\u81f4\u3001\u4f4d\u7f6e\u504f\u89c1\u3001\u5197\u957f\u504f\u89c1\u4ee5\u53ca\u5bf9\u5bf9\u6297\u6027\u6270\u52a8\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u957f\u6587\u672c\u95ee\u7b54\u9700\u8981\u7cbe\u7ec6\u8bc4\u4f30\u591a\u53e5\u5b50\u89e3\u91ca\u6027\u56de\u7b54\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\uff0c\u5f71\u54cd\u4e86\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u6784\u5efa\u5927\u89c4\u6a21\u4eba\u5de5\u6210\u5bf9\u504f\u597d\u6570\u636e\u96c6LFQA-HP-1M\uff1b\u8bbe\u8ba1\u4e5d\u4e2a\u7b54\u6848\u8d28\u91cf\u8bc4\u4f30\u7ec6\u5219\uff1b\u8bad\u7ec3\u57fa\u4e8e\u8fd9\u4e9b\u7279\u5f81\u7684\u7ebf\u6027\u6a21\u578b\u5e76\u4e0eSOTA LLM\u8bc4\u4f30\u5668\u5bf9\u6bd4\uff1b\u7cfb\u7edf\u68c0\u9a8cLLM\u8bc4\u4f30\u5668\u7684\u4f20\u9012\u6027\u4e00\u81f4\u6027\u3001\u4f4d\u7f6e\u504f\u89c1\u3001\u5197\u957f\u504f\u89c1\u53ca\u5bf9\u5bf9\u6297\u6027\u6270\u52a8\u7684\u8106\u5f31\u6027\u3002", "result": "\u57fa\u4e8e\u4e5d\u9879\u7ec6\u5219\u7684\u7ebf\u6027\u6a21\u578b\u5728\u8bc4\u4f30\u6027\u80fd\u4e0a\u4e0e\u5148\u8fdbLLM\u8bc4\u4f30\u5668\u76f8\u5f53\uff1b\u53d1\u73b0LLM\u8bc4\u4f30\u5668\u5b58\u5728\u4f20\u9012\u6027\u903b\u8f91\u4e0d\u4e00\u81f4\u3001\u663e\u8457\u7684\u4f4d\u7f6e\u504f\u89c1\u548c\u5197\u957f\u504f\u89c1\uff1b\u9a8c\u8bc1\u4e86LLM\u8bc4\u4f30\u5668\u6613\u53d7\u5bf9\u6297\u6027\u653b\u51fb\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u6700\u5927\u7684\u516c\u5f00LFQA\u504f\u597d\u6570\u636e\u96c6\u4e4b\u4e00\uff0c\u5efa\u7acb\u4e86\u900f\u660e\u53ef\u9760\u7684\u7ec6\u5219\u9a71\u52a8\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u8bc4\u4f30\u5668\u7684\u591a\u91cd\u8106\u5f31\u6027\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u5960\u5b9a\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2602.23701", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23701", "abs": "https://arxiv.org/abs/2602.23701", "authors": ["Yawen Wang", "Wenjie Wu", "Junjie Wang", "Qing Wang"], "title": "From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems", "comment": null, "summary": "LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.", "AI": {"tldr": "\u9488\u5bf9LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6545\u969c\u5f52\u56e0\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faCHIEF\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5c42\u6b21\u5316\u56e0\u679c\u56fe\u3001\u5206\u5c42\u56de\u6eaf\u548c\u56e0\u679c\u7b5b\u9009\uff0c\u6709\u6548\u8bc6\u522b\u6545\u969c\u6839\u672c\u539f\u56e0\uff0c\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u4f46\u5b58\u5728\u8106\u5f31\u6027\u548c\u4e0d\u900f\u660e\u7684\u6545\u969c\u673a\u5236\u3002\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u5c06\u6267\u884c\u65e5\u5fd7\u89c6\u4e3a\u7ebf\u6027\u5e8f\u5217\uff0c\u65e0\u6cd5\u89e3\u6790\u7cfb\u7edf\u5185\u90e8\u7684\u590d\u6742\u56e0\u679c\u5173\u7cfb\uff0c\u5bfc\u81f4\u53ef\u89c2\u6d4b\u6027\u5f31\u3001\u8d23\u4efb\u8fb9\u754c\u6a21\u7cca\u3002", "method": "CHIEF\u6846\u67b6\u5305\u542b\u4e09\u5c42\uff1a1) \u5c06\u6df7\u4e71\u8f68\u8ff9\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u5c42\u6b21\u56e0\u679c\u56fe\uff1b2) \u91c7\u7528\u5206\u5c42\u795e\u8c15\u5f15\u5bfc\u56de\u6eaf\uff0c\u901a\u8fc7\u865a\u62df\u795e\u8c15\u9ad8\u6548\u526a\u679d\u641c\u7d22\u7a7a\u95f4\uff1b3) \u901a\u8fc7\u6e10\u8fdb\u5f0f\u56e0\u679c\u7b5b\u9009\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u5f52\u56e0\uff0c\u533a\u5206\u6839\u672c\u539f\u56e0\u4e0e\u884d\u751f\u75c7\u72b6\u3002", "result": "\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cCHIEF\u5728\u667a\u80fd\u4f53\u548c\u6b65\u9aa4\u7ea7\u522b\u51c6\u786e\u7387\u4e0a\u5747\u4f18\u4e8e\u516b\u79cd\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "CHIEF\u901a\u8fc7\u5c42\u6b21\u56e0\u679c\u56fe\u5efa\u6a21\u6709\u6548\u89e3\u51b3\u4e86MAS\u6545\u969c\u5f52\u56e0\u96be\u9898\uff0c\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u53ef\u89c2\u6d4b\u6027\u548c\u660e\u786e\u7684\u8d23\u4efb\u8fb9\u754c\uff0c\u4e3a\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.23964", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23964", "abs": "https://arxiv.org/abs/2602.23964", "authors": ["Zhiguo Chen", "Guohao Sun", "Yiming Qiu", "Xingzhi Yao", "Mingming Li", "Huimu Wang", "Yangqi Zhang", "Songlin Wang", "Sulong Xu"], "title": "RAD-DPO: Robust Adaptive Denoising Direct Preference Optimization for Generative Retrieval in E-commerce", "comment": null, "summary": "Generative Retrieval (GR) has emerged as a powerful paradigm in e-commerce search, retrieving items via autoregressive decoding of Semantic IDs (SIDs). However, aligning GR with complex user preferences remains challenging. While Direct Preference Optimization (DPO) offers an efficient alignment solution, its direct application to structured SIDs suffers from three limitations: (i) it penalizes shared hierarchical prefixes, causing gradient conflicts; (ii) it is vulnerable to noisy pseudo-negatives from implicit feedback; and (iii) in multi-label queries with multiple relevant items, it exacerbates a probability \"squeezing effect\" among valid candidates. To address these issues, we propose RAD-DPO, which introduces token-level gradient detachment to protect prefix structures, similarity-based dynamic reward weighting to mitigate label noise, and a multi-label global contrastive objective integrated with global SFT loss to explicitly expand positive coverage. Extensive offline experiments and online A/B testing on a large-scale e-commerce platform demonstrate significant improvements in ranking quality and training efficiency.", "AI": {"tldr": "\u9488\u5bf9\u751f\u6210\u5f0f\u68c0\u7d22\u5728\u7535\u5546\u641c\u7d22\u4e2d\u7684\u504f\u597d\u5bf9\u9f50\u96be\u9898\uff0c\u672c\u6587\u63d0\u51faRAD-DPO\u65b9\u6cd5\uff0c\u901a\u8fc7token\u7ea7\u68af\u5ea6\u622a\u65ad\u4fdd\u62a4\u8bed\u4e49ID\u524d\u7f00\u7ed3\u6784\u3001\u52a8\u6001\u5956\u52b1\u52a0\u6743\u6291\u5236\u566a\u58f0\u4f2a\u8d1f\u6837\u672c\u3001\u4ee5\u53ca\u591a\u6807\u7b7e\u5168\u5c40\u5bf9\u6bd4\u5b66\u4e60\u7f13\u89e3\u6982\u7387\u6324\u538b\u6548\u5e94\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6392\u5e8f\u8d28\u91cf\u4e0e\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u751f\u6210\u5f0f\u68c0\u7d22\u901a\u8fc7\u81ea\u56de\u5f52\u89e3\u7801\u8bed\u4e49ID\u5df2\u6210\u4e3a\u7535\u5546\u641c\u7d22\u7684\u91cd\u8981\u8303\u5f0f\uff0c\u4f46\u96be\u4ee5\u6709\u6548\u5bf9\u9f50\u590d\u6742\u7528\u6237\u504f\u597d\u3002\u76f4\u63a5\u5e94\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u5b58\u5728\u4e09\u65b9\u9762\u5c40\u9650\uff1a\u4e00\u662f\u4f1a\u60e9\u7f5a\u5171\u4eab\u7684\u5c42\u6b21\u5316\u524d\u7f00\uff0c\u5f15\u53d1\u68af\u5ea6\u51b2\u7a81\uff1b\u4e8c\u662f\u5bf9\u9690\u5f0f\u53cd\u9988\u4e2d\u7684\u566a\u58f0\u4f2a\u8d1f\u6837\u672c\u654f\u611f\uff1b\u4e09\u662f\u5728\u591a\u6807\u7b7e\u67e5\u8be2\u573a\u666f\u4e0b\uff0c\u4f1a\u52a0\u5267\u6709\u6548\u5019\u9009\u9879\u76ee\u95f4\u7684\u6982\u7387\"\u6324\u538b\u6548\u5e94\"\u3002", "method": "\u4e3a\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u63d0\u51faRAD-DPO\u6846\u67b6\uff0c\u5305\u542b\u4e09\u9879\u5173\u952e\u6280\u672f\uff1a1) token\u7ea7\u68af\u5ea6\u5206\u79bb\u673a\u5236\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u4fdd\u62a4\u6b63\u786e\u7684\u524d\u7f00\u7ed3\u6784\uff1b2) \u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u52a8\u6001\u5956\u52b1\u52a0\u6743\u7b56\u7565\uff0c\u964d\u4f4e\u566a\u58f0\u6837\u672c\u7684\u5f71\u54cd\uff1b3) \u878d\u5408\u5168\u5c40\u76d1\u7763\u5fae\u8c03\u635f\u5931\u7684\u591a\u6807\u7b7e\u5168\u5c40\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u663e\u5f0f\u6269\u5927\u6b63\u6837\u672c\u8986\u76d6\u8303\u56f4\u3002", "result": "\u5728\u5927\u578b\u7535\u5546\u5e73\u53f0\u7684\u5e7f\u6cdb\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660e\uff0cRAD-DPO\u5728\u6392\u5e8f\u8d28\u91cf\u548c\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "RAD-DPO\u4e3a\u751f\u6210\u5f0f\u68c0\u7d22\u7684\u504f\u597d\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.23610", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23610", "abs": "https://arxiv.org/abs/2602.23610", "authors": ["Yu Zhu", "Kai Yang"], "title": "LLM-Driven Multi-Turn Task-Oriented Dialogue Synthesis for Realistic Reasoning", "comment": null, "summary": "The reasoning capability of large language models (LLMs), defined as their ability to analyze, infer, and make decisions based on input information, is essential for building intelligent task-oriented dialogue systems. However, existing benchmarks do not sufficiently reflect the complexity of real-world scenarios, which limits their effectiveness in evaluating and enhancing LLM reasoning in practical contexts. Many current reasoning datasets are overly simplistic and abstract, often disconnected from realistic task flows, domain constraints, and operational rules, making it difficult to effectively evaluate LLMs' logical reasoning ability. In addition, data contamination from pretraining corpora undermines the reliability of evaluation results, and traditional crowdsourcing methods for dataset construction are labor-intensive and difficult to scale. To address these challenges, we propose a LLM-driven framework for synthesizing multi-turn, task-oriented dialogues grounded in realistic reasoning scenarios, leveraging trilevel optimization to enhance dialogue quality. Our method generates dialogues grounded in authentic task scenarios, enriched with real-world information, and exhibiting strong contextual coherence. Corresponding reasoning tasks are carefully designed around these dialogues and iteratively refined to continuously improve the tasks' quality and challenge. The resulting dataset serves as a valuable benchmark for assessing and advancing the realistic logical reasoning capabilities of LLMs. Experimental results show that our synthetic data-based reasoning tasks introduce non-trivial reasoning challenges and provide meaningful support for improving the reasoning capabilities of LLMs.", "AI": {"tldr": "\u9488\u5bf9\u73b0\u6709LLM\u63a8\u7406\u8bc4\u6d4b\u57fa\u51c6\u8fc7\u4e8e\u7b80\u5316\u3001\u8131\u79bb\u5b9e\u9645\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdLLM\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u7ea7\u4f18\u5316\u751f\u6210\u57fa\u4e8e\u771f\u5b9e\u573a\u666f\u7684\u591a\u8f6e\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4ee5\u8bc4\u4f30\u548c\u589e\u5f3aLLM\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u7684\u6784\u5efa\u4f9d\u8d56\u4e8eLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\u5b58\u5728\u4e09\u5927\u7f3a\u9677\uff1a\u6570\u636e\u96c6\u8fc7\u4e8e\u7b80\u5355\u62bd\u8c61\uff0c\u8131\u79bb\u771f\u5b9e\u4efb\u52a1\u6d41\u7a0b\u548c\u9886\u57df\u7ea6\u675f\uff1b\u9884\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u5f71\u54cd\u8bc4\u4f30\u53ef\u9760\u6027\uff1b\u4f20\u7edf\u4f17\u5305\u6784\u5efa\u65b9\u5f0f\u52b3\u52a8\u5bc6\u96c6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\u3002\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86LLM\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8bc4\u4f30\u548c\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e09\u7ea7\u4f18\u5316\u7684LLM\u9a71\u52a8\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u624e\u6839\u4e8e\u771f\u5b9e\u63a8\u7406\u573a\u666f\u7684\u591a\u8f6e\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u3002\u751f\u6210\u7684\u5bf9\u8bdd\u5bcc\u542b\u73b0\u5b9e\u4e16\u754c\u4fe1\u606f\uff0c\u5177\u6709\u5f3a\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u3002\u56f4\u7ed5\u8fd9\u4e9b\u5bf9\u8bdd\u8bbe\u8ba1\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u6301\u7eed\u63d0\u5347\u4efb\u52a1\u8d28\u91cf\u548c\u6311\u6218\u6027\uff0c\u5f62\u6210\u9ad8\u8d28\u91cf\u7684\u8bc4\u6d4b\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u63d0\u4f9b\u4e86\u975e\u5e73\u51e1\u7684\u63a8\u7406\u6311\u6218\uff0c\u80fd\u6709\u6548\u8bc4\u4f30\u548c\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3aLLM\u5b9e\u9645\u903b\u8f91\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u548c\u589e\u5f3a\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\u4e0e\u771f\u5b9e\u573a\u666f\u8131\u8282\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u63a8\u7406\u6570\u636e\uff0c\u4e3a\u8bc4\u4f30\u548c\u589e\u5f3aLLM\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u66f4\u53ef\u9760\u7684\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.23716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23716", "abs": "https://arxiv.org/abs/2602.23716", "authors": ["Jiangyuan Wang", "Kejun Xiao", "Huaipeng Zhao", "Tao Luo", "Xiaoyi Zeng"], "title": "ProductResearch: Training E-Commerce Deep Research Agents via Multi-Agent Synthetic Trajectory Distillation", "comment": null, "summary": "Large Language Model (LLM)-based agents show promise for e-commerce conversational shopping, yet existing implementations lack the interaction depth and contextual breadth required for complex product research. Meanwhile, the Deep Research paradigm, despite advancing information synthesis in web search, suffers from domain gaps when transferred to e-commerce. We propose ProductResearch, a multi-agent framework that synthesizes high-fidelity, long-horizon tool-use trajectories for training robust e-commerce shopping agents. The framework employs a User Agent to infer nuanced shopping intents from behavioral histories, and a Supervisor Agent that orchestrates iterative collaboration with a Research Agent to generate synthetic trajectories culminating in comprehensive, insightful product research reports. These trajectories are rigorously filtered and distilled through a reflective internalization process that consolidates multi-agent supervisory interactions into coherent single-role training examples, enabling effective fine-tuning of LLM agents for complex shopping inquiries. Extensive experiments show that a compact MoE model fine-tuned on our synthetic data achieves substantial improvements over its base model in response comprehensiveness, research depth, and user-perceived utility, approaching the performance of frontier proprietary deep research systems and establishing multi-agent synthetic trajectory training as an effective and scalable paradigm for enhancing LLM-based shopping assistance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProductResearch\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u9ad8\u8d28\u91cf\u957f\u65f6\u7a0b\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\u5e76\u7ecf\u8fc7\u53cd\u601d\u5185\u5316\u8fc7\u7a0b\uff0c\u8bad\u7ec3\u7535\u5546\u8d2d\u7269\u667a\u80fd\u4f53\uff0c\u4f7f\u7d27\u51d1MoE\u6a21\u578b\u5728\u54cd\u5e94\u5168\u9762\u6027\u3001\u7814\u7a76\u6df1\u5ea6\u548c\u7528\u6237\u611f\u77e5\u6548\u7528\u65b9\u9762\u663e\u8457\u63d0\u5347\uff0c\u6027\u80fd\u63a5\u8fd1\u524d\u6cbf\u4e13\u4e1a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709LLM\u7535\u5546\u8d2d\u7269\u667a\u80fd\u4f53\u7f3a\u4e4f\u590d\u6742\u4ea7\u54c1\u7814\u7a76\u6240\u9700\u7684\u4ea4\u4e92\u6df1\u5ea6\u4e0e\u4e0a\u4e0b\u6587\u5e7f\u5ea6\uff0c\u800cDeep Research\u8303\u5f0f\u76f4\u63a5\u8fc1\u79fb\u81f3\u7535\u5546\u9886\u57df\u5b58\u5728\u9886\u57df\u9e3f\u6c9f\uff0c\u4e9f\u9700\u6784\u5efa\u66f4\u9002\u914d\u7535\u5546\u573a\u666f\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\u65b9\u6848\u3002", "method": "\u63d0\u51faProductResearch\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u7528\u6237\u667a\u80fd\u4f53\u4ece\u884c\u4e3a\u5386\u53f2\u63a8\u65ad\u7ec6\u7c92\u5ea6\u8d2d\u7269\u610f\u56fe\uff1b\u4e3b\u7ba1\u667a\u80fd\u4f53\u534f\u8c03\u7814\u7a76\u667a\u80fd\u4f53\u8fdb\u884c\u8fed\u4ee3\u534f\u4f5c\uff0c\u751f\u6210\u5408\u6210\u8f68\u8ff9\u5e76\u4ea7\u51fa\u4ea7\u54c1\u7814\u7a76\u62a5\u544a\uff1b\u901a\u8fc7\u53cd\u601d\u5185\u5316\u6d41\u7a0b\u5c06\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u63d0\u70bc\u4e3a\u8fde\u8d2f\u7684\u5355\u89d2\u8272\u8bad\u7ec3\u6837\u672c\u3002", "result": "\u57fa\u4e8e\u5408\u6210\u8f68\u8ff9\u5fae\u8c03\u7684\u7d27\u51d1MoE\u6a21\u578b\u5728\u591a\u9879\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u5176\u7efc\u5408\u6027\u80fd\u63a5\u8fd1\u524d\u6cbf\u5546\u4e1a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u5408\u6210\u8f68\u8ff9\u8bad\u7ec3\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5408\u6210\u8f68\u8ff9\u8bad\u7ec3\u8303\u5f0f\u88ab\u786e\u7acb\u4e3a\u589e\u5f3aLLM\u8d2d\u7269\u8f85\u52a9\u80fd\u529b\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u65b9\u6848\uff0c\u4e3a\u7535\u5546\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.23529", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23529", "abs": "https://arxiv.org/abs/2602.23529", "authors": ["Martin \u010cern\u00fd", "David Sychrovsk\u00fd", "Filip \u00daradn\u00edk", "Jakub \u010cern\u00fd"], "title": "Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning", "comment": null, "summary": "Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u503c\u7f3a\u5931\u7684\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u6700\u5c0f\u5316\u6700\u5c0f\u4e0e\u6700\u5927\u8865\u5168\u95f4\u7684\u8ddd\u79bb\u6765\u9ad8\u6548\u8fd1\u4f3c\u672a\u77e5\u51fd\u6570\uff0c\u63d0\u51fa\u79bb\u7ebf\u548c\u5728\u7ebf\u67e5\u8be2\u7b56\u7565\uff0c\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\u5728\u7ec4\u5408\u62cd\u5356\u3001\u7ec4\u5408\u4f18\u5316\u548c\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u4e2d\u5177\u6709\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5b8c\u6574\u6307\u5b9a\u9700\u6307\u6570\u7ea7\u5b50\u96c6\u503c\u3002\u5f53\u503c\u6765\u81ea\u5916\u90e8\u8ba1\u7b97\uff08\u5982\u673a\u5668\u5b66\u4e60\u6a21\u578b\u91cd\u8bad\u7ec3\uff09\u65f6\uff0c\u6210\u672c\u9ad8\u6602\u3002\u503c\u7f3a\u5931\u5bfc\u81f4\u4e25\u91cd\u6b67\u4e49\uff0c\u5c24\u5176\u5f53\u9700\u4f18\u5316\u4e0d\u5b8c\u6574\u51fd\u6570\u65f6\u3002\u5c3d\u7ba1\u786e\u5b9a\u6027\u503c\u67e5\u8be2\u5bf9\u4e58\u6cd5\u8bef\u5dee\u8fd1\u4f3c\u6b21\u53ef\u52a0\u51fd\u6570\u5b58\u5728\u4e0d\u53ef\u8fd1\u4f3c\u6027\u7ed3\u679c\uff0c\u4f46\u52a0\u6cd5\u8bef\u5dee\u8fd1\u4f3c\u95ee\u9898\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u4e3b\u52a8\u67e5\u8be2\u989d\u5916\u5b50\u96c6\u7684\u503c\uff0c\u9488\u5bf9\u5177\u6709\u5df2\u77e5\u5148\u9a8c\u7684\u51fd\u6570\u7c7b\u522b\uff0c\u5206\u522b\u8bbe\u8ba1\u79bb\u7ebf\u548c\u5728\u7ebf\u4e24\u79cd\u7b56\u7565\u4ee5\u6700\u5c0f\u5316\u6700\u5c0f\u4e0e\u6700\u5927\u8865\u5168\u95f4\u7684\u8ddd\u79bb\u3002", "result": "1) \u6df1\u5165\u5206\u6790\u4e86\u4e0d\u540c\u7c7b\u522b\u96c6\u51fd\u6570\u5728\u503c\u7f3a\u5931\u4e0b\u7684\u6700\u5c0f/\u6700\u5927\u8865\u5168\u53ca\u4e8c\u8005\u8ddd\u79bb\uff1b2) \u57fa\u4e8e\u5148\u9a8c\u77e5\u8bc6\u5f00\u53d1\u6700\u5c0f\u5316\u8ddd\u79bb\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u79bb\u7ebf\u548c\u5728\u7ebf\u67e5\u8be2\uff1b3) \u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5b9e\u9a8c\u9a8c\u8bc1\u7b97\u6cd5\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\u7684\u503c\u7f3a\u5931\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7406\u8bba\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u5728\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u540c\u65f6\u4fdd\u8bc1\u4e86\u8fd1\u4f3c\u8d28\u91cf\uff0c\u5728\u8ba1\u7b97\u7ecf\u6d4e\u5b66\u548cAI\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.23978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23978", "abs": "https://arxiv.org/abs/2602.23978", "authors": ["Huimu Wang", "Xingzhi Yao", "Yiming Qiu", "Qinghong Zhang", "Haotian Wang", "Yufan Cui", "Songlin Wang", "Sulong Xu", "Mingming Li"], "title": "Towards Efficient and Generalizable Retrieval: Adaptive Semantic Quantization and Residual Knowledge Transfer", "comment": null, "summary": "While semantic ID-based generative retrieval enables efficient end-to-end modeling in industrial applications, these methods face a persistent trade-off: head items are susceptible to ID collisions that negatively impact downstream tasks, whereas data-sparse tail items, including cold-start items, exhibit limited generalization. To address this issue, we propose the Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ) framework. The framework introduces Sequential Adaptive Residual Quantization (SARQ) to dynamically allocate code lengths based on item path entropy, assigning longer, discriminative IDs to head items and shorter, generalizable IDs to tail items. To mitigate data sparsity, the Anchored Curriculum Residual Quantization (ACRQ) component utilizes a frozen semantic manifold learned from head items to regularize and accelerate the representation learning of tail items. Experimental results from a large-scale industrial search system and multiple public datasets indicate that SA^2CRQ yields consistent improvements over existing baselines, particularly in cold-start retrieval scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa SA^2CRQ \u6846\u67b6\u89e3\u51b3\u8bed\u4e49 ID \u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u5934\u90e8\u9879\u76ee ID \u78b0\u649e\u4e0e\u5c3e\u90e8\u9879\u76ee\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u901a\u8fc7\u8def\u5f84\u71b5\u52a8\u6001\u5206\u914d\u7801\u957f\uff0c\u5e76\u5229\u7528\u5934\u90e8\u9879\u76ee\u5b66\u4e60\u7684\u8bed\u4e49\u6d41\u5f62\u6b63\u5219\u5316\u5c3e\u90e8\u9879\u76ee\u8868\u793a\uff0c\u5728\u5de5\u4e1a\u7ea7\u641c\u7d22\u7cfb\u7edf\u548c\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u51b7\u542f\u52a8\u68c0\u7d22\u573a\u666f\u3002", "motivation": "\u8bed\u4e49 ID \u751f\u6210\u5f0f\u68c0\u7d22\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u5b58\u5728\u56fa\u6709\u77db\u76fe\uff1a\u5934\u90e8\u9879\u76ee\u56e0\u6570\u636e\u91cf\u5927\u6613\u51fa\u73b0 ID \u78b0\u649e\uff0c\u635f\u5bb3\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff1b\u800c\u6570\u636e\u7a00\u758f\u7684\u5c3e\u90e8\u9879\u76ee\uff08\u542b\u51b7\u542f\u52a8\u9879\u76ee\uff09\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u5bfc\u81f4\u8868\u793a\u5b66\u4e60\u4e0d\u5145\u5206\uff0c\u5f71\u54cd\u6574\u4f53\u68c0\u7d22\u6548\u679c\u3002", "method": "\u63d0\u51fa SA^2CRQ \u53cc\u7ec4\u4ef6\u6846\u67b6\uff1a1) \u987a\u5e8f\u81ea\u9002\u5e94\u6b8b\u5dee\u91cf\u5316 (SARQ) \u6839\u636e\u9879\u76ee\u8def\u5f84\u71b5\u52a8\u6001\u5206\u914d\u7801\u957f\uff0c\u5934\u90e8\u9879\u76ee\u83b7\u5f97\u66f4\u957f\u5224\u522b\u6027 ID\uff0c\u5c3e\u90e8\u9879\u76ee\u83b7\u5f97\u66f4\u77ed\u6cdb\u5316\u6027 ID\uff1b2) \u951a\u5b9a\u8bfe\u7a0b\u6b8b\u5dee\u91cf\u5316 (ACRQ) \u5229\u7528\u5934\u90e8\u9879\u76ee\u9884\u8bad\u7ec3\u7684\u51bb\u7ed3\u8bed\u4e49\u6d41\u5f62\uff0c\u6b63\u5219\u5316\u5e76\u52a0\u901f\u5c3e\u90e8\u9879\u76ee\u7684\u8868\u793a\u5b66\u4e60\uff0c\u7f13\u89e3\u6570\u636e\u7a00\u758f\u6027\u3002", "result": "\u5728\u5927\u578b\u5de5\u4e1a\u641c\u7d22\u7cfb\u7edf\u548c\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSA^2CRQ \u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e00\u81f4\u6027\u80fd\u63d0\u5347\uff0c\u5c24\u5176\u5728\u51b7\u542f\u52a8\u68c0\u7d22\u573a\u666f\u4e0b\u6539\u5584\u663e\u8457\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "SA^2CRQ \u901a\u8fc7\u7ed3\u5408\u81ea\u9002\u5e94\u91cf\u5316\u4e0e\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u6709\u6548\u5e73\u8861\u4e86\u5934\u90e8\u9879\u76ee\u5224\u522b\u6027\u4e0e\u5c3e\u90e8\u9879\u76ee\u6cdb\u5316\u6027\u7684\u77db\u76fe\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u51b7\u542f\u52a8\u95ee\u9898\u5177\u6709\u91cd\u8981\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2602.23656", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23656", "abs": "https://arxiv.org/abs/2602.23656", "authors": ["Zitong Xu", "Yuqing Wu", "Yue Zhao"], "title": "TRIZ-RAGNER: A Retrieval-Augmented Large Language Model for TRIZ-Aware Named Entity Recognition in Patent-Based Contradiction Mining", "comment": null, "summary": "TRIZ-based contradiction mining is a fundamental task in patent analysis and systematic innovation, as it enables the identification of improving and worsening technical parameters that drive inventive problem solving. However, existing approaches largely rely on rule-based systems or traditional machine learning models, which struggle with semantic ambiguity, domain dependency, and limited generalization when processing complex patent language. Recently, large language models (LLMs) have shown strong semantic understanding capabilities, yet their direct application to TRIZ parameter extraction remains challenging due to hallucination and insufficient grounding in structured TRIZ knowledge. To address these limitations, this paper proposes TRIZ-RAGNER, a retrieval-augmented large language model framework for TRIZ-aware named entity recognition in patent-based contradiction mining. TRIZ-RAGNER reformulates contradiction mining as a semantic-level NER task and integrates dense retrieval over a TRIZ knowledge base, cross-encoder reranking for context refinement, and structured LLM prompting to extract improving and worsening parameters from patent sentences. By injecting domain-specific TRIZ knowledge into the LLM reasoning process, the proposed framework effectively reduces semantic noise and improves extraction consistency. Experiments on the PaTRIZ dataset demonstrate that TRIZ-RAGNER consistently outperforms traditional sequence labeling models and LLM-based baselines. The proposed framework achieves a precision of 85.6%, a recall of 82.9%, and an F1-score of 84.2% in TRIZ contradiction pair identification. Compared with the strongest baseline using prompt-enhanced GPT, TRIZ-RAGNER yields an absolute F1-score improvement of 7.3 percentage points, confirming the effectiveness of retrieval-augmented TRIZ knowledge grounding for robust and accurate patent-based contradiction mining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTRIZ-RAGNER\uff0c\u4e00\u79cd\u68c0\u7d22\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u4e13\u5229\u6587\u672c\u4e2d\u7684TRIZ\u77db\u76fe\u53c2\u6570\u6316\u6398\u3002\u8be5\u6846\u67b6\u901a\u8fc7TRIZ\u77e5\u8bc6\u5e93\u7a20\u5bc6\u68c0\u7d22\u3001\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u548c\u7ed3\u6784\u5316LLM\u63d0\u793a\uff0c\u5c06\u77db\u76fe\u8bc6\u522b\u8f6c\u5316\u4e3a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\uff0c\u6709\u6548\u7f13\u89e3\u8bed\u4e49\u6b67\u4e49\u4e0eLLM\u5e7b\u89c9\u95ee\u9898\uff0c\u5728PaTRIZ\u6570\u636e\u96c6\u4e0a\u8fbe\u523084.2%\u7684F1\u503c\uff0c\u8f83\u6700\u5f3a\u57fa\u7ebf\u63d0\u53477.3\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709TRIZ\u77db\u76fe\u6316\u6398\u65b9\u6cd5\u4f9d\u8d56\u89c4\u5219\u7cfb\u7edf\u6216\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff0c\u9762\u4e34\u8bed\u4e49\u6b67\u4e49\u3001\u9886\u57df\u4f9d\u8d56\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7b49\u74f6\u9888\u3002\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5177\u5f3a\u5927\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u5b58\u5728\u5e7b\u89c9\u548cTRIZ\u77e5\u8bc6\u7ed3\u6784\u5316\u4e0d\u8db3\u7684\u7f3a\u9677\uff0c\u4e9f\u9700\u878d\u5408\u9886\u57df\u77e5\u8bc6\u4e0eLLM\u63a8\u7406\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faTRIZ-RAGNER\u6846\u67b6\uff0c\u5c06\u77db\u76fe\u6316\u6398\u91cd\u6784\u4e3a\u8bed\u4e49\u7ea7\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u3002\u6838\u5fc3\u8bbe\u8ba1\u5305\u62ec\uff1a1)\u57fa\u4e8eTRIZ\u77e5\u8bc6\u5e93\u7684\u7a20\u5bc6\u68c0\u7d22\u83b7\u53d6\u76f8\u5173\u53c2\u6570\uff1b2)\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u7cbe\u70bc\u4e0a\u4e0b\u6587\uff1b3)\u7ed3\u6784\u5316\u63d0\u793a\u5f15\u5bfcLLM\u62bd\u53d6\u6539\u5584\u4e0e\u6076\u5316\u53c2\u6570\u3002\u901a\u8fc7\u6ce8\u5165\u9886\u57df\u7279\u5b9a\u7684TRIZ\u77e5\u8bc6\uff0c\u6291\u5236\u8bed\u4e49\u566a\u58f0\u5e76\u63d0\u5347\u63d0\u53d6\u4e00\u81f4\u6027\u3002", "result": "\u5728PaTRIZ\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728TRIZ\u77db\u76fe\u5bf9\u8bc6\u522b\u4e2d\u5b9e\u73b085.6%\u7cbe\u786e\u7387\u300182.9%\u53ec\u56de\u7387\u548c84.2% F1\u503c\u3002\u76f8\u6bd4\u57fa\u4e8e\u63d0\u793a\u589e\u5f3a\u7684GPT\u6700\u5f3a\u57fa\u7ebf\uff0cF1\u503c\u7edd\u5bf9\u63d0\u53477.3\u4e2a\u767e\u5206\u70b9\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\u4e0eLLM\u57fa\u7ebf\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u7684TRIZ\u77e5\u8bc6\u6ce8\u5165\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u4e13\u5229\u77db\u76fe\u6316\u6398\u7684\u9c81\u68d2\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u9a8c\u8bc1\u4e86\u5916\u90e8\u77e5\u8bc6\u5e93\u4e0eLLM\u63a8\u7406\u7ed3\u5408\u5728\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u63d0\u53d6\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7cfb\u7edf\u5316\u521b\u65b0\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.23720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23720", "abs": "https://arxiv.org/abs/2602.23720", "authors": ["Sheng Cao", "Zhao Chang", "Chang Li", "Hannan Li", "Liyao Fu", "Ji Tang"], "title": "The Auton Agentic AI Framework", "comment": null, "summary": "The field of Artificial Intelligence is undergoing a transition from Generative AI -- probabilistic generation of text and images -- to Agentic AI, in which autonomous systems execute actions within external environments on behalf of users. This transition exposes a fundamental architectural mismatch: Large Language Models (LLMs) produce stochastic, unstructured outputs, whereas the backend infrastructure they must control -- databases, APIs, cloud services -- requires deterministic, schema-conformant inputs. The present paper describes the Auton Agentic AI Framework, a principled architecture for standardizing the creation, execution, and governance of autonomous agent systems. The framework is organized around a strict separation between the Cognitive Blueprint, a declarative, language-agnostic specification of agent identity and capabilities, and the Runtime Engine, the platform-specific execution substrate that instantiates and runs the agent. This separation enables cross-language portability, formal auditability, and modular tool integration via the Model Context Protocol (MCP). The paper formalizes the agent execution model as an augmented Partially Observable Markov Decision Process (POMDP) with a latent reasoning space, introduces a hierarchical memory consolidation architecture inspired by biological episodic memory systems, defines a constraint manifold formalism for safety enforcement via policy projection rather than post-hoc filtering, presents a three-level self-evolution framework spanning in-context adaptation through reinforcement learning, and describes runtime optimizations -- including parallel graph execution, speculative inference, and dynamic context pruning -- that reduce end-to-end latency for multi-step agent workflows.", "AI": {"tldr": "\u9488\u5bf9\u751f\u6210\u5f0fAI\u5411\u667a\u80fd\u4f53AI\u8f6c\u578b\u4e2dLLM\u968f\u673a\u8f93\u51fa\u4e0e\u540e\u7aef\u786e\u5b9a\u6027\u9700\u6c42\u95f4\u7684\u67b6\u6784\u5931\u914d\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faAuton\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u77e5\u84dd\u56fe\u4e0e\u8fd0\u884c\u65f6\u5f15\u64ce\u7684\u4e25\u683c\u5206\u79bb\uff0c\u7ed3\u5408\u589e\u5f3aPOMDP\u6a21\u578b\u3001\u5206\u5c42\u8bb0\u5fc6\u3001\u7ea6\u675f\u6d41\u5f62\u5b89\u5168\u673a\u5236\u3001\u4e09\u7ea7\u81ea\u6211\u6f14\u5316\u53ca\u5e76\u884c\u56fe\u6267\u884c\u7b49\u4f18\u5316\u6280\u672f\uff0c\u5b9e\u73b0\u53ef\u79fb\u690d\u3001\u53ef\u5ba1\u8ba1\u3001\u5b89\u5168\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u6b63\u7ecf\u5386\u4ece\u751f\u6210\u5f0fAI\uff08\u6982\u7387\u6027\u751f\u6210\u6587\u672c\u548c\u56fe\u50cf\uff09\u5230\u667a\u80fd\u4f53AI\uff08\u4ee3\u8868\u7528\u6237\u5728\u5916\u90e8\u73af\u5883\u4e2d\u6267\u884c\u52a8\u4f5c\u7684\u81ea\u4e3b\u7cfb\u7edf\uff09\u7684\u8f6c\u578b\u3002\u8fd9\u4e00\u8f6c\u578b\u66b4\u9732\u4e86\u4e00\u4e2a\u6839\u672c\u6027\u7684\u67b6\u6784\u5931\u914d\u95ee\u9898\uff1a\u5927\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u968f\u673a\u3001\u975e\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u800c\u5b83\u4eec\u5fc5\u987b\u63a7\u5236\u7684\u5e95\u5c42\u57fa\u7840\u8bbe\u65bd\uff08\u6570\u636e\u5e93\u3001API\u3001\u4e91\u670d\u52a1\uff09\u5219\u9700\u8981\u786e\u5b9a\u6027\u3001\u7b26\u5408\u6a21\u5f0f\u89c4\u8303\u7684\u8f93\u5165\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u8fd9\u79cd\u7ed3\u6784\u6027\u77db\u76fe\uff0c\u5bfc\u81f4\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u96be\u4ee5\u5ba1\u8ba1\u4e14\u5b58\u5728\u5b89\u5168\u9690\u60a3\u3002", "method": "\u672c\u6587\u63d0\u51faAuton\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u91c7\u7528\u8ba4\u77e5\u84dd\u56fe\uff08\u58f0\u660e\u5f0f\u3001\u8bed\u8a00\u65e0\u5173\u7684\u667a\u80fd\u4f53\u8eab\u4efd\u548c\u80fd\u529b\u89c4\u8303\uff09\u4e0e\u8fd0\u884c\u65f6\u5f15\u64ce\uff08\u5e73\u53f0\u7279\u5b9a\u7684\u6267\u884c\u57fa\u8d28\uff09\u7684\u4e25\u683c\u5206\u79bb\u67b6\u6784\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u5b9e\u73b0\u8de8\u8bed\u8a00\u53ef\u79fb\u690d\u6027\u548c\u6a21\u5757\u5316\u5de5\u5177\u96c6\u6210\uff1b2\uff09\u5c06\u667a\u80fd\u4f53\u6267\u884c\u5f62\u5f0f\u5316\u4e3a\u5e26\u6f5c\u5728\u63a8\u7406\u7a7a\u95f4\u7684\u589e\u5f3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\uff1b3\uff09\u8bbe\u8ba1\u53d7\u751f\u7269\u60c5\u666f\u8bb0\u5fc6\u542f\u53d1\u7684\u5206\u5c42\u8bb0\u5fc6\u6574\u5408\u67b6\u6784\uff1b4\uff09\u63d0\u51fa\u7ea6\u675f\u6d41\u5f62\u5f62\u5f0f\u4e3b\u4e49\uff0c\u901a\u8fc7\u7b56\u7565\u6295\u5f71\u800c\u975e\u4e8b\u540e\u8fc7\u6ee4\u5b9e\u73b0\u5b89\u5168\u5f3a\u5316\uff1b5\uff09\u5efa\u7acb\u6db5\u76d6\u4e0a\u4e0b\u6587\u9002\u5e94\u5230\u5f3a\u5316\u5b66\u4e60\u7684\u4e09\u7ea7\u81ea\u6211\u6f14\u5316\u6846\u67b6\uff1b6\uff09\u5b9e\u65bd\u5e76\u884c\u56fe\u6267\u884c\u3001\u63a8\u6d4b\u63a8\u7406\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u526a\u679d\u7b49\u8fd0\u884c\u65f6\u4f18\u5316\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u521b\u5efa\u3001\u6267\u884c\u548c\u6cbb\u7406\u67b6\u6784\u3002\u5f62\u5f0f\u5316\u6a21\u578b\u4e3a\u667a\u80fd\u4f53\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff1b\u5206\u5c42\u8bb0\u5fc6\u7cfb\u7edf\u652f\u6301\u957f\u671f\u5b66\u4e60\u548c\u7ecf\u9a8c\u590d\u7528\uff1b\u7ea6\u675f\u6d41\u5f62\u673a\u5236\u5b9e\u73b0\u4e86\u5185\u7f6e\u5b89\u5168\u6027\u800c\u975e\u5916\u90e8\u8fc7\u6ee4\uff1b\u4e09\u7ea7\u6f14\u5316\u6846\u67b6\u652f\u6301\u667a\u80fd\u4f53\u6301\u7eed\u6539\u8fdb\uff1b\u8fd0\u884c\u65f6\u4f18\u5316\u663e\u8457\u964d\u4f4e\u4e86\u591a\u6b65\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u8be5\u67b6\u6784\u80fd\u6709\u6548\u5f25\u5408LLM\u4e0e\u540e\u7aef\u7cfb\u7edf\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u3002", "conclusion": "Auton\u6846\u67b6\u901a\u8fc7\u8ba4\u77e5\u84dd\u56fe\u4e0e\u8fd0\u884c\u65f6\u5f15\u64ce\u7684\u89e3\u8026\uff0c\u7cfb\u7edf\u6027\u89e3\u51b3\u4e86\u751f\u6210\u5f0fAI\u5411\u667a\u80fd\u4f53AI\u8f6c\u578b\u4e2d\u7684\u67b6\u6784\u5931\u914d\u6311\u6218\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u8de8\u8bed\u8a00\u53ef\u79fb\u690d\u6027\u548c\u5f62\u5f0f\u5316\u53ef\u5ba1\u8ba1\u6027\uff0c\u8fd8\u901a\u8fc7\u7ea6\u675f\u6d41\u5f62\u548c\u81ea\u6211\u6f14\u5316\u673a\u5236\u786e\u4fdd\u4e86\u5b89\u5168\u6027\u4e0e\u9002\u5e94\u6027\uff0c\u4e3a\u6784\u5efa\u6807\u51c6\u5316\u3001\u53ef\u4fe1\u8d56\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u63a8\u52a8\u667a\u80fd\u4f53AI\u7684\u5de5\u4e1a\u5316\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.23982", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23982", "abs": "https://arxiv.org/abs/2602.23982", "authors": ["Minh Hieu Nguyen"], "title": "Robust Aggregation for Federated Sequential Recommendation with Sparse and Poisoned Data", "comment": null, "summary": "Federated sequential recommendation distributes model training across user devices so that behavioural data remains local, reducing privacy risks. Yet, this setting introduces two intertwined difficulties. On the one hand, individual clients typically contribute only short and highly sparse interaction sequences, limiting the reliability of learned user representations. On the other hand, the federated optimisation process is vulnerable to malicious or corrupted client updates, where poisoned gradients can significantly distort the global model. These challenges are particularly severe in sequential recommendation, where temporal dynamics further complicate signal aggregation. To address this problem, we propose a robust aggregation framework tailored for federated sequential recommendation under sparse and adversarial conditions. Instead of relying on standard averaging, our method introduces a defence-aware aggregation mechanism that identifies and down-weights unreliable client updates while preserving informative signals from sparse but benign participants. The framework incorporates representation-level constraints to stabilise user and item embeddings, preventing poisoned or anomalous contributions from dominating the global parameter space. In addition, we integrate sequence-aware regularisation to maintain temporal coherence in user modelling despite limited local observations.", "AI": {"tldr": "\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u805a\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u9632\u5fa1\u611f\u77e5\u805a\u5408\u673a\u5236\u3001\u8868\u793a\u5c42\u7ea6\u675f\u548c\u5e8f\u5217\u611f\u77e5\u6b63\u5219\u5316\uff0c\u540c\u65f6\u89e3\u51b3\u6570\u636e\u7a00\u758f\u6027\u548c\u5bf9\u6297\u6027\u653b\u51fb\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u867d\u80fd\u901a\u8fc7\u5206\u5e03\u5f0f\u8bad\u7ec3\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u4f46\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u4e00\u662f\u5ba2\u6237\u7aef\u4ea4\u4e92\u5e8f\u5217\u77ed\u4e14\u9ad8\u5ea6\u7a00\u758f\uff0c\u5bfc\u81f4\u7528\u6237\u8868\u793a\u5b66\u4e60\u4e0d\u53ef\u9760\uff1b\u4e8c\u662f\u8054\u90a6\u4f18\u5316\u8fc7\u7a0b\u6613\u53d7\u6076\u610f\u6216\u635f\u574f\u7684\u5ba2\u6237\u7aef\u66f4\u65b0\u5f71\u54cd\uff0c\u4e2d\u6bd2\u68af\u5ea6\u4f1a\u4e25\u91cd\u626d\u66f2\u5168\u5c40\u6a21\u578b\uff0c\u4e14\u65f6\u5e8f\u52a8\u6001\u6027\u4f7f\u4fe1\u53f7\u805a\u5408\u66f4\u52a0\u590d\u6742\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u805a\u5408\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1\uff09\u9632\u5fa1\u611f\u77e5\u805a\u5408\u673a\u5236\uff0c\u8bc6\u522b\u5e76\u964d\u4f4e\u4e0d\u53ef\u9760\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u6743\u91cd\uff0c\u540c\u65f6\u4fdd\u7559\u7a00\u758f\u4f46\u826f\u6027\u53c2\u4e0e\u8005\u7684\u4fe1\u606f\uff1b2\uff09\u8868\u793a\u5c42\u7ea6\u675f\uff0c\u7a33\u5b9a\u7528\u6237\u548c\u7269\u54c1\u5d4c\u5165\uff0c\u9632\u6b62\u4e2d\u6bd2\u8d21\u732e\u4e3b\u5bfc\u5168\u5c40\u53c2\u6570\u7a7a\u95f4\uff1b3\uff09\u5e8f\u5217\u611f\u77e5\u6b63\u5219\u5316\uff0c\u5728\u6709\u9650\u672c\u5730\u89c2\u6d4b\u4e0b\u4fdd\u6301\u7528\u6237\u5efa\u6a21\u7684\u65f6\u5e8f\u4e00\u81f4\u6027\u3002", "result": "\u6458\u8981\u672a\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u8be5\u6846\u67b6\u65e8\u5728\u63d0\u5347\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u5728\u7a00\u758f\u548c\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u9762\u7684\u9c81\u68d2\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u6784\u5efa\u66f4\u53ef\u9760\u3001\u66f4\u9690\u79c1\u4fdd\u62a4\u7684\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u3002"}}
{"id": "2602.23729", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23729", "abs": "https://arxiv.org/abs/2602.23729", "authors": ["Seungdong Yoa", "Sanghyu Yoon", "Suhee Yoon", "Dongmin Kim", "Ye Seul Sim", "Junhyun Lee", "Woohyung Lim"], "title": "From Static Benchmarks to Dynamic Protocol: Agent-Centric Text Anomaly Detection for Evaluating LLM Reasoning", "comment": "Accepted to ICLR 2026", "summary": "The evaluation of large language models (LLMs) has predominantly relied on static datasets, which offer limited scalability and fail to capture the evolving reasoning capabilities of recent models. To overcome these limitations, we propose an agent-centric benchmarking paradigm that moves beyond static datasets by introducing a dynamic protocol in which autonomous agents iteratively generate, validate, and solve problems. Within this protocol, a teacher agent generates candidate problems, an orchestrator agent rigorously verifies their validity and guards against adversarial attacks, and a student agent attempts to solve the validated problems. An invalid problem is revised by the teacher agent until it passes validation. If the student correctly solves the problem, the orchestrator prompts the teacher to generate more challenging variants. Consequently, the benchmark scales in difficulty automatically as more capable agents are substituted into any role, enabling progressive evaluation of large language models without manually curated datasets. Adopting text anomaly detection as our primary evaluation format, which demands cross-sentence logical inference and resists pattern-matching shortcuts, we demonstrate that this protocol systematically exposes corner-case reasoning errors that conventional benchmarks fail to reveal. We further advocate evaluating systems along several complementary axes including cross-model pairwise performance and progress between the initial and orchestrator-finalized problems. By shifting the focus from fixed datasets to dynamic protocols, our approach offers a sustainable direction for evaluating ever-evolving language models and introduces a research agenda centered on the co-evolution of agent-centric benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u52a8\u6001\u8bc4\u6d4b\u8303\u5f0f\uff0c\u901a\u8fc7\u6559\u5e08\u3001\u7f16\u6392\u8005\u548c\u5b66\u751f\u4e09\u4e2a\u667a\u80fd\u4f53\u534f\u540c\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u89e3\u51b3\u95ee\u9898\uff0c\u5b9e\u73b0\u81ea\u52a8\u6269\u5c55\u96be\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u65b9\u6cd5\u4ee5\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u4e3a\u4e3b\u8981\u8bc4\u4f30\u5f62\u5f0f\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u66b4\u9732\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u53d1\u73b0\u7684\u63a8\u7406\u9519\u8bef\uff0c\u4e3a\u8bc4\u4f30\u6301\u7eed\u6f14\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6301\u7eed\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u6269\u5c55\u6027\u6709\u9650\u4e14\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u4e0d\u65ad\u6f14\u8fdb\u7684\u63a8\u7406\u80fd\u529b\u3002\u9759\u6001\u6570\u636e\u96c6\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684\u5927\u6a21\u578b\u6280\u672f\uff0c\u5bb9\u6613\u8fc7\u65f6\u5e76\u4ea7\u751f\u8bc4\u4f30\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e09\u667a\u80fd\u4f53\u534f\u540c\u7684\u52a8\u6001\u8bc4\u6d4b\u534f\u8bae\uff1a\u6559\u5e08\u667a\u80fd\u4f53\u751f\u6210\u5019\u9009\u95ee\u9898\uff0c\u7f16\u6392\u8005\u667a\u80fd\u4f53\u4e25\u683c\u9a8c\u8bc1\u95ee\u9898\u6709\u6548\u6027\u5e76\u9632\u5fa1\u5bf9\u6297\u653b\u51fb\uff0c\u5b66\u751f\u667a\u80fd\u4f53\u5c1d\u8bd5\u89e3\u51b3\u9a8c\u8bc1\u540e\u7684\u95ee\u9898\u3002\u65e0\u6548\u95ee\u9898\u7531\u6559\u5e08\u667a\u80fd\u4f53\u4fee\u8ba2\u76f4\u81f3\u901a\u8fc7\u9a8c\u8bc1\uff1b\u5f53\u5b66\u751f\u6b63\u786e\u89e3\u9898\u540e\uff0c\u7f16\u6392\u8005\u4f1a\u4fc3\u4f7f\u6559\u5e08\u751f\u6210\u66f4\u5177\u6311\u6218\u6027\u7684\u53d8\u4f53\u3002\u8be5\u534f\u8bae\u4f7f\u8bc4\u6d4b\u96be\u5ea6\u968f\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u5347\u81ea\u52a8\u6269\u5c55\u3002", "result": "\u91c7\u7528\u9700\u8981\u8de8\u53e5\u903b\u8f91\u63a8\u7406\u4e14\u80fd\u62b5\u6297\u6a21\u5f0f\u5339\u914d\u6377\u5f84\u7684\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u4f5c\u4e3a\u4e3b\u8981\u8bc4\u4f30\u5f62\u5f0f\uff0c\u8bc1\u660e\u8be5\u534f\u8bae\u80fd\u7cfb\u7edf\u6027\u5730\u66b4\u9732\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u63ed\u793a\u7684\u8fb9\u754c\u60c5\u51b5\u63a8\u7406\u9519\u8bef\u3002\u540c\u65f6\u63d0\u5021\u6cbf\u591a\u4e2a\u4e92\u8865\u7ef4\u5ea6\u8bc4\u4f30\u7cfb\u7edf\uff0c\u5305\u62ec\u8de8\u6a21\u578b\u6210\u5bf9\u6027\u80fd\u548c\u521d\u59cb\u95ee\u9898\u4e0e\u7f16\u6392\u8005\u6700\u7ec8\u786e\u5b9a\u95ee\u9898\u4e4b\u95f4\u7684\u8fdb\u6b65\u7a0b\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8bc4\u4f30\u7126\u70b9\u4ece\u56fa\u5b9a\u6570\u636e\u96c6\u8f6c\u5411\u52a8\u6001\u534f\u8bae\uff0c\u8be5\u7814\u7a76\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u6f14\u8fdb\u63d0\u4f9b\u4e86\u53ef\u6301\u7eed\u7684\u8bc4\u4f30\u65b9\u5411\uff0c\u5e76\u63d0\u51fa\u4e86\u4ee5\u667a\u80fd\u4f53\u4e3a\u4e2d\u5fc3\u7684\u57fa\u51c6\u6d4b\u8bd5\u534f\u540c\u6f14\u5316\u7684\u7814\u7a76\u8bae\u7a0b\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u8bc4\u4f30\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2602.23730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23730", "abs": "https://arxiv.org/abs/2602.23730", "authors": ["Longyin Zhang", "Shuo Sun", "Yingxu He", "Won Cheng Yi Lewis", "Muhammad Huzaifah Bin Md Shahrin", "Hardik Bhupendra Sailor", "Heng Meng Jeremy Wong", "Tarun Kumar Vangani", "Yi Ma", "Qiongqiong Wang", "Minh Duc Pham", "Ridong Jiang", "Jingtao Li", "Jingyi Liao", "Zhuohan Liu", "Yanfeng Lu", "Manas Gupta", "Ai Ti Aw"], "title": "Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off", "comment": null, "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates \"System 1\" (Perception) and \"System 2\" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.\n  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdMERaLiON2-Omni (Alpha)\uff0c\u4e00\u4e2a100\u4ebf\u53c2\u6570\u7684\u591a\u8bed\u8a00\u5168\u611f\u77e5\u591a\u6a21\u6001\u5927\u6a21\u578b\uff0c\u4e13\u4e3a\u4e1c\u5357\u4e9a\u5730\u533a\u8bbe\u8ba1\u3002\u7814\u7a76\u63d0\u51fa\u89e3\u8026\u518d\u878d\u5408\u611f\u77e5\u4e0e\u63a8\u7406\u7684\u6e10\u8fdb\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u6b63\u4ea4\u6a21\u6001\u9002\u914d\u6784\u5efa\u533a\u57df\u611f\u77e5\u4e3b\u5e72\uff0c\u5e76\u5229\u7528\u751f\u6210-\u8bc4\u5224-\u7cbe\u70bc\u7ba1\u9053\u5408\u6210\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u63a8\u7406\u6570\u636e\u3002\u5728SEA-Omni\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63ed\u793a\u4e86\u6548\u7387-\u7a33\u5b9a\u6027\u6096\u8bba\uff1a\u63a8\u7406\u80fd\u529b\u867d\u975e\u7ebf\u6027\u63d0\u5347\u62bd\u8c61\u4efb\u52a1\u8868\u73b0\uff0c\u5374\u5f15\u53d1\u65f6\u5e8f\u6f02\u79fb\u548c\u89c6\u89c9\u8fc7\u5ea6\u89e3\u8bfb\u7b49\u611f\u77e5\u4e0d\u7a33\u5b9a\u73b0\u8c61\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u8ffd\u6c42\u5168\u611f\u77e5\u80fd\u529b\uff0c\u4f46\u5c06\u7a33\u5065\u7684\u611f\u5b98grounding\u4e0e\u590d\u6742\u63a8\u7406\u6709\u6548\u878d\u5408\u4ecd\u662f\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u5bf9\u4e1c\u5357\u4e9a\u7b49\u6570\u636e\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u533a\u57df\u3002\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u5904\u7406\u533a\u57df\u7279\u5b9a\u6587\u5316\u8bed\u5883\uff08\u5982\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u6df7\u7801\u3001\u672c\u5730\u6587\u5316\u5730\u6807\uff09\uff0c\u4e9f\u9700\u5f00\u53d1\u5177\u5907\u533a\u57df\u9002\u5e94\u6027\u7684\u611f\u77e5-\u63a8\u7406\u534f\u540c\u67b6\u6784\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6e10\u8fdb\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u89e3\u8026\u7cfb\u7edf1\uff08\u611f\u77e5\uff09\u4e0e\u7cfb\u7edf2\uff08\u63a8\u7406\uff09\uff0c\u901a\u8fc7\u6b63\u4ea4\u6a21\u6001\u9002\u914d\u6280\u672f\u5c06\u4e1c\u5357\u4e9a\u7279\u8272\u89c6\u542c\u7ebf\u7d22\u4e0e\u591a\u8bed\u8a00LLM\u5bf9\u9f50\uff0c\u6784\u5efa\u7a33\u5065\u611f\u77e5\u4e3b\u5e72\uff1b\u7b2c\u4e8c\u9636\u6bb5\u878d\u5408\u9636\u6bb5\u91c7\u7528\u751f\u6210-\u8bc4\u5224-\u7cbe\u70bc\u6846\u67b6\uff0c\u5229\u7528\u8d85\u7ea7\u5927\u6a21\u578b\u8fc7\u6ee4\u5e7b\u89c9\u5e76\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u5408\u6210\u94f6\u6807\u6570\u636e\uff0c\u5b9e\u73b0\u6587\u672c\u94fe\u5f0f\u63a8\u7406\u5411\u591a\u6a21\u6001\u573a\u666f\u8fc1\u79fb\u3002", "result": "\u5728SEA-Omni\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d1\u73b0\u6548\u7387-\u7a33\u5b9a\u6027\u6096\u8bba\uff1a\u63a8\u7406\u4f5c\u4e3a\u975e\u7ebf\u6027\u653e\u5927\u5668\u663e\u8457\u63d0\u5347\u6570\u5b66\u4e0e\u6307\u4ee4\u9075\u5faa\u7b49\u62bd\u8c61\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u540c\u6b65\u5f15\u5165\u4f4e\u5c42\u6b21\u611f\u77e5\u4e0d\u7a33\u5b9a\u6027\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\u957f\u65f6\u97f3\u9891\u7684\u65f6\u5e8f\u6f02\u79fb\uff08\u63a8\u7406\u5bfc\u81f4\u58f0\u5b66\u65f6\u95f4\u6233\u5931\u540c\u6b65\uff09\u548c\u89c6\u89c9\u8fc7\u5ea6\u89e3\u8bfb\uff08\u903b\u8f91\u8986\u76d6\u50cf\u7d20\u7ea7\u73b0\u5b9e\uff09\u4e24\u5927\u73b0\u8c61\u3002", "conclusion": "\u672c\u7814\u7a76\u62a5\u544a\u4e86MERaLiON2-Omni\u7684\u67b6\u6784\u8bbe\u8ba1\u4e0e\u6570\u636e\u9ad8\u6548\u8bad\u7ec3\u65b9\u6848\uff0c\u901a\u8fc7\u8bca\u65ad\u5206\u6790\u63ed\u793a\u4e86\u611f\u77e5\u7a33\u5065\u6027\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u95f4\u7684\u5185\u5728\u6743\u8861\u3002\u53d1\u73b0\u8868\u660e\uff0c\u611f\u77e5\u4e0e\u63a8\u7406\u80fd\u529b\u7684\u878d\u5408\u5b58\u5728\u6839\u672c\u6027\u77db\u76fe\uff0c\u4e3a\u672a\u6765\u591a\u6a21\u6001\u6a21\u578b\u5728\u8ffd\u6c42\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u4fdd\u6301\u611f\u77e5\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u5173\u952e\u6d1e\u89c1\u3002"}}
{"id": "2602.23565", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.23565", "abs": "https://arxiv.org/abs/2602.23565", "authors": ["Adhyyan Narang", "Sarah Dean", "Lillian J Ratliff", "Maryam Fazel"], "title": "Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing", "comment": null, "summary": "In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the \"local\" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to \"probe\" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u591a\u5e73\u53f0\u673a\u5668\u5b66\u4e60\u4e2d\u7684\"\u8fc7\u4e13\u95e8\u5316\u9677\u9631\"\u73b0\u8c61\uff0c\u5373\u5b66\u4e60\u8005\u901a\u8fc7\u53cd\u9988\u673a\u5236\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u4efb\u610f\u5dee\u7684\u5168\u5c40\u6027\u80fd\u6a21\u578b\u3002\u53d7\u77e5\u8bc6\u84b8\u998f\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u63a2\u6d4b\u7b97\u6cd5\uff0c\u4f7f\u5b66\u4e60\u8005\u80fd\u591f\u901a\u8fc7\u63a2\u6d4b\u540c\u884c\u6a21\u578b\u9884\u6d4b\u6765\u5b66\u4e60\u975e\u81ea\u8eab\u7528\u6237\u3002\u7406\u8bba\u8bc1\u660e\u5728\u63a2\u6d4b\u6e90\u4fe1\u606f\u5145\u5206\uff08\u5982\u5e02\u573a\u9886\u5bfc\u8005\u6216\u591a\u6570\u826f\u597d\u540c\u884c\uff09\u65f6\uff0c\u7b97\u6cd5\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u6709\u754c\u5168\u5c40\u98ce\u9669\u7684\u5e73\u7a33\u70b9\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u7684\u534a\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5728\u7ecf\u6d4e\u76f8\u5173\u7684\u673a\u5668\u5b66\u4e60\u90e8\u7f72\u573a\u666f\u4e2d\uff0c\u591a\u4e2a\u5e73\u53f0\u5171\u4eab\u540c\u4e00\u7528\u6237\u6c60\uff0c\u7528\u6237\u81ea\u4e3b\u9009\u62e9\u504f\u597d\u5e73\u53f0\u3002\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u5b66\u4e60\u8005\u89c2\u5bdf\u6570\u636e\u5206\u5e03\u4e0a\u7684\u5c40\u90e8\u635f\u5931\u3002\u7136\u800c\uff0c\u5b58\u5728\u53cd\u9988\u8bf1\u5bfc\u7684\"\u8fc7\u4e13\u95e8\u5316\u9677\u9631\"\uff1a\u5b66\u4e60\u8005\u4f18\u5316\u73b0\u6709\u504f\u597d\u7528\u6237\u7684\u8fc7\u7a0b\u4f7f\u5176\u5bf9\u5916\u90e8\u7528\u6237\u5438\u5f15\u529b\u4e0b\u964d\uff0c\u5bfc\u81f4\u89c2\u5bdf\u6570\u636e\u8fdb\u4e00\u6b65\u53d7\u9650\uff0c\u4ece\u800c\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u4efb\u610f\u5dee\u7684\u5168\u5c40\u6027\u80fd\u6a21\u578b\uff0c\u5373\u4f7f\u4f4e\u5168\u5c40\u635f\u5931\u7684\u6a21\u578b\u5b58\u5728\u3002", "method": "\u501f\u9274\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u77e5\u8bc6\u84b8\u998f\u601d\u60f3\uff0c\u63d0\u51fa\u63a2\u6d4b\u7b97\u6cd5\uff0c\u5141\u8bb8\u5b66\u4e60\u8005\u63a2\u6d4b\u540c\u884c\u6a21\u578b\u7684\u9884\u6d4b\u4ee5\u5b66\u4e60\u672a\u9009\u62e9\u81ea\u8eab\u7684\u7528\u6237\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u5f81\u63a2\u6d4b\u6210\u529f\u6761\u4ef6\uff1a\u5f53\u63a2\u6d4b\u6e90\u4fe1\u606f\u5145\u5206\uff08\u5982\u5df2\u77e5\u5e02\u573a\u9886\u5bfc\u8005\u6216\u5177\u6709\u826f\u597d\u5168\u5c40\u6027\u80fd\u7684\u5927\u591a\u6570\u540c\u884c\uff09\u65f6\uff0c\u8be5\u8fc7\u7a0b\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5177\u6709\u6709\u754c\u5168\u5c40\u98ce\u9669\u7684\u5e73\u7a33\u70b9\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u63a2\u6d4b\u6e90\u4fe1\u606f\u5145\u5206\u7684\u6761\u4ef6\u4e0b\uff08\u5e02\u573a\u9886\u5bfc\u8005\u6216\u826f\u597d\u5168\u5c40\u6027\u80fd\u540c\u884c\u5360\u591a\u6570\uff09\uff0c\u63a2\u6d4b\u7b97\u6cd5\u80fd\u591f\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5177\u6709\u6709\u754c\u5168\u5c40\u98ce\u9669\u7684\u5e73\u7a33\u70b9\u3002\u7814\u7a76\u8005\u5728MovieLens\u3001Census\u548cAmazon Sentiment\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u534a\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u591a\u5e73\u53f0\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u8fc7\u4e13\u95e8\u5316\u9677\u9631\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u63a2\u6d4b\u89e3\u51b3\u65b9\u6848\u3002\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5229\u7528\u540c\u884c\u6a21\u578b\u4fe1\u606f\uff0c\u5b66\u4e60\u8005\u80fd\u591f\u7a81\u7834\u81ea\u9009\u62e9\u504f\u5dee\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u5168\u5c40\u6027\u80fd\u3002\u8fd9\u4e3a\u5e73\u53f0\u5728\u7528\u6237\u81ea\u9009\u62e9\u573a\u666f\u4e0b\u907f\u514d\u8fc7\u62df\u5408\u3001\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2602.24067", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24067", "abs": "https://arxiv.org/abs/2602.24067", "authors": ["Thom Vaughan", "Pedro Ortiz Suarez"], "title": "Colour Contrast on the Web: A WCAG 2.1 Level AA Compliance Audit of Common Crawl's Top 500 Domains", "comment": "8 pages, 4 tables. Companion website and reproducible analysis code available at https://thunderpoot.github.io/wcag-audit/ and https://github.com/thunderpoot/wcag-audit", "summary": "We present a large-scale automated audit of WCAG 2.1/2.2 Level AA colour contrast compliance across the 500 most frequently crawled registered domains in Common Crawl's CC-MAIN-2026-08 February 2026 crawl archive. Rather than conducting a live crawl, all page content was sourced from Common Crawl's open WARC archives, ensuring reproducibility and eliminating any load on target web servers. Our static CSS analysis of 240 homepages identified 4,327 unique foreground/background colour pairings, of which 1,771 (40.9%) failed to meet the 4.5:1 contrast ratio threshold for normal text. The median per-site pass rate was 62.7%, with 20.4% of sites achieving full compliance across all detected colour pairings. These findings suggest that colour contrast remains a widespread accessibility barrier on the most prominent websites, with significant variation across domain categories.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf92026\u5e742\u6708Common Crawl\u6293\u53d6\u7684500\u4e2a\u6700\u5e38\u89c1\u57df\u540d\u8fdb\u884c\u4e86WCAG 2.1/2.2 AA\u7ea7\u989c\u8272\u5bf9\u6bd4\u5ea6\u81ea\u52a8\u5316\u5ba1\u8ba1\u3002\u901a\u8fc7\u5bf9240\u4e2a\u9996\u9875\u7684\u9759\u6001CSS\u5206\u6790\uff0c\u53d1\u73b040.9%\u7684\u989c\u8272\u7ec4\u5408\u672a\u8fbe\u5230\u6b63\u5e38\u6587\u672c4.5:1\u7684\u5bf9\u6bd4\u5ea6\u8981\u6c42\uff0c\u4e2d\u4f4d\u901a\u8fc7\u7387\u4e3a62.7%\uff0c\u4ec520.4%\u7684\u7f51\u7ad9\u5b8c\u5168\u5408\u89c4\uff0c\u8868\u660e\u989c\u8272\u5bf9\u6bd4\u5ea6\u4ecd\u662f\u7f51\u7ad9\u53ef\u8bbf\u95ee\u6027\u7684\u4e3b\u8981\u969c\u788d\u3002", "motivation": "\u989c\u8272\u5bf9\u6bd4\u5ea6\u4e0d\u8db3\u662f\u7f51\u7ad9\u53ef\u8bbf\u95ee\u6027\u7684\u91cd\u8981\u969c\u788d\uff0c\u5f71\u54cd\u89c6\u969c\u7528\u6237\u7684\u8bbf\u95ee\u4f53\u9a8c\u3002\u5c3d\u7ba1WCAG\u6807\u51c6\u5df2\u5b58\u5728\u591a\u5e74\uff0c\u4f46\u5b9e\u9645\u5408\u89c4\u60c5\u51b5\u7f3a\u4e4f\u5927\u89c4\u6a21\u6570\u636e\u652f\u6491\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u53ef\u91cd\u590d\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u9876\u5c16\u7f51\u7ad9\u7684\u989c\u8272\u5bf9\u6bd4\u5ea6\u5408\u89c4\u73b0\u72b6\uff0c\u63ed\u793a\u95ee\u9898\u7684\u666e\u904d\u6027\u548c\u4e25\u91cd\u7a0b\u5ea6\u3002", "method": "\u7814\u7a76\u91c7\u7528\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u4eceCommon Crawl\u7684CC-MAIN-2026-08\u516c\u5f00WARC\u6863\u6848\u4e2d\u63d0\u53d6500\u4e2a\u6700\u5e38\u89c1\u57df\u540d\u7684\u9875\u9762\u5185\u5bb9\uff0c\u907f\u514d\u4e86\u5bf9\u76ee\u6807\u670d\u52a1\u5668\u7684\u8d1f\u8f7d\u5e76\u786e\u4fdd\u7ed3\u679c\u53ef\u91cd\u590d\u3002\u5bf9\u5176\u4e2d240\u4e2a\u9996\u9875\u7684CSS\u8fdb\u884c\u89e3\u6790\uff0c\u63d0\u53d64,327\u4e2a\u72ec\u7279\u7684\u524d\u666f\u8272/\u80cc\u666f\u8272\u914d\u5bf9\uff0c\u5e76\u81ea\u52a8\u5316\u8bc4\u4f30\u5176\u662f\u5426\u7b26\u5408WCAG 2.1/2.2 Level AA\u76844.5:1\u5bf9\u6bd4\u5ea6\u9608\u503c\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c40.9%\uff081,771\u4e2a\uff09\u7684\u989c\u8272\u914d\u5bf9\u672a\u8fbe\u5230\u6b63\u5e38\u6587\u672c\u6240\u9700\u76844.5:1\u5bf9\u6bd4\u5ea6\u9608\u503c\u3002\u7f51\u7ad9\u95f4\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u4e2d\u4f4d\u901a\u8fc7\u7387\u4e3a62.7%\uff0c\u4f46\u4ec520.4%\u7684\u7f51\u7ad9\u5728\u6240\u6709\u68c0\u6d4b\u5230\u7684\u989c\u8272\u914d\u5bf9\u4e0a\u5b9e\u73b0\u5b8c\u5168\u5408\u89c4\u3002\u7ed3\u679c\u8868\u660e\u989c\u8272\u5bf9\u6bd4\u5ea6\u95ee\u9898\u5728\u4e3b\u6d41\u7f51\u7ad9\u4e2d\u4ecd\u7136\u666e\u904d\u5b58\u5728\u3002", "conclusion": "\u989c\u8272\u5bf9\u6bd4\u5ea6\u5408\u89c4\u6027\u4ecd\u7136\u662f\u7edd\u5927\u591a\u6570\u7f51\u7ad9\u7684\u53ef\u8bbf\u95ee\u6027\u969c\u788d\uff0c\u5373\u4f7f\u5728\u6d41\u91cf\u6700\u9ad8\u7684\u7f51\u7ad9\u4e2d\u4e5f\u8fdc\u672a\u5f97\u5230\u5145\u5206\u89e3\u51b3\u3002\u7814\u7a76\u7ed3\u679c\u51f8\u663e\u4e86\u6301\u7eed\u6539\u8fdb\u7f51\u7ad9\u8bbe\u8ba1\u548c\u52a0\u5f3a\u53ef\u8bbf\u95ee\u6027\u6807\u51c6\u6267\u884c\u7684\u5fc5\u8981\u6027\uff0c\u4e0d\u540c\u57df\u540d\u7c7b\u522b\u95f4\u5b58\u5728\u7684\u663e\u8457\u5dee\u5f02\u4e5f\u8868\u660e\u9700\u8981\u9488\u5bf9\u6027\u7684\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2602.23753", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23753", "abs": "https://arxiv.org/abs/2602.23753", "authors": ["Jiasen Zheng", "Zijun Zhou", "Huajun Zhang", "Junjiang Lin", "Jingyun Jia", "Qi Wang"], "title": "Structured Prompt Optimization for Few-Shot Text Classification via Semantic Alignment in Latent Space", "comment": null, "summary": "This study addresses the issues of semantic entanglement, unclear label structure, and insufficient feature representation in few-shot text classification, and proposes an optimization framework based on structured prompts to enhance semantic understanding and task adaptation under low-resource conditions. The framework first uses a pretrained language model to encode the input text and obtain basic semantic representations. It then introduces structured prompts composed of multi-dimensional semantic factors and integrates them with text features through a learnable combination mechanism, which forms task-related representations with clear boundaries in the latent space. To further strengthen the consistency between text representations and label semantics, the method constructs a structured label embedding matrix and employs a cross-space alignment mechanism to ensure stable matching between textual features and label attributes. In addition, the model applies prompt orthogonality constraints and a joint optimization objective to maintain independence across different semantic factors in the prompts, allowing the structured prompts to provide transparent and controllable guidance for classification decisions. Three types of sensitivity experiments, including learning rate sensitivity, prompt length sensitivity, and data scale sensitivity, are designed to evaluate the stability and robustness of the framework under different conditions. Experimental results show that the proposed structured prompt optimization framework effectively alleviates semantic conflicts and label ambiguity in few-shot text classification. It significantly improves performance on accuracy, precision, recall, and AUC, and demonstrates strong cross-task applicability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u5316\u63d0\u793a\u7684\u5c11\u6837\u672c\u6587\u672c\u5206\u7c7b\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u591a\u7ef4\u5ea6\u8bed\u4e49\u56e0\u5b50\u63d0\u793a\u548c\u8de8\u7a7a\u95f4\u5bf9\u9f50\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u4e49\u7ea0\u7f20\u3001\u6807\u7b7e\u7ed3\u6784\u4e0d\u6e05\u6670\u548c\u7279\u5f81\u8868\u793a\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u9488\u5bf9\u5c11\u6837\u672c\u6587\u672c\u5206\u7c7b\u4e2d\u5b58\u5728\u7684\u8bed\u4e49\u7ea0\u7f20\u3001\u6807\u7b7e\u7ed3\u6784\u4e0d\u6e05\u6670\u548c\u7279\u5f81\u8868\u793a\u4e0d\u8db3\u7b49\u5173\u952e\u95ee\u9898\uff0c\u9700\u8981\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u63d0\u5347\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u548c\u4efb\u52a1\u9002\u5e94\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u533a\u5206\u4e0d\u540c\u8bed\u4e49\u56e0\u7d20\u7684\u5173\u7cfb\uff0c\u4e14\u6587\u672c\u8868\u793a\u4e0e\u6807\u7b7e\u8bed\u4e49\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5206\u7c7b\u8fb9\u754c\u6a21\u7cca\u3002", "method": "\u8be5\u6846\u67b6\u9996\u5148\u4f7f\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5bf9\u8f93\u5165\u6587\u672c\u8fdb\u884c\u7f16\u7801\u83b7\u53d6\u57fa\u7840\u8bed\u4e49\u8868\u793a\uff1b\u968f\u540e\u5f15\u5165\u7531\u591a\u7ef4\u5ea6\u8bed\u4e49\u56e0\u5b50\u6784\u6210\u7684\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7ec4\u5408\u673a\u5236\u5c06\u5176\u4e0e\u6587\u672c\u7279\u5f81\u878d\u5408\uff0c\u5f62\u6210\u5177\u6709\u6e05\u6670\u8fb9\u754c\u7684\u4efb\u52a1\u76f8\u5173\u8868\u793a\uff1b\u4e3a\u589e\u5f3a\u6587\u672c\u8868\u793a\u4e0e\u6807\u7b7e\u8bed\u4e49\u7684\u4e00\u81f4\u6027\uff0c\u6784\u5efa\u4e86\u7ed3\u6784\u5316\u6807\u7b7e\u5d4c\u5165\u77e9\u9635\u5e76\u91c7\u7528\u8de8\u7a7a\u95f4\u5bf9\u9f50\u673a\u5236\u786e\u4fdd\u6587\u672c\u7279\u5f81\u4e0e\u6807\u7b7e\u5c5e\u6027\u7684\u7a33\u5b9a\u5339\u914d\uff1b\u6b64\u5916\uff0c\u901a\u8fc7\u65bd\u52a0\u63d0\u793a\u6b63\u4ea4\u7ea6\u675f\u548c\u8054\u5408\u4f18\u5316\u76ee\u6807\uff0c\u4fdd\u6301\u4e0d\u540c\u8bed\u4e49\u56e0\u5b50\u95f4\u7684\u72ec\u7acb\u6027\uff0c\u4f7f\u7ed3\u6784\u5316\u63d0\u793a\u4e3a\u5206\u7c7b\u51b3\u7b56\u63d0\u4f9b\u900f\u660e\u53ef\u63a7\u7684\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7ed3\u6784\u5316\u63d0\u793a\u4f18\u5316\u6846\u67b6\u6709\u6548\u7f13\u89e3\u4e86\u5c11\u6837\u672c\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u8bed\u4e49\u51b2\u7a81\u548c\u6807\u7b7e\u6b67\u4e49\u95ee\u9898\uff0c\u5728\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cAUC\u7b49\u6307\u6807\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u4efb\u52a1\u9002\u7528\u6027\u3002\u4e09\u79cd\u654f\u611f\u6027\u5b9e\u9a8c\uff08\u5b66\u4e60\u7387\u3001\u63d0\u793a\u957f\u5ea6\u3001\u6570\u636e\u89c4\u6a21\uff09\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u63d0\u793a\u4f18\u5316\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8bed\u4e49\u7ed3\u6784\u548c\u6807\u7b7e\u5173\u7cfb\uff0c\u4e3a\u5c11\u6837\u672c\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u900f\u660e\u53ef\u63a7\u7684\u63d0\u793a\u8bbe\u8ba1\u601d\u8def\u4e3a\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u6587\u672c\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.23777", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23777", "abs": "https://arxiv.org/abs/2602.23777", "authors": ["Zhipeng Xu", "Zilong Wang", "Xinyang Jiang", "Dongsheng Li", "De Cheng", "Nannan Wang"], "title": "Reasoning-Driven Multimodal LLM for Domain Generalization", "comment": "Accepted at ICLR 2026 (Poster)", "summary": "This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\u3002\u901a\u8fc7\u6784\u5efa\u63a8\u7406\u94fe\u6765\u63a8\u5bfc\u56fe\u50cf\u7c7b\u522b\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u57fa\u4e8e\u63a8\u7406\u7684\u76d1\u7763\u76f8\u6bd4\u76f4\u63a5\u6807\u7b7e\u76d1\u7763\u66f4\u5177\u6311\u6218\u6027\uff0c\u5e76\u5b58\u5728\u8bed\u4e49\u4e30\u5bcc\u5ea6\u4e0e\u4f18\u5316\u6548\u7387\u7684\u6743\u8861\u95ee\u9898\u3002\u63d0\u51fa\u7684RD-MLDG\u6846\u67b6\u7ed3\u5408\u591a\u4efb\u52a1\u4ea4\u53c9\u8bad\u7ec3\u548c\u81ea\u5bf9\u9f50\u63a8\u7406\u6b63\u5219\u5316\uff0c\u5728\u6807\u51c6DomainBed\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u63a8\u7406\u4fe1\u53f7\u5bf9\u9886\u57df\u6cdb\u5316\u7684\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u7279\u5f81\u4e0d\u53d8\u6027\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6784\u5efa\u63a8\u7406\u94fe\u6765\u63a8\u5bfc\u56fe\u50cf\u7c7b\u522b\u7684\u6f5c\u529b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u9886\u57df\u5916\u6cdb\u5316\u9884\u6d4b\uff0c\u5e76\u7cfb\u7edf\u7814\u7a76\u63a8\u7406\u5728\u9886\u57df\u6cdb\u5316\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51faRD-MLDG\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) MTCT\uff08\u591a\u4efb\u52a1\u4ea4\u53c9\u8bad\u7ec3\uff09\uff0c\u5f15\u5165\u989d\u5916\u7684\u76f4\u63a5\u5206\u7c7b\u8def\u5f84\u6765\u5f15\u5bfc\u63a8\u7406\u76d1\u7763\uff1b2) SARR\uff08\u81ea\u5bf9\u9f50\u63a8\u7406\u6b63\u5219\u5316\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u6807\u6ce8\u4fdd\u6301\u63a8\u7406\u94fe\u7684\u8bed\u4e49\u4e30\u5bcc\u5ea6\uff0c\u540c\u65f6\u7f13\u89e3\u63a8\u7406\u6a21\u5f0f\u4e0d\u5339\u914d\u95ee\u9898\u3002\u7814\u7a76\u57fa\u4e8e\u65b0\u6784\u5efa\u7684DomainBed-Reasoning\u6570\u636e\u96c6\u8fdb\u884c\u3002", "result": "\u5728PACS\u3001VLCS\u3001OfficeHome\u3001TerraInc\u7b49\u6807\u51c6DomainBed\u6570\u636e\u96c6\u4e0a\uff0cRD-MLDG\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63a8\u7406\u94fe\u53ef\u4f5c\u4e3a\u9886\u57df\u6cdb\u5316\u7684\u91cd\u8981\u4e92\u8865\u4fe1\u53f7\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u9886\u57df\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u9886\u57df\u6cdb\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.24125", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24125", "abs": "https://arxiv.org/abs/2602.24125", "authors": ["Rohit Chivukula", "T. Jaya Lakshmi", "Hemlata Sharma", "C. H. S. N. P. Sairam Rallabandi"], "title": "Recommendation Algorithms: A Comparative Study in Movie Domain", "comment": null, "summary": "Intelligent recommendation systems have clearly increased the revenue of well-known e-commerce firms. Users receive product recommendations from recommendation systems. Cinematic recommendations are made to users by a movie recommendation system. There have been numerous approaches to the problem of recommendation in the literature. It is viewed as a regression task in this research. A regression model was built using novel properties extracted from the dataset and used as features in the model. For experimentation, the Netflix challenge dataset has been used. Video streaming service Netflix is a popular choice for many. Customers' prior viewing habits are taken into account when Netflix makes movie recommendations to them. An exploratory data analysis on the Netflix dataset was conducted to gain insights into user rating behaviour and movie characteristics. Various kinds of features, including aggregating, Matrix Factorization (MF) based, and user and movie similarity based, have been extracted in the subsequent stages. In addition to a feature in the XGBoost regression algorithm, the K-Nearest Neighbors and MF algorithms from Python's Surprise library are used for recommendations. Based on Root Mean Square Error (RMSE), MF-based algorithms have provided the best recommendations.", "AI": {"tldr": "\u672c\u6587\u5c06\u7535\u5f71\u63a8\u8350\u95ee\u9898\u89c6\u4e3a\u56de\u5f52\u4efb\u52a1\uff0c\u57fa\u4e8eNetflix\u6570\u636e\u96c6\u63d0\u53d6\u591a\u79cd\u7279\u5f81\uff0c\u5bf9\u6bd4XGBoost\u3001KNN\u548cMF\u7b49\u7b97\u6cd5\uff0c\u53d1\u73b0\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u65b9\u6cd5\u5728RMSE\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u7535\u5546\u6536\u5165\uff0cNetflix\u4f5c\u4e3a\u70ed\u95e8\u6d41\u5a92\u4f53\u5e73\u53f0\uff0c\u5176\u7535\u5f71\u63a8\u8350\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u7814\u7a76\u4ef7\u503c\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63d0\u53d6\u65b0\u9896\u7279\u5f81\u5e76\u5bf9\u6bd4\u591a\u79cd\u56de\u5f52\u7b97\u6cd5\uff0c\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "method": "\u672c\u6587\u5c06\u63a8\u8350\u95ee\u9898\u5efa\u6a21\u4e3a\u56de\u5f52\u4efb\u52a1\u3002\u9996\u5148\u5bf9Netflix\u6570\u636e\u96c6\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff0c\u968f\u540e\u63d0\u53d6\u805a\u5408\u7279\u5f81\u3001\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u7279\u5f81\u4ee5\u53ca\u7528\u6237\u548c\u7535\u5f71\u76f8\u4f3c\u5ea6\u7279\u5f81\u3002\u91c7\u7528XGBoost\u3001K\u6700\u8fd1\u90bb\u548c\u77e9\u9635\u5206\u89e3\u7b97\u6cd5\uff08\u6765\u81eaPython Surprise\u5e93\uff09\u8fdb\u884c\u63a8\u8350\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\uff08MF\uff09\u7684\u7b97\u6cd5\u5728\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u80fd\u591f\u63d0\u4f9b\u6700\u4f73\u63a8\u8350\u6548\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u5b9e\uff0c\u5728\u7535\u5f71\u63a8\u8350\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u65b9\u6cd5\u76f8\u6bd4XGBoost\u548cK\u6700\u8fd1\u90bb\u7b97\u6cd5\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u51c6\u786e\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.23792", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23792", "abs": "https://arxiv.org/abs/2602.23792", "authors": ["Xiangzhong Luo", "Yilin An", "Zhicheng Yu", "Weichen Liu", "Xu Yang"], "title": "Divide and Conquer: Accelerating Diffusion-Based Large Language Models via Adaptive Parallel Decoding", "comment": "11 pages, 7 figures", "summary": "Diffusion-based large language models (dLLMs) have shown promising performance across various reasoning tasks, establishing themselves as an alternative to autoregressive large language models (LLMs). Unlike autoregressive LLMs that generate one token per step based on all previous tokens, dLLMs theoretically enable parallel generation of multiple tokens at each decoding step. However, recent dLLMs still favor one-token-per-step generation in practice, as directly decoding multiple masked tokens often leads to degraded generation quality and stability. This reveals a substantial gap between the theoretical parallelism and practical performance of dLLMs. To bridge this gap, we introduce an adaptive parallel decoding approach, namely DiCo, which features a three-phase divide-and-conquer paradigm to unleash the inherent parallelism of dLLMs. During the Divide phase, DiCo first explores the input masked sequence and identifies masked tokens as seed tokens, which are then expanded to construct a set of local clusters. During the Conquer phase, DiCo performs parallel decoding across different local clusters constructed in the Divide phase. The divide-and-conquer process repeatedly alternates between the Divide and Conquer phases until convergence. During the Finalize phase, DiCo decodes the remaining few masked tokens using an effective fine-grained compound decoding scheme to finalize the generation. Extensive experiments demonstrate that DiCo can achieve significant inference speedups while maintaining competitive generation quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiCo\u81ea\u9002\u5e94\u5e76\u884c\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u5206\u6cbb\u8303\u5f0f\u89e3\u51b3\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b(dLLMs)\u7406\u8bba\u5e76\u884c\u6027\u4e0e\u5b9e\u9645\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u95ee\u9898\uff0c\u5b9e\u73b0\u63a8\u7406\u52a0\u901f\u7684\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b(dLLMs)\u867d\u7406\u8bba\u4e0a\u652f\u6301\u6bcf\u6b65\u5e76\u884c\u751f\u6210\u591atoken\uff0c\u4f46\u5b9e\u8df5\u4ecd\u91c7\u7528\u9010token\u89e3\u7801\uff0c\u56e0\u76f4\u63a5\u5e76\u884c\u89e3\u7801\u4f1a\u5bfc\u81f4\u751f\u6210\u8d28\u91cf\u4e0e\u7a33\u5b9a\u6027\u4e0b\u964d\uff0c\u5b58\u5728\u7406\u8bba\u5e76\u884c\u6027\u4e0e\u5b9e\u9645\u6027\u80fd\u95f4\u7684\u663e\u8457\u9e3f\u6c9f\u3002", "method": "DiCo\u91c7\u7528\u4e09\u9636\u6bb5\u5206\u6cbb\u7b56\u7565\uff1a\u5212\u5206\u9636\u6bb5\u8bc6\u522b\u79cd\u5b50token\u5e76\u6784\u5efa\u5c40\u90e8\u7c07\uff1b\u5f81\u670d\u9636\u6bb5\u5728\u5404\u7c07\u4e0a\u5e76\u884c\u89e3\u7801\uff1b\u5b8c\u6210\u9636\u6bb5\u7528\u7ec6\u7c92\u5ea6\u590d\u5408\u89e3\u7801\u5904\u7406\u5269\u4f59token\u3002\u5212\u5206\u4e0e\u5f81\u670d\u9636\u6bb5\u91cd\u590d\u4ea4\u66ff\u76f4\u81f3\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eDiCo\u53ef\u5b9e\u73b0\u663e\u8457\u63a8\u7406\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u5177\u6709\u7ade\u4e89\u529b\u7684\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "DiCo\u6709\u6548\u91ca\u653e\u4e86dLLMs\u7684\u5e76\u884c\u6f5c\u529b\uff0c\u5f25\u5408\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002"}}
{"id": "2602.23802", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23802", "abs": "https://arxiv.org/abs/2602.23802", "authors": ["Yiyang Fang", "Wenke Huang", "Pei Fu", "Yihao Yang", "Kehua Su", "Zhenbo Luo", "Jian Luan", "Mang Ye"], "title": "EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models", "comment": "Accepted by CVPR 2026", "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEMO-R3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u60c5\u611f\u601d\u8003\u548c\u53cd\u601d\u6027\u60c5\u611f\u5956\u52b1\u673a\u5236\uff0c\u5229\u7528\u53cd\u601d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u63a8\u7406\u80fd\u529b\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u591a\u4e2a\u89c6\u89c9\u60c5\u611f\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6027\u80fd\u7a81\u7834\u3002", "motivation": "\u73b0\u6709MLLM\u96be\u4ee5\u6355\u6349\u4eba\u7c7b\u60c5\u611f\u7684\u590d\u6742\u6027\u4e0e\u4e3b\u89c2\u6027\uff0c\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800cGroup Relative Policy Optimization\u7b49\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u672a\u80fd\u4e0e\u60c5\u611f\u8ba4\u77e5\u7684\u5185\u5728\u7279\u6027\u6709\u6548\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u53cd\u601d\u5f3a\u5316\u5b66\u4e60\u6846\u67b6EMO-R3\uff0c\u6838\u5fc3\u5305\u62ec\uff1a1\uff09\u7ed3\u6784\u5316\u60c5\u611f\u601d\u8003\uff0c\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u9010\u6b65\u60c5\u611f\u63a8\u7406\uff1b2\uff09\u53cd\u601d\u6027\u60c5\u611f\u5956\u52b1\u51fd\u6570\uff0c\u57fa\u4e8e\u89c6\u89c9-\u6587\u672c\u4e00\u81f4\u6027\u4e0e\u60c5\u611f\u8fde\u8d2f\u6027\u5b9e\u73b0\u63a8\u7406\u8fc7\u7a0b\u7684\u81ea\u8bc4\u4f30\u4e0e\u4f18\u5316\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cEMO-R3\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u60c5\u611f\u667a\u80fd\u6c34\u5e73\uff0c\u5728\u591a\u9879\u89c6\u89c9\u60c5\u611f\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e1a\u754c\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "EMO-R3\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u601d\u8003\u4e0e\u53cd\u601d\u5956\u52b1\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86MLLM\u60c5\u611f\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u60c5\u611f\u8ba4\u77e5\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.23826", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23826", "abs": "https://arxiv.org/abs/2602.23826", "authors": ["Sebastian Gerstner", "Hinrich Sch\u00fctze"], "title": "GLUScope: A Tool for Analyzing GLU Neurons in Transformer Language Models", "comment": "6 pages for main body, 9 pages in total. 4 figures", "summary": "We present GLUScope, an open-source tool for analyzing neurons in Transformer-based language models, intended for interpretability researchers. We focus on more recent models than previous tools do; specifically we consider gated activation functions such as SwiGLU. This introduces a new challenge: understanding positive activations is not enough. Instead, both the gate and the in activation of a neuron can be positive or negative, leading to four different possible sign combinations that in some cases have quite different functionalities. Accordingly, for any neuron, our tool shows text examples for each of the four sign combinations, and indicates how often each combination occurs. We describe examples of how our tool can lead to novel insights. A demo is available at https: //sjgerstner.github.io/gluscope.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GLUScope\uff0c\u4e00\u4e2a\u9762\u5411\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u5143\u3002\u8be5\u5de5\u5177\u4e13\u6ce8\u4e8e\u652f\u6301SwiGLU\u7b49\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\u7684\u65b0\u578b\u6a21\u578b\uff0c\u901a\u8fc7\u5c55\u793a\u795e\u7ecf\u5143\u56db\u79cd\u7b26\u53f7\u7ec4\u5408\uff08\u95e8\u63a7\u4e0e\u6fc0\u6d3b\u7684\u6b63\u8d1f\u7ec4\u5408\uff09\u5bf9\u5e94\u7684\u6587\u672c\u793a\u4f8b\u548c\u51fa\u73b0\u9891\u7387\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u7406\u89e3\u795e\u7ecf\u5143\u884c\u4e3a\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u6d1e\u5bdf\u6848\u4f8b\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u5143\u5206\u6790\u5de5\u5177\u4e3b\u8981\u9488\u5bf9\u8f83\u65e9\u671f\u7684\u6a21\u578b\uff0c\u800c\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u91c7\u7528SwiGLU\u7b49\u95e8\u63a7\u6fc0\u6d3b\u7ed3\u6784\u3002\u8fd9\u79cd\u7ed3\u6784\u4e0b\uff0c\u4ec5\u5206\u6790\u6b63\u6fc0\u6d3b\u503c\u4e0d\u8db3\u4ee5\u5168\u9762\u7406\u89e3\u795e\u7ecf\u5143\u529f\u80fd\uff0c\u56e0\u4e3a\u95e8\u63a7\u5355\u5143\u548c\u6fc0\u6d3b\u5355\u5143\u5747\u53ef\u72ec\u7acb\u53d6\u6b63\u8d1f\u503c\uff0c\u5f62\u6210\u56db\u79cd\u529f\u80fd\u8fe5\u5f02\u7684\u7b26\u53f7\u7ec4\u5408\u3002\u7f3a\u4e4f\u4e13\u95e8\u5de5\u5177\u9650\u5236\u4e86\u7814\u7a76\u4eba\u5458\u5bf9\u8fd9\u4e9b\u65b0\u6a21\u578b\u7684\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u5f00\u6e90\u5de5\u5177GLUScope\uff0c\u9488\u5bf9\u6bcf\u4e2a\u795e\u7ecf\u5143\uff0c\u7cfb\u7edf\u6027\u5730\u5c55\u793a\u5176\u56db\u79cd\u7b26\u53f7\u7ec4\u5408\uff08\u95e8\u63a7\u6b63\u00d7\u6fc0\u6d3b\u6b63\u3001\u95e8\u63a7\u6b63\u00d7\u6fc0\u6d3b\u8d1f\u3001\u95e8\u63a7\u8d1f\u00d7\u6fc0\u6d3b\u6b63\u3001\u95e8\u63a7\u8d1f\u00d7\u6fc0\u6d3b\u8d1f\uff09\u6240\u5bf9\u5e94\u7684\u4ee3\u8868\u6027\u6587\u672c\u793a\u4f8b\uff0c\u5e76\u91cf\u5316\u5404\u7ec4\u5408\u7684\u51fa\u73b0\u9891\u7387\uff0c\u4ee5\u652f\u6301\u529f\u80fd\u6a21\u5f0f\u8bc6\u522b\u3002", "result": "\u5de5\u5177\u80fd\u591f\u63ed\u793a\u4e0d\u540c\u7b26\u53f7\u7ec4\u5408\u4e0b\u795e\u7ecf\u5143\u7684\u5dee\u5f02\u5316\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u53d1\u73b0\u4f20\u7edf\u6b63\u6fc0\u6d3b\u5206\u6790\u65e0\u6cd5\u6355\u6349\u7684\u65b0\u9896\u8bed\u4e49\u7279\u5f81\u548c\u529f\u80fd\u673a\u5236\uff0c\u5e76\u5df2\u901a\u8fc7\u5728\u7ebf\u6f14\u793a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "GLUScope\u4e3a\u95e8\u63a7\u6fc0\u6d3b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u5176\u56db\u8c61\u9650\u7b26\u53f7\u7ec4\u5408\u5206\u6790\u6846\u67b6\u6df1\u5316\u4e86\u5bf9\u795e\u7ecf\u5143\u529f\u80fd\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.23581", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23581", "abs": "https://arxiv.org/abs/2602.23581", "authors": ["Xiang Ao"], "title": "SDMixer: Sparse Dual-Mixer for Time Series Forecasting", "comment": "12pages,2 figures", "summary": "Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer", "code_url": "https://github.com/SDMixer/SDMixer", "code_stars": 0, "code_last_update": "2025-11-23", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41\u7a00\u758fMixer\u9884\u6d4b\u6846\u67b6\u6765\u89e3\u51b3\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u3001\u5f31\u76f8\u5173\u6027\u548c\u566a\u58f0\u5e72\u6270\u95ee\u9898\u3002\u8be5\u6846\u67b6\u5206\u522b\u5728\u9891\u57df\u548c\u65f6\u95f4\u57df\u63d0\u53d6\u5168\u5c40\u8d8b\u52bf\u548c\u5c40\u90e8\u52a8\u6001\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u7a00\u758f\u673a\u5236\u8fc7\u6ee4\u65e0\u6548\u4fe1\u606f\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u4ea4\u901a\u3001\u80fd\u6e90\u548c\u91d1\u878d\u7b49\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u53d7\u9650\u4e8e\u6570\u636e\u7684\u591a\u5c3a\u5ea6\u7279\u6027\u3001\u53d8\u91cf\u95f4\u5f31\u76f8\u5173\u6027\u548c\u566a\u58f0\u5e72\u6270\uff0c\u5bfc\u81f4\u9884\u6d4b\u6027\u80fd\u4e0d\u4f73\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u63d0\u51fa\u53cc\u6d41\u7a00\u758fMixer\u6846\u67b6\uff0c\u901a\u8fc7\u9891\u57df\u5206\u652f\u63d0\u53d6\u5168\u5c40\u8d8b\u52bf\u7279\u5f81\uff0c\u65f6\u95f4\u57df\u5206\u652f\u6355\u6349\u5c40\u90e8\u52a8\u6001\u7279\u5f81\u3002\u5f15\u5165\u7a00\u758f\u673a\u5236\u7b5b\u9009\u6709\u6548\u4fe1\u606f\uff0c\u5f3a\u5316\u8de8\u53d8\u91cf\u4f9d\u8d56\u5efa\u6a21\u3002\u91c7\u7528\u53cc\u8def\u5e76\u884c\u7ed3\u6784\u540c\u65f6\u5904\u7406\u4e0d\u540c\u5c3a\u5ea6\u7684\u6a21\u5f0f\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u573a\u666f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u9884\u6d4b\u6027\u80fd\u3002\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u89e3\u51b3\u591a\u5c3a\u5ea6\u7279\u5f81\u3001\u5f31\u76f8\u5173\u6027\u548c\u566a\u58f0\u95ee\u9898\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u53cc\u6d41\u7a00\u758fMixer\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u9891\u57df-\u65f6\u95f4\u57df\u534f\u540c\u5efa\u6a21\u548c\u7a00\u758f\u8fc7\u6ee4\u673a\u5236\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u5904\u7406\u590d\u6742\u6570\u636e\u6a21\u5f0f\u7684\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.23845", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23845", "abs": "https://arxiv.org/abs/2602.23845", "authors": ["Jian Kai", "Zidong Zhang", "Jiwen Chen", "Zhengxiang Wu", "Songtao Sun", "Fuyang Li", "Yang Cao", "Qiang Liu"], "title": "CLFEC: A New Task for Unified Linguistic and Factual Error Correction in paragraph-level Chinese Professional Writing", "comment": null, "summary": "Chinese text correction has traditionally focused on spelling and grammar, while factual error correction is usually treated separately. However, in paragraph-level Chinese professional writing, linguistic (word/grammar/punctuation) and factual errors frequently co-occur and interact, making unified correction both necessary and challenging. This paper introduces CLFEC (Chinese Linguistic & Factual Error Correction), a new task for joint linguistic and factual correction. We construct a mixed, multi-domain Chinese professional writing dataset spanning current affairs, finance, law, and medicine. We then conduct a systematic study of LLM-based correction paradigms, from prompting to retrieval-augmented generation (RAG) and agentic workflows. The analysis reveals practical challenges, including limited generalization of specialized correction models, the need for evidence grounding for factual repair, the difficulty of mixed-error paragraphs, and over-correction on clean inputs. Results further show that handling linguistic and factual Error within the same context outperform decoupled processes, and that agentic workflows can be effective with suitable backbone models. Overall, our dataset and empirical findings provide guidance for building reliable, fully automatic proofreading systems in industrial settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCLFEC\uff08\u4e2d\u6587\u8bed\u8a00\u4e0e\u4e8b\u5b9e\u7ea0\u9519\uff09\u65b0\u4efb\u52a1\uff0c\u6784\u5efa\u591a\u9886\u57df\u4e13\u4e1a\u5199\u4f5c\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u7814\u7a76LLM\u7ea0\u9519\u8303\u5f0f\uff0c\u53d1\u73b0\u7edf\u4e00\u5904\u7406\u8bed\u8a00\u4e0e\u4e8b\u5b9e\u9519\u8bef\u4f18\u4e8e\u5206\u79bb\u5904\u7406\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u81ea\u52a8\u6821\u5bf9\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u4e2d\u6587\u7ea0\u9519\u7814\u7a76\u591a\u805a\u7126\u62fc\u5199\u8bed\u6cd5\uff0c\u4e8b\u5b9e\u7ea0\u9519\u5e38\u88ab\u72ec\u7acb\u5904\u7406\u3002\u4f46\u5728\u6bb5\u843d\u7ea7\u4e13\u4e1a\u5199\u4f5c\u4e2d\uff0c\u8bed\u8a00\u9519\u8bef\u4e0e\u4e8b\u5b9e\u9519\u8bef\u9ad8\u9891\u5171\u73b0\u4e14\u76f8\u4e92\u5f71\u54cd\uff0c\u4e9f\u9700\u7edf\u4e00\u7ea0\u9519\u6846\u67b6\u3002", "method": "1) \u6784\u5efa\u8986\u76d6\u65f6\u653f\u3001\u91d1\u878d\u3001\u6cd5\u5f8b\u3001\u533b\u7597\u7684\u6df7\u5408\u9886\u57df\u4e13\u4e1a\u5199\u4f5c\u6570\u636e\u96c6\uff1b2) \u7cfb\u7edf\u7814\u7a76\u4ece\u63d0\u793a\u5b66\u4e60\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5230\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684LLM\u7ea0\u9519\u8303\u5f0f\uff1b3) \u5206\u6790\u5b9e\u9645\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\u3002", "result": "1) \u540c\u4e00\u4e0a\u4e0b\u6587\u4e2d\u5904\u7406\u6df7\u5408\u9519\u8bef\u7684\u6548\u679c\u4f18\u4e8e\u5206\u79bb\u5904\u7406\uff1b2) \u4e13\u4e1a\u7ea0\u9519\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e8b\u5b9e\u4fee\u590d\u9700\u8bc1\u636e\u652f\u6491\uff1b3) \u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5728\u5408\u9002\u57fa\u6a21\u578b\u4e0b\u6548\u679c\u663e\u8457\uff1b4) \u5b58\u5728\u8fc7\u5ea6\u7ea0\u9519\u4e0e\u6df7\u5408\u9519\u8bef\u6bb5\u843d\u5904\u7406\u56f0\u96be\u7b49\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u8054\u5408\u7ea0\u9519\u7684\u5fc5\u8981\u6027\uff0c\u6240\u6784\u5efa\u6570\u636e\u96c6\u4e0e\u5b9e\u8bc1\u7ed3\u679c\u4e3a\u5de5\u4e1a\u573a\u666f\u4e0b\u6784\u5efa\u53ef\u9760\u5168\u81ea\u52a8\u6821\u5bf9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2602.23876", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23876", "abs": "https://arxiv.org/abs/2602.23876", "authors": ["Ning Gao", "Xiuhui Zhang", "Xingyu Jiang", "Mukang You", "Mohan Zhang", "Yue Deng"], "title": "RF-Agent: Automated Reward Function Design via Language Agent Tree Search", "comment": "39 pages, 9 tables, 11 figures, Project page see https://github.com/deng-ai-lab/RF-Agent", "summary": "Designing efficient reward functions for low-level control tasks is a challenging problem. Recent research aims to reduce reliance on expert experience by using Large Language Models (LLMs) with task information to generate dense reward functions. These methods typically rely on training results as feedback, iteratively generating new reward functions with greedy or evolutionary algorithms. However, they suffer from poor utilization of historical feedback and inefficient search, resulting in limited improvements in complex control tasks. To address this challenge, we propose RF-Agent, a framework that treats LLMs as language agents and frames reward function design as a sequential decision-making process, enhancing optimization through better contextual reasoning. RF-Agent integrates Monte Carlo Tree Search (MCTS) to manage the reward design and optimization process, leveraging the multi-stage contextual reasoning ability of LLMs. This approach better utilizes historical information and improves search efficiency to identify promising reward functions. Outstanding experimental results in 17 diverse low-level control tasks demonstrate the effectiveness of our method. The source code is available at https://github.com/deng-ai-lab/RF-Agent.", "code_url": "https://github.com/deng-ai-lab/RF-Agen", "AI": {"tldr": "\u9488\u5bf9\u4f4e\u7ea7\u522b\u63a7\u5236\u4efb\u52a1\u4e2d\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u96be\u9898\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u5386\u53f2\u53cd\u9988\u5229\u7528\u4e0d\u8db3\u548c\u641c\u7d22\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002\u672c\u6587\u63d0\u51faRF-Agent\u6846\u67b6\uff0c\u5c06LLM\u89c6\u4e3a\u8bed\u8a00\u667a\u80fd\u4f53\u5e76\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u901a\u8fc7\u5e8f\u5217\u51b3\u7b56\u548c\u591a\u9636\u6bb5\u4e0a\u4e0b\u6587\u63a8\u7406\u63d0\u5347\u5956\u52b1\u51fd\u6570\u4f18\u5316\u6548\u7387\uff0c\u572817\u4e2a\u591a\u6837\u63a7\u5236\u4efb\u52a1\u4e0a\u53d6\u5f97\u4f18\u5f02\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5956\u52b1\u51fd\u6570\u751f\u6210\u65b9\u6cd5\u91c7\u7528\u8d2a\u5a6a\u6216\u8fdb\u5316\u7b97\u6cd5\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u4f46\u5b58\u5728\u5386\u53f2\u53cd\u9988\u4fe1\u606f\u5229\u7528\u7387\u4f4e\u3001\u641c\u7d22\u6548\u7387\u5dee\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u63a7\u5236\u4efb\u52a1\u4e2d\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "\u63d0\u51faRF-Agent\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u5c06\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\u3002\u96c6\u6210\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22(MCTS)\u7ba1\u7406\u4f18\u5316\u6d41\u7a0b\uff0c\u5229\u7528LLM\u7684\u591a\u9636\u6bb5\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u5728\u641c\u7d22\u8fc7\u7a0b\u4e2d\u6709\u6548\u6574\u5408\u5386\u53f2\u4fe1\u606f\uff0c\u8bc6\u522b\u9ad8\u6027\u80fd\u5956\u52b1\u51fd\u6570\u3002", "result": "\u572817\u4e2a\u591a\u6837\u4f4e\u7ea7\u522b\u63a7\u5236\u4efb\u52a1\u4e0a\u53d6\u5f97\u4f18\u5f02\u5b9e\u9a8c\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002\u6e90\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "RF-Agent\u901a\u8fc7\u7ed3\u5408LLM\u4e0a\u4e0b\u6587\u63a8\u7406\u4e0eMCTS\u9ad8\u6548\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u6548\u7387\uff0c\u4e3a\u590d\u6742\u63a7\u5236\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u5956\u52b1\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.24265", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24265", "abs": "https://arxiv.org/abs/2602.24265", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "Beyond the Click: A Framework for Inferring Cognitive Traces in Search", "comment": null, "summary": "User simulators are essential for evaluating search systems, but they primarily copy user actions without understanding the underlying thought process. This gap exists since large-scale interaction logs record what users do, but not what they might be thinking or feeling, such as confusion or satisfaction. To solve this problem, we present a framework to infer cognitive traces from behavior logs. Our method uses a multi-agent system grounded in Information Foraging Theory (IFT) and human expert judgment. These traces improve model performance on tasks like forecasting session outcomes and user struggle recovery. We release a collection of annotations for several public datasets, including AOL and Stack Overflow, and an open-source tool that allows researchers to apply our method to their own data. This work provides the tools and data needed to build more human-like user simulators and to assess retrieval systems on user-oriented dimensions of performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ece\u7528\u6237\u884c\u4e3a\u65e5\u5fd7\u4e2d\u63a8\u65ad\u8ba4\u77e5\u8f68\u8ff9\u7684\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8e\u4fe1\u606f\u89c5\u98df\u7406\u8bba\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u4e13\u5bb6\u5224\u65ad\uff0c\u663e\u8457\u63d0\u5347\u7528\u6237\u6a21\u62df\u5668\u5728\u9884\u6d4b\u4f1a\u8bdd\u7ed3\u679c\u548c\u7528\u6237\u56f0\u96be\u6062\u590d\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u5f00\u6e90\u4e86AOL\u548cStack Overflow\u7b49\u6570\u636e\u96c6\u7684\u6807\u6ce8\u96c6\u53ca\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7528\u6237\u6a21\u62df\u5668\u4ec5\u80fd\u590d\u5236\u7528\u6237\u884c\u4e3a\uff0c\u7f3a\u4e4f\u5bf9\u6f5c\u5728\u8ba4\u77e5\u8fc7\u7a0b\uff08\u5982\u56f0\u60d1\u6216\u6ee1\u610f\uff09\u7684\u7406\u89e3\uff0c\u800c\u5927\u89c4\u6a21\u4ea4\u4e92\u65e5\u5fd7\u867d\u8bb0\u5f55\u884c\u4e3a\u5374\u65e0\u6cd5\u53cd\u6620\u7528\u6237\u601d\u7ef4\u611f\u53d7\uff0c\u5bfc\u81f4\u6a21\u62df\u5668\u4e0e\u4eba\u673a\u4ea4\u4e92\u771f\u5b9e\u573a\u666f\u5b58\u5728\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u89c5\u98df\u7406\u8bba\uff08IFT\uff09\u548c\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u4ece\u884c\u4e3a\u65e5\u5fd7\u4e2d\u63a8\u65ad\u8ba4\u77e5\u8f68\u8ff9\u3002\u901a\u8fc7\u667a\u80fd\u4f53\u6a21\u62df\u7528\u6237\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u7ed3\u5408\u4e13\u5bb6\u77e5\u8bc6\u6807\u6ce8\uff0c\u6784\u5efa\u80fd\u591f\u53cd\u6620\u7528\u6237\u601d\u7ef4\u72b6\u6001\u7684\u884c\u4e3a\u8868\u5f81\u3002", "result": "\u8ba4\u77e5\u8f68\u8ff9\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9884\u6d4b\u4f1a\u8bdd\u7ed3\u679c\u548c\u7528\u6237\u56f0\u96be\u6062\u590d\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u540c\u65f6\u53d1\u5e03\u4e86AOL\u548cStack Overflow\u7b49\u516c\u5f00\u6570\u636e\u96c6\u7684\u6807\u6ce8\u96c6\uff0c\u4ee5\u53ca\u53ef\u4f9b\u7814\u7a76\u8005\u5e94\u7528\u4e8e\u81ea\u6709\u6570\u636e\u7684\u5f00\u6e90\u5de5\u5177\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6784\u5efa\u66f4\u7c7b\u4eba\u7528\u6237\u6a21\u62df\u5668\u6240\u9700\u7684\u5de5\u5177\u548c\u8bc4\u4f30\u6570\u636e\uff0c\u4f7f\u68c0\u7d22\u7cfb\u7edf\u80fd\u591f\u5728\u4ee5\u7528\u6237\u4e3a\u5bfc\u5411\u7684\u6027\u80fd\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5f25\u8865\u4e86\u884c\u4e3a\u6570\u636e\u4e0e\u8ba4\u77e5\u72b6\u6001\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2602.23928", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23928", "abs": "https://arxiv.org/abs/2602.23928", "authors": ["Gary Lupyan", "Senyi Yang"], "title": "The Astonishing Ability of Large Language Models to Parse Jabberwockified Language", "comment": "Submitted to the 2026 Annual Meeting of the Cognitive Science Society", "summary": "We show that large language models (LLMs) have an astonishing ability to recover meaning from severely degraded English texts. Texts in which content words have been randomly substituted by nonsense strings, e.g., \"At the ghybe of the swuint, we are haiveed to Wourge Phrear-gwurr, who sproles into an ghitch flount with his crurp\", can be translated to conventional English that is, in many cases, close to the original text, e.g., \"At the start of the story, we meet a man, Chow, who moves into an apartment building with his wife.\" These results show that structural cues (e.g., morphosyntax, closed-class words) constrain lexical meaning to a much larger degree than imagined. Although the abilities of LLMs to make sense of \"Jabberwockified\" English are clearly superhuman, they are highly relevant to understanding linguistic structure and suggest that efficient language processing either in biological or artificial systems likely benefits from very tight integration between syntax, lexical semantics, and general world knowledge.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u4ece\u5185\u5bb9\u8bcd\u88ab\u968f\u673a\u66ff\u6362\u4e3a\u65e0\u610f\u4e49\u5b57\u7b26\u4e32\u7684\u4e25\u91cd\u9000\u5316\u82f1\u6587\u6587\u672c\u4e2d\u60ca\u4eba\u5730\u6062\u590d\u8bed\u4e49\uff0c\u8868\u660e\u7ed3\u6784\u7ebf\u7d22\uff08\u5f62\u6001\u53e5\u6cd5\u3001\u5c01\u95ed\u8bcd\u7c7b\uff09\u5bf9\u8bcd\u4e49\u7684\u7ea6\u675f\u8fdc\u8d85\u9884\u671f\uff0c\u8fd9\u5bf9\u7406\u89e3\u8bed\u8a00\u7ed3\u6784\u548c\u9ad8\u6548\u8bed\u8a00\u5904\u7406\u673a\u5236\u5177\u6709\u91cd\u8981\u542f\u793a\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u4ece\u5185\u5bb9\u8bcd\u88ab\u968f\u673a\u66ff\u6362\u4e3a\u65e0\u610f\u4e49\u5b57\u7b26\u4e32\u7684\"\u80e1\u8a00\u4e71\u8bed\u5316\"\u82f1\u6587\u6587\u672c\u4e2d\u6062\u590d\u539f\u59cb\u8bed\u4e49\uff0c\u4ee5\u68c0\u9a8c\u7ed3\u6784\u7ebf\u7d22\u5bf9\u8bcd\u4e49\u7684\u7ea6\u675f\u4f5c\u7528\uff0c\u5e76\u63a2\u8ba8\u751f\u7269\u6216\u4eba\u5de5\u7cfb\u7edf\u4e2d\u9ad8\u6548\u8bed\u8a00\u5904\u7406\u53ef\u80fd\u7684\u8ba4\u77e5\u4e0e\u8ba1\u7b97\u57fa\u7840\u3002", "method": "\u7814\u7a76\u8005\u5c06\u82f1\u6587\u6587\u672c\u4e2d\u7684\u5185\u5bb9\u8bcd\u968f\u673a\u66ff\u6362\u4e3a\u65e0\u610f\u4e49\u5b57\u7b26\u4e32\uff0c\u751f\u6210\"\u80e1\u8a00\u4e71\u8bed\u5316\"\u7684\u9000\u5316\u6587\u672c\uff08\u4f8b\u5982\uff1a\"At the ghybe of the swuint...\"\uff09\uff0c\u7136\u540e\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u8fd9\u4e9b\u6587\u672c\u7ffb\u8bd1\u56de\u5e38\u89c4\u82f1\u6587\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u539f\u59cb\u6587\u672c\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u60ca\u4eba\u7684\u8bed\u4e49\u6062\u590d\u80fd\u529b\uff0c\u5176\u7ffb\u8bd1\u7ed3\u679c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u63a5\u8fd1\u539f\u59cb\u6587\u672c\u3002\u8fd9\u8868\u660e\u53e5\u6cd5\u7ed3\u6784\u3001\u5f62\u6001\u6807\u8bb0\u548c\u5c01\u95ed\u8bcd\u7c7b\u7b49\u7ed3\u6784\u7ebf\u7d22\u5bf9\u8bcd\u4e49\u7684\u7ea6\u675f\u7a0b\u5ea6\u8fdc\u8d85\u4eba\u4eec\u6b64\u524d\u60f3\u8c61\uff0c\u4e3a\u7406\u89e3\u8bed\u8a00\u7406\u89e3\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u8bc1\u636e\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u9000\u5316\u6587\u672c\u7684\u80fd\u529b\u867d\u8d85\u8d8a\u4eba\u7c7b\uff0c\u4f46\u5bf9\u8bed\u8a00\u5b66\u7406\u8bba\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002\u7814\u7a76\u8ba4\u4e3a\uff0c\u9ad8\u6548\u7684\u8bed\u8a00\u5904\u7406\uff08\u65e0\u8bba\u751f\u7269\u6216\u4eba\u5de5\u7cfb\u7edf\uff09\u53ef\u80fd\u4f9d\u8d56\u4e8e\u53e5\u6cd5\u3001\u8bcd\u6c47\u8bed\u4e49\u548c\u4e16\u754c\u77e5\u8bc6\u4e09\u8005\u4e4b\u95f4\u6781\u4e3a\u7d27\u5bc6\u7684\u6574\u5408\u673a\u5236\uff0c\u8fd9\u4e00\u53d1\u73b0\u4e3a\u8ba4\u77e5\u8bed\u8a00\u5b66\u548c\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.23974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23974", "abs": "https://arxiv.org/abs/2602.23974", "authors": ["Fan Zhang", "Baoru Huang", "Xin Zhang"], "title": "Pessimistic Auxiliary Policy for Offline Reinforcement Learning", "comment": null, "summary": "Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.", "AI": {"tldr": "\u9488\u5bf9\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5206\u5e03\u5916\u52a8\u4f5c\u5bfc\u81f4\u7684\u8fd1\u4f3c\u8bef\u5dee\u7d2f\u79ef\u548c\u9ad8\u4f30\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\uff0c\u901a\u8fc7\u6700\u5927\u5316Q\u51fd\u6570\u7684\u4e0b\u7f6e\u4fe1\u754c\u6765\u91c7\u6837\u53ef\u9760\u52a8\u4f5c\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8bef\u5dee\u7d2f\u79ef\u5e76\u63d0\u5347\u4e86\u5176\u4ed6\u79bb\u7ebfRL\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4ece\u9884\u6536\u96c6\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u7b56\u7565\uff0c\u907f\u514d\u4e86\u4e0d\u5b89\u5168\u7684\u5728\u7ebf\u4ea4\u4e92\uff0c\u4f46\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e0d\u53ef\u907f\u514d\u4f1a\u8bbf\u95ee\u5206\u5e03\u5916\u52a8\u4f5c\uff0c\u5f15\u5165\u8fd1\u4f3c\u8bef\u5dee\uff0c\u5bfc\u81f4\u8bef\u5dee\u7d2f\u79ef\u548c\u4e25\u91cd\u7684\u9ad8\u4f30\u95ee\u9898\u3002", "method": "\u6784\u9020\u4e00\u79cd\u65b0\u7684\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\uff0c\u901a\u8fc7\u6700\u5927\u5316Q\u51fd\u6570\u7684\u4e0b\u7f6e\u4fe1\u754c\u6765\u9009\u62e9\u52a8\u4f5c\u3002\u8be5\u7b56\u7565\u5728\u5b66\u4e60\u7b56\u7565\u9644\u8fd1\u8868\u73b0\u51fa\u76f8\u5bf9\u8f83\u9ad8\u7684\u4ef7\u503c\u548c\u8f83\u4f4e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u907f\u514d\u91c7\u6837\u5177\u6709\u6f5c\u5728\u9ad8\u8bef\u5dee\u7684\u9ad8\u4ef7\u503c\u52a8\u4f5c\u3002", "result": "\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528\u8be5\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u5176\u4ed6\u79bb\u7ebfRL\u65b9\u6cd5\u7684\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u901a\u8fc7\u51cf\u5c11\u8fd1\u4f3c\u8bef\u5dee\u7d2f\u79ef\uff0c\u4e3a\u6539\u5584\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6027\u80fd\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.23614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23614", "abs": "https://arxiv.org/abs/2602.23614", "authors": ["Kejing Yin", "Haizhou Xu", "Wenfang Yao", "Chen Liu", "Zijie Chen", "Yui Haang Cheung", "William K. Cheung", "Jing Qin"], "title": "When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion", "comment": null, "summary": "Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.", "code_url": "https://github.com/jakeykj/CareBench", "code_stars": 1, "code_last_update": "2026-02-11", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5\u5206\u6790\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55(EHR)\u4e0e\u80f8\u90e8X\u5149(CXR)\u591a\u6a21\u6001\u878d\u5408\u5728\u4e34\u5e8a\u9884\u6d4b\u4e2d\u7684\u5b9e\u9645\u6548\u679c\uff0c\u53d1\u73b0\u5728\u6a21\u6001\u5b8c\u6574\u65f6\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5728\u6a21\u6001\u7f3a\u5931\u548c\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u6548\u679c\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u53d1\u5e03\u4e86\u7075\u6d3b\u7684\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u5305CareBench\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7279\u522b\u662f\u5728\u6a21\u6001\u7f3a\u5931\u548c\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\uff0c\u591a\u6a21\u6001\u5b66\u4e60\u4f55\u65f6\u771f\u6b63\u6709\u6548\u4ecd\u4e0d\u660e\u786e\u3002\u4e3a\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u56de\u7b54\u56db\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u591a\u6a21\u6001\u878d\u5408\u4f55\u65f6\u80fd\u63d0\u5347\u4e34\u5e8a\u9884\u6d4b\u6027\u80fd\u3001\u4e0d\u540c\u878d\u5408\u7b56\u7565\u7684\u4f18\u52a3\u6bd4\u8f83\u3001\u73b0\u6709\u65b9\u6cd5\u5bf9\u7f3a\u5931\u6a21\u6001\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u6a21\u578b\u662f\u5426\u80fd\u591f\u5b9e\u73b0\u7b97\u6cd5\u516c\u5e73\u6027\u3002", "method": "\u7814\u7a76\u57fa\u4e8eMIMIC-IV\u548cMIMIC-CXR\u7684\u6807\u51c6\u5316\u961f\u5217\uff0c\u5bf9EHR\u4e0eCXR\u7684\u591a\u6a21\u6001\u878d\u5408\u8fdb\u884c\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u56de\u7b54\u4e0a\u8ff0\u56db\u4e2a\u6838\u5fc3\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1) \u591a\u6a21\u6001\u878d\u5408\u5728\u6a21\u6001\u5b8c\u6574\u65f6\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u589e\u76ca\u96c6\u4e2d\u5728\u9700\u8981EHR\u548cCXR\u4e92\u8865\u4fe1\u606f\u7684\u75be\u75c5\u4e0a\uff1b2) \u8de8\u6a21\u6001\u5b66\u4e60\u673a\u5236\u53ef\u6355\u6349\u8d85\u8d8a\u7b80\u5355\u62fc\u63a5\u7684\u4e34\u5e8a\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46EHR\u7684\u4e30\u5bcc\u65f6\u5e8f\u7ed3\u6784\u5bfc\u81f4\u663e\u8457\u7684\u6a21\u6001\u4e0d\u5e73\u8861\uff0c\u4ec5\u9760\u67b6\u6784\u590d\u6742\u6027\u65e0\u6cd5\u514b\u670d\uff1b3) \u5728\u771f\u5b9e\u7f3a\u5931\u573a\u666f\u4e0b\uff0c\u9664\u975e\u6a21\u578b\u663e\u5f0f\u8bbe\u8ba1\u4ee5\u5904\u7406\u4e0d\u5b8c\u6574\u8f93\u5165\uff0c\u5426\u5219\u591a\u6a21\u6001\u6536\u76ca\u8fc5\u901f\u8870\u51cf\uff1b4) \u591a\u6a21\u6001\u878d\u5408\u5e76\u4e0d\u80fd\u6539\u5584\u7b97\u6cd5\u516c\u5e73\u6027\uff0c\u4e9a\u7ec4\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7ec4\u95f4\u7684\u4e0d\u5747\u8861\u654f\u611f\u6027\uff1b5) \u7814\u7a76\u540c\u65f6\u53d1\u5e03\u4e86\u7075\u6d3b\u53ef\u63d2\u62d4\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u5305CareBench\uff0c\u652f\u6301\u65b0\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u96c6\u6210\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3\u591a\u6a21\u6001\u5b66\u4e60\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u660e\u786e\u4e86\u5176\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6709\u6548\u6027\u8fb9\u754c\u548c\u5931\u6548\u539f\u56e0\uff0c\u4e3a\u5f00\u53d1\u65e2\u6709\u6548\u53c8\u53ef\u9760\u7684\u4e34\u5e8a\u53ef\u90e8\u7f72\u591a\u6a21\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2602.24277", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24277", "abs": "https://arxiv.org/abs/2602.24277", "authors": ["Dake Zhang", "Mark D. Smucker", "Charles L. A. Clarke"], "title": "Resources for Automated Evaluation of Assistive RAG Systems that Help Readers with News Trustworthiness Assessment", "comment": null, "summary": "Many readers today struggle to assess the trustworthiness of online news because reliable reporting coexists with misinformation. The TREC 2025 DRAGUN (Detection, Retrieval, and Augmented Generation for Understanding News) Track provided a venue for researchers to develop and evaluate assistive RAG systems that support readers' news trustworthiness assessment by producing reader-oriented, well-attributed reports. As the organizers of the DRAGUN track, we describe the resources that we have newly developed to allow for the reuse of the track's tasks. The track had two tasks: (Task 1) Question Generation, producing 10 ranked investigative questions; and (Task 2, the main task) Report Generation, producing a 250-word report grounded in the MS MARCO V2.1 Segmented Corpus. As part of the track's evaluation, we had TREC assessors create importance-weighted rubrics of questions with expected short answers for 30 different news articles. These rubrics represent the information that assessors believe is important for readers to assess an article's trustworthiness. The assessors then used their rubrics to manually judge the participating teams' submitted runs. To make these tasks and their rubrics reusable, we have created an automated process to judge runs not part of the original assessing. We show that our AutoJudge ranks existing runs well compared to the TREC human-assessed evaluation (Kendall's $\u03c4= 0.678$ for Task 1 and $\u03c4= 0.872$ for Task 2). These resources enable both the evaluation of RAG systems for assistive news trustworthiness assessment and, with the human evaluation as a benchmark, research on improving automated RAG evaluation.", "AI": {"tldr": "TREC 2025 DRAGUN\u4efb\u52a1\u5f00\u53d1\u4e86\u53ef\u91cd\u7528\u7684\u8d44\u6e90\uff08\u4e24\u4e2a\u4efb\u52a1\u3001\u8bc4\u4f30\u91cf\u8868\u548c\u81ea\u52a8\u8bc4\u5224\u7cfb\u7edf\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u5e2e\u52a9\u8bfb\u8005\u5224\u65ad\u65b0\u95fb\u53ef\u4fe1\u5ea6\u7684RAG\u7cfb\u7edf\uff0c\u7ed3\u679c\u663e\u793a\u81ea\u52a8\u8bc4\u5224\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u5177\u6709\u8f83\u5f3a\u76f8\u5173\u6027\uff08\u03c4>0.67\uff09\u3002", "motivation": "\u9762\u5bf9\u5728\u7ebf\u65b0\u95fb\u4e2d\u53ef\u9760\u62a5\u9053\u4e0e\u865a\u5047\u4fe1\u606f\u6df7\u6742\u7684\u6311\u6218\uff0c\u672c\u6587\u901a\u8fc7\u7ec4\u7ec7TREC 2025 DRAGUN\u4efb\u52a1\uff0c\u65e8\u5728\u5f00\u53d1\u548c\u8bc4\u4f30\u80fd\u591f\u751f\u6210\u9762\u5411\u8bfb\u8005\u4e14\u5145\u5206\u5f15\u8bc1\u7684\u8f85\u52a9\u6027RAG\u7cfb\u7edf\uff0c\u4ee5\u5e2e\u52a9\u8bfb\u8005\u51c6\u786e\u8bc4\u4f30\u65b0\u95fb\u53ef\u4fe1\u5ea6\u3002", "method": "\u672c\u6587\u4f5c\u4e3aDRAGUN\u4efb\u52a1\u7684\u7ec4\u7ec7\u8005\uff0c\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u6838\u5fc3\u4efb\u52a1\uff1a\u4efb\u52a11\uff08\u95ee\u9898\u751f\u6210\uff09\u8981\u6c42\u751f\u621010\u4e2a\u6392\u5e8f\u7684\u8c03\u67e5\u6027\u95ee\u9898\uff1b\u4efb\u52a12\uff08\u62a5\u544a\u751f\u6210\uff09\u57fa\u4e8eMS MARCO V2.1\u8bed\u6599\u5e93\u751f\u6210250\u5b57\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u62a5\u544a\u3002\u901a\u8fc7TREC\u8bc4\u4f30\u5458\u4e3a30\u7bc7\u65b0\u95fb\u6587\u7ae0\u6784\u5efa\u4e86\u91cd\u8981\u6027\u52a0\u6743\u8bc4\u4f30\u91cf\u8868\uff0c\u5e76\u5f00\u53d1\u4e86AutoJudge\u81ea\u52a8\u5316\u8bc4\u5224\u6d41\u7a0b\u8fdb\u884c\u7ed3\u679c\u8bc4\u4f30\u3002", "result": "\u81ea\u52a8\u8bc4\u5224\u7cfb\u7edfAutoJudge\u7684\u6392\u5e8f\u7ed3\u679c\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5176\u4e2d\u4efb\u52a11\u7684Kendall's \u03c4\u7cfb\u6570\u4e3a0.678\uff0c\u4efb\u52a12\u8fbe\u52300.872\u3002\u6210\u529f\u521b\u5efa\u4e86\u53ef\u590d\u7528\u7684\u4efb\u52a1\u6846\u67b6\u3001\u8bc4\u4f30\u57fa\u51c6\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u5de5\u5177\uff0c\u4e3aRAG\u7cfb\u7edf\u8bc4\u4f30\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u8d44\u6e90\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u8f85\u52a9\u65b0\u95fb\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u65b9\u6848\uff0c\u66f4\u4ee5\u4eba\u5de5\u8bc4\u4f30\u4e3a\u91d1\u6807\u51c6\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316RAG\u8bc4\u4f30\u65b9\u6cd5\u7684\u7814\u7a76\uff0c\u5bf9\u63d0\u5347\u65b0\u95fb\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u6280\u672f\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.23940", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23940", "abs": "https://arxiv.org/abs/2602.23940", "authors": ["Nischal Karki", "Bipesh Subedi", "Prakash Poudyal", "Rupak Raj Ghimire", "Bal Krishna Bal"], "title": "Benchmarking BERT-based Models for Sentence-level Topic Classification in Nepali Language", "comment": "5 pages, 2 figures. Accepted and presented at the Regional International Conference on Natural Language Processing (RegICON 2025), Gauhati University, Guwahati, India, November 27-29, 2025. To appear in the conference proceedings. Accepted papers list available at: https://www.regicon2025.in/accepted-papers", "summary": "Transformer-based models such as BERT have significantly advanced Natural Language Processing (NLP) across many languages. However, Nepali, a low-resource language written in Devanagari script, remains relatively underexplored. This study benchmarks multilingual, Indic, Hindi, and Nepali BERT variants to evaluate their effectiveness in Nepali topic classification. Ten pre-trained models, including mBERT, XLM-R, MuRIL, DevBERT, HindiBERT, IndicBERT, and NepBERTa, were fine-tuned and tested on the balanced Nepali dataset containing 25,006 sentences across five conceptual domains and the performance was evaluated using accuracy, weighted precision, recall, F1-score, and AUROC metrics. The results reveal that Indic models, particularly MuRIL-large, achieved the highest F1-score of 90.60%, outperforming multilingual and monolingual models. NepBERTa also performed competitively with an F1-score of 88.26%. Overall, these findings establish a robust baseline for future document-level classification and broader Nepali NLP applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f3010\u79cdBERT\u53d8\u4f53\u572825,006\u53e5\u4e94\u7c7b\u5c3c\u6cca\u5c14\u8bed\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002Indic\u6a21\u578bMuRIL-large\u4ee590.60%\u7684F1\u5206\u6570\u6700\u4f18\uff0cNepBERTa\u6b21\u4e4b\uff0888.26%\uff09\uff0c\u4e3a\u5c3c\u6cca\u5c14\u8bedNLP\u5efa\u7acb\u4e86\u53ef\u9760\u57fa\u7ebf\u3002", "motivation": "\u5c3c\u6cca\u5c14\u8bed\u4f5c\u4e3a\u5929\u57ce\u6587\u4e66\u5199\u7cfb\u7edf\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u5728NLP\u9886\u57df\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u5c3d\u7ba1\u57fa\u4e8eTransformer\u7684\u591a\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5c3c\u6cca\u5c14\u8bed\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u5728\u5305\u542b25,006\u4e2a\u53e5\u5b50\u7684\u5e73\u8861\u5c3c\u6cca\u5c14\u8bed\u6570\u636e\u96c6\uff08\u6db5\u76d65\u4e2a\u4e3b\u9898\u57df\uff09\u4e0a\uff0c\u5bf9mBERT\u3001XLM-R\u3001MuRIL\u3001DevBERT\u3001HindiBERT\u3001IndicBERT\u548cNepBERTa\u7b4910\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u91c7\u7528\u51c6\u786e\u7387\u3001\u52a0\u6743\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cAUROC\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u3002", "result": "Indic\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u591a\u8bed\u8a00\u548c\u5355\u8bed\u6a21\u578b\uff0c\u5176\u4e2dMuRIL-large\u53d6\u5f97\u6700\u9ad8F1\u5206\u657090.60%\u3002\u4e13\u4e3a\u5c3c\u6cca\u5c14\u8bed\u8bbe\u8ba1\u7684NepBERTa\u8868\u73b0\u540c\u6837\u51fa\u8272\uff0cF1\u5206\u6570\u8fbe\u523088.26%\u3002\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6027\u80fd\u57fa\u51c6\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5c3c\u6cca\u5c14\u8bed\u4e3b\u9898\u5206\u7c7b\u5efa\u7acb\u4e86\u5f3a\u6709\u529b\u7684\u57fa\u7ebf\uff0c\u8bc1\u660e\u57fa\u4e8e\u5370\u5ea6\u8bed\u6599\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\u3002\u6210\u679c\u5c06\u4fc3\u8fdb\u672a\u6765\u6587\u6863\u7ea7\u5206\u7c7b\u53ca\u66f4\u5e7f\u6cdb\u7684\u5c3c\u6cca\u5c14\u8bedNLP\u5e94\u7528\uff0c\u5e76\u4e3a\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u7814\u7a76\u63d0\u4f9b\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2602.24037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24037", "abs": "https://arxiv.org/abs/2602.24037", "authors": ["Vanya Priscillia Bendatu", "Yao Lu"], "title": "Portfolio Reinforcement Learning with Scenario-Context Rollout", "comment": null, "summary": "Market regime shifts induce distribution shifts that can degrade the performance of portfolio rebalancing policies. We propose macro-conditioned scenario-context rollout (SCR) that generates plausible next-day multivariate return scenarios under stress events. However, doing so faces new challenges, as history will never tell what would have happened differently. As a result, incorporating scenario-based rewards from rollouts introduces a reward--transition mismatch in temporal-difference learning, destabilizing RL critic training.\n  We analyze this inconsistency and show it leads to a mixed evaluation target. Guided by this analysis, we construct a counterfactual next state using the rollout-implied continuations and augment the critic agent's bootstrap target. Doing so stabilizes the learning and provides a viable bias-variance tradeoff.\n  In out-of-sample evaluations across 31 distinct universes of U.S. equity and ETF portfolios, our method improves Sharpe ratio by up to 76% and reduces maximum drawdown by up to 53% compared with classic and RL-based portfolio rebalancing baselines.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5e02\u573a\u5236\u5ea6\u8f6c\u6362\u5bfc\u81f4\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u51fa\u5b8f\u89c2\u6761\u4ef6\u5316\u60c5\u666f\u4e0a\u4e0b\u6587\u5c55\u5f00\uff08SCR\uff09\u65b9\u6cd5\u751f\u6210\u538b\u529b\u60c5\u666f\u4e0b\u7684\u6b21\u65e5\u591a\u5143\u6536\u76ca\u60c5\u666f\u3002\u901a\u8fc7\u5206\u6790\u5e76\u89e3\u51b3\u65f6\u5e8f\u5dee\u5206\u5b66\u4e60\u4e2d\u7684\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u6784\u5efa\u53cd\u4e8b\u5b9e\u4e0b\u4e00\u72b6\u6001\u7a33\u5b9aRL\u8bc4\u8bba\u5bb6\u8bad\u7ec3\uff0c\u572831\u4e2a\u7f8e\u80a1\u548cETF\u6295\u8d44\u7ec4\u5408\u7684\u6837\u672c\u5916\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u590f\u666e\u6bd4\u7387\u6700\u9ad8\u63d0\u534776%\u3001\u6700\u5927\u56de\u64a4\u6700\u9ad8\u964d\u4f4e53%\u7684\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u5e02\u573a\u5236\u5ea6\u8f6c\u6362\u5f15\u53d1\u5206\u5e03\u504f\u79fb\uff0c\u5bfc\u81f4\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u7b56\u7565\u6027\u80fd\u9000\u5316\u3002\u5386\u53f2\u6570\u636e\u65e0\u6cd5\u63d0\u4f9b\u53cd\u4e8b\u5b9e\u60c5\u666f\uff0c\u4f7f\u5f97\u57fa\u4e8e\u60c5\u666f\u5316\u5956\u52b1\u7684\u65f6\u5e8f\u5dee\u5206\u5b66\u4e60\u51fa\u73b0\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u8fdb\u800c destabilizing RL critic training\u3002", "method": "\u63d0\u51fa\u5b8f\u89c2\u6761\u4ef6\u5316\u60c5\u666f\u4e0a\u4e0b\u6587\u5c55\u5f00\uff08SCR\uff09\u751f\u6210\u538b\u529b\u4e8b\u4ef6\u4e0b\u7684\u5408\u7406\u6536\u76ca\u60c5\u666f\uff1b\u5206\u6790\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u5bfc\u81f4\u6df7\u5408\u8bc4\u4f30\u76ee\u6807\u7684\u95ee\u9898\uff1b\u6784\u5efa\u57fa\u4e8e\u5c55\u5f00\u7ed3\u679c\u7684\u53cd\u4e8b\u5b9e\u4e0b\u4e00\u72b6\u6001\uff0c\u589e\u5f3a\u8bc4\u8bba\u5bb6\u667a\u80fd\u4f53\u7684bootstrap\u76ee\u6807\uff0c\u5b9e\u73b0\u7a33\u5b9a\u5b66\u4e60\u548c\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002", "result": "\u572831\u4e2a\u4e0d\u540c\u7684\u7f8e\u56fd\u80a1\u7968\u548cETF\u6295\u8d44\u7ec4\u5408\u6837\u672c\u5916\u8bc4\u4f30\u4e2d\uff0c\u76f8\u6bd4\u7ecf\u5178\u548cRL-based\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u590f\u666e\u6bd4\u7387\u63d0\u5347\u6700\u9ad8\u8fbe76%\uff0c\u6700\u5927\u56de\u64a4\u964d\u4f4e\u6700\u9ad8\u8fbe53%\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u60c5\u666f\u5316\u5956\u52b1\u5f15\u5165\u7684\u5185\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u5e94\u5bf9\u4e86\u5e02\u573a\u5236\u5ea6\u8f6c\u6362\u6311\u6218\uff0c\u4e3a\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u63d0\u4f9b\u4e86\u7a33\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5728\u5b9e\u9645\u5e02\u573a\u4e2d\u9a8c\u8bc1\u4e86\u663e\u8457\u7684\u98ce\u9669\u8c03\u6574\u540e\u6536\u76ca\u6539\u8fdb\u3002"}}
{"id": "2602.23941", "categories": ["cs.CL", "cs.DL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23941", "abs": "https://arxiv.org/abs/2602.23941", "authors": ["Ludovic Moncla", "Pierre Nugues", "Thierry Joliveau", "Katherine McDonough"], "title": "EDDA-Coordinata: An Annotated Dataset of Historical Geographic Coordinates", "comment": "Accepted at LREC 2026", "summary": "This paper introduces a dataset of enriched geographic coordinates retrieved from Diderot and d'Alembert's eighteenth-century Encyclopedie. Automatically recovering geographic coordinates from historical texts is a complex task, as they are expressed in a variety of ways and with varying levels of precision. To improve retrieval of coordinates from similar digitized early modern texts, we have created a gold standard dataset, trained models, published the resulting inferred and normalized coordinate data, and experimented applying these models to new texts. From 74,000 total articles in each of the digitized versions of the Encyclopedie from ARTFL and ENCCRE, we examined 15,278 geographical entries, manually identifying 4,798 containing coordinates, and 10,480 with descriptive but non-numerical references. Leveraging our gold standard annotations, we trained transformer-based models to retrieve and normalize coordinates. The pipeline presented here combines a classifier to identify coordinate-bearing entries and a second model for retrieval, tested across encoder-decoder and decoder architectures. Cross-validation yielded an 86% EM score. On an out-of-domain eighteenth-century Trevoux dictionary (also in French), our fine-tuned model had a 61% EM score, while for the nineteenth-century, 7th edition of the Encyclopaedia Britannica in English, the EM was 77%. These findings highlight the gold standard dataset's usefulness as training data, and our two-step method's cross-lingual, cross-domain generalizability.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e8618\u4e16\u7eaa\u300a\u767e\u79d1\u5168\u4e66\u300b\u5730\u7406\u5750\u6807\u7684\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u4e24\u6b65\u6d41\u6c34\u7ebf\u6a21\u578b\uff0c\u5b9e\u73b0\u5750\u6807\u81ea\u52a8\u8bc6\u522b\u4e0e\u6807\u51c6\u5316\uff0c\u5728\u8de8\u8bed\u8a00\u8de8\u9886\u57df\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5386\u53f2\u6587\u732e\u4e2d\u7684\u5730\u7406\u5750\u6807\u8868\u8fbe\u65b9\u5f0f\u591a\u6837\u4e14\u7cbe\u5ea6\u4e0d\u4e00\uff0c\u81ea\u52a8\u63d0\u53d6\u56f0\u96be\u3002\u4e3a\u63d0\u5347\u65e9\u671f\u73b0\u4ee3\u6570\u5b57\u5316\u6587\u672c\u7684\u5750\u6807\u68c0\u7d22\u6548\u679c\uff0c\u9700\u5efa\u7acb\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u5e76\u5f00\u53d1\u9c81\u68d2\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u4ece74,000\u7bc7\u6570\u5b57\u5316\u6587\u7ae0\u4e2d\u6807\u6ce815,278\u6761\u5730\u7406\u6761\u76ee\uff084,798\u6761\u542b\u5750\u6807\uff09\uff0c\u6784\u5efa\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u5148\u8bad\u7ec3\u5206\u7c7b\u5668\u8bc6\u522b\u542b\u5750\u6807\u6761\u76ee\uff0c\u518d\u7528\u68c0\u7d22\u6a21\u578b\u63d0\u53d6\u5e76\u5f52\u4e00\u5316\u5750\u6807\uff1b\u6d4b\u8bd5\u4e86\u7f16\u7801-\u89e3\u7801\u548c\u89e3\u7801\u67b6\u6784\u7684Transformer\u6a21\u578b\u3002", "result": "\u4ea4\u53c9\u9a8c\u8bc1\u8fbe\u523086%\u7684\u7cbe\u786e\u5339\u914d\u5206\u6570\uff1b\u572818\u4e16\u7eaa\u6cd5\u8bedTrevoux\u8bcd\u5178\u4e0a\u5f97\u5206\u4e3a61%\uff1b\u572819\u4e16\u7eaa\u82f1\u8bed\u300a\u5927\u82f1\u767e\u79d1\u5168\u4e66\u300b\u7b2c\u4e03\u7248\u4e0a\u5f97\u5206\u4e3a77%\uff0c\u8bc1\u660e\u6a21\u578b\u5177\u6709\u8de8\u8bed\u8a00\u3001\u8de8\u9886\u57df\u6cdb\u5316\u6027\u3002", "conclusion": "\u91d1\u6807\u51c6\u6570\u636e\u96c6\u4e3a\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6491\uff0c\u4e24\u6b65\u6cd5\u5728\u8de8\u8bed\u8a00\u548c\u8de8\u9886\u57df\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2602.24055", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24055", "abs": "https://arxiv.org/abs/2602.24055", "authors": ["Reva Schwartz", "Carina Westling", "Morgan Briggs", "Marzieh Fadaee", "Isar Nejadgholi", "Matthew Holmes", "Fariza Rashid", "Maya Carlyle", "Afaf Ta\u00efk", "Kyra Wilson", "Peter Douglas", "Theodora Skeadas", "Gabriella Waters", "Rumman Chowdhury", "Thiago Lacerda"], "title": "CIRCLE: A Framework for Evaluating AI from a Real-World Lens", "comment": "Accepted at Intelligent Systems Conference (IntelliSys) 2026", "summary": "This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCIRCLE\u6846\u67b6\uff0c\u4e00\u4e2a\u516d\u9636\u6bb5\u7684\u57fa\u4e8e\u751f\u547d\u5468\u671f\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5f25\u5408\u6a21\u578b\u4e2d\u5fc3\u6027\u80fd\u6307\u6807\u4e0eAI\u90e8\u7f72\u5b9e\u9645\u6548\u679c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u5c06\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u4fe1\u53f7\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5b9e\u9645\u4e0b\u6e38\u5f71\u54cd\u7684\u6cbb\u7406\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u5982MLOps\u5173\u6ce8\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u57fa\u51c6\u6d4b\u8bd5\u8861\u91cf\u62bd\u8c61\u80fd\u529b\uff0c\u4f46AI\u6280\u672f\u6808\u5916\u7684\u51b3\u7b56\u8005\u7f3a\u4e4f\u5173\u4e8eAI\u5728\u771f\u5b9e\u4e16\u754c\u7528\u6237\u53d8\u5316\u548c\u7ea6\u675f\u4e0b\u884c\u4e3a\u7684\u7cfb\u7edf\u8bc1\u636e\u3002\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u548c\u7b97\u6cd5\u5ba1\u8ba1\u5206\u522b\u5b58\u5728\u5c40\u90e8\u6027\u548c\u56de\u987e\u6027\u5c40\u9650\u3002", "method": "CIRCLE\u6846\u67b6\u901a\u8fc7\u516d\u9636\u6bb5\u751f\u547d\u5468\u671f\u65b9\u6cd5\uff0c\u5c06TEVV\u4e2d\u7684\u9a8c\u8bc1\u9636\u6bb5\u64cd\u4f5c\u5316\uff0c\u5f62\u5f0f\u5316\u5730\u5c06\u6280\u672f\u6808\u5916\u7684\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u4fe1\u53f7\u3002\u6574\u5408\u5b9e\u5730\u6d4b\u8bd5\u3001\u7ea2\u961f\u6f14\u7ec3\u548c\u7eb5\u5411\u7814\u7a76\u7b49\u65b9\u6cd5\uff0c\u5f62\u6210\u534f\u8c03\u6d41\u6c34\u7ebf\u3002", "result": "\u4ea7\u751f\u7cfb\u7edf\u6027\u77e5\u8bc6\uff1a\u65e2\u80fd\u5728\u4e0d\u540c\u573a\u666f\u95f4\u8fdb\u884c\u6bd4\u8f83\uff0c\u53c8\u5bf9\u672c\u5730\u60c5\u5883\u654f\u611f\u3002\u4e3a\u6cbb\u7406\u63d0\u4f9b\u57fa\u4e8e\u5b9e\u9645\u4e0b\u6e38\u5f71\u54cd\u800c\u975e\u7406\u8bba\u80fd\u529b\u7684\u8bc1\u636e\u652f\u6301\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7fAI\u6cbb\u7406\u80fd\u591f\u57fa\u4e8e\u5b9e\u9645\u90e8\u7f72\u6548\u679c\u800c\u975e\u7406\u8bba\u6027\u80fd\uff0c\u63d0\u4f9b\u66f4\u524d\u77bb\u6027\u3001\u7ed3\u6784\u5316\u7684\u534f\u8bae\u6765\u8fde\u63a5\u60c5\u5883\u654f\u611f\u7684\u5b9a\u6027\u6d1e\u5bdf\u4e0e\u53ef\u6269\u5c55\u7684\u5b9a\u91cf\u6307\u6807\u3002"}}
{"id": "2602.23633", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23633", "abs": "https://arxiv.org/abs/2602.23633", "authors": ["Yubo Zhou", "Luo Luo", "Guang Dai", "Haishan Ye"], "title": "On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation", "comment": null, "summary": "Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $\u03ba$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $\u03b5$-stationary point with an oracle complexity of $\\mathcal{O}(\u03ba^7 \u03b5^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\\mathcal{O}(\u03b5^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $\u03ba$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u5355\u5faa\u73af\u968f\u673a\u8fd1\u4f3c\u9690\u5f0f\u5fae\u5206\uff08SSAID\uff09\u7b97\u6cd5\u8fdb\u884c\u7cbe\u7ec6\u5316\u6536\u655b\u5206\u6790\uff0c\u8bc1\u660e\u5176\u5728O(\u03ba^7 \u03b5^{-2})\u7684Oracle\u590d\u6742\u5ea6\u4e0b\u80fd\u591f\u8fbe\u5230\u03b5-\u9a7b\u70b9\uff0c\u65e2\u5339\u914d\u591a\u5faa\u73af\u65b9\u6cd5\u7684\u6700\u4f18\u6536\u655b\u901f\u7387\uff0c\u53c8\u9996\u6b21\u663e\u5f0f\u63ed\u793a\u4e86\u6761\u4ef6\u6570\u03ba\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u968f\u673a\u53cc\u5c42\u4f18\u5316\u662f\u5143\u5b66\u4e60\u548c\u8d85\u53c2\u6570\u4f18\u5316\u7684\u6838\u5fc3\u6846\u67b6\uff0c\u5355\u5faa\u73af\u7b97\u6cd5\u867d\u5728\u5b9e\u9645\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u7406\u8bba\u7406\u89e3\u5c24\u5176\u5728\u968f\u673a\u60c5\u51b5\u4e0b\u76f8\u5bf9\u6ede\u540e\u3002\u73b0\u6709\u5206\u6790\u5f80\u5f80\u6536\u655b\u901f\u7387\u6b21\u4f18\uff0c\u6216\u5c06\u5173\u952e\u7684\u4e0b\u5c42\u6761\u4ef6\u6570\u03ba\u9690\u85cf\u5728Lipschitz\u5e38\u6570\u4e2d\uff0c\u672a\u80fd\u663e\u5f0f\u523b\u753b\u5176\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7cbe\u7ec6\u7684\u6982\u7387\u5206\u6790\u3001\u968f\u673a\u8fd1\u4f3c\u6280\u672f\u4ee5\u53ca\u9690\u51fd\u6570\u5b9a\u7406\uff0c\u9488\u5bf9SSAID\u7b97\u6cd5\u63a8\u5bfc\u51fa\u6536\u655b\u4e0a\u754c\uff0c\u5e76\u663e\u5f0f\u5206\u79bb\u51fa\u03ba\u7684\u5e42\u6b21\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0cSSAID\u5728O(\u03ba^7 \u03b5^{-2})\u7684Oracle\u590d\u6742\u5ea6\u4e0b\u8fbe\u5230\u03b5-\u9a7b\u70b9\u3002\u8fd9\u4e00\u7ed3\u679c\u9996\u6b21\u5728\u968f\u673aAID-based\u5355\u5faa\u73af\u65b9\u6cd5\u4e2d\u7ed9\u51fa\u03ba\u7684\u663e\u5f0f\u3001\u7ec6\u7c92\u5ea6\u523b\u753b\uff0c\u5e76\u4e14\u5176\u03b5^{-2}\u7684\u901f\u7387\u4e0e\u6700\u5148\u8fdb\u7684\u591a\u5faa\u73af\u65b9\u6cd5\uff08\u5982stocBiO\uff09\u76f8\u5339\u914d\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660eSSAID\u4e0d\u4ec5\u662f\u4e00\u79cd\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u66f4\u5177\u5907\u4e25\u683c\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u5176\u6536\u655b\u6027\u80fd\u53ef\u4e0e\u4e3b\u6d41\u591a\u5faa\u73af\u6846\u67b6\u76f8\u5ab2\u7f8e\uff0c\u4e3a\u5355\u5faa\u73af\u7b97\u6cd5\u5728\u968f\u673a\u53cc\u5c42\u4f18\u5316\u4e2d\u7684\u7406\u8bba\u7406\u89e3\u548c\u5e94\u7528\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.23944", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23944", "abs": "https://arxiv.org/abs/2602.23944", "authors": ["Peng Liu", "Zhen Tao", "Jihao Zhao", "Ding Chen", "Yansong Zhang", "Cuiping Li", "Zhiyu Li", "Hong Chen"], "title": "MemEmo: Evaluating Emotion in Memory Systems of Agents", "comment": null, "summary": "Memory systems address the challenge of context loss in Large Language Model during prolonged interactions. However, compared to human cognition, the efficacy of these systems in processing emotion-related information remains inconclusive. To address this gap, we propose an emotion-enhanced memory evaluation benchmark to assess the performance of mainstream and state-of-the-art memory systems in handling affective information. We developed the \\textbf{H}uman-\\textbf{L}ike \\textbf{M}emory \\textbf{E}motion (\\textbf{HLME}) dataset, which evaluates memory systems across three dimensions: emotional information extraction, emotional memory updating, and emotional memory question answering. Experimental results indicate that none of the evaluated systems achieve robust performance across all three tasks. Our findings provide an objective perspective on the current deficiencies of memory systems in processing emotional memories and suggest a new trajectory for future research and system optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u4e2d\u60c5\u611f\u8bb0\u5fc6\u5904\u7406\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u60c5\u611f\u589e\u5f3a\u7684\u8bb0\u5fc6\u8bc4\u4f30\u57fa\u51c6HLME\uff0c\u4ece\u60c5\u611f\u4fe1\u606f\u63d0\u53d6\u3001\u8bb0\u5fc6\u66f4\u65b0\u548c\u95ee\u7b54\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u53d1\u73b0\u65e0\u4e00\u7cfb\u7edf\u80fd\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bb0\u5fc6\u7cfb\u7edf\u867d\u80fd\u7f13\u89e3\u957f\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u4e22\u5931\u95ee\u9898\uff0c\u4f46\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u76f8\u6bd4\uff0c\u5176\u5728\u60c5\u611f\u76f8\u5173\u4fe1\u606f\u5904\u7406\u65b9\u9762\u7684\u6548\u80fd\u5c1a\u4e0d\u660e\u786e\uff0c\u5b58\u5728\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u60c5\u611f\u589e\u5f3a\u7684\u8bb0\u5fc6\u8bc4\u4f30\u57fa\u51c6\uff0c\u5f00\u53d1\u4eba\u7c7b\u76f8\u4f3c\u8bb0\u5fc6\u60c5\u611f\uff08HLME\uff09\u6570\u636e\u96c6\uff0c\u4ece\u60c5\u611f\u4fe1\u606f\u63d0\u53d6\u3001\u60c5\u611f\u8bb0\u5fc6\u66f4\u65b0\u548c\u60c5\u611f\u8bb0\u5fc6\u95ee\u7b54\u4e09\u4e2a\u7ef4\u5ea6\u5bf9\u4e3b\u6d41\u53ca\u5148\u8fdb\u8bb0\u5fc6\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u8bc4\u4f30\u7684\u8bb0\u5fc6\u7cfb\u7edf\u5728\u5168\u90e8\u4e09\u9879\u4efb\u52a1\u4e0a\u5747\u672a\u80fd\u5b9e\u73b0\u7a33\u5065\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u5728\u60c5\u611f\u8bb0\u5fc6\u5904\u7406\u65b9\u9762\u7684\u6839\u672c\u7f3a\u9677\u3002", "conclusion": "\u7814\u7a76\u5ba2\u89c2\u6307\u51fa\u4e86\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u5728\u60c5\u611f\u8bb0\u5fc6\u5904\u7406\u4e0a\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u7cfb\u7edf\u4f18\u5316\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.24080", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.24080", "abs": "https://arxiv.org/abs/2602.24080", "authors": ["Xiang Li", "Jiabao Gao", "Sipei Lin", "Xuan Zhou", "Chi Zhang", "Bo Cheng", "Jiale Han", "Benyou Wang"], "title": "Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction", "comment": "Accepted by ICLR 2026 Conference", "summary": "The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5bf9\u8bed\u97f3\u5230\u8bed\u97f3(S2S)\u7cfb\u7edf\u8fdb\u884c\u4e86\u56fe\u7075\u6d4b\u8bd5\uff0c\u6536\u96c6\u4e862,968\u6761\u4eba\u5de5\u8bc4\u5224\uff0c\u53d1\u73b0\u73b0\u6709\u7cfb\u7edf\u5747\u672a\u901a\u8fc7\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u4eba\u673a\u5bf9\u8bdd\u7684\u81ea\u7136\u5ea6\u5dee\u8ddd\u3002\u7814\u7a76\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e8618\u7ef4\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u4f53\u7cfb\uff0c\u8bca\u65ad\u51fa\u74f6\u9888\u5728\u4e8e\u526f\u8bed\u8a00\u5b66\u7279\u5f81\u3001\u60c5\u611f\u8868\u8fbe\u548c\u5bf9\u8bdd\u4eba\u683c\uff0c\u5e76\u63d0\u51fa\u53ef\u89e3\u91ca\u6a21\u578b\u5b9e\u73b0\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "motivation": "\u53d7\u56fe\u7075\u6d4b\u8bd5\u542f\u53d1\uff0c\u7814\u7a76\u73b0\u4ee3\u8bed\u97f3\u5230\u8bed\u97f3\u7cfb\u7edf\u662f\u5426\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u81ea\u7136\u5bf9\u8bdd\uff0c\u4ee5\u8bc4\u4f30\u5f53\u524d\u5bf9\u8bdd\u5f0fAI\u7684\u771f\u5b9e\u6c34\u5e73\u5e76\u8bc6\u522b\u6539\u8fdb\u65b9\u5411\u3002", "method": "\u9996\u6b21\u5bf99\u4e2a\u5148\u8fdbS2S\u7cfb\u7edf\u548c28\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u8fdb\u884c\u56fe\u7075\u6d4b\u8bd5\uff0c\u6536\u96c62,968\u6761\u4eba\u5de5\u8bc4\u5224\uff1b\u6784\u5efa\u5305\u542b18\u4e2a\u4eba\u7c7b\u76f8\u4f3c\u6027\u7ef4\u5ea6\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4f53\u7cfb\u5e76\u5bf9\u5bf9\u8bdd\u8fdb\u884c\u4f17\u5305\u6807\u6ce8\uff1b\u5f00\u53d1\u53ef\u89e3\u91ca\u6a21\u578b\u5229\u7528\u7ec6\u7c92\u5ea6\u8bc4\u5206\u8fdb\u884c\u4eba\u673a\u5224\u522b\u3002", "result": "\u6240\u6709\u88ab\u8bc4\u4f30\u7684S2S\u7cfb\u7edf\u5747\u672a\u901a\u8fc7\u56fe\u7075\u6d4b\u8bd5\uff1b\u74f6\u9888\u4e0d\u5728\u4e8e\u8bed\u4e49\u7406\u89e3\uff0c\u800c\u5728\u4e8e\u526f\u8bed\u8a00\u5b66\u7279\u5f81\u3001\u60c5\u611f\u8868\u8fbe\u80fd\u529b\u548c\u5bf9\u8bdd\u4eba\u683c\uff1b\u73b0\u6210AI\u6a21\u578b\u4f5c\u4e3a\u56fe\u7075\u6d4b\u8bd5\u8bc4\u5224\u8005\u8868\u73b0\u4e0d\u53ef\u9760\uff1b\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u6a21\u578b\u80fd\u5b9e\u73b0\u51c6\u786e\u900f\u660e\u7684\u4eba\u673a\u5224\u522b\u3002", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u9996\u4e2aS2S\u7cfb\u7edf\u4eba\u7c7b\u76f8\u4f3c\u6027\u8bc4\u4f30\u57fa\u51c6\uff0c\u8d85\u8d8a\u4e8c\u5143\u7ed3\u679c\u63d0\u4f9b\u8be6\u7ec6\u8bca\u65ad\u6d1e\u5bdf\uff0c\u4e3a\u63d0\u5347\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u7c7b\u4eba\u6027\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2602.23636", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23636", "abs": "https://arxiv.org/abs/2602.23636", "authors": ["Zhihao Ding", "Jinming Li", "Ze Lu", "Jieming Shi"], "title": "FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation", "comment": null, "summary": "Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.", "AI": {"tldr": "\u9488\u5bf9LLM\u5185\u5bb9\u5b89\u5168\u5ba1\u6838\u4e2d\u4e25\u683c\u5ea6\u5b9a\u4e49\u56fa\u5b9a\u5bfc\u81f4\u7684\u6a21\u578b\u8106\u5f31\u6027\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faFlexGuard\u2014\u2014\u4e00\u79cd\u8f93\u51fa\u8fde\u7eed\u98ce\u9669\u5206\u6570\u7684LLM\u5ba1\u6838\u5668\uff0c\u901a\u8fc7\u98ce\u9669\u5bf9\u9f50\u4f18\u5316\u548c\u9608\u503c\u9009\u62e9\u7b56\u7565\u5b9e\u73b0\u4e25\u683c\u5ea6\u81ea\u9002\u5e94\uff0c\u5728FlexBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4e8c\u5143\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709LLM\u62a4\u680f\u6a21\u578b\u5c06\u5185\u5bb9\u5ba1\u6838\u7b80\u5316\u4e3a\u56fa\u5b9a\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\uff0c\u9690\u542b\u5047\u8bbe\u5371\u5bb3\u6027\u5b9a\u4e49\u662f\u9759\u6001\u4e0d\u53d8\u7684\u3002\u7136\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5ba1\u6838\u4e25\u683c\u5ea6\u56e0\u5e73\u53f0\u800c\u5f02\u4e14\u968f\u65f6\u95f4\u6f14\u53d8\uff0c\u5bfc\u81f4\u4e8c\u5143\u5ba1\u6838\u5668\u5728\u9762\u5bf9\u53d8\u5316\u7684\u5ba1\u6838\u8981\u6c42\u65f6\u8868\u73b0\u8106\u5f31\uff0c\u4e9f\u9700\u80fd\u591f\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u4e25\u683c\u5ea6\u6807\u51c6\u7684\u5ba1\u6838\u65b9\u6848\u3002", "method": "1) \u6784\u5efaFlexBench\u57fa\u51c6\uff0c\u652f\u6301\u591a\u4e25\u683c\u5ea6\u4f53\u7cfb\u4e0b\u7684\u53ef\u63a7\u8bc4\u4f30\uff1b2) \u63d0\u51faFlexGuard\u5ba1\u6838\u5668\uff0c\u8f93\u51fa\u6821\u51c6\u7684\u8fde\u7eed\u98ce\u9669\u5206\u6570\u53cd\u6620\u98ce\u9669\u4e25\u91cd\u6027\uff0c\u901a\u8fc7\u9608\u503c\u5316\u5b9e\u73b0\u7279\u5b9a\u4e25\u683c\u5ea6\u51b3\u7b56\uff1b3) \u91c7\u7528\u98ce\u9669\u5bf9\u9f50\u4f18\u5316\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u5206\u6570-\u4e25\u91cd\u6027\u4e00\u81f4\u6027\uff1b4) \u63d0\u4f9b\u90e8\u7f72\u65f6\u53ef\u7528\u7684\u9608\u503c\u9009\u62e9\u7b56\u7565\u4ee5\u9002\u5e94\u76ee\u6807\u4e25\u683c\u5ea6\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u73b0\u6709\u5ba1\u6838\u5668\u5b58\u5728\u4e25\u91cd\u8de8\u4e25\u683c\u5ea6\u4e0d\u4e00\u81f4\u6027\uff1a\u540c\u4e00\u6a21\u578b\u5728\u4e0d\u540c\u4e25\u683c\u5ea6\u4f53\u7cfb\u4e0b\u6027\u80fd\u5dee\u5f02\u5de8\u5927\u3002FlexGuard\u5728FlexBench\u53ca\u516c\u5f00\u57fa\u51c6\u4e0a\u5747\u5b9e\u73b0\u66f4\u9ad8\u5ba1\u6838\u51c6\u786e\u7387\uff0c\u5e76\u5728\u4e25\u683c\u5ea6\u53d8\u5316\u65f6\u8868\u73b0\u51fa\u663e\u8457\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4e8c\u5143\u5ba1\u6838\u5668\u7684\u9002\u5e94\u6027\u7f3a\u9677\u3002", "conclusion": "\u8fde\u7eed\u98ce\u9669\u5206\u6570\u8868\u793a\u7ed3\u5408\u9608\u503c\u5316\u7b56\u7565\u662f\u6784\u5efa\u5b9e\u7528\u5316LLM\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u7684\u6709\u6548\u8def\u5f84\u3002FlexGuard\u901a\u8fc7\u98ce\u9669\u5bf9\u9f50\u4f18\u5316\u5b9e\u73b0\u4e86\u4e25\u683c\u5ea6\u81ea\u9002\u5e94\uff0c\u4e3a\u52a8\u6001\u6f14\u5316\u7684\u5ba1\u6838\u9700\u6c42\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u63a8\u52a8LLM\u5b89\u5168\u90e8\u7f72\u5177\u6709\u91cd\u8981\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2602.23993", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23993", "abs": "https://arxiv.org/abs/2602.23993", "authors": ["Jonathan Drechsel", "Steffen Herbold"], "title": "The GRADIEND Python Package: An End-to-End System for Gradient-Based Feature Learning", "comment": null, "summary": "We present gradiend, an open-source Python package that operationalizes the GRADIEND method for learning feature directions from factual-counterfactual MLM and CLM gradients in language models. The package provides a unified workflow for feature-related data creation, training, evaluation, visualization, persistent model rewriting via controlled weight updates, and multi-feature comparison. We demonstrate GRADIEND on an English pronoun paradigm and on a large-scale feature comparison that reproduces prior use cases.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd gradiend\uff0c\u4e00\u4e2a\u5f00\u6e90 Python \u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5b9e\u73b0 GRADIEND \u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u63d0\u53d6\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e8b\u5b9e-\u53cd\u4e8b\u5b9e\u68af\u5ea6\uff08MLM \u548c CLM\uff09\u6765\u5b66\u4e60\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u65b9\u5411\u3002\u8be5\u5de5\u5177\u5305\u63d0\u4f9b\u6570\u636e\u521b\u5efa\u3001\u8bad\u7ec3\u3001\u8bc4\u4f30\u3001\u53ef\u89c6\u5316\u3001\u53ef\u63a7\u6743\u91cd\u66f4\u65b0\u7684\u6301\u4e45\u5316\u6a21\u578b\u6539\u5199\u4ee5\u53ca\u591a\u7279\u5f81\u6bd4\u8f83\u7684\u7edf\u4e00\u5de5\u4f5c\u6d41\uff0c\u5e76\u5728\u82f1\u8bed\u4ee3\u8bcd\u8303\u5f0f\u548c\u5927\u578b\u7279\u5f81\u5bf9\u6bd4\u5b9e\u9a8c\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u63d0\u51fa\u4e86 GRADIEND \u65b9\u6cd5\u7528\u4e8e\u4ece\u8bed\u8a00\u6a21\u578b\u68af\u5ea6\u4e2d\u63d0\u53d6\u7279\u5f81\u65b9\u5411\uff0c\u4f46\u7f3a\u4e4f\u53ef\u590d\u73b0\u3001\u53ef\u6269\u5c55\u7684\u5f00\u7bb1\u5373\u7528\u5de5\u5177\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f00\u53d1\u5f00\u6e90 Python \u5305\uff0c\u5c06\u8fd9\u4e00\u65b9\u6cd5\u64cd\u4f5c\u5316\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7edf\u4e00\u7684\u5de5\u4f5c\u6d41\uff0c\u964d\u4f4e\u68af\u5ea6\u7279\u5f81\u5206\u6790\u4e0e\u6a21\u578b\u6539\u5199\u7684\u95e8\u69db\uff0c\u4fc3\u8fdb\u53ef\u89e3\u91ca\u6027 AI \u7684\u5b9e\u7528\u5316\u3002", "method": "1) \u5b9e\u73b0 GRADIEND \u7b97\u6cd5\uff1a\u4ece MLM\uff08\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff09\u548c CLM\uff08\u56e0\u679c\u8bed\u8a00\u6a21\u578b\uff09\u7684\u4e8b\u5b9e-\u53cd\u4e8b\u5b9e\u68af\u5ea6\u4e2d\u5b66\u4e60\u7279\u5f81\u65b9\u5411\u5411\u91cf\uff1b2) \u6784\u5efa gradiend \u5de5\u5177\u5305\uff1a\u63d0\u4f9b\u7279\u5f81\u6570\u636e\u521b\u5efa\u3001\u6a21\u578b\u8bad\u7ec3\u3001\u8bc4\u4f30\u6307\u6807\u3001\u53ef\u89c6\u5316\u5206\u6790\u3001\u57fa\u4e8e\u68af\u5ea6\u66f4\u65b0\u7684\u6301\u4e45\u5316\u6a21\u578b\u53c2\u6570\u7f16\u8f91\u4ee5\u53ca\u591a\u7279\u5f81\u5bf9\u6bd4\u529f\u80fd\uff1b3) \u8bbe\u8ba1\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u7aef\u5230\u7aef\u5b9e\u9a8c\u6d41\u7a0b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u5e76\u5f00\u6e90\u4e86 gradiend Python \u5305\uff1b\u5728\u82f1\u8bed\u4ee3\u8bcd\u8303\u5f0f\u4e0a\u5b8c\u6210\u4e86\u7279\u5f81\u65b9\u5411\u5b66\u4e60\u4e0e\u6a21\u578b\u6539\u5199\u9a8c\u8bc1\uff1b\u901a\u8fc7\u5927\u89c4\u6a21\u7279\u5f81\u5bf9\u6bd4\u5b9e\u9a8c\u590d\u73b0\u4e86\u5148\u524d\u7814\u7a76\u7684\u5178\u578b\u7528\u4f8b\uff0c\u8bc1\u660e\u4e86\u5de5\u5177\u5305\u7684\u5b9e\u7528\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "gradiend \u5de5\u5177\u5305\u6709\u6548\u5b9e\u73b0\u4e86 GRADIEND \u65b9\u6cd5\u7684\u64cd\u4f5c\u5316\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u68af\u5ea6\u7279\u5f81\u5206\u6790\u3001\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e0e\u53ef\u63a7\u7f16\u8f91\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6a21\u578b\u884c\u4e3a\u5206\u6790\u4e0e\u5b89\u5168\u6539\u8fdb\u7684\u79d1\u5b66\u7814\u7a76\u3002"}}
{"id": "2602.23638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23638", "abs": "https://arxiv.org/abs/2602.23638", "authors": ["Haoran Zhang", "Dongjun Kim", "Seohyeon Cha", "Haris Vikalo"], "title": "FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA", "comment": "preprint", "summary": "Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faFedRot-LoRA\uff0c\u901a\u8fc7\u6b63\u4ea4\u53d8\u6362\u5bf9\u9f50\u5ba2\u6237\u7aef\u4f4e\u79e9\u66f4\u65b0\u56e0\u5b50\uff0c\u89e3\u51b3\u8054\u90a6LoRA\u4e2d\u56e0\u65cb\u8f6c\u4e0d\u53d8\u6027\u5bfc\u81f4\u7684\u5b50\u7a7a\u95f4\u5931\u914d\u548c\u805a\u5408\u8bef\u5dee\u95ee\u9898\uff0c\u5728\u4e0d\u589e\u52a0\u901a\u4fe1\u5f00\u9500\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u5f02\u6784\u6570\u636e\u4e0b\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u8054\u90a6LoRA\u91c7\u7528\u56e0\u5b50-wise\u5e73\u5747\u8fdb\u884c\u805a\u5408\uff0c\u4f46\u4f4e\u79e9\u5206\u89e3\u7684\u65cb\u8f6c\u4e0d\u53d8\u6027\u4f7f\u5404\u5ba2\u6237\u7aef\u66f4\u65b0\u53ef\u4f4d\u4e8e\u4e0d\u540c\u8bed\u4e49\u7b49\u4ef7\u7684\u5b50\u7a7a\u95f4\uff0c\u76f4\u63a5\u5e73\u5747\u5bfc\u81f4\u7834\u574f\u6027\u5e72\u6d89\u3002\u73b0\u6709\u7814\u7a76\u672a\u89e3\u51b3\u6b64\u6839\u672c\u95ee\u9898\uff0c\u4e25\u91cd\u5f71\u54cd\u8054\u90a6\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51faFedRot-LoRA\u6846\u67b6\uff0c\u5728\u805a\u5408\u524d\u5bf9\u5ba2\u6237\u7aef\u4f4e\u79e9\u56e0\u5b50\u65bd\u52a0\u6b63\u4ea4\u53d8\u6362\u5b9e\u73b0\u5bf9\u9f50\uff0c\u4fdd\u6301\u66f4\u65b0\u8bed\u4e49\u4e0d\u53d8\u7684\u540c\u65f6\u6700\u5c0f\u5316\u5b50\u7a7a\u95f4\u5dee\u5f02\uff0c\u5e76\u63d0\u4f9b\u6536\u655b\u6027\u5206\u6790\u8bc1\u660e\u5bf9\u9f50\u53ef\u51cf\u5c0f\u805a\u5408\u8bef\u5dee\u4e0a\u754c\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\uff0cFedRot-LoRA\u5728\u4e0d\u540c\u6570\u636e\u5f02\u6784\u7a0b\u5ea6\u548cLoRA\u79e9\u8bbe\u7f6e\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u66f4\u7a33\u5b9a\uff0c\u6027\u80fd\u63d0\u5347\u660e\u663e\u3002", "conclusion": "\u65cb\u8f6c\u5bf9\u9f50\u662f\u8054\u90a6LoRA\u4e2d\u6d88\u9664\u805a\u5408\u8bef\u5dee\u7684\u5173\u952e\u6280\u672f\uff0c\u8be5\u5de5\u4f5c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u9ad8\u6548\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u65b9\u6cd5\u652f\u6491\u3002"}}
{"id": "2602.24002", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24002", "abs": "https://arxiv.org/abs/2602.24002", "authors": ["Iris Dania Jimenez", "Christoph Kern"], "title": "Dialect and Gender Bias in YouTube's Spanish Captioning System", "comment": "21 pages, 4 tables", "summary": "Spanish is the official language of twenty-one countries and is spoken by over 441 million people. Naturally, there are many variations in how Spanish is spoken across these countries. Media platforms such as YouTube rely on automatic speech recognition systems to make their content accessible to different groups of users. However, YouTube offers only one option for automatically generating captions in Spanish. This raises the question: could this captioning system be biased against certain Spanish dialects? This study examines the potential biases in YouTube's automatic captioning system by analyzing its performance across various Spanish dialects. By comparing the quality of captions for female and male speakers from different regions, we identify systematic disparities which can be attributed to specific dialects. Our study provides further evidence that algorithmic technologies deployed on digital platforms need to be calibrated to the diverse needs and experiences of their user populations.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5YouTube\u897f\u73ed\u7259\u8bed\u81ea\u52a8\u5b57\u5e55\u7cfb\u7edf\u5bf9\u65b9\u8a00\u7684\u504f\u89c1\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u5730\u533a\u7537\u5973\u8bf4\u8bdd\u8005\u7684\u5b57\u5e55\u8d28\u91cf\uff0c\u53d1\u73b0\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u8868\u660e\u7b97\u6cd5\u9700\u9488\u5bf9\u591a\u6837\u5316\u7528\u6237\u7fa4\u4f53\u6821\u51c6\u3002", "motivation": "\u897f\u73ed\u7259\u8bed\u572821\u4e2a\u56fd\u5bb6\u6709\u8d85\u8fc74.41\u4ebf\u4f7f\u7528\u8005\uff0c\u5b58\u5728\u591a\u79cd\u65b9\u8a00\u53d8\u4f53\uff0c\u4f46YouTube\u4ec5\u63d0\u4f9b\u5355\u4e00\u897f\u73ed\u7259\u8bed\u81ea\u52a8\u5b57\u5e55\u9009\u9879\uff0c\u53ef\u80fd\u5bf9\u67d0\u4e9b\u65b9\u8a00\u9020\u6210\u504f\u89c1\uff0c\u5f71\u54cd\u5185\u5bb9\u53ef\u8bbf\u95ee\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u6765\u81ea\u4e0d\u540c\u897f\u73ed\u7259\u8bed\u5730\u533a\u7537\u5973\u8bf4\u8bdd\u8005\u7684\u81ea\u52a8\u5b57\u5e55\u8d28\u91cf\uff0c\u8bc6\u522b\u53ef\u5f52\u56e0\u4e8e\u7279\u5b9a\u65b9\u8a00\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4ee5\u8bc4\u4f30YouTube\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0YouTube\u81ea\u52a8\u5b57\u5e55\u7cfb\u7edf\u5bf9\u4e0d\u540c\u897f\u73ed\u7259\u8bed\u65b9\u8a00\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u8bc6\u522b\u8d28\u91cf\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u67d0\u4e9b\u65b9\u8a00\u8868\u73b0\u660e\u663e\u8f83\u5dee\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6570\u5b57\u5e73\u53f0\u7b97\u6cd5\u6280\u672f\u9700\u8981\u6821\u51c6\u4ee5\u9002\u5e94\u591a\u6837\u5316\u7528\u6237\u7fa4\u4f53\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u8bc1\u636e\uff0c\u5f3a\u8c03\u786e\u4fdd\u6280\u672f\u516c\u5e73\u6027\u548c\u5305\u5bb9\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.24100", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24100", "abs": "https://arxiv.org/abs/2602.24100", "authors": ["Richard Csaky"], "title": "Artificial Agency Program: Curiosity, compression, and communication in agents", "comment": "This is a working draft. Feedback and criticism is most welcome", "summary": "This paper presents the Artificial Agency Program (AAP), a position and research agenda for building AI systems as reality embedded, resource-bounded agents whose development is driven by curiosity-as-learning-progress under physical and computational constraints. The central thesis is that AI is most useful when treated as part of an extended human--tool system that increases sensing, understanding, and actuation capability while reducing friction at the interface between people, tools, and environments. The agenda unifies predictive compression, intrinsic motivation, empowerment and control, interface quality (unification), and language/self-communication as selective information bottlenecks. We formulate these ideas as a falsifiable program with explicit costs, staged experiments, and a concrete multimodal tokenized testbed in which an agent allocates limited budget among observation, action, and deliberation. The aim is to provide a conceptual and experimental framework that connects intrinsic motivation, information theory, thermodynamics, bounded rationality, and modern reasoning systems", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u4eba\u5de5\u4e3b\u4f53\u8ba1\u5212\"(AAP)\uff0c\u4e00\u4e2a\u5c06AI\u7cfb\u7edf\u6784\u5efa\u4e3a\u73b0\u5b9e\u5d4c\u5165\u3001\u8d44\u6e90\u53d7\u9650\u4e3b\u4f53\u7684\u7acb\u573a\u4e0e\u7814\u7a76\u8bae\u7a0b\u3002\u6838\u5fc3\u8bba\u70b9\u662fAI\u4f5c\u4e3a\u6269\u5c55\u4eba\u7c7b-\u5de5\u5177\u7cfb\u7edf\u7684\u4e00\u90e8\u5206\u6700\u6709\u4ef7\u503c\uff0c\u80fd\u589e\u5f3a\u611f\u77e5\u3001\u7406\u89e3\u548c\u6267\u884c\u80fd\u529b\u5e76\u51cf\u5c11\u4eba\u673a\u73af\u5883\u4e0e\u5de5\u5177\u95f4\u7684\u754c\u9762\u6469\u64e6\u3002\u8be5\u8ba1\u5212\u5c06\u9884\u6d4b\u538b\u7f29\u3001\u5185\u5728\u52a8\u673a\u3001\u6388\u6743\u63a7\u5236\u3001\u754c\u9762\u8d28\u91cf\u53ca\u8bed\u8a00/\u81ea\u6211\u901a\u4fe1\u7edf\u4e00\u4e3a\u9009\u62e9\u6027\u4fe1\u606f\u74f6\u9888\uff0c\u4ee5\u53ef\u8bc1\u4f2a\u65b9\u5f0f\u6784\u5efa\uff0c\u5305\u542b\u663e\u5f0f\u6210\u672c\u3001\u5206\u9636\u6bb5\u5b9e\u9a8c\u548c\u591a\u6a21\u6001\u6807\u8bb0\u5316\u6d4b\u8bd5\u5e73\u53f0\uff0c\u65e8\u5728\u8fde\u63a5\u5185\u5728\u52a8\u673a\u3001\u4fe1\u606f\u8bba\u3001\u70ed\u529b\u5b66\u3001\u6709\u9650\u7406\u6027\u4e0e\u73b0\u4ee3\u63a8\u7406\u7cfb\u7edf\u7684\u6982\u5ff5\u4e0e\u5b9e\u9a8c\u6846\u67b6\u3002", "motivation": "\u5f53\u524dAI\u7814\u7a76\u7f3a\u4e4f\u5bf9\u73b0\u5b9e\u5d4c\u5165\u6027\u548c\u8d44\u6e90\u7ea6\u675f\u7684\u7cfb\u7edf\u6027\u8003\u91cf\uff0c\u5bfc\u81f4\u4eba\u673a\u534f\u4f5c\u6548\u7387\u4f4e\u4e0b\u3002\u4f5c\u8005\u8ba4\u4e3aAI\u5e94\u4f5c\u4e3a\u589e\u5f3a\u4eba\u7c7b\u80fd\u529b\u7684\u5de5\u5177\u7cfb\u7edf\u7ec4\u6210\u90e8\u5206\u800c\u975e\u72ec\u7acb\u667a\u80fd\u4f53\uff0c\u9700\u901a\u8fc7\u597d\u5947\u5fc3\u9a71\u52a8\u7684\u5b66\u4e60\u8fdb\u5c55\u6765\u4f18\u5316\u7269\u7406\u4e0e\u8ba1\u7b97\u7ea6\u675f\u4e0b\u7684\u611f\u77e5\u3001\u7406\u89e3\u548c\u6267\u884c\u80fd\u529b\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u4eba-\u5de5\u5177-\u73af\u5883\u63a5\u53e3\u95f4\u7684\u6469\u64e6\u6210\u672c\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u7edf\u4e00\u4fe1\u606f\u8bba\u3001\u70ed\u529b\u5b66\u548c\u6709\u9650\u7406\u6027\u7b49\u57fa\u7840\u7406\u8bba\uff0c\u4e9f\u9700\u4e00\u4e2a\u6574\u5408\u6027\u7814\u7a76\u6846\u67b6\u6765\u63a8\u52a8\u5177\u8eabAI\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u53ef\u8bc1\u4f2a\u7684\u7814\u7a76\u7eb2\u9886\u8bbe\u8ba1\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u65b9\u6cd5\uff1a1) \u663e\u5f0f\u6210\u672c\u5efa\u6a21\uff0c\u5c06\u7269\u7406\u4e0e\u8ba1\u7b97\u7ea6\u675f\u91cf\u5316\u4e3a\u53ef\u4f18\u5316\u7684\u9884\u7b97\u5206\u914d\u95ee\u9898\uff1b2) \u5206\u9636\u6bb5\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u901a\u8fc7\u53ef\u63a7\u5b9e\u9a8c\u9010\u6b65\u9a8c\u8bc1\u7406\u8bba\u5047\u8bbe\uff1b3) \u6784\u5efa\u591a\u6a21\u6001\u6807\u8bb0\u5316\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4f7f\u4e3b\u4f53\u5728\u6709\u9650\u9884\u7b97\u4e0b\u52a8\u6001\u5206\u914d\u4e8e\u89c2\u5bdf\u3001\u884c\u52a8\u4e0e deliberation \u4e09\u4e2a\u7ef4\u5ea6\u3002\u7406\u8bba\u5c42\u9762\u5c06\u9884\u6d4b\u538b\u7f29\u3001\u5185\u5728\u52a8\u673a\u3001\u6388\u6743\u63a7\u5236\u3001\u754c\u9762\u8d28\u91cf\u53ca\u81ea\u6211\u901a\u4fe1\u7edf\u4e00\u5efa\u6a21\u4e3a\u9009\u62e9\u6027\u4fe1\u606f\u74f6\u9888\uff0c\u5e76\u5f15\u5165\u4fe1\u606f\u8bba\u3001\u70ed\u529b\u5b66\u3001\u6709\u9650\u7406\u6027\u4f5c\u4e3a\u57fa\u7840\u5206\u6790\u5de5\u5177\u3002", "result": "\u63d0\u51fa\u4e86\u5b8c\u6574\u7684AAP\u7406\u8bba\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4e94\u5927\u6982\u5ff5\u7684\u6570\u5b66\u7edf\u4e00\uff1a\u9884\u6d4b\u538b\u7f29\u5bf9\u5e94\u4fe1\u606f\u74f6\u9888\uff0c\u5185\u5728\u52a8\u673a\u4f53\u73b0\u4e3a\u5b66\u4e60\u8fdb\u5c55\uff0c\u6388\u6743\u63a7\u5236\u8868\u5f81\u4e3a\u53ef\u63a7\u72b6\u6001\u7a7a\u95f4\uff0c\u754c\u9762\u8d28\u91cf\u5b9a\u4e49\u4e3a\u4e92\u4fe1\u606f\u4f18\u5316\uff0c\u8bed\u8a00/\u81ea\u6211\u901a\u4fe1\u89c6\u4e3a\u5185\u90e8\u4fe1\u606f\u74f6\u9888\u3002\u8bbe\u8ba1\u4e86\u5177\u4f53\u7684\u591a\u6a21\u6001\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5176\u4e2d\u4e3b\u4f53\u5fc5\u987b\u6743\u8861\u89c2\u5bdf\u3001\u884c\u52a8\u4e0e deliberation \u7684\u9884\u7b97\u5206\u914d\u3002\u5efa\u7acb\u4e86\u8fde\u63a5\u4fe1\u606f\u8bba\u3001\u70ed\u529b\u5b66\u4e0e\u6709\u9650\u7406\u6027\u7684\u7406\u8bba\u6865\u6881\uff0c\u4e3a\u73b0\u4ee3\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u8bc1\u4f2a\u7684\u5b9e\u9a8c\u7814\u7a76\u8303\u5f0f\u3002", "conclusion": "\u8be5\u8ba1\u5212\u4e3a\u6784\u5efa\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8d44\u6e90\u53d7\u9650AI\u4e3b\u4f53\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6982\u5ff5\u4e0e\u5b9e\u9a8c\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5185\u5728\u52a8\u673a\u3001\u4fe1\u606f\u8bba\u3001\u70ed\u529b\u5b66\u548c\u6709\u9650\u7406\u6027\u7edf\u4e00\uff0c\u6709\u671b\u63a8\u52a8AI\u4ece\u62bd\u8c61\u63a8\u7406\u5411\u5177\u8eab\u667a\u80fd\u8f6c\u53d8\u3002\u6700\u7ec8\u76ee\u6807\u662f\u521b\u5efa\u80fd\u591f\u4e0e\u4eba\u7c7b\u65e0\u7f1d\u534f\u4f5c\u3001\u5728\u7269\u7406\u7ea6\u675f\u4e0b\u901a\u8fc7\u597d\u5947\u5fc3\u9a71\u52a8\u6301\u7eed\u5b66\u4e60\u3001\u5e76\u4f18\u5316\u6574\u4f53\u7cfb\u7edf\u6548\u80fd\u7684\u667a\u80fd\u5de5\u5177\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4eba\u673a\u534f\u540c\u7cfb\u7edf\u5960\u5b9a\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.23662", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23662", "abs": "https://arxiv.org/abs/2602.23662", "authors": ["Kohei Obata", "Zheng Chen", "Yasuko Matsubara", "Lingwei Zhu", "Yasushi Sakurai"], "title": "Selective Denoising Diffusion Model for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAnomalyFilter\uff0c\u4e00\u79cd\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u578b\u6269\u6563\u6a21\u578b\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a9\u7801\u8bad\u7ec3\u566a\u58f0\u548c\u5b9e\u4f8b\u53bb\u566a\u65f6\u4e0d\u6dfb\u52a0\u566a\u58f0\uff0c\u5b9e\u73b0\u4ec5\u5bf9\u5f02\u5e38\u90e8\u5206\u53bb\u566a\u5e76\u4fdd\u7559\u6b63\u5e38\u90e8\u5206\u7684\u9009\u62e9\u6027\u8fc7\u6ee4\uff0c\u514b\u670d\u4e86\u73b0\u6709\u6761\u4ef6\u91cd\u6784\u65b9\u6cd5\u7684\u6027\u80fd\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u91c7\u7528\u6761\u4ef6\u7b56\u7565\u4ece\u767d\u566a\u58f0\u91cd\u6784\u8f93\u5165\u5b9e\u4f8b\uff0c\u4f46\u96be\u4ee5\u51c6\u786e\u91cd\u6784\u6b63\u5e38\u90e8\u5206\uff0c\u5bfc\u81f4\u68c0\u6d4b\u6027\u80fd\u4e0d\u7406\u60f3\u3002\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u80fd\u66f4\u597d\u4fdd\u7559\u6b63\u5e38\u6a21\u5f0f\u3001\u4e13\u6ce8\u4e8e\u5f02\u5e38\u68c0\u6d4b\u7684\u6269\u6563\u6a21\u578b\u566a\u58f0\u7b56\u7565\u3002", "method": "\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u8bad\u7ec3\u9636\u6bb5\u5bf9\u9ad8\u65af\u566a\u58f0\u8fdb\u884c\u63a9\u7801\u5904\u7406\uff1b2\uff09\u53bb\u566a\u8fc7\u7a0b\u4e2d\u4e0d\u518d\u5411\u5b9e\u4f8b\u6dfb\u52a0\u566a\u58f0\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4f7f\u6a21\u578b\u6210\u4e3a\u9009\u62e9\u6027\u8fc7\u6ee4\u5668\uff0c\u4ec5\u5bf9\u5b9e\u4f8b\u4e2d\u7684\u5f02\u5e38\u90e8\u5206\u8fdb\u884c\u53bb\u566a\uff0c\u540c\u65f6\u5b8c\u6574\u4fdd\u7559\u6b63\u5e38\u90e8\u5206\u3002\u4e24\u4e2a\u7b80\u5355\u7ec4\u4ef6\u7684\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u4e86\u6734\u7d20\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAnomalyFilter\u5728\u6b63\u5e38\u90e8\u5206\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u91cd\u5efa\u8bef\u5dee\uff0c\u4e3a\u5f02\u5e38\u68c0\u6d4b\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e13\u6ce8\u4e8e\u566a\u58f0\u8bbe\u8ba1\uff0c\u5c55\u793a\u4e86\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u65b0\u5e94\u7528\u8303\u5f0f\u3002", "conclusion": "AnomalyFilter\u662f\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e13\u95e8\u8bbe\u8ba1\u7684\u6269\u6563\u6a21\u578b\u566a\u58f0\u7b56\u7565\u7684\u5f00\u521b\u6027\u65b9\u6cd5\u3002\u5b83\u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7814\u7a76\u65b9\u5411\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u8fc7\u6ee4\u800c\u975e\u5b8c\u5168\u91cd\u6784\u7684\u601d\u8def\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u548c\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2602.24060", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24060", "abs": "https://arxiv.org/abs/2602.24060", "authors": ["Donghao Huang", "Zhaoxia Wang"], "title": "Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis", "comment": "12 pages, 1 figure, 3 tables. Accepted at PAKDD 2026", "summary": "Large language models (LLMs) with reasoning capabilities have fueled a compelling narrative that reasoning universally improves performance across language tasks. We test this claim through a comprehensive evaluation of 504 configurations across seven model families--including adaptive, conditional, and reinforcement learning-based reasoning architectures--on sentiment analysis datasets of varying granularity (binary, five-class, and 27-class emotion). Our findings reveal that reasoning effectiveness is strongly task-dependent, challenging prevailing assumptions: (1) Reasoning shows task-complexity dependence--binary classification degrades up to -19.9 F1 percentage points (pp), while 27-class emotion recognition gains up to +16.0pp; (2) Distilled reasoning variants underperform base models by 3-18 pp on simpler tasks, though few-shot prompting enables partial recovery; (3) Few-shot learning improves over zero-shot in most cases regardless of model type, with gains varying by architecture and task complexity; (4) Pareto frontier analysis shows base models dominate efficiency-performance trade-offs, with reasoning justified only for complex emotion recognition despite 2.1x-54x computational overhead. We complement these quantitative findings with qualitative error analysis revealing that reasoning degrades simpler tasks through systematic over-deliberation, offering mechanistic insight beyond the high-level overthinking hypothesis.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30504\u79cd\u914d\u7f6e\u6311\u6218\u4e86\"\u63a8\u7406\u666e\u904d\u63d0\u5347\u5927\u6a21\u578b\u6027\u80fd\"\u7684\u4e3b\u6d41\u89c2\u70b9\uff0c\u53d1\u73b0\u63a8\u7406\u6548\u679c\u5177\u6709\u5f3a\u70c8\u4efb\u52a1\u4f9d\u8d56\u6027\uff1a\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1F1\u4e0b\u964d\u8fbe-19.9pp\uff0c27\u7c7b\u60c5\u611f\u8bc6\u522b\u63d0\u5347+16.0pp\u3002\u57fa\u7840\u6a21\u578b\u5728\u6548\u7387-\u6027\u80fd\u6743\u8861\u4e0a\u5360\u4f18\uff0c\u63a8\u7406\u4ec5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u503c\u5f972.1-54\u500d\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u5173\u4e8e\u63a8\u7406\u80fd\u529b\u80fd\u666e\u904d\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6240\u6709\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u7684\u4e3b\u6d41\u53d9\u4e8b\uff0c\u901a\u8fc7\u5168\u9762\u8bc4\u4f30\u9a8c\u8bc1\u5176\u771f\u5b9e\u6709\u6548\u6027\u3002", "method": "\u5bf97\u4e2a\u6a21\u578b\u5bb6\u65cf\u7684504\u79cd\u914d\u7f6e\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u6db5\u76d6\u81ea\u9002\u5e94\u3001\u6761\u4ef6\u548c\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u67b6\u6784\uff0c\u5728\u4e8c\u5143\u3001\u4e94\u7c7b\u548c27\u7c7b\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u5e76\u7ed3\u5408\u5b9a\u6027\u9519\u8bef\u5206\u6790\u63ed\u793a\u673a\u5236\u3002", "result": "(1)\u63a8\u7406\u6548\u679c\u4f9d\u8d56\u4efb\u52a1\u590d\u6742\u5ea6\uff0c\u4e8c\u5143\u5206\u7c7bF1\u4e0b\u964d\u8fbe-19.9pp\uff0c27\u7c7b\u60c5\u611f\u8bc6\u522b\u63d0\u5347+16.0pp\uff1b(2)\u84b8\u998f\u63a8\u7406\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u6bd4\u57fa\u7840\u6a21\u578b\u4f4e3-18pp\uff1b(3)\u5c11\u6837\u672c\u5b66\u4e60\u666e\u904d\u4f18\u4e8e\u96f6\u6837\u672c\uff1b(4)\u57fa\u7840\u6a21\u578b\u4e3b\u5bfc\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63a8\u7406\u4ec5\u590d\u6742\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e2d\u503c\u5f972.1-54\u500d\u5f00\u9500\uff1b(5)\u5b9a\u6027\u5206\u6790\u63ed\u793a\u63a8\u7406\u901a\u8fc7\u7cfb\u7edf\u6027\u8fc7\u5ea6\u601d\u8003\u635f\u5bb3\u7b80\u5355\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u63a8\u7406\u5e76\u4e0d\u80fd\u666e\u904d\u63d0\u5347\u5927\u6a21\u578b\u6027\u80fd\uff0c\u5176\u6709\u6548\u6027\u5177\u6709\u5f3a\u70c8\u4efb\u52a1\u4f9d\u8d56\u6027\u3002\u57fa\u7840\u6a21\u578b\u5bf9\u7b80\u5355\u4efb\u52a1\u66f4\u9ad8\u6548\uff0c\u63a8\u7406\u673a\u5236\u4ec5\u5728\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc6\u522b\u7b49\u590d\u6742\u573a\u666f\u4e2d\u624d\u5177\u4ef7\u503c\uff0c\u6311\u6218\u4e86\u5f53\u524d\u4e3b\u6d41\u5047\u8bbe\u3002"}}
{"id": "2602.24110", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24110", "abs": "https://arxiv.org/abs/2602.24110", "authors": ["Yanwei Ren", "Haotian Zhang", "Likang Xiao", "Xikai Zhang", "Jiaxing Huang", "Jiayan Qiu", "Baosheng Yu", "Quan Chen", "Liu Liu"], "title": "Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCOPE\u6846\u67b6\uff0c\u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5bf9\u90e8\u5206\u6b63\u786e\u7684\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u9010\u6b65\u4fee\u6b63\uff0c\u89e3\u51b3\u4e86RLVR\u4e2d\u56e0\u7c97\u7c92\u5ea6\u5956\u52b1\u5bfc\u81f4\u7684\u63a2\u7d22\u7a7a\u95f4\u8fc7\u65e9\u7f29\u5c0f\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523046.6%\u7684SOTA\u51c6\u786e\u7387\u3002", "motivation": "\u6807\u51c6\u7ed3\u679c\u76d1\u7763\u7684RLVR\u4f1a\u5c06\u6709\u5927\u90e8\u5206\u6b63\u786e\u6b65\u9aa4\u4f46\u56e0\u5c11\u91cf\u9519\u8bef\u5931\u8d25\u7684\u8f68\u8ff9\u4e0e\u5b8c\u5168\u9519\u8bef\u8f68\u8ff9\u540c\u7b49\u60e9\u7f5a\uff0c\u8fd9\u79cd\u7c97\u7c92\u5ea6\u53cd\u9988\u5bfc\u81f4\u6a21\u578b\u4e22\u5f03\u6709\u4ef7\u503c\u7684\u8f68\u8ff9\uff0c\u964d\u4f4e\u63a2\u7d22\u591a\u6837\u6027\u5e76\u8fc7\u65e9\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5229\u7528\u6a21\u578b\u81ea\u8eab\u751f\u6210\u7684\u90e8\u5206\u6b63\u786e\u8f68\u8ff9\u3002", "method": "SCOPE\u6846\u67b6\u5229\u7528\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc6\u522b\u6b21\u4f18\u8f68\u8ff9\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u5e76\u5e94\u7528\u7ec6\u7c92\u5ea6\u7684\u79bb\u7b56\u7565\u9010\u6b65\u4fee\u6b63\u3002\u901a\u8fc7\u7cbe\u786e\u4fee\u590d\u90e8\u5206\u6b63\u786e\u7684\u8f68\u8ff9\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u633d\u6551\u8fd9\u4e9b\u8f68\u8ff9\u5e76\u6269\u5927\u63a2\u7d22\u7a7a\u95f4\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u8fbe46.6%\uff0c\u5206\u5e03\u5916\u63a8\u7406\u4efb\u52a1\u51c6\u786e\u7387\u8fbe53.4%\uff0c\u8f68\u8ff9\u591a\u6837\u6027\u5f97\u5206\u63d0\u534713.5%\uff0c\u5efa\u7acb\u4e86\u65b0\u7684SOTA\u7ed3\u679c\u3002", "conclusion": "SCOPE\u901a\u8fc7\u7cbe\u7ec6\u5316\u7684\u8f68\u8ff9\u4fee\u6b63\u6709\u6548\u7f13\u89e3\u4e86RLVR\u7684\u63a2\u7d22\u7a7a\u95f4\u7f29\u5c0f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23663", "abs": "https://arxiv.org/abs/2602.23663", "authors": ["Kohei Obata", "Taichi Murayama", "Zheng Chen", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning", "comment": null, "summary": "Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST.", "code_url": "https://github.com/KoheiObata/MoST", "code_stars": 1, "code_last_update": "2025-04-02", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMoST\u6a21\u578b\uff0c\u4e00\u79cd\u9488\u5bf9\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u65b0\u578b\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f20\u91cf\u5207\u7247\u964d\u4f4e\u7ed3\u6784\u590d\u6742\u5ea6\uff0c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5c06\u8868\u793a\u5206\u89e3\u4e3a\u6a21\u5f0f\u7279\u5b9a\u7279\u5f81\u548c\u6a21\u5f0f\u4e0d\u53d8\u7279\u5f81\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5206\u7c7b\u548c\u9884\u6d4b\u7cbe\u5ea6\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u5e7f\u6cdb\u5b58\u5728\u4e8e\u641c\u7d22\u5f15\u64ce\u3001\u73af\u5883\u76d1\u6d4b\u7b49\u9886\u57df\uff0c\u4f46\u5176\u5185\u5728\u590d\u6742\u5ea6\u963b\u788d\u4e86\u4e30\u5bcc\u8868\u793a\u7684\u5b66\u4e60\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5904\u7406\u5f20\u91cf\u7ed3\u6784\u5e76\u89e3\u8026\u4e0d\u540c\u6a21\u5f0f\u95f4\u7684\u7279\u5f81\u5173\u7cfb\u3002", "method": "MoST\u91c7\u7528\u5f20\u91cf\u5207\u7247\u7b56\u7565\u7b80\u5316TTS\u7ed3\u6784\u590d\u6742\u5ea6\uff0c\u5b66\u4e60\u53ef\u5206\u89e3\u4e3a\u4e2a\u4f53\u975e\u65f6\u5e8f\u6a21\u5f0f\u7684\u8868\u793a\u3002\u6bcf\u4e2a\u8868\u793a\u6355\u83b7\u6a21\u5f0f\u7279\u5b9a\u7279\u5f81\uff08\u540c\u4e00\u6a21\u5f0f\u5185\u53d8\u91cf\u95f4\u5173\u7cfb\uff09\u548c\u6a21\u5f0f\u4e0d\u53d8\u7279\u5f81\uff08\u4e0d\u540c\u6a21\u5f0f\u95f4\u5171\u6027\uff09\u3002\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u53c2\u6570\uff0c\u635f\u5931\u51fd\u6570\u5305\u542b\u6a21\u5f0f\u7279\u5b9a\u548c\u6a21\u5f0f\u4e0d\u53d8\u4e24\u90e8\u5206\uff0c\u5c06\u89e3\u8026\u8868\u793a\u4f5c\u4e3a\u6570\u636e\u589e\u5f3a\u6709\u6548\u5229\u7528\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMoST\u5728\u5206\u7c7b\u548c\u9884\u6d4b\u51c6\u786e\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "conclusion": "MoST\u901a\u8fc7\u5f20\u91cf\u5207\u7247\u548c\u5bf9\u6bd4\u5b66\u4e60\u6210\u529f\u89e3\u8026\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u590d\u6742\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8868\u793a\u5b66\u4e60\uff0c\u4e3a\u76f8\u5173\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.24082", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24082", "abs": "https://arxiv.org/abs/2602.24082", "authors": ["Jaekyung Cho"], "title": "Preference Packing: Efficient Preference Optimization for Large Language Models", "comment": null, "summary": "Resource-efficient training optimization techniques are becoming increasingly important as the size of large language models (LLMs) continues to grow. In particular, batch packing is commonly used in pre-training and supervised fine-tuning to achieve resource-efficient training. We propose preference packing, a method to enhance resource efficiency in training techniques that use data with different responses for the same input prompt, such as reward models or Direct Preference Optimization (DPO). Preference packing improves resource efficiency by reducing the attention operations for duplicate input prompts and decreasing KV cache memory usage. We conducted experiments on text-only datasets and image-included datasets and achieved at least 37% reduction in training time. Notably, this method can be applied alongside existing optimization techniques such as batch sorting, resulting in a 3.22x speedup.", "AI": {"tldr": "\u63d0\u51fa preference packing \u65b9\u6cd5\uff0c\u9488\u5bf9\u5956\u52b1\u6a21\u578b\u548c DPO \u7b49\u540c\u4e00\u63d0\u793a\u5bf9\u5e94\u591a\u4e2a\u54cd\u5e94\u7684\u8bad\u7ec3\u573a\u666f\uff0c\u901a\u8fc7\u51cf\u5c11\u91cd\u590d\u6ce8\u610f\u529b\u8ba1\u7b97\u548c KV \u7f13\u5b58\u5185\u5b58\uff0c\u5b9e\u73b0\u81f3\u5c11 37% \u8bad\u7ec3\u65f6\u95f4\u964d\u4f4e\uff0c\u5e76\u53ef\u4e0e batch sorting \u7ed3\u5408\u8fbe\u5230 3.22 \u500d\u52a0\u901f\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u6301\u7eed\u6269\u5927\uff0c\u8d44\u6e90\u9ad8\u6548\u8bad\u7ec3\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5728\u5956\u52b1\u6a21\u578b\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u7b49\u573a\u666f\u4e2d\uff0c\u540c\u4e00\u8f93\u5165\u63d0\u793a\u5bf9\u5e94\u591a\u4e2a\u4e0d\u540c\u54cd\u5e94\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u91cd\u590d\u8ba1\u7b97\u548c\u5185\u5b58\u6d6a\u8d39\u95ee\u9898\uff0c\u4e9f\u9700\u4f18\u5316\u3002", "method": "\u63d0\u51fa preference packing \u6280\u672f\uff0c\u901a\u8fc7\u5c06\u76f8\u540c\u8f93\u5165\u63d0\u793a\u7684\u6837\u672c\u667a\u80fd\u6253\u5305\uff0c\u51cf\u5c11\u91cd\u590d\u7684\u6ce8\u610f\u529b\u8fd0\u7b97\u548c KV \u7f13\u5b58\u5185\u5b58\u5360\u7528\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u3002", "result": "\u5728\u7eaf\u6587\u672c\u548c\u56fe\u6587\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bad\u7ec3\u65f6\u95f4\u81f3\u5c11\u51cf\u5c11 37%\u3002\u4e0e batch sorting \u7b49\u73b0\u6709\u4f18\u5316\u6280\u672f\u7ed3\u5408\u540e\uff0c\u6574\u4f53\u52a0\u901f\u6bd4\u8fbe 3.22 \u500d\u3002", "conclusion": "preference packing \u662f\u4e00\u79cd\u9002\u7528\u4e8e\u91cd\u590d\u63d0\u793a\u8bad\u7ec3\u573a\u666f\u7684\u9ad8\u6548\u8d44\u6e90\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u4e14\u4e0e\u73b0\u6709\u4f18\u5316\u6280\u672f\u517c\u5bb9\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.23696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23696", "abs": "https://arxiv.org/abs/2602.23696", "authors": ["Yongzhong Xu"], "title": "Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training", "comment": "18 pages, 4 figures", "summary": "We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u975e\u4e2d\u5fc3\u5316\u884c\u5f52\u4e00\u5316\u8f68\u8ff9PCA\u63ed\u793a\u5c0f\u578bTransformer\u8bad\u7ec3\u8f68\u8ff9\u5448\u73b0\u4e3b\u5bfc\u6f02\u79fb\u65b9\u5411\u4e0e\u6a2a\u5411\u6b8b\u4f59\u52a8\u529b\u5b66\u3002AdamW\u4e0eSGD\u5728\u76f8\u540c\u635f\u5931\u4e0b\u5c55\u73b0\u663e\u8457\u51e0\u4f55\u5dee\u5f02\uff1aAdamW\u4e3a\u591a\u7ef4\u6f02\u79fb\u7ed3\u6784\uff0cSGD\u8fd1\u4e4e\u5171\u7ebf\u6f14\u5316\u3002\u91cd\u52a0\u70ed\u9009\u62e9\u6027\u5730\u6270\u52a8\u6a2a\u5411\u5206\u91cf\uff0c\u8868\u660e\u4f18\u5316\u5668\u5851\u9020\u8d85\u8d8a\u635f\u5931\u503c\u7684\u5b66\u4e60\u8f68\u8ff9\u51e0\u4f55\u7ed3\u6784\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u4f18\u5316\u5668\u5982\u4f55\u5851\u9020\u6a21\u578b\u8bad\u7ec3\u7684\u52a8\u6001\u51e0\u4f55\u7ed3\u6784\uff0c\u8d85\u8d8a\u4f20\u7edf\u635f\u5931\u5206\u6790\uff0c\u7406\u89e3\u4f18\u5316\u7b97\u6cd5\u5bf9\u53c2\u6570\u6f14\u5316\u8def\u5f84\u548c\u6709\u6548\u7ef4\u5ea6\u7684\u5f71\u54cd\u673a\u5236\u3002", "method": "\u91c7\u7528\u975e\u4e2d\u5fc3\u5316\u884c\u5f52\u4e00\u5316\u8f68\u8ff9\u4e3b\u6210\u5206\u5206\u6790(tPCA)\u91cf\u5316\u5c0f\u578bTransformer\u53c2\u6570\u66f4\u65b0\u8f68\u8ff9\uff0c\u5bf9\u6bd4\u5339\u914d\u635f\u5931\u6c34\u5e73\u4e0bAdamW\u4e0eSGD\u65cf\u4f18\u5316\u5668\u7684\u51e0\u4f55\u7279\u5f81\u5dee\u5f02\u3002", "result": "\u65e9\u671f\u8bad\u7ec3\u4e2d\u5355\u4e00\u4e3b\u6210\u5206\u6355\u83b7\u5927\u90e8\u5206\u7d2f\u79ef\u53c2\u6570\u79fb\u52a8\uff0c\u5269\u4f59\u6210\u5206\u7f16\u7801\u8f85\u52a9\u63a2\u9488\u6027\u80fd\u7684\u632f\u8361\u884c\u4e3a\uff1b\u77ac\u65f6\u68af\u5ea6\u4e0e\u4e3b\u5bfc\u65b9\u5411\u5bf9\u9f50\u5ea6\u4f4e\uff1bAdamW\u5448\u73b0\u591a\u7ef4\u6f02\u79fb\u7ed3\u6784\uff0cSGD\u65cf\u5448\u73b0\u8fd1\u4e4e\u5171\u7ebf\u53c2\u6570\u6f14\u5316\u4e0e\u8f83\u5f31\u63a2\u9488\u52a8\u529b\u5b66\uff1b\u91cd\u52a0\u70ed\u9009\u62e9\u6027\u5730\u6270\u52a8\u6a2a\u5411\u5206\u91cf\u3002", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u6df1\u523b\u5f71\u54cd\u5b66\u4e60\u8f68\u8ff9\u7684\u6709\u6548\u7ef4\u5ea6\u4e0e\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u79cd\u5f71\u54cd\u65e0\u6cd5\u4ec5\u4ece\u635f\u5931\u503c\u4e2d\u4f53\u73b0\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u4f18\u5316\u7b97\u6cd5\u5728\u8bad\u7ec3\u52a8\u6001\u4e0a\u7684\u672c\u8d28\u5dee\u5f02\u3002"}}
{"id": "2602.24109", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24109", "abs": "https://arxiv.org/abs/2602.24109", "authors": ["Sara Nabhani", "Federico Pianzola", "Khalid Al-Khatib", "Malvina Nissim"], "title": "ARGUS: Seeing the Influence of Narrative Features on Persuasion in Argumentative Texts", "comment": "22 pages, 8 figures, submitted to ACM Transactions on Intelligent Systems and Technology", "summary": "Can narratives make arguments more persuasive? And to this end, which narrative features matter most? Although stories are often seen as powerful tools for persuasion, their specific role in online, unstructured argumentation remains underexplored. To address this gap, we present ARGUS, a framework for studying the impact of narration on persuasion in argumentative discourse. ARGUS introduces a new ChangeMyView corpus annotated for story presence and six key narrative features, integrating insights from two established theoretical frameworks that capture both textual narrative features and their effects on recipients. Leveraging both encoder-based classifiers and zero-shot large language models (LLMs), ARGUS identifies stories and narrative features and applies them at scale to examine how different narrative dimensions influence persuasion success in online argumentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faARGUS\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u7814\u7a76\u53d9\u4e8b\u5bf9\u5728\u7ebf\u8bba\u8bc1\u8bf4\u670d\u529b\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u6807\u6ce8ChangeMyView\u8bed\u6599\u5e93\u5e76\u8bc6\u522b\u6545\u4e8b\u53ca\u516d\u5927\u53d9\u4e8b\u7279\u5f81\uff0c\u7ed3\u5408\u7f16\u7801\u5668\u5206\u7c7b\u5668\u548c\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5927\u89c4\u6a21\u5206\u6790\u4e0d\u540c\u53d9\u4e8b\u7ef4\u5ea6\u5982\u4f55\u5f71\u54cd\u8bf4\u670d\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1\u6545\u4e8b\u5e38\u88ab\u89c6\u4e3a\u5f3a\u5927\u7684\u8bf4\u670d\u5de5\u5177\uff0c\u4f46\u5176\u5728\u5728\u7ebf\u975e\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u7684\u5177\u4f53\u4f5c\u7528\u673a\u5236\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7684\u7814\u7a76\u6846\u67b6\u548c\u5206\u6790\u65b9\u6cd5\u3002", "method": "1) \u6784\u5efa\u65b0ChangeMyView\u8bed\u6599\u5e93\uff0c\u6807\u6ce8\u6545\u4e8b\u5b58\u5728\u6027\u53ca\u516d\u5927\u5173\u952e\u53d9\u4e8b\u7279\u5f81\uff1b2) \u6574\u5408\u4e24\u4e2a\u7406\u8bba\u6846\u67b6\u5206\u522b\u6355\u6349\u6587\u672c\u53d9\u4e8b\u7279\u5f81\u53ca\u5176\u5bf9\u63a5\u6536\u8005\u7684\u5f71\u54cd\uff1b3) \u7ed3\u5408\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u5206\u7c7b\u5668\u548c\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u8bc6\u522b\uff1b4) \u5927\u89c4\u6a21\u5e94\u7528\u4ee5\u5206\u6790\u5404\u53d9\u4e8b\u7ef4\u5ea6\u5bf9\u8bf4\u670d\u6210\u529f\u7684\u5dee\u5f02\u5316\u5f71\u54cd\u3002", "result": "\u6458\u8981\u4e3b\u8981\u805a\u7126\u6846\u67b6\u6784\u5efa\uff0c\u672a\u660e\u786e\u5448\u73b0\u5177\u4f53\u6570\u503c\u7ed3\u679c\u3002\u4f46\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u53d9\u4e8b\u7279\u5f81\u7684\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u8bc6\u522b\u4e0e\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u7814\u7a76\u7ba1\u9053\uff0c\u4e3a\u63ed\u793a\u53d9\u4e8b\u7ef4\u5ea6\u4e0e\u8bf4\u670d\u6548\u679c\u4e4b\u95f4\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\u3002", "conclusion": "ARGUS\u6846\u67b6\u586b\u8865\u4e86\u5728\u7ebf\u8bba\u8bc1\u4e2d\u53d9\u4e8b\u8bf4\u670d\u529b\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u6807\u6ce8\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u4e3a\u7406\u89e3\u53d9\u4e8b\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u8bf4\u670d\u6548\u679c\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5de5\u5177\u652f\u6491\uff0c\u672a\u6765\u53ef\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u8bba\u8bc1\u573a\u666f\u7814\u7a76\u3002"}}
{"id": "2602.23737", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23737", "abs": "https://arxiv.org/abs/2602.23737", "authors": ["Hanping Zhang", "Yuhong Guo"], "title": "Bridging Dynamics Gaps via Diffusion Schr\u00f6dinger Bridge for Cross-Domain Reinforcement Learning", "comment": null, "summary": "Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schr\u00f6dinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.", "AI": {"tldr": "\u63d0\u51faBDGxRL\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u859b\u5b9a\u8c14\u6865\u5bf9\u9f50\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u52a8\u6001\u5dee\u5f02\uff0c\u7ed3\u5408\u5956\u52b1\u8c03\u5236\u673a\u5236\uff0c\u5b9e\u73b0\u65e0\u9700\u76ee\u6807\u57df\u73af\u5883\u4ea4\u4e92\u7684\u8de8\u57df\u7b56\u7565\u5b66\u4e60\uff0c\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8eSOTA\u65b9\u6cd5\u3002", "motivation": "\u8de8\u57df\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u76ee\u6807\u57df\u65e0\u73af\u5883\u4ea4\u4e92\u548c\u5956\u52b1\u76d1\u7763\u7684\u5173\u952e\u6311\u6218\uff0c\u5bfc\u81f4\u76f4\u63a5\u7b56\u7565\u5b66\u4e60\u4e0d\u53ef\u884c\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6865\u63a5\u52a8\u6001\u95f4\u9699\u3002", "method": "1\uff09\u4f7f\u7528\u6269\u6563\u859b\u5b9a\u8c14\u6865\u5c06\u6e90\u57df\u8f6c\u79fb\u4e0e\u76ee\u6807\u57df\u79bb\u7ebf\u6f14\u793a\u7f16\u7801\u7684\u52a8\u6001\u5bf9\u9f50\uff1b2\uff09\u8bbe\u8ba1\u57fa\u4e8e\u72b6\u6001\u8f6c\u79fb\u7684\u5956\u52b1\u8c03\u5236\u673a\u5236\uff1b3\uff09\u5b8c\u5168\u5728\u6e90\u57df\u5185\u8fdb\u884c\u76ee\u6807\u5bfc\u5411\u7b56\u7565\u5b66\u4e60\uff0c\u65e0\u9700\u8bbf\u95ee\u76ee\u6807\u73af\u5883\u3002", "result": "\u5728MuJoCo\u8de8\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u8f6c\u79fb\u52a8\u6001\u53d8\u5316\u7684\u5f3a\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "BDGxRL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u76ee\u6807\u57df\u4ea4\u4e92\u4e0b\u7684\u8de8\u57df\u8fc1\u79fb\u96be\u9898\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u5b9e\u9645\u8de8\u57df\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.24119", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24119", "abs": "https://arxiv.org/abs/2602.24119", "authors": ["James L. Zainaldin", "Cameron Pattison", "Manuela Marai", "Jacob Wu", "Mark J. Schiefsky"], "title": "Terminology Rarity Predicts Catastrophic Failure in LLM Translation of Low-Resource Ancient Languages: Evidence from Ancient Greek", "comment": "Article + supplementary information", "summary": "This study presents the first systematic, reference-free human evaluation of large language model (LLM) machine translation (MT) for Ancient Greek (AG) technical prose. We evaluate translations by three commercial LLMs (Claude, Gemini, ChatGPT) of twenty paragraph-length passages from two works by the Greek physician Galen of Pergamum (ca. 129-216 CE): On Mixtures, which has two published English translations, and On the Composition of Drugs according to Kinds, which has never been fully translated into English. We assess translation quality using both standard automated evaluation metrics (BLEU, chrF++, METEOR, ROUGE-L, BERTScore, COMET, BLEURT) and expert human evaluation via a modified Multidimensional Quality Metrics (MQM) framework applied to all 60 translations by a team of domain specialists. On the previously translated expository text, LLMs achieved high translation quality (mean MQM score 95.2/100), with performance approaching expert level. On the untranslated pharmacological text, aggregate quality was lower (79.9/100) but with high variance driven by two passages presenting extreme terminological density; excluding these, scores converged to within 4 points of the translated text. Terminology rarity, operationalized via corpus frequency in the literary Diorisis Ancient Greek Corpus, emerged as a strong predictor of translation failure (r = -.97 for passage-level quality on the untranslated text). Automated metrics showed moderate correlation with human judgment overall on the text with a wide quality spread (Composition), but no metric discriminated among high-quality translations. We discuss implications for the use of LLMs in Classical scholarship and for the design of automated evaluation pipelines for low-resource ancient languages.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u53e4\u5e0c\u814a\u533b\u5b66\u672f\u8bed\u6587\u672c\u7684\u7ffb\u8bd1\u8d28\u91cf\u3002\u901a\u8fc7\u4e13\u5bb6\u4eba\u5de5\u8bc4\u4f30\u548c\u81ea\u52a8\u5316\u6307\u6807\u5206\u6790\u53d1\u73b0\uff0cLLM\u5728\u5df2\u6709\u82f1\u8bd1\u672c\u7684\u6587\u672c\u4e0a\u8868\u73b0\u63a5\u8fd1\u4e13\u5bb6\u6c34\u5e73\uff0c\u4f46\u5728\u672f\u8bed\u5bc6\u96c6\u7684\u672a\u7ffb\u8bd1\u836f\u7406\u5b66\u6587\u672c\u4e0a\u8d28\u91cf\u663e\u8457\u4e0b\u964d\uff0c\u4e14\u672f\u8bed\u7f55\u89c1\u5ea6\u662f\u9884\u6d4b\u7ffb\u8bd1\u5931\u8d25\u7684\u5173\u952e\u56e0\u7d20\u3002\u81ea\u52a8\u5316\u6307\u6807\u6574\u4f53\u76f8\u5173\u6027\u6709\u9650\uff0c\u65e0\u6cd5\u533a\u5206\u9ad8\u8d28\u91cf\u8bd1\u6587\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4f4e\u8d44\u6e90\u53e4\u4ee3\u8bed\u8a00\uff08\u5982\u53e4\u5e0c\u814a\u8bed\uff09\u6280\u672f\u6587\u672c\u7684\u7ffb\u8bd1\u80fd\u529b\uff0c\u4e3a\u53e4\u5178\u5b66\u7814\u7a76\u63d0\u4f9b\u65b0\u7684\u5de5\u5177\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u81ea\u52a8\u5316\u8bc4\u4f30\u6307\u6807\u5728\u6b64\u7c7b\u7279\u6b8a\u9886\u57df\u7684\u9002\u7528\u6027\u3002", "method": "\u9009\u53d6\u4f3d\u4f26\u533b\u5b66\u8457\u4f5c\u4e2d\u5df2\u7ffb\u8bd1\u548c\u672a\u7ffb\u8bd1\u7684\u4e24\u7c7b\u6587\u672c\uff0c\u4f7f\u7528Claude\u3001Gemini\u3001ChatGPT\u4e09\u4e2a\u5546\u4e1aLLM\u751f\u6210\u8bd1\u6587\u3002\u91c7\u7528\u6807\u51c6\u81ea\u52a8\u5316\u6307\u6807\uff08BLEU\u3001COMET\u7b49\uff09\u548c\u7ecf\u4fee\u6539\u7684\u591a\u7ef4\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff08MQM\uff09\uff0c\u7531\u9886\u57df\u4e13\u5bb6\u56e2\u961f\u5bf960\u7bc7\u8bd1\u6587\u8fdb\u884c\u4eba\u5de5\u8bc4\u4f30\uff0c\u5e76\u7ed3\u5408\u8bed\u6599\u5e93\u9891\u7387\u5206\u6790\u672f\u8bed\u7f55\u89c1\u5ea6\u4e0e\u7ffb\u8bd1\u8d28\u91cf\u7684\u5173\u7cfb\u3002", "result": "\u5728\u5df2\u7ffb\u8bd1\u6587\u672c\u4e0a\uff0cLLM\u8bd1\u6587\u5e73\u5747MQM\u5f97\u5206\u9ad8\u8fbe95.2/100\uff0c\u63a5\u8fd1\u4e13\u5bb6\u6c34\u5e73\uff1b\u5728\u672a\u7ffb\u8bd1\u6587\u672c\u4e0a\u5e73\u5747\u5f97\u5206\u4e3a79.9/100\uff0c\u4f46\u6392\u9664\u4e24\u4e2a\u672f\u8bed\u6781\u5bc6\u96c6\u6bb5\u843d\u540e\uff0c\u5dee\u8ddd\u7f29\u5c0f\u81f34\u5206\u4ee5\u5185\u3002\u672f\u8bed\u7f55\u89c1\u5ea6\u4e0e\u7ffb\u8bd1\u8d28\u91cf\u5448\u5f3a\u8d1f\u76f8\u5173\uff08r=-0.97\uff09\u3002\u81ea\u52a8\u5316\u6307\u6807\u4ec5\u5728\u8d28\u91cf\u5dee\u5f02\u5927\u7684\u6587\u672c\u4e0a\u4e0e\u4eba\u5de5\u8bc4\u4ef7\u4e2d\u5ea6\u76f8\u5173\uff0c\u65e0\u6cd5\u533a\u5206\u9ad8\u8d28\u91cf\u8bd1\u6587\u95f4\u7684\u5dee\u5f02\u3002", "conclusion": "LLM\u5728\u53e4\u5178\u5b66\u672f\u7ffb\u8bd1\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u5c24\u5176\u5bf9\u5df2\u6709\u53c2\u8003\u8bd1\u672c\u7684\u6587\u672c\uff1b\u4f46\u9762\u5bf9\u672f\u8bed\u5bc6\u5ea6\u9ad8\u7684\u672a\u7ffb\u8bd1\u6587\u672c\u65f6\u4ecd\u9762\u4e34\u6311\u6218\u3002\u672f\u8bed\u7f55\u89c1\u5ea6\u662f\u6838\u5fc3\u96be\u70b9\u3002\u81ea\u52a8\u5316\u8bc4\u4f30\u6307\u6807\u9700\u9488\u5bf9\u4f4e\u8d44\u6e90\u53e4\u4ee3\u8bed\u8a00\u8fdb\u884c\u4e13\u95e8\u4f18\u5316\uff0c\u672a\u6765\u5e94\u6784\u5efa\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684\u4e13\u7528\u8bc4\u4f30\u6d41\u7a0b\u3002"}}
{"id": "2602.24195", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24195", "abs": "https://arxiv.org/abs/2602.24195", "authors": ["Gregory Kang Ruey Lau", "Hieu Dao", "Nicole Kan Hui Lin", "Bryan Kian Hsiang Low"], "title": "Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume", "comment": "Earlier versions presented at ICLR 2025 QUESTION workshop and ICML 2025 R2-FM workshop", "summary": "Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faUMPIRE\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba1\u7b97\u6a21\u578b\u91c7\u6837\u54cd\u5e94\u7684\u8bed\u4e49\u4f53\u79ef\u5e76\u8c03\u6574\u4e0d\u4e00\u81f4\u6027\uff0c\u4ec5\u5229\u7528\u5185\u90e8\u7279\u5f81\u5373\u53ef\u8de8\u6a21\u6001\u5de5\u4f5c\uff0c\u65e0\u9700\u5916\u90e8\u5de5\u5177\u3002\u5728\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u56fe\u50cf/\u97f3\u9891\u751f\u6210\u7b49\u975e\u6587\u672c\u8f93\u51fa\u4efb\u52a1\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u53ef\u80fd\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u5374\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u963b\u788d\u4e86\u53ef\u9760\u90e8\u7f72\u3002\u51c6\u786e\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u53ef\u5e2e\u52a9\u8bc6\u522b\u4e0d\u53ef\u9760\u67e5\u8be2\u5e76\u8f6c\u4ea4\u4eba\u5de5\u6216\u66f4\u5927\u6a21\u578b\u5904\u7406\u3002\u7136\u800c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u4ec5\u9650\u7279\u5b9a\u6a21\u6001\u3001\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u901a\u7528\u3001\u9ad8\u6548\u4e14\u65e0\u9700\u5916\u90e8\u4f9d\u8d56\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6848\u3002", "method": "UMPIRE\u6846\u67b6\u91c7\u7528\u8bad\u7ec3-free\u65b9\u5f0f\uff0c\u4ec5\u5229\u7528\u6a21\u578b\u5185\u90e8\u6a21\u6001\u7279\u5f81\u3002\u5176\u6838\u5fc3\u662f\u8ba1\u7b97\u7ed9\u5b9a\u4efb\u52a1\u5b9e\u4f8b\u7684\u91c7\u6837MLLM\u54cd\u5e94\u7684\"\u4e0d\u4e00\u81f4\u6027\u8c03\u6574\u7684\u8bed\u4e49\u4f53\u79ef\"\uff0c\u540c\u65f6\u6355\u6349\u6837\u672c\u7684\u5168\u5c40\u8bed\u4e49\u591a\u6837\u6027\u4e0e\u57fa\u4e8e\u5185\u90e8\u6a21\u578b\u4fe1\u5fc3\u7684\u5c40\u90e8\u54cd\u5e94\u4e0d\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u7f6e\u4fe1\u5ea6\u52a0\u6743\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUMPIRE\u5728\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u6548\u679c\u663e\u8457\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u6cdb\u5316\u81f3\u56fe\u50cf\u548c\u97f3\u9891\u751f\u6210\u7b49\u975e\u6587\u672c\u8f93\u51fa\u4efb\u52a1\u3002", "conclusion": "UMPIRE\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u5176\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u53ef\u9760\u8bc6\u522b\u6a21\u578b\u9519\u8bef\uff0c\u4e3a\u63d0\u5347MLLM\u90e8\u7f72\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u5c55\u73b0\u51fa\u826f\u597d\u7684\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.23761", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23761", "abs": "https://arxiv.org/abs/2602.23761", "authors": ["Yuyu Geng", "Lei Sun", "Yao Gao", "Xinxin Hu", "Zhonghua Yi", "Xiaolong Qian", "Weijian Hu", "Jian Bai", "Kaiwei Wang"], "title": "OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design", "comment": null, "summary": "Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5149\u5b66\u8bbe\u8ba1\u9886\u57df\uff0c\u901a\u8fc7\u6784\u5efaOptiDesignQA\u6570\u636e\u96c6\u3001\u91c7\u7528\u6df7\u5408\u76ee\u6807\u51fd\u6570\u6ce8\u5165\u4e13\u4e1a\u77e5\u8bc6\u3001\u4f7f\u7528\u5149\u5b66\u8bcd\u5178\u5956\u52b1\u5f15\u5bfc\u7684DrGRPO\u7b97\u6cd5\u8fdb\u884c\u7269\u7406\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u4e0e\u4e13\u4e1a\u5149\u5b66\u4f18\u5316\u7a0b\u5e8f\u96c6\u6210\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u975e\u5149\u5b66\u4e13\u5bb6\u4e5f\u80fd\u8bbe\u8ba1\u529f\u80fd\u6027\u955c\u5934\u7cfb\u7edf\uff0c\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u7b97\u6cd5\u548c\u5176\u4ed6LLM\u65b9\u6cd5\u3002", "motivation": "\u5149\u5b66\u8bbe\u8ba1\u662f\u4e00\u4e2a\u9ad8\u5ea6\u975e\u51f8\u7684\u4f18\u5316\u95ee\u9898\uff0c\u4e25\u91cd\u4f9d\u8d56\u4eba\u7c7b\u542f\u53d1\u5f0f\u4e13\u4e1a\u77e5\u8bc6\u548c\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5177\u5907\u4e30\u5bcc\u7684\u5149\u5b66\u77e5\u8bc6\uff0c\u4f46\u5728\u5b9e\u9645\u955c\u5934\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\u4ecd\u7136\u53d7\u9650\uff0c\u5b58\u5728\u4e13\u4e1a\u77e5\u8bc6\u5e94\u7528\u9e3f\u6c9f\u3002", "method": "1) \u6784\u5efaOptiDesignQA\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ecf\u5178\u6559\u6750\u955c\u5934\u7cfb\u7edf\u548c\u81ea\u52a8\u5316\u7b97\u6cd5\u751f\u6210\u7684\u65b0\u9896\u914d\u7f6e\uff1b2) \u901a\u8fc7\u5168\u7cfb\u7edf\u5408\u6210\u4e0e\u955c\u5934\u8865\u5168\u7684\u6df7\u5408\u76ee\u6807\u5411LLM\u6ce8\u5165\u5149\u5b66\u4e13\u4e1a\u77e5\u8bc6\uff1b3) \u91c7\u7528\u57fa\u4e8e\u5149\u5b66\u8bcd\u5178\u5956\u52b1\u7684Group Relative Policy Optimization Done Right (DrGRPO)\u8fdb\u884c\u7269\u7406\u9a71\u52a8\u7684\u7b56\u7565\u5bf9\u9f50\uff0c\u5956\u52b1\u673a\u5236\u5305\u542b\u7ed3\u6784\u683c\u5f0f\u5956\u52b1\u3001\u7269\u7406\u53ef\u884c\u6027\u5956\u52b1\u3001\u5149\u7ebf\u64cd\u63a7\u7cbe\u5ea6\u548cLLM\u542f\u53d1\u5f0f\u5956\u52b1\uff1b4) \u96c6\u6210\u4e13\u4e1a\u5149\u5b66\u4f18\u5316\u7a0b\u5e8f\u8fdb\u884c\u7aef\u5230\u7aef\u5fae\u8c03\u548c\u7cbe\u5ea6\u4f18\u5316\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u672c\u7814\u7a76\u65b9\u6cd5\u76f8\u8f83\u4e8e\u4f20\u7edf\u57fa\u4e8e\u4f18\u5316\u7684\u81ea\u52a8\u5316\u8bbe\u8ba1\u7b97\u6cd5\u548c\u5176\u4ed6LLM\u57fa\u7ebf\u65b9\u6cd5\u5747\u8868\u73b0\u51fa\u663e\u8457\u4f18\u8d8a\u6027\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f25\u5408\u4e86\u5149\u5b66\u8bbe\u8ba1\u9886\u57df\u7684\u4e13\u4e1a\u77e5\u8bc6\u9e3f\u6c9f\uff0c\u4f7f\u672a\u7ecf\u6b63\u5f0f\u5149\u5b66\u8bad\u7ec3\u7684\u7528\u6237\u80fd\u591f\u5f00\u53d1\u529f\u80fd\u6027\u955c\u5934\u7cfb\u7edf\uff0c\u4e3aLLM\u5728\u5149\u5b66\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u5f00\u8f9f\u4e86\u91cd\u8981\u65b9\u5411\uff0c\u5e76\u5c55\u793a\u4e86\u7269\u7406\u5956\u52b1\u673a\u5236\u4e0e\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u76f8\u7ed3\u5408\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.24142", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24142", "abs": "https://arxiv.org/abs/2602.24142", "authors": ["Yuxuan Liu", "Weikai Xu", "Kun Huang", "Changyu Chen", "Jiankun Zhao", "Pengzhi Gao", "Wei Liu", "Jian Luan", "Shuo Shang", "Bo Du", "Ji-Rong Wen", "Rui Yan"], "title": "CoME: Empowering Channel-of-Mobile-Experts with Informative Hybrid-Capabilities Reasoning", "comment": null, "summary": "Mobile Agents can autonomously execute user instructions, which requires hybrid-capabilities reasoning, including screen summary, subtask planning, action decision and action function. However, existing agents struggle to achieve both decoupled enhancement and balanced integration of these capabilities. To address these challenges, we propose Channel-of-Mobile-Experts (CoME), a novel agent architecture consisting of four distinct experts, each aligned with a specific reasoning stage, CoME activates the corresponding expert to generate output tokens in each reasoning stage via output-oriented activation. To empower CoME with hybrid-capabilities reasoning, we introduce a progressive training strategy: Expert-FT enables decoupling and enhancement of different experts' capability; Router-FT aligns expert activation with the different reasoning stage; CoT-FT facilitates seamless collaboration and balanced optimization across multiple capabilities. To mitigate error propagation in hybrid-capabilities reasoning, we propose InfoGain-Driven DPO (Info-DPO), which uses information gain to evaluate the contribution of each intermediate step, thereby guiding CoME toward more informative reasoning. Comprehensive experiments show that CoME outperforms dense mobile agents and MoE methods on both AITZ and AMEX datasets.", "AI": {"tldr": "\u9488\u5bf9\u79fb\u52a8\u667a\u80fd\u4f53\u6df7\u5408\u63a8\u7406\u80fd\u529b\u96be\u4ee5\u89e3\u8026\u589e\u5f3a\u4e0e\u5e73\u8861\u96c6\u6210\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faCoME\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e13\u5bb6\u5206\u5de5\u3001\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u53caInfoGain-Driven DPO\u4f18\u5316\uff0c\u5728AITZ\u548cAMEX\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6027\u80fd\u7a81\u7834\u3002", "motivation": "\u79fb\u52a8\u667a\u80fd\u4f53\u9700\u540c\u6b65\u5b9e\u73b0\u5c4f\u5e55\u6458\u8981\u3001\u5b50\u4efb\u52a1\u89c4\u5212\u3001\u884c\u52a8\u51b3\u7b56\u4e0e\u6267\u884c\u7b49\u591a\u9636\u6bb5\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u80fd\u529b\u8026\u5408\u4e25\u91cd\u3001\u96be\u4ee5\u5e73\u8861\u4f18\u5316\u7684\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u63d0\u51faChannel-of-Mobile-Experts (CoME)\u56db\u4e13\u5bb6\u67b6\u6784\uff0c\u6bcf\u4e13\u5bb6\u4e13\u7cbe\u4e8e\u7279\u5b9a\u63a8\u7406\u9636\u6bb5\u3002\u91c7\u7528\u8f93\u51fa\u5bfc\u5411\u6fc0\u6d3b\u673a\u5236\u52a8\u6001\u8c03\u7528\u4e13\u5bb6\u3002\u8bbe\u8ba1\u6e10\u8fdb\u5f0f\u4e09\u9636\u6bb5\u8bad\u7ec3\uff1aExpert-FT\u5b9e\u73b0\u4e13\u5bb6\u80fd\u529b\u89e3\u8026\u589e\u5f3a\uff0cRouter-FT\u786e\u4fdd\u4e13\u5bb6\u6fc0\u6d3b\u4e0e\u63a8\u7406\u9636\u6bb5\u5bf9\u9f50\uff0cCoT-FT\u4fc3\u8fdb\u591a\u80fd\u529b\u534f\u540c\u4f18\u5316\u3002\u5f15\u5165InfoGain-Driven DPO\uff0c\u5229\u7528\u4fe1\u606f\u589e\u76ca\u91cf\u5316\u4e2d\u95f4\u6b65\u9aa4\u8d21\u732e\uff0c\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u66f4\u6709\u6548\u7684\u63a8\u7406\u4ee5\u6291\u5236\u9519\u8bef\u4f20\u64ad\u3002", "result": "\u5728AITZ\u548cAMEX\u4e24\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cCoME\u67b6\u6784\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5bc6\u96c6\u79fb\u52a8\u667a\u80fd\u4f53\u6a21\u578b\u53ca\u4f20\u7edfMoE\u65b9\u6cd5\u3002", "conclusion": "CoME\u901a\u8fc7\u4e13\u5bb6\u5316\u5206\u5de5\u4e0e\u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408\u63a8\u7406\u80fd\u529b\u7684\u89e3\u8026\u589e\u5f3a\u4e0e\u5e73\u8861\u96c6\u6210\u96be\u9898\uff0cInfoGain-Driven DPO\u8fdb\u4e00\u6b65\u7f13\u89e3\u4e86\u9519\u8bef\u4f20\u64ad\u95ee\u9898\uff0c\u4e3a\u79fb\u52a8\u667a\u80fd\u4f53\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.24273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24273", "abs": "https://arxiv.org/abs/2602.24273", "authors": ["Borja Requena Pozo", "Austin Letson", "Krystian Nowakowski", "Izan Beltran Ferreiro", "Leopoldo Sarra"], "title": "A Minimal Agent for Automated Theorem Proving", "comment": null, "summary": "We propose a minimal agentic baseline that enables systematic comparison across different AI-based theorem prover architectures. This design implements the core features shared among state-of-the-art systems: iterative proof refinement, library search and context management. We evaluate our baseline using qualitatively different benchmarks and compare various popular models and design choices, and demonstrate competitive performance compared to state-of-the-art approaches, while using a significantly simpler architecture. Our results demonstrate consistent advantages of an iterative approach over multiple single-shot generations, especially in terms of sample efficiency and cost effectiveness. The implementation is released open-source as a candidate reference for future research and as an accessible prover for the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6781\u7b80\u7684\u667a\u80fd\u4f53\u57fa\u7ebf\u7cfb\u7edf\uff0c\u7528\u4e8e\u7cfb\u7edf\u5316\u6bd4\u8f83\u4e0d\u540cAI\u5b9a\u7406\u8bc1\u660e\u5668\u67b6\u6784\u3002\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86SOTA\u7cfb\u7edf\u7684\u6838\u5fc3\u529f\u80fd\uff08\u8fed\u4ee3\u8bc1\u660e\u4f18\u5316\u3001\u5e93\u641c\u7d22\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\uff09\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u67b6\u6784\u66f4\u7b80\u5355\u3002\u7814\u7a76\u8868\u660e\u8fed\u4ee3\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u4f18\u4e8e\u5355\u6b21\u751f\u6210\u65b9\u6cd5\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u5f53\u524dAI\u5b9a\u7406\u8bc1\u660e\u5668\u67b6\u6784\u591a\u6837\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6bd4\u8f83\u57fa\u51c6\uff0c\u4f7f\u5f97\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u5bf9\u6bd4\u53d8\u5f97\u56f0\u96be\u3002\u9700\u8981\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u667a\u80fd\u4f53\u6846\u67b6\u6765\u5b9e\u73b0\u516c\u5e73\u6bd4\u8f83\uff0c\u540c\u65f6\u4fdd\u6301\u8db3\u591f\u7684\u8868\u8fbe\u529b\u6765\u8bc4\u4f30\u5404\u79cd\u8bbe\u8ba1\u9009\u62e9\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\u7684\u6781\u7b80\u667a\u80fd\u4f53\u57fa\u7ebf\uff1a1\uff09\u8fed\u4ee3\u8bc1\u660e\u4f18\u5316\u673a\u5236\uff1b2\uff09\u5e93\u641c\u7d22\u529f\u80fd\uff1b3\uff09\u4e0a\u4e0b\u6587\u7ba1\u7406\u7cfb\u7edf\u3002\u5728\u4e0d\u540c\u8d28\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u8be5\u7cfb\u7edf\uff0c\u5e76\u6bd4\u8f83\u4e86\u591a\u79cd\u6d41\u884c\u6a21\u578b\u548c\u8bbe\u8ba1\u9009\u62e9\u3002", "result": "\u8be5\u57fa\u7ebf\u7cfb\u7edf\u5728\u6027\u80fd\u4e0a\u8fbe\u5230\u4e0eSOTA\u65b9\u6cd5\u7ade\u4e89\u7684\u6c34\u5e73\uff0c\u540c\u65f6\u67b6\u6784\u663e\u8457\u7b80\u5316\u3002\u5173\u952e\u53d1\u73b0\u662f\u8fed\u4ee3\u65b9\u6cd5\u76f8\u6bd4\u5355\u6b21\u751f\u6210\u5177\u6709\u4e00\u81f4\u6027\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u6837\u672c\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8fed\u4ee3\u8bc1\u660e\u751f\u6210\u662fAI\u5b9a\u7406\u8bc1\u660e\u7684\u5173\u952e\u8303\u5f0f\uff0c\u5177\u6709\u663e\u8457\u7684\u6548\u7387\u4f18\u52bf\u3002\u8be5\u5f00\u6e90\u57fa\u7ebf\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u53c2\u8003\uff0c\u4e5f\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u8bc1\u660e\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2602.23770", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23770", "abs": "https://arxiv.org/abs/2602.23770", "authors": ["Chenxing Lin", "Xinhui Gao", "Haipeng Zhang", "Xinran Li", "Haitao Wang", "Songzhu Mei", "Chenglu Wen", "Weiquan Liu", "Siqi Shen", "Cheng Wang"], "title": "MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning", "comment": "ICLR2026", "summary": "Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMAGE\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u5c3a\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6761\u4ef6\u5f15\u5bfc\u7684\u591a\u5c3a\u5ea6\u81ea\u52a8\u7f16\u7801\u5668\u548c\u4ece\u7c97\u5230\u7ec6\u751f\u6210\u8f68\u8ff9\u7684\u591a\u5c3a\u5ea6Transformer\uff0c\u6709\u6548\u6355\u6349\u957f\u65f6\u5e8f\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u7684\u591a\u5c42\u6b21\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u751f\u6210\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u957f\u65f6\u5e8f\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5c42\u6b21\u5316\u751f\u6210\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u8f68\u8ff9\u4e2d\u56fa\u6709\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u7ed3\u6784\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u3002", "method": "MAGE\u91c7\u7528\u6761\u4ef6\u5f15\u5bfc\u7684\u591a\u5c3a\u5ea6\u81ea\u52a8\u7f16\u7801\u5668\u5b66\u4e60\u5c42\u6b21\u5316\u8f68\u8ff9\u8868\u793a\uff0c\u5e76\u8bbe\u8ba1\u591a\u5c3a\u5ea6Transformer\u4ee5\u4ece\u7c97\u5230\u7ec6\u7684\u65f6\u95f4\u5c3a\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u8f68\u8ff9\u8868\u793a\uff0c\u540c\u65f6\u901a\u8fc7\u6761\u4ef6\u5f15\u5bfc\u89e3\u7801\u5668\u7cbe\u786e\u63a7\u5236\u77ed\u671f\u884c\u4e3a\u3002", "result": "\u5728\u4e94\u4e2a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e\u5341\u4e94\u79cd\u57fa\u7ebf\u7b97\u6cd5\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMAGE\u6210\u529f\u878d\u5408\u4e86\u591a\u5c3a\u5ea6\u8f68\u8ff9\u5efa\u6a21\u4e0e\u6761\u4ef6\u5f15\u5bfc\uff0c\u5728\u957f\u65f6\u5e8f\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u751f\u6210\u4e86\u8fde\u8d2f\u4e14\u53ef\u63a7\u7684\u8f68\u8ff9\u3002", "conclusion": "MAGE\u80fd\u591f\u6709\u6548\u6355\u6349\u8f68\u8ff9\u7684\u591a\u5206\u8fa8\u7387\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u4e3a\u957f\u65f6\u5e8f\u7a00\u758f\u5956\u52b1\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591a\u5c3a\u5ea6\u751f\u6210\u5efa\u6a21\u65b9\u6848\u3002"}}
{"id": "2602.24172", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24172", "abs": "https://arxiv.org/abs/2602.24172", "authors": ["Adam Dejl", "Deniz Gorur", "Francesca Toni"], "title": "ArgLLM-App: An Interactive System for Argumentative Reasoning with Large Language Models", "comment": "AAMAS 2026 Demonstration Track", "summary": "Argumentative LLMs (ArgLLMs) are an existing approach leveraging Large Language Models (LLMs) and computational argumentation for decision-making, with the aim of making the resulting decisions faithfully explainable to and contestable by humans. Here we propose a web-based system implementing ArgLLM-empowered agents for binary tasks. ArgLLM-App supports visualisation of the produced explanations and interaction with human users, allowing them to identify and contest any mistakes in the system's reasoning. It is highly modular and enables drawing information from trusted external sources. ArgLLM-App is publicly available at https://argllm.app, with a video demonstration at https://youtu.be/vzwlGOr0sPM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faArgLLM-App\uff0c\u4e00\u4e2a\u57fa\u4e8e\u8bba\u8bc1\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff08ArgLLMs\uff09\u7684Web\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e8c\u5143\u51b3\u7b56\u4efb\u52a1\u3002\u8be5\u7cfb\u7edf\u63d0\u4f9b\u53ef\u89c6\u5316\u89e3\u91ca\u3001\u4eba\u673a\u4ea4\u4e92\u754c\u9762\uff0c\u5141\u8bb8\u7528\u6237\u8bc6\u522b\u5e76\u8d28\u7591\u7cfb\u7edf\u63a8\u7406\u9519\u8bef\uff0c\u5177\u5907\u9ad8\u6a21\u5757\u5316\u67b6\u6784\uff0c\u53ef\u96c6\u6210\u53ef\u4fe1\u5916\u90e8\u4fe1\u606f\u6765\u6e90\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5f62\u6210\u201c\u9ed1\u7bb1\u201d\u95ee\u9898\u3002\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8ba1\u7b97\u8bba\u8bc1\u7ed3\u5408\uff0c\u65e8\u5728\u6784\u5efa\u53ef\u5fe0\u5b9e\u89e3\u91ca\u4e14\u53ef\u4f9b\u4eba\u7c7b\u8d28\u8be2\u7684\u51b3\u7b56\u7cfb\u7edf\uff0c\u589e\u5f3aAI\u51b3\u7b56\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u95ee\u8d23\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aArgLLM-App\u7684Web\u5e94\u7528\u7a0b\u5e8f\uff0c\u90e8\u7f72\u8bba\u8bc1\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5904\u7406\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u3002\u7cfb\u7edf\u6838\u5fc3\u529f\u80fd\u5305\u62ec\uff1a\u63a8\u7406\u8fc7\u7a0b\u53ef\u89c6\u5316\u3001\u7528\u6237\u4ea4\u4e92\u754c\u9762\u7528\u4e8e\u8bc6\u522b\u548c\u53cd\u9a73\u7cfb\u7edf\u9519\u8bef\u3001\u6a21\u5757\u5316\u8bbe\u8ba1\u4ee5\u53ca\u5916\u90e8\u53ef\u4fe1\u6570\u636e\u6e90\u96c6\u6210\u80fd\u529b\u3002", "result": "\u7cfb\u7edf\u5df2\u516c\u5f00\u53d1\u5e03\u4e8ehttps://argllm.app\uff0c\u5e76\u914d\u5957\u6f14\u793a\u89c6\u9891\uff08https://youtu.be/vzwlGOr0sPM\uff09\u3002\u6210\u529f\u5b9e\u73b0\u4e86\u8bba\u8bc1\u578b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7528\u6237\u7aef\u5e94\u7528\uff0c\u652f\u6301\u5b9e\u65f6\u4eba\u673a\u534f\u540c\u7ea0\u9519\u3002", "conclusion": "ArgLLM-App\u4e3a\u53ef\u4fe1\u8d56AI\u63d0\u4f9b\u4e86\u5b9e\u7528\u5316\u8def\u5f84\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u8fa9\u9a73\u6027\u8bbe\u8ba1\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u5bf9\u7528\u6237\u900f\u660e\u4e14\u53ef\u4fee\u6b63\u3002\u6a21\u5757\u5316\u67b6\u6784\u4e0e\u5916\u90e8\u4fe1\u606f\u6e90\u96c6\u6210\u589e\u5f3a\u4e86\u5176\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4e3a\u8d1f\u8d23\u4efbAI\u90e8\u7f72\u5efa\u7acb\u4e86\u91cd\u8981\u8303\u4f8b\u3002"}}
{"id": "2602.24288", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24288", "abs": "https://arxiv.org/abs/2602.24288", "authors": ["Fan Shu", "Yite Wang", "Ruofan Wu", "Boyi Liu", "Zhewei Yao", "Yuxiong He", "Feng Yan"], "title": "DARE-bench: Evaluating Modeling and Instruction Fidelity of LLMs in Data Science", "comment": "Published as a conference paper at ICLR 2026. 10 pages plus appendix", "summary": "The fast-growing demands in using Large Language Models (LLMs) to tackle complex multi-step data science tasks create an emergent need for accurate benchmarking. There are two major gaps in existing benchmarks: (i) the lack of standardized, process-aware evaluation that captures instruction adherence and process fidelity, and (ii) the scarcity of accurately labeled training data. To bridge these gaps, we introduce DARE-bench, a benchmark designed for machine learning modeling and data science instruction following. Unlike many existing benchmarks that rely on human- or model-based judges, all tasks in DARE-bench have verifiable ground truth, ensuring objective and reproducible evaluation. To cover a broad range of tasks and support agentic tools, DARE-bench consists of 6,300 Kaggle-derived tasks and provides both large-scale training data and evaluation sets. Extensive evaluations show that even highly capable models such as gpt-o4-mini struggle to achieve good performance, especially in machine learning modeling tasks. Using DARE-bench training tasks for fine-tuning can substantially improve model performance. For example, supervised fine-tuning boosts Qwen3-32B's accuracy by 1.83x and reinforcement learning boosts Qwen3-4B's accuracy by more than 8x. These significant improvements verify the importance of DARE-bench both as an accurate evaluation benchmark and critical training data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDARE-bench\uff0c\u4e00\u4e2a\u542b6,300\u4e2a\u53ef\u9a8c\u8bc1Kaggle\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u6570\u636e\u79d1\u5b66\u80fd\u529b\u3002\u5b9e\u9a8c\u663e\u793a\u5f3a\u6a21\u578b\u5982gpt-o4-mini\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u57fa\u4e8e\u8be5\u57fa\u51c6\u7684\u5fae\u8c03\u53ef\u4f7fQwen3\u6a21\u578b\u51c6\u786e\u7387\u63d0\u5347\u6700\u9ad88\u500d\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e24\u5927\u7f3a\u9677\uff1a\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u8fc7\u7a0b\u611f\u77e5\u8bc4\u4f30\uff08\u65e0\u6cd5\u8861\u91cf\u6307\u4ee4\u9075\u5faa\u548c\u8fc7\u7a0b\u4fdd\u771f\u5ea6\uff09\uff0c\u4ee5\u53ca\u51c6\u786e\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7684\u7a00\u7f3a\u6027\u3002\u968f\u7740LLM\u5728\u590d\u6742\u591a\u6b65\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e2d\u5e94\u7528\u9700\u6c42\u6fc0\u589e\uff0c\u4e9f\u9700\u4e00\u4e2a\u66f4\u51c6\u786e\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86DARE-bench\uff0c\u5305\u542b6,300\u4e2a\u6e90\u81eaKaggle\u7684\u6570\u636e\u79d1\u5b66\u4efb\u52a1\uff0c\u6240\u6709\u4efb\u52a1\u5747\u8bbe\u6709\u53ef\u9a8c\u8bc1\u7684\u5ba2\u89c2\u7b54\u6848\uff0c\u907f\u514d\u4f9d\u8d56\u4e3b\u89c2\u7684\u4eba\u6216\u6a21\u578b\u8bc4\u5224\u3002\u8be5\u57fa\u51c6\u540c\u65f6\u63d0\u4f9b\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u96c6\uff0c\u8986\u76d6\u5e7f\u6cdb\u7684\u4efb\u52a1\u7c7b\u578b\u5e76\u652f\u6301\u667a\u80fd\u4f53\u5de5\u5177\u7684\u4f7f\u7528\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u662fgpt-o4-mini\u7b49\u9ad8\u6027\u80fd\u6a21\u578b\u5728\u673a\u5668\u5b66\u4e60\u5efa\u6a21\u4efb\u52a1\u4e2d\u8868\u73b0\u4ecd\u7136\u4e0d\u4f73\u3002\u4f7f\u7528DARE-bench\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u6548\u679c\u663e\u8457\uff1a\u76d1\u7763\u5fae\u8c03\u4f7fQwen3-32B\u51c6\u786e\u7387\u63d0\u53471.83\u500d\uff0c\u5f3a\u5316\u5b66\u4e60\u4f7fQwen3-4B\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc78\u500d\u3002", "conclusion": "DARE-bench\u901a\u8fc7\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u5ba2\u89c2\u8bc4\u4f30\u548c\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4e0d\u4ec5\u4f5c\u4e3a\u51c6\u786e\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u66f4\u6210\u4e3a\u5173\u952e\u7684\u8bad\u7ec3\u8d44\u6e90\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u63a8\u52a8LLM\u6570\u636e\u79d1\u5b66\u80fd\u529b\u63d0\u5347\u65b9\u9762\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.24174", "categories": ["cs.CL", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.24174", "abs": "https://arxiv.org/abs/2602.24174", "authors": ["Dor Tsur", "Sharon Adar", "Ran Levy"], "title": "Task-Centric Acceleration of Small-Language Models", "comment": null, "summary": "Small language models (SLMs) have emerged as efficient alternatives to large language models for task-specific applications. However, they are often employed in high-volume, low-latency settings, where efficiency is crucial. We propose TASC, Task-Adaptive Sequence Compression, a framework for SLM acceleration comprising two use-cases: When performing SLM fine-tuning, we propose TASC-ft, which iteratively enriches the tokenizer vocabulary with high-frequency output n-grams and then fine-tunes the model to utilize the expanded vocabulary. Next, we propose an inference-time method, termed TASC-spec. TASC-spec is a lightweight, training-free speculative decoding method that constructs an n-gram draft model from the task's output corpus, mixing task and context n-gram information.TASC-spec avoids any additional training, while bypassing draft-target vocabulary alignment constraints. We demonstrate the effectiveness of both methods across multiple low output-variability generation tasks. Our methods show consistent improvements in inference efficiency while maintaining task performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTASC\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u81ea\u9002\u5e94\u5e8f\u5217\u538b\u7f29\u52a0\u901f\u5c0f\u8bed\u8a00\u6a21\u578b\u3002\u5305\u542b\u4e24\u79cd\u65b9\u6cd5\uff1aTASC-ft\u5728\u5fae\u8c03\u65f6\u6269\u5c55\u8bcd\u8868\u52a0\u5165\u9ad8\u9891\u8f93\u51fan-gram\uff1bTASC-spec\u5728\u63a8\u7406\u65f6\u6784\u5efan-gram\u8349\u7a3f\u6a21\u578b\u8fdb\u884c\u63a8\u6d4b\u89e3\u7801\uff0c\u65e0\u9700\u8bad\u7ec3\u4e14\u80fd\u7ed5\u8fc7\u8bcd\u8868\u5bf9\u9f50\u9650\u5236\u3002\u5728\u4f4e\u8f93\u51fa\u53d8\u5f02\u6027\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u4e14\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u5e94\u7528\u4e2d\u867d\u6bd4\u5927\u6a21\u578b\u9ad8\u6548\uff0c\u4f46\u5728\u9ad8\u5e76\u53d1\u3001\u4f4e\u5ef6\u8fdf\u573a\u666f\u4e0b\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6548\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u5982\u5fae\u8c03\u6210\u672c\u9ad8\u6216\u63a8\u6d4b\u89e3\u7801\u53d7\u8bcd\u8868\u5bf9\u9f50\u7ea6\u675f\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u5347\u63a8\u7406\u6548\u7387\u53c8\u4e0d\u727a\u7272\u4efb\u52a1\u6027\u80fd\u7684\u538b\u7f29\u52a0\u901f\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09TASC-ft\uff1a\u8fed\u4ee3\u5f0f\u6269\u5145\u5206\u8bcd\u5668\u8bcd\u8868\uff0c\u52a0\u5165\u4efb\u52a1\u8f93\u51fa\u4e2d\u7684\u9ad8\u9891n-gram\uff0c\u7136\u540e\u5fae\u8c03\u6a21\u578b\u9002\u914d\u6269\u5c55\u8bcd\u8868\uff1b2\uff09TASC-spec\uff1a\u63a8\u7406\u65f6\u57fa\u4e8e\u4efb\u52a1\u8f93\u51fa\u8bed\u6599\u6784\u5efa\u8f7b\u91cf\u7ea7n-gram\u8349\u7a3f\u6a21\u578b\uff0c\u878d\u5408\u4efb\u52a1\u5148\u9a8c\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u8fdb\u884c\u63a8\u6d4b\u89e3\u7801\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u907f\u514d\u8349\u7a3f\u4e0e\u76ee\u6807\u6a21\u578b\u95f4\u7684\u8bcd\u8868\u5bf9\u9f50\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u4f4e\u8f93\u51fa\u53d8\u5f02\u6027\u751f\u6210\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u663e\u793a\u4e00\u81f4\u7684\u63a8\u7406\u6548\u7387\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u4e0d\u4e0b\u964d\u3002", "conclusion": "TASC\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u81ea\u9002\u5e94\u7684\u5e8f\u5217\u538b\u7f29\u7b56\u7565\uff0c\u4e3a\u5c0f\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5fae\u8c03\u4e0e\u63a8\u7406\u52a0\u901f\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5bf9\u5ef6\u8fdf\u654f\u611f\u7684\u9ad8\u541e\u5410\u91cf\u573a\u666f\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.23785", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23785", "abs": "https://arxiv.org/abs/2602.23785", "authors": ["Zhiwei Han", "Stefan Matthes", "Hao Shen"], "title": "Provable Subspace Identification of Nonlinear Multi-view CCA", "comment": null, "summary": "We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \\geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u89c6\u89d2\u975e\u7ebf\u6027\u5178\u578b\u76f8\u5173\u5206\u6790\uff08CCA\uff09\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u5c06\u95ee\u9898\u91cd\u65b0\u6846\u67b6\u4e3a\u57fa\u4e0d\u53d8\u5b50\u7a7a\u95f4\u8bc6\u522b\u3002\u8bc1\u660e\u5728\u9002\u5f53\u6f5c\u5728\u5148\u9a8c\u548c\u8c31\u5206\u79bb\u6761\u4ef6\u4e0b\uff0c\u591a\u89c6\u89d2CCA\u53ef\u5728\u89c6\u89d2\u6b63\u4ea4\u6a21\u7cca\u4e0b\u6062\u590d\u4fe1\u53f7\u5b50\u7a7a\u95f4\uff1b\u5f53\u89c6\u89d2\u6570N\u22653\u65f6\uff0c\u53ef\u5206\u79bb\u6240\u6709\u89c6\u89d2\u5171\u4eab\u7684\u8054\u5408\u76f8\u5173\u5b50\u7a7a\u95f4\u5e76\u6d88\u9664\u79c1\u6709\u566a\u58f0\uff0c\u901a\u8fc7\u8c31\u6270\u52a8\u7406\u8bba\u5efa\u7acb\u6709\u9650\u6837\u672c\u4e00\u81f4\u6027\u754c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "motivation": "\u975e\u7ebf\u6027\u5178\u578b\u76f8\u5173\u5206\u6790\uff08CCA\uff09\u662f\u591a\u89c6\u89d2\u5b66\u4e60\u7684\u6838\u5fc3\u65b9\u6cd5\uff0c\u4f46\u5176\u5728\u975e\u7ebf\u6027\u573a\u666f\u4e0b\u7684\u53ef\u8bc6\u522b\u6027\u7406\u8bba\u5c1a\u4e0d\u5b8c\u5584\u3002\u4f20\u7edf\u7cbe\u786e\u89e3\u6df7\u65b9\u6cd5\u88ab\u8bc1\u660e\u662f\u75c5\u6001\u95ee\u9898\uff0c\u5bfc\u81f4\u7406\u8bba\u4fdd\u8bc1\u7f3a\u5931\u3002\u672c\u7814\u7a76\u65e8\u5728\u5efa\u7acb\u975e\u7ebf\u6027\u591a\u89c6\u89d2CCA\u7684\u53ef\u8bc6\u522b\u6027\u7406\u8bba\uff0c\u660e\u786e\u5728\u5b58\u5728\u89c6\u89d2\u79c1\u6709\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u4ece\u591a\u4e2a\u975e\u7ebf\u6027\u89c2\u6d4b\u4e2d\u53ef\u9760\u6062\u590d\u4f55\u79cd\u7ed3\u6784\uff0c\u4e3a\u591a\u89c6\u89d2\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5c06\u591a\u89c6\u89d2CCA\u91cd\u65b0\u6846\u67b6\u5316\u4e3a\u57fa\u4e0d\u53d8\u5b50\u7a7a\u95f4\u8bc6\u522b\u95ee\u9898\uff0c\u907f\u514d\u76f4\u63a5\u6c42\u89e3\u75c5\u6001\u7684\u7cbe\u786e\u89e3\u6df7\u3002\u5728\u5408\u9002\u7684\u6f5c\u5728\u53d8\u91cf\u5148\u9a8c\u548c\u8c31\u5206\u79bb\u6761\u4ef6\u4e0b\uff0c\u5229\u7528\u7ecf\u9a8c\u4e92\u534f\u65b9\u5dee\u77e9\u9635\u7684\u6d53\u5ea6\u6027\u8d28\uff0c\u901a\u8fc7\u8c31\u6270\u52a8\u7406\u8bba\u63a8\u5bfc\u5b50\u7a7a\u95f4\u8bef\u5dee\u7684\u663e\u5f0f\u4e0a\u754c\uff0c\u4ece\u800c\u5efa\u7acb\u6709\u9650\u6837\u672c\u4e00\u81f4\u6027\u4fdd\u8bc1\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff1a1\uff09\u5728N\u4e2a\u89c6\u89d2\u4e0b\uff0c\u7b97\u6cd5\u53ef\u6062\u590d\u6210\u5bf9\u76f8\u5173\u7684\u4fe1\u53f7\u5b50\u7a7a\u95f4\uff0c\u81f3\u591a\u5b58\u5728\u89c6\u89d2\u6b63\u4ea4\u6a21\u7cca\uff1b2\uff09\u5f53N\u22653\u65f6\uff0c\u76ee\u6807\u51fd\u6570\u80fd\u552f\u4e00\u5730\u5206\u79bb\u6240\u6709\u89c6\u89d2\u5171\u4eab\u7684\u8054\u5408\u76f8\u5173\u5b50\u7a7a\u95f4\uff0c\u540c\u65f6\u6d88\u9664\u89c6\u89d2\u79c1\u6709\u53d8\u5316\uff1b3\uff09\u57fa\u4e8e\u8c31\u6270\u52a8\u7406\u8bba\u83b7\u5f97\u4e86\u663e\u5f0f\u7684\u5b50\u7a7a\u95f4\u4f30\u8ba1\u8bef\u5dee\u754c\uff0c\u8bc1\u660e\u4e86\u6709\u9650\u6837\u672c\u4e00\u81f4\u6027\uff1b4\uff09\u5408\u6210\u6570\u636e\u548c\u6e32\u67d3\u56fe\u50cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u5e76\u786e\u8ba4\u4e86\u5047\u8bbe\u6761\u4ef6\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5efa\u7acb\u4e86\u975e\u7ebf\u6027\u591a\u89c6\u89d2CCA\u7684\u53ef\u8bc6\u522b\u6027\u7406\u8bba\uff0c\u901a\u8fc7\u57fa\u4e0d\u53d8\u5b50\u7a7a\u95f4\u8bc6\u522b\u6846\u67b6\u89e3\u51b3\u4e86\u7cbe\u786e\u89e3\u6df7\u7684\u75c5\u6001\u6027\u95ee\u9898\u3002\u7406\u8bba\u63ed\u793a\u4e86\u591a\u89c6\u89d2\u4fe1\u606f\u878d\u5408\u7684\u672c\u8d28\u4f18\u52bf\uff08N\u22653\u65f6\u7684\u552f\u4e00\u53ef\u8bc6\u522b\u6027\uff09\uff0c\u5e76\u901a\u8fc7\u4e25\u683c\u7684\u6709\u9650\u6837\u672c\u5206\u6790\u63d0\u4f9b\u4e86\u7b97\u6cd5\u7684\u7406\u8bba\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7684\u6709\u6548\u6027\uff0c\u4e3a\u975e\u7ebf\u6027\u591a\u89c6\u89d2\u5b66\u4e60\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.24188", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24188", "abs": "https://arxiv.org/abs/2602.24188", "authors": ["Jacob Eisenstein", "Fantine Huot", "Adam Fisch", "Jonathan Berant", "Mirella Lapata"], "title": "MT-PingEval: Evaluating Multi-Turn Collaboration with Private Information Games", "comment": null, "summary": "We present a scalable methodology for evaluating language models in multi-turn interactions, using a suite of collaborative games that require effective communication about private information. This enables an interactive scaling analysis, in which a fixed token budget is divided over a variable number of turns. We find that in many cases, language models are unable to use interactive collaboration to improve over the non-interactive baseline scenario in which one agent attempts to summarize its information and the other agent immediately acts -- despite substantial headroom. This suggests that state-of-the-art models still suffer from significant weaknesses in planning and executing multi-turn collaborative conversations. We analyze the linguistic features of these dialogues, assessing the roles of sycophancy, information density, and discourse coherence. While there is no single linguistic explanation for the collaborative weaknesses of contemporary language models, we note that humans achieve comparable task success at superior token efficiency by producing dialogues that are more coherent than those produced by most language models. The proactive management of private information is a defining feature of real-world communication, and we hope that MT-PingEval will drive further work towards improving this capability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMT-PingEval\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u6e38\u620f\u8bc4\u4f30\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8bed\u8a00\u6a21\u578b\u7684\u79c1\u6709\u4fe1\u606f\u6c9f\u901a\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u65e0\u6cd5\u5229\u7528\u591a\u8f6e\u534f\u4f5c\u8d85\u8d8a\u975e\u4ea4\u4e92\u57fa\u7ebf\uff0c\u5b58\u5728\u663e\u8457\u534f\u4f5c\u89c4\u5212\u7f3a\u9677\u3002\u4eba\u7c7b\u901a\u8fc7\u66f4\u9ad8\u8fde\u8d2f\u6027\u7684\u5bf9\u8bdd\u5b9e\u73b0\u66f4\u4f18\u7684token\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u534f\u4f5c\u5bf9\u8bdd\u4e2d\u5b58\u5728\u6839\u672c\u6027\u5f31\u70b9\uff0c\u65e0\u6cd5\u6709\u6548\u7ba1\u7406\u79c1\u6709\u4fe1\u606f\u4ea4\u6d41\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6df1\u5165\u5206\u6790\u6a21\u578b\u5728\u4ea4\u4e92\u5f0f\u534f\u4f5c\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5176\u89c4\u5212\u6267\u884c\u7f3a\u9677\uff0c\u4e3a\u63d0\u5347\u771f\u5b9e\u4e16\u754c\u6c9f\u901a\u80fd\u529b\u63d0\u4f9b\u7814\u7a76\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684MT-PingEval\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u9700\u8981\u4ea4\u6d41\u79c1\u6709\u4fe1\u606f\u7684\u534f\u4f5c\u6e38\u620f\u5957\u4ef6\uff0c\u5728\u56fa\u5b9atoken\u9884\u7b97\u4e0b\u8fdb\u884c\u53ef\u53d8\u8f6e\u6b21\u7684\u4ea4\u4e92\u5f0f\u6269\u5c55\u5206\u6790\uff0c\u5bf9\u6bd4\u591a\u8f6e\u534f\u4f5c\u573a\u666f\u4e0e\u975e\u4ea4\u4e92\u57fa\u7ebf\u573a\u666f\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u591a\u6570\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u901a\u8fc7\u591a\u8f6e\u534f\u4f5c\u6539\u5584\u6027\u80fd\uff0c\u4ecd\u663e\u8457\u843d\u540e\u4e8e\u975e\u4ea4\u4e92\u57fa\u7ebf\u3002\u6a21\u578b\u5b58\u5728\u534f\u4f5c\u89c4\u5212\u4e0e\u6267\u884c\u7684\u91cd\u5927\u7f3a\u9677\uff0c\u4e14\u65e0\u5355\u4e00\u8bed\u8a00\u7279\u5f81\uff08\u5982\u5949\u627f\u3001\u4fe1\u606f\u5bc6\u5ea6\u3001\u8bdd\u8bed\u8fde\u8d2f\u6027\uff09\u80fd\u5b8c\u5168\u89e3\u91ca\u6b64\u5f31\u70b9\u3002\u4eba\u7c7b\u901a\u8fc7\u4ea7\u751f\u66f4\u8fde\u8d2f\u7684\u5bf9\u8bdd\u5b9e\u73b0\u66f4\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u4e0etoken\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u51fa\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u534f\u4f5c\u5bf9\u8bdd\u4e2d\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u5c24\u5176\u5728\u4e3b\u52a8\u7ba1\u7406\u79c1\u6709\u4fe1\u606f\u65b9\u9762\u3002MT-PingEval\u6846\u67b6\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76\uff0c\u4fc3\u8fdb\u6a21\u578b\u5411\u5177\u5907\u771f\u5b9e\u4e16\u754c\u534f\u4f5c\u80fd\u529b\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2602.24210", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24210", "abs": "https://arxiv.org/abs/2602.24210", "authors": ["Haritz Puerto", "Haonan Li", "Xudong Han", "Timothy Baldwin", "Iryna Gurevych"], "title": "Controllable Reasoning Models Are Private Thinkers", "comment": null, "summary": "AI agents powered by reasoning models require access to sensitive user data. However, their reasoning traces are difficult to control, which can result in the unintended leakage of private information to external parties. We propose training models to follow instructions not only in the final answer, but also in reasoning traces, potentially under different constraints. We hypothesize that improving their instruction following abilities in the reasoning traces can improve their privacy-preservation skills. To demonstrate this, we fine-tune models on a new instruction-following dataset with explicit restrictions on reasoning traces. We further introduce a generation strategy that decouples reasoning and answer generation using separate LoRA adapters. We evaluate our approach on six models from two model families, ranging from 1.7B to 14B parameters, across two instruction-following benchmarks and two privacy benchmarks. Our method yields substantial improvements, achieving gains of up to 20.9 points in instruction-following performance and up to 51.9 percentage points on privacy benchmarks. These improvements, however, can come at the cost of task utility, due to the trade-off between reasoning performance and instruction-following abilities. Overall, our results show that improving instruction-following behavior in reasoning models can significantly enhance privacy, suggesting a promising direction for the development of future privacy-aware agents. Our code and data are available at https://github.com/UKPLab/arxiv2026-controllable-reasoning-models", "code_url": "https://github.com/UKPLab/arxiv2026-controllable-reasoning-models", "code_stars": 0, "code_last_update": "2026-02-27", "AI": {"tldr": "\u9488\u5bf9\u63a8\u7406\u6a21\u578b\u8bbf\u95ee\u654f\u611f\u6570\u636e\u65f6\u5b58\u5728\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u5728\u63a8\u7406\u75d5\u8ff9\u5c42\u9762\u5b9e\u65bd\u6307\u4ee4\u7ea6\u675f\u4ee5\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u3002\u901a\u8fc7\u5728\u65b0\u6784\u5efa\u7684\u542b\u63a8\u7406\u75d5\u8ff9\u9650\u5236\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u5206\u79bb\u63a8\u7406\u4e0e\u7b54\u6848\u751f\u6210\u7684\u53ccLoRA\u9002\u914d\u5668\u7b56\u7565\uff0c\u57286\u4e2a1.7B-14B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u6307\u4ee4\u9075\u5faa\u6027\u80fd\u63d0\u5347\u8fbe20.9\u70b9\uff0c\u9690\u79c1\u4fdd\u62a4\u63d0\u5347\u8fbe51.9\u4e2a\u767e\u5206\u70b9\uff0c\u4f46\u9700\u6743\u8861\u4efb\u52a1\u6548\u7528\u3002", "motivation": "\u73b0\u6709AI\u63a8\u7406\u6a21\u578b\u5728\u5904\u7406\u654f\u611f\u7528\u6237\u6570\u636e\u65f6\uff0c\u5176\u96be\u4ee5\u63a7\u5236\u7684\u63a8\u7406\u75d5\u8ff9\u53ef\u80fd\u5bfc\u81f4\u9690\u79c1\u4fe1\u606f\u610f\u5916\u6cc4\u9732\u3002\u5f53\u524d\u7814\u7a76\u591a\u805a\u7126\u4e8e\u6700\u7ec8\u8f93\u51fa\u7684\u5b89\u5168\u6027\uff0c\u5ffd\u89c6\u4e86\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u7684\u9690\u79c1\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u8ba4\u4e3a\u5fc5\u987b\u5728\u63a8\u7406\u75d5\u8ff9\u5c42\u9762\u5f15\u5165\u6307\u4ee4\u9075\u5faa\u673a\u5236\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "method": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u6307\u4ee4\u9075\u5faa\u6570\u636e\u96c6\uff0c\u660e\u786e\u5bf9\u63a8\u7406\u75d5\u8ff9\u65bd\u52a0\u9650\u5236\u3002\u65b9\u6cd5\u91c7\u7528\u72ec\u7acb\u7684LoRA\u9002\u914d\u5668\u89e3\u8026\u63a8\u7406\u8fc7\u7a0b\u4e0e\u7b54\u6848\u751f\u6210\uff0c\u5728\u4e24\u4e2a\u6a21\u578b\u5bb6\u65cf\u7684\u516d\u4e2a\u6a21\u578b\uff08\u53c2\u6570\u91cf1.7B\u81f314B\uff09\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u5728\u4e24\u4e2a\u6307\u4ee4\u9075\u5faa\u57fa\u51c6\u548c\u4e24\u4e2a\u9690\u79c1\u57fa\u51c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6307\u4ee4\u9075\u5faa\u6027\u80fd\u4e0a\u83b7\u5f97\u6700\u9ad820.9\u70b9\u7684\u63d0\u5347\uff0c\u5728\u9690\u79c1\u57fa\u51c6\u4e0a\u83b7\u5f97\u6700\u9ad851.9\u4e2a\u767e\u5206\u70b9\u7684\u63d0\u5347\u3002\u7136\u800c\uff0c\u6027\u80fd\u6539\u8fdb\u4f34\u968f\u7740\u4efb\u52a1\u6548\u7528\u7684\u4ee3\u4ef7\uff0c\u53cd\u6620\u4e86\u63a8\u7406\u6027\u80fd\u4e0e\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u4e4b\u95f4\u7684\u5185\u5728\u6743\u8861\u3002\u7814\u7a76\u5728\u591a\u79cd\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\uff0c\u5f3a\u5316\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u75d5\u8ff9\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u884c\u4e3a\u53ef\u663e\u8457\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4e3a\u5f00\u53d1\u9690\u79c1\u611f\u77e5\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002\u5c3d\u7ba1\u5b58\u5728\u4e0e\u4efb\u52a1\u6548\u7528\u7684\u6743\u8861\uff0c\u4f46\u8be5\u65b9\u5411\u5177\u6709\u524d\u77bb\u6027\u4ef7\u503c\u3002"}}
{"id": "2602.23795", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23795", "abs": "https://arxiv.org/abs/2602.23795", "authors": ["Wenwu Tang", "Dong Wang", "Lothar Thiele", "Olga Saukh"], "title": "GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks", "comment": "Conference on Parsimony and Learning (CPAL)", "summary": "Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.", "code_url": "https://github.com/TWWinde/GRAIL", "code_stars": 1, "code_last_update": "2026-02-05", "AI": {"tldr": "\u63d0\u51faGRAIL\uff0c\u4e00\u79cd\u96f6\u5fae\u8c03\u7684\u540e\u7f6e\u5757\u7ea7\u8865\u507f\u65b9\u6cd5\uff0c\u901a\u8fc7Gram\u77e9\u9635\u548c\u5cad\u56de\u5f52\u91cd\u5efa\u9690\u85cf\u8868\u793a\uff0c\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u5373\u53ef\u5728\u5404\u79cd\u6a21\u578b\u4e0a\u63d0\u5347\u538b\u7f29\u540e\u7684\u7cbe\u5ea6\u3002", "motivation": "\u7ed3\u6784\u5316\u6df1\u5ea6\u6a21\u578b\u538b\u7f29\u867d\u80fd\u964d\u4f4e\u5185\u5b58\u548c\u63a8\u7406\u5f00\u9500\uff0c\u4f46\u6fc0\u8fdb\u538b\u7f29\u5bfc\u81f4\u7684\u7cbe\u5ea6\u635f\u5931\u5e38\u9700\u540e\u538b\u7f29\u5fae\u8c03\uff0c\u800c\u6807\u6ce8\u6570\u636e\u7f3a\u5931\u6216\u8bad\u7ec3\u6210\u672c\u8fc7\u9ad8\u4f7f\u5fae\u8c03\u96be\u4ee5\u5b9e\u65bd\u3002", "method": "GRAIL\u5229\u7528\u5c0f\u6821\u51c6\u96c6\uff0c\u901a\u8fc7Gram\u77e9\u9635\u6355\u83b7\u9690\u85cf\u6fc0\u6d3b\u7edf\u8ba1\u7279\u6027\uff0c\u91c7\u7528\u5cad\u56de\u5f52\u5b66\u4e60\u4ece\u538b\u7f29\u8868\u793a\u5230\u539f\u59cb\u8868\u793a\u7684\u7ebf\u6027\u91cd\u5efa\u6620\u5c04\uff0c\u5e76\u5c06\u5176\u878d\u5408\u5230\u4e0b\u6e38\u6295\u5f71\u6743\u91cd\u4e2d\uff0c\u5b9e\u73b0\u5757\u7ea7\u8f93\u5165\u8f93\u51fa\u884c\u4e3a\u6062\u590d\u3002", "result": "\u5728ResNets\u3001ViTs\u548c\u89e3\u7801\u5668-only\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cGRAIL\u5728\u5b9e\u7528\u538b\u7f29\u7387\u4e0b\u6301\u7eed\u4f18\u4e8e\u65e0\u6570\u636e/\u6570\u636e\u611f\u77e5\u526a\u679d\u548c\u6298\u53e0\u57fa\u7ebf\uff0c\u4ec5\u5e26\u6765\u53ef\u7ba1\u7406\u5f00\u9500\u4e14\u65e0\u9700\u68af\u5ea6\u56de\u4f20\u3002", "conclusion": "GRAIL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u3001\u65e0\u9700\u5fae\u8c03\u7684\u540e\u538b\u7f29\u8865\u507f\u65b9\u6848\uff0c\u80fd\u663e\u8457\u6062\u590d\u538b\u7f29\u6a21\u578b\u7cbe\u5ea6\uff0c\u4e14\u9002\u7528\u4e8e\u591a\u79cd\u9009\u62e9\u5668\u548c\u6a21\u578b\u67b6\u6784\u3002"}}
{"id": "2602.24287", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24287", "abs": "https://arxiv.org/abs/2602.24287", "authors": ["Jenny Y. Huang", "Leshem Choshen", "Ramon Astudillo", "Tamara Broderick", "Jacob Andreas"], "title": "Do LLMs Benefit From Their Own Words?", "comment": null, "summary": "Multi-turn interactions with large language models typically retain the assistant's own past responses in the conversation history. In this work, we revisit this design choice by asking whether large language models benefit from conditioning on their own prior responses. Using in-the-wild, multi-turn conversations, we compare standard (full-context) prompting with a user-turn-only prompting approach that omits all previous assistant responses, across three open reasoning models and one state-of-the-art model. To our surprise, we find that removing prior assistant responses does not affect response quality on a large fraction of turns. Omitting assistant-side history can reduce cumulative context lengths by up to 10x. To explain this result, we find that multi-turn conversations consist of a substantial proportion (36.4%) of self-contained prompts, and that many follow-up prompts provide sufficient instruction to be answered using only the current user turn and prior user turns. When analyzing cases where user-turn-only prompting substantially outperforms full context, we identify instances of context pollution, in which models over-condition on their previous responses, introducing errors, hallucinations, or stylistic artifacts that propagate across turns. Motivated by these findings, we design a context-filtering approach that selectively omits assistant-side context. Our findings suggest that selectively omitting assistant history can improve response quality while reducing memory consumption.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7701\u7565\u52a9\u624b\u5386\u53f2\u56de\u590d\u5728\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\u4e0d\u5f71\u54cd\u8d28\u91cf\uff0c\u53cd\u800c\u80fd\u51cf\u5c1110\u500d\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5e76\u8bc6\u522b\u51fa36.4%\u81ea\u5305\u542b\u63d0\u793a\u53ca\"\u4e0a\u4e0b\u6587\u6c61\u67d3\"\u73b0\u8c61\uff0c\u63d0\u51fa\u9009\u62e9\u6027\u8fc7\u6ee4\u65b9\u6cd5\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u591a\u8f6e\u5bf9\u8bdd\u9ed8\u8ba4\u4fdd\u7559\u52a9\u624b\u5386\u53f2\u56de\u590d\uff0c\u4f46\u8fd9\u4e00\u8bbe\u8ba1\u662f\u5426\u5fc5\u8981\u7f3a\u4e4f\u9a8c\u8bc1\u3002\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u8be5\u8bbe\u8ba1\u9009\u62e9\uff0c\u63a2\u7a76\u6a21\u578b\u662f\u5426\u771f\u9700\u8981\u4f9d\u8d56\u81ea\u8eab\u5148\u524d\u56de\u590d\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u54cd\u5e94\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\uff0c\u5bf9\u6bd4\u6807\u51c6\u5168\u4e0a\u4e0b\u6587\u63d0\u793a\u4e0e\u4ec5\u7528\u6237\u8f6e\u6b21\u63d0\u793a\uff08\u5b8c\u5168\u7701\u7565\u5148\u524d\u52a9\u624b\u56de\u590d\uff09\u7684\u6548\u679c\uff0c\u5728\u4e09\u4e2a\u5f00\u653e\u63a8\u7406\u6a21\u578b\u548c\u4e00\u4e2a\u5148\u8fdb\u6a21\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u79fb\u9664\u52a9\u624b\u5386\u53f2\u5728\u5927\u90e8\u5206\u8f6e\u6b21\u4e0d\u5f71\u54cd\u8d28\u91cf\uff1b\u53ef\u51cf\u5c11\u9ad8\u8fbe10\u500d\u4e0a\u4e0b\u6587\u957f\u5ea6\uff1b36.4%\u63d0\u793a\u4e3a\u81ea\u5305\u542b\uff1b\u8bb8\u591a\u540e\u7eed\u63d0\u793a\u4ec5\u51ed\u5f53\u524d\u548c\u5148\u524d\u7528\u6237\u8f6e\u6b21\u5373\u53ef\u56de\u7b54\uff1b\u8bc6\u522b\u51fa\"\u4e0a\u4e0b\u6587\u6c61\u67d3\"\u73b0\u8c61\uff08\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u5148\u524d\u56de\u590d\u5bfc\u81f4\u9519\u8bef\u3001\u5e7b\u89c9\u6216\u98ce\u683c\u6c61\u67d3\u5e76\u8de8\u8f6e\u4f20\u64ad\uff09\uff1b\u8bbe\u8ba1\u4e86\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u65b9\u6cd5\u3002", "conclusion": "\u6709\u9009\u62e9\u5730\u7701\u7565\u52a9\u624b\u5386\u53f2\u65e2\u80fd\u63d0\u5347\u54cd\u5e94\u8d28\u91cf\uff08\u907f\u514d\u6c61\u67d3\uff09\uff0c\u53c8\u80fd\u663e\u8457\u964d\u4f4e\u5185\u5b58\u6d88\u8017\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u4fdd\u7559\u5168\u90e8\u5bf9\u8bdd\u5386\u53f2\u7684\u8bbe\u8ba1\u5047\u8bbe\u3002"}}
{"id": "2602.23798", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23798", "abs": "https://arxiv.org/abs/2602.23798", "authors": ["Tiantong Wang", "Xinyu Yan", "Tiantong Wu", "Yurong Hao", "Yong Jiang", "Fei Huang", "Wei Yang Bryan Lim"], "title": "MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models", "comment": null, "summary": "Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.", "code_url": "https://github.com/Tristan-SHU/MPU", "code_stars": 0, "code_last_update": "2026-02-11", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u4e2d\u7684\u9690\u79c1\u56f0\u5883\uff08\u670d\u52a1\u5668\u53c2\u6570\u4e0e\u5ba2\u6237\u7aef\u9057\u5fd8\u96c6\u5747\u4e0d\u80fd\u5171\u4eab\uff09\uff0c\u672c\u6587\u63d0\u51faMPU\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u5904\u7406\u7684\u968f\u673a\u5316\u526f\u672c\u751f\u6210\u548c\u540e\u5904\u7406\u7684\u66f4\u65b0\u805a\u5408\uff0c\u5728\u4fdd\u62a4\u53cc\u65b9\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u9ad8\u6548\u9057\u5fd8\u3002\u572810%\u566a\u58f0\u4e0b\uff0c7\u79cd\u7b97\u6cd5\u7684\u5e73\u5747\u6027\u80fd\u9000\u5316\u4f4e\u4e8e1%\uff0c\u90e8\u5206\u7b97\u6cd5\u57281%\u566a\u58f0\u4e0b\u751a\u81f3\u4f18\u4e8e\u65e0\u566a\u58f0\u57fa\u7ebf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u9057\u5fd8\u9762\u4e34\u53cc\u91cd\u975e\u62ab\u9732\u7ea6\u675f\uff1a\u670d\u52a1\u5668\u65e0\u6cd5\u5171\u4eab\u6a21\u578b\u53c2\u6570\uff0c\u5ba2\u6237\u7aef\u65e0\u6cd5\u5171\u4eab\u9057\u5fd8\u6570\u636e\u96c6\u3002\u8fd9\u5bfc\u81f4\u4f20\u7edf\u9057\u5fd8\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4fdd\u62a4\u53cc\u65b9\u9690\u79c1\u3002\u9700\u8981\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u4f7f\u670d\u52a1\u5668\u80fd\u5728\u4e0d\u6cc4\u9732\u539f\u59cb\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u534f\u52a9\u5ba2\u6237\u7aef\u5b8c\u6210\u9057\u5fd8\uff0c\u540c\u65f6\u5ba2\u6237\u7aef\u4e5f\u80fd\u5728\u4e0d\u66b4\u9732\u9057\u5fd8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u672c\u5730\u66f4\u65b0\u3002", "method": "\u63d0\u51faMPU\uff08\u591a\u6270\u52a8\u526f\u672c\u9057\u5fd8\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u670d\u52a1\u5668\u7aef\u6a21\u5757\uff1a1\uff09\u9884\u5904\u7406\u6a21\u5757\uff1a\u751f\u6210\u591a\u4e2a\u6270\u52a8\u5e76\u91cd\u53c2\u6570\u5316\u7684\u6a21\u578b\u5b9e\u4f8b\uff0c\u5ba2\u6237\u7aef\u57fa\u4e8e\u79c1\u6709\u9057\u5fd8\u96c6\u8fdb\u884c\u672c\u5730\u9057\u5fd8\uff1b2\uff09\u540e\u5904\u7406\u6a21\u5757\uff1a\u901a\u8fc7\u9006\u91cd\u53c2\u6570\u5316\u548c\u8c10\u6ce2\u53bb\u566a\u805a\u5408\u66f4\u65b0\uff0c\u51cf\u8f7b\u6270\u52a8\u5f71\u54cd\u3002\u8be5\u6846\u67b6\u4e0e\u7b97\u6cd5\u65e0\u5173\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u9057\u5fd8\u65b9\u6cd5\u3002", "result": "\u57287\u79cd\u9057\u5fd8\u7b97\u6cd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1aMPU\u572810%\u566a\u58f0\u6c34\u5e73\u4e0b\u8fbe\u5230\u4e0e\u65e0\u566a\u58f0\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e73\u5747\u6027\u80fd\u9000\u5316\u4f4e\u4e8e1%\uff1b\u57281%\u566a\u58f0\u4e0b\uff0c\u90e8\u5206\u7b97\u6cd5\u751a\u81f3\u4f18\u4e8e\u65e0\u566a\u58f0\u57fa\u7ebf\u3002\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u80fd\u7ef4\u6301\u9ad8\u6548\u7684\u9057\u5fd8\u6027\u80fd\u3002", "conclusion": "MPU\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u673a\u5668\u9057\u5fd8\u4e2d\u7684\u9690\u79c1\u56f0\u5883\uff0c\u5b9e\u73b0\u4e86\u670d\u52a1\u5668\u53c2\u6570\u548c\u5ba2\u6237\u7aef\u9057\u5fd8\u96c6\u7684\u53cc\u91cd\u4fdd\u62a4\u3002\u8be5\u6846\u67b6\u5177\u6709\u7b97\u6cd5\u65e0\u5173\u6027\u3001\u5b9e\u73b0\u7b80\u5355\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u7279\u70b9\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u9057\u5fd8\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23811", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23811", "abs": "https://arxiv.org/abs/2602.23811", "authors": ["Xiang Li", "Nan Jiang", "Yuheng Zhang"], "title": "Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies", "comment": null, "summary": "We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e00\u822c\u51fd\u6570\u8fd1\u4f3c\u4e0b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\uff0c\u9488\u5bf9\u73b0\u6709\u7b97\u6cd5\uff08\u5982PSPI\uff09\u4ec5\u9002\u7528\u4e8e\u6709\u9650\u5c0f\u52a8\u4f5c\u7a7a\u95f4\u4e14\u9700\u9690\u5f0f\u8bf1\u5bfc\u7b56\u7565\u7684\u5c40\u9650\uff0c\u5c06\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u81f3\u5927\u89c4\u6a21/\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684\u53c2\u6570\u5316\u7b56\u7565\u7c7b\u3002\u901a\u8fc7\u8bc6\u522b\u4e0a\u4e0b\u6587\u8026\u5408\u7684\u6838\u5fc3\u96be\u70b9\u5e76\u8fde\u63a5\u955c\u50cf\u4e0b\u964d\u4e0e\u81ea\u7136\u7b56\u7565\u68af\u5ea6\uff0c\u83b7\u5f97\u4e86\u65b0\u9896\u7684\u7406\u8bba\u5206\u6790\u3001\u4fdd\u8bc1\u4e0e\u7b97\u6cd5\u6d1e\u89c1\uff0c\u5e76\u63ed\u793a\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u610f\u5916\u7edf\u4e00\u6027\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\u867d\u901a\u8fc7\u60b2\u89c2\u4e3b\u4e49\u53ef\u5b66\u4e60\u826f\u597d\u7b56\u7565\uff0c\u4f46\u4ec5\u9650\u4e8e\u6709\u9650\u52a8\u4f5c\u7a7a\u95f4\u4e14\u9700\u4f9d\u8d56\u72b6\u6001\u955c\u50cf\u4e0b\u964d\u548c\u4ece\u4ef7\u503c\u51fd\u6570\u9690\u5f0f\u8bf1\u5bfc\u7b56\u7565\uff0c\u65e0\u6cd5\u9002\u5e94\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u72ec\u7acb\u53c2\u6570\u5316\u7b56\u7565\u8868\u793a\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21/\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u3002\u4e3a\u6b64\uff0c\u672c\u6587\u81f4\u529b\u4e8e\u5c06\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u81f3\u66f4\u5b9e\u9645\u7684\u53c2\u6570\u5316\u7b56\u7565\u8bbe\u5b9a\u3002", "method": "\u5c06\u955c\u50cf\u4e0b\u964d\u6269\u5c55\u81f3\u53c2\u6570\u5316\u7b56\u7565\u7c7b\uff0c\u8bc6\u522b\"\u4e0a\u4e0b\u6587\u8026\u5408\"\u4e3a\u6838\u5fc3\u96be\u70b9\uff0c\u5e76\u901a\u8fc7\u5efa\u7acb\u955c\u50cf\u4e0b\u964d\u4e0e\u81ea\u7136\u7b56\u7565\u68af\u5ea6\u7684\u8054\u7cfb\uff0c\u53d1\u5c55\u65b0\u7684\u7406\u8bba\u5206\u6790\u4e0e\u7b97\u6cd5\u6846\u67b6\u3002", "result": "\u83b7\u5f97\u4e86\u53c2\u6570\u5316\u7b56\u7565\u7c7b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0b\u7684\u65b0\u7406\u8bba\u5206\u6790\u4e0e\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86\u4e0a\u4e0b\u6587\u8026\u5408\u96be\u9898\uff0c\u5f97\u5230\u4e86\u7b97\u6cd5\u5c42\u9762\u7684\u65b0\u6d1e\u89c1\uff0c\u5e76\u53d1\u73b0\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u610f\u5916\u7edf\u4e00\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5c06\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u8bba\u4fdd\u8bc1\u63a8\u5e7f\u81f3\u66f4\u7b26\u5408\u5b9e\u9645\u7684\u5927\u89c4\u6a21/\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u53c2\u6570\u5316\u7b56\u7565\u573a\u666f\uff0c\u901a\u8fc7\u955c\u50cf\u4e0b\u964d\u4e0e\u81ea\u7136\u7b56\u7565\u68af\u5ea6\u7684\u6865\u6881\uff0c\u4e0d\u4ec5\u653b\u514b\u4e86\u4e0a\u4e0b\u6587\u8026\u5408\u96be\u9898\uff0c\u8fd8\u63ed\u793a\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u6df1\u523b\u5185\u5728\u8054\u7cfb\u3002"}}
{"id": "2602.23816", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23816", "abs": "https://arxiv.org/abs/2602.23816", "authors": ["George Papadopoulos", "George A. Vouros"], "title": "Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective", "comment": "Accepted for publication at AAMAS 2026", "summary": "Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise\" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSafeQIL\u7b97\u6cd5\uff0c\u89e3\u51b3\u5728\u672a\u77e5\u7ea6\u675f\u6761\u4ef6\u4e0b\u4ece\u5b89\u5168\u6f14\u793a\u8f68\u8ff9\u4e2d\u5b66\u4e60\u7b56\u7565\u7684\u95ee\u9898\u3002\u901a\u8fc7Q\u503c\u878d\u5408\u4efb\u52a1\u5956\u52b1\u4e0e\u5b89\u5168\u6027\u8bc4\u4f30\uff0c\u5e73\u8861\u4fdd\u5b88\u6027\u4e0e\u9ad8\u56de\u62a5\u63a2\u7d22\uff0c\u6700\u5927\u5316\u6709\u524d\u666f\u8f68\u8ff9\u7684\u6982\u7387\u3002", "motivation": "\u5728\u7ea6\u675f\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u4eba\u7c7b\u6f14\u793a\u63d0\u4f9b\u4e86\u5b89\u5168\u6267\u884c\u4efb\u52a1\u7684\u8f68\u8ff9\uff0c\u4f46\u7ea6\u675f\u6761\u4ef6\u4e0e\u6210\u672c\u51fd\u6570\u672a\u77e5\u3002\u9700\u8981\u5b66\u4e60\u4e00\u4e2a\u7b56\u7565\uff0c\u65e2\u80fd\u62df\u5408\u9ad8\u5956\u52b1\u8f68\u8ff9\uff0c\u53c8\u80fd\u786e\u4fdd\u5b89\u5168\u6027\uff0c\u5728\u4fdd\u5b88\u9075\u5faa\u6f14\u793a\u4e0e\u63a2\u7d22\u6f5c\u5728\u9ad8\u56de\u62a5\u4f46\u53ef\u80fd\u4e0d\u5b89\u5168\u7684\u52a8\u4f5c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u5b89\u5168Q\u9006\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60(SafeQIL)\u7b97\u6cd5\u3002\u5c06\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\"\u524d\u666f\"\u91cf\u5316\u4e3aQ\u503c\uff0c\u8be5\u503c\u7efc\u5408\u4efb\u52a1\u7279\u5b9a\u5956\u52b1\u548c\u72b6\u6001\u5b89\u5168\u6027\u8bc4\u4f30\u3002\u4ece\u9006\u5f3a\u5316\u5b66\u4e60\u89c6\u89d2\uff0c\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5b89\u5168Q\u5b66\u4e60\uff0c\u65e8\u5728\u5b66\u4e60\u4e00\u4e2a\u80fd\u6700\u5927\u5316\u6700\u6709\u524d\u666f\u8f68\u8ff9\u6982\u7387\u7684\u7b56\u7565\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0cSafeQIL\u4e0e\u73b0\u6709\u5148\u8fdb\u9006\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u672a\u77e5\u7ea6\u675f\u4e0b\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u5b89\u5168\u7b56\u7565\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u901a\u8fc7Q\u503c\u878d\u5408\u5956\u52b1\u4e0e\u5b89\u5168\u8bc4\u4f30\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u8bc6\u522b\u5e76\u6267\u884c\u6709\u524d\u666f\u7684\u8f68\u8ff9\uff0c\u4e3a\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.23824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23824", "abs": "https://arxiv.org/abs/2602.23824", "authors": ["Pavlin G. Poli\u010dar", "Dalibor Stanimirovi\u0107", "Bla\u017e Zupan"], "title": "Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach", "comment": null, "summary": "Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.", "AI": {"tldr": "\u9488\u5bf9\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5de6\u5220\u5931\u5bfc\u81f4\u75be\u75c5\u53d1\u75c5\u65f6\u95f4\u96be\u4ee5\u786e\u5b9a\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5904\u65b9\u7eed\u7b7e\u52a8\u6001\u7684\u6982\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u6d4b\u4ece\u96f6\u661f\u7528\u836f\u5230\u6301\u7eed\u6cbb\u7597\u7684\u8f6c\u53d8\u6765\u63a8\u65ad\u6162\u6027\u75c5\u53d1\u75c5\u65f6\u95f4\u3002", "motivation": "\u7eb5\u5411\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55(EHR)\u6570\u636e\u5e38\u5b58\u5728\u5de6\u5220\u5931\uff0c\u4f7f\u5f97\u8bca\u65ad\u8bb0\u5f55\u4e0d\u5b8c\u6574\u4e14\u4e0d\u53ef\u9760\uff0c\u96be\u4ee5\u51c6\u786e\u5224\u65ad\u75be\u75c5\u53d1\u75c5\u65f6\u95f4\u3002\u95e8\u8bca\u5904\u65b9\u6570\u636e\u5219\u5f62\u6210\u7eed\u7b7e\u8f68\u8ff9\uff0c\u63d0\u4f9b\u4e86\u75be\u75c5\u7ba1\u7406\u7684\u8fde\u7eed\u4fe1\u53f7\uff0c\u53ef\u4f5c\u4e3a\u63a8\u65ad\u53d1\u75c5\u65f6\u95f4\u7684\u66ff\u4ee3\u6570\u636e\u6e90\u3002", "method": "\u63d0\u51fa\u6982\u7387\u6846\u67b6\uff0c\u5c06\u5904\u65b9\u52a8\u6001\u5efa\u6a21\u4e3a\u7eed\u7b7e\u8fc7\u7a0b\uff0c\u91c7\u7528\u53d8\u70b9\u68c0\u6d4b\u65b9\u6cd5\u5728\u4e24\u4e2a\u4f53\u5236\u95f4\u8bc6\u522b\u8f6c\u53d8\uff1a\u57fa\u7ebf\u6cca\u677e\u6a21\u578b\uff08\u4ee3\u8868\u96f6\u661f\u5904\u65b9\uff09\u548c\u5a01\u5e03\u5c14\u7eed\u7b7e\u6a21\u578b\uff08\u4ee3\u8868\u6301\u7eed\u6cbb\u7597\uff09\u3002", "result": "\u57fa\u4e8e240\u4e07\u4eba\u5168\u56fd\u6027\u7535\u5b50\u5904\u65b9\u6570\u636e\u96c6\u9a8c\u8bc1\u663e\u793a\uff1a\u76f8\u6bd4\u6734\u7d20\u89c4\u5219\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u4ea7\u751f\u66f4\u5408\u7406\u7684\u65f6\u95f4\u53d1\u75c5\u4f30\u8ba1\uff0c\u5728\u5f3a\u5de6\u5220\u5931\u6761\u4ef6\u4e0b\u663e\u8457\u51cf\u5c11\u4e0d\u5408\u7406\u65e9\u671f\u68c0\u6d4b\uff1b\u68c0\u6d4b\u6027\u80fd\u56e0\u75be\u75c5\u7c7b\u578b\u800c\u5f02\uff0c\u4e14\u4e0e\u5904\u65b9\u5bc6\u5ea6\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86EHR\u5de6\u5220\u5931\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8e\u6cbb\u7597\u6570\u636e\u63a8\u65ad\u75be\u75c5\u53d1\u75c5\u65f6\u95f4\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6982\u7387\u5efa\u6a21\u6846\u67b6\uff0c\u4f46\u6027\u80fd\u53d7\u9650\u4e8e\u5904\u65b9\u5bc6\u5ea6\uff0c\u63ed\u793a\u4e86\u6cbb\u7597\u57fa\u7840\u53d1\u75c5\u63a8\u65ad\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u3002"}}
{"id": "2602.23827", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23827", "abs": "https://arxiv.org/abs/2602.23827", "authors": ["Junkang Liu", "Fanhua Shang", "Yuxuan Tian", "Hongying Liu", "Yuanyuan Liu"], "title": "FedNSAM:Consistency of Local and Global Flatness for Federated Learning", "comment": null, "summary": "In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \\textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \\textbf{flatness distance}, we propose a novel \\textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \\textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \\textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.", "code_url": "https://github.com/junkangLiu0/FedNSAM", "code_stars": 65, "code_last_update": "2025-11-27", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u56e0\u591a\u6b65\u672c\u5730\u66f4\u65b0\u4e0e\u6570\u636e\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u5168\u5c40\u6a21\u578b\u6027\u80fd\u9000\u5316\u95ee\u9898\uff0c\u63d0\u51faFedNSAM\u7b97\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u5168\u5c40Nesterov\u52a8\u91cf\u534f\u8c03\u5168\u5c40\u4e0e\u5c40\u90e8\u5e73\u5766\u5ea6\u4e00\u81f4\u6027\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u8f83FedSAM\u5177\u6709\u66f4\u7d27\u7684\u6536\u655b\u754c\uff0c\u5e76\u5728CNN\u4e0eTransformer\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u591a\u6b65\u672c\u5730\u66f4\u65b0\u4e0e\u6570\u636e\u5f02\u8d28\u6027\u901a\u5e38\u5bfc\u81f4\u66f4\u5c16\u9510\u7684\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u4ece\u800c\u635f\u5bb3\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316(SAM)\u5f15\u5165\u672c\u5730\u8bad\u7ec3\uff0c\u4f46\u5728\u9ad8\u5ea6\u5f02\u8d28\u6570\u636e\u4e0b\uff0c\u5c40\u90e8\u5e73\u5766\u6027\u65e0\u6cd5\u4fdd\u8bc1\u5168\u5c40\u5e73\u5766\u6027\uff0c\u4f7f\u5f97SAM\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u53d7\u9650\u3002", "method": "\u5b9a\u4e49\u5e73\u5766\u5ea6\u8ddd\u79bb\u89e3\u91ca\u4e0a\u8ff0\u73b0\u8c61\uff0c\u63d0\u51faFedNSAM\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5c06\u5168\u5c40Nesterov\u52a8\u91cf\u4f5c\u4e3a\u5ba2\u6237\u7aef\u5168\u5c40\u6270\u52a8\u4f30\u8ba1\u4e0e\u5916\u63a8\u65b9\u5411\uff0c\u5d4c\u5165\u5230\u672c\u5730\u66f4\u65b0\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u5168\u5c40\u4e0e\u5c40\u90e8\u5e73\u5766\u5ea6\u7684\u534f\u8c03\u4e00\u81f4\u3002", "result": "\u7406\u8bba\u4e0a\u901a\u8fc7Nesterov\u5916\u63a8\u83b7\u5f97\u4e86\u6bd4FedSAM\u66f4\u7d27\u7684\u6536\u655b\u8fb9\u754c\u3002\u5728CNN\u548cTransformer\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFedNSAM\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedNSAM\u901a\u8fc7\u5168\u5c40Nesterov\u52a8\u91cf\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5c40\u90e8\u4e0e\u5168\u5c40\u5e73\u5766\u5ea6\u4e0d\u4e00\u81f4\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u5f02\u8d28\u6027\u573a\u666f\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u6548\u679c\u3002"}}
{"id": "2602.23852", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.23852", "abs": "https://arxiv.org/abs/2602.23852", "authors": ["Zhaowen Wang", "Dongdong Zhou", "Qi Xu", "Fengyu Cong", "Mohammad Al-Sa'd", "Jenni Raitoharju"], "title": "ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring", "comment": "Accepted to ICASSP 2026", "summary": "Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.", "code_url": "https://github.com/wzw999/ULW-SLEEPNET", "code_stars": 0, "code_last_update": "2026-01-19", "AI": {"tldr": "\u672c\u6587\u63d0\u51faULW-SleepNet\uff0c\u4e00\u79cd\u8d85\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u7761\u7720\u5206\u671f\u8bc4\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u6d41\u53ef\u5206\u79bb\u5377\u79ef\u5757\u548c\u53c2\u6570\u5171\u4eab\u673a\u5236\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u590d\u6742\u5ea6\uff08\u4ec513.3K\u53c2\u6570\uff09\uff0c\u540c\u65f6\u5728\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff0886.9%/81.4%\uff09\uff0c\u4e3a\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u7761\u7720\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u5728\u81ea\u52a8\u7761\u7720\u5206\u671f\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u591a\u4e3a\u5355\u901a\u9053\u8111\u7535\u8bbe\u8ba1\uff0c\u96be\u4ee5\u6709\u6548\u5904\u7406\u591a\u6a21\u6001\u591a\u5bfc\u7761\u7720\u56fe\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u53ef\u7a7f\u6234\u8bbe\u5907\u548c\u7269\u8054\u7f51\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e2\u9ad8\u6548\u53c8\u51c6\u786e\u7684\u591a\u6a21\u6001\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002", "method": "\u63d0\u51faULW-SleepNet\u6846\u67b6\uff0c\u6838\u5fc3\u5305\u62ec\uff1a1\uff09\u53cc\u6d41\u53ef\u5206\u79bb\u5377\u79ef\u5757\u9ad8\u6548\u878d\u5408\u591a\u751f\u7406\u4fe1\u53f7\u7279\u5f81\uff1b2\uff09\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u91cf\uff1b3\uff09\u901a\u9053\u7ea7\u53c2\u6570\u5171\u4eab\u8fdb\u4e00\u6b65\u538b\u7f29\u6a21\u578b\u89c4\u6a21\uff1b4\uff09\u5168\u5c40\u5e73\u5747\u6c60\u5316\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42\u3002\u8be5\u67b6\u6784\u4e13\u4e3a\u591a\u6a21\u6001PSG\u6570\u636e\u4f18\u5316\u3002", "result": "\u5728Sleep-EDF-20\u548cSleep-EDF-78\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523086.9%\u548c81.4%\u7684\u51c6\u786e\u7387\uff0c\u6a21\u578b\u4ec5\u542b13.3K\u53c2\u6570\u548c7.89M\u6d6e\u70b9\u8fd0\u7b97\u91cf\u3002\u4e0e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u76f8\u6bd4\uff0c\u53c2\u6570\u91cf\u51cf\u5c11\u9ad8\u8fbe98.6%\u800c\u6027\u80fd\u635f\u5931\u6781\u5c0f\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "ULW-SleepNet\u8bc1\u660e\u4e86\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u51c6\u786e\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u521b\u65b0\u67b6\u6784\u8bbe\u8ba1\u53ef\u5b9e\u73b0\u7761\u7720\u5206\u671f\u6a21\u578b\u7684\u6781\u81f4\u8f7b\u91cf\u5316\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u53ef\u7a7f\u6234\u8bbe\u5907\u548c\u7269\u8054\u7f51\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u7761\u7720\u76d1\u6d4b\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5177\u6709\u660e\u786e\u7684\u4e34\u5e8a\u8f6c\u5316\u4ef7\u503c\u3002"}}
{"id": "2602.23880", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23880", "abs": "https://arxiv.org/abs/2602.23880", "authors": ["Zhang Wan", "Tingting Mu", "Samuel Kaski"], "title": "A Theory of Random Graph Shift in Truncated-Spectrum vRKHS", "comment": null, "summary": "This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u968f\u673a\u56fe\u751f\u6210\u6a21\u578b(RGM)\u7406\u8bba\u6846\u67b6\u7814\u7a76\u57df\u504f\u79fb\u4e0b\u7684\u56fe\u5206\u7c7b\u95ee\u9898\uff0c\u57fa\u4e8e\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4(vRKHS)\u63a8\u5bfc\u51fa\u6cdb\u5316\u8bef\u5dee\u754c\uff0c\u5176\u504f\u79fb\u60e9\u7f5a\u53ef\u5206\u89e3\u4e3a\u57df\u5dee\u5f02\u3001\u8c31\u51e0\u4f55\u548c\u632f\u5e45\u4e09\u9879\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u9879\u7684\u7406\u8bba\u6d1e\u5bdf\u3002", "motivation": "\u7ecf\u5178\u57df\u9002\u5e94\u7406\u8bba\u867d\u80fd\u5904\u7406\u56fe\u5206\u5e03\u504f\u79fb\uff0c\u4f46\u8f83\u5c11\u5229\u7528\u56fe\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u672c\u8eab\u3002\u56fe\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u7279\u6027\u548c\u4e13\u7528\u5b66\u4e60\u67b6\u6784\u4f7f\u5f97\u5bf9\u56fe\u5206\u5e03\u504f\u79fb\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\u53d8\u5f97\u590d\u6742\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u7cbe\u7ec6\u523b\u753b\u504f\u79fb\u673a\u5236\u3002", "method": "\u5047\u8bbe\u968f\u673a\u56fe\u6a21\u578b\u4e3a\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u5229\u7528\u5176\u4e0e\u51fd\u6570\u7a7a\u95f4\u5047\u8bbe\u590d\u6742\u5ea6\u7684\u8054\u7cfb\uff0c\u6784\u5efa\u57fa\u4e8e\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4(vRKHS)\u7684\u7406\u8bba\u5f62\u5f0f\u5316\u4f53\u7cfb\uff0c\u4ece\u800c\u63a8\u5bfc\u6cdb\u5316\u6027\u80fd\u754c\u3002", "result": "\u63a8\u5bfc\u51fa\u4e00\u4e2a\u6cdb\u5316\u8bef\u5dee\u754c\uff0c\u5176\u57df\u504f\u79fb\u60e9\u7f5a\u9879\u53ef\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a(i)\u57df\u5dee\u5f02\u9879\uff0c(ii)\u7531\u53ef\u53ca\u622a\u65ad\u8c31\u603b\u7ed3\u7684\u8c31\u51e0\u4f55\u9879\uff0c(iii)\u805a\u5408\u6536\u655b\u6027\u4e0e\u6784\u9020\u7a33\u5b9a\u6027\u6548\u5e94\u7684\u632f\u5e45\u9879\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u56fe\u57df\u504f\u79fb\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u5206\u6790\u5de5\u5177\uff0c\u4e09\u9879\u5206\u89e3\u63ed\u793a\u4e86\u504f\u79fb\u7684\u4e0d\u540c\u6765\u6e90\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u6709\u6548\u6027\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u9c81\u68d2\u7684\u56fe\u57df\u9002\u5e94\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2602.24040", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24040", "abs": "https://arxiv.org/abs/2602.24040", "authors": ["Daniel Yang", "Samuel Stante", "Florian Redhardt", "Lena Libon", "Parnian Kassraie", "Ido Hakimi", "Barna P\u00e1sztor", "Andreas Krause"], "title": "RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models", "comment": null, "summary": "Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.", "code_url": "https://github.com/lasgroup/rewarduq", "code_stars": 12, "code_last_update": "2026-02-21", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRewardUQ\u7edf\u4e00\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u548c\u521d\u59cb\u5316\u5bf9\u6027\u80fd\u5f71\u54cd\u6700\u4e3a\u5173\u952e\uff0c\u5e76\u5f00\u6e90\u4e86Python\u5de5\u5177\u5305\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u70b9\u4f30\u8ba1\uff0c\u5ffd\u7565\u4e86\u6709\u9650\u4eba\u7c7b\u53cd\u9988\u5e26\u6765\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u53ef\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u5e76\u7f13\u89e3\u8fc7\u5ea6\u4f18\u5316\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\uff0c\u5bfc\u81f4\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u6784\u5efaRewardUQ\u6846\u67b6\uff0c\u5728\u51c6\u786e\u6027\u548c\u6821\u51c6\u6307\u6807\u4e0b\u5bf9\u6bd4\u5e38\u89c1\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u878d\u5408\u53cc\u7ef4\u5ea6\u7684\u65b0\u6392\u5e8f\u7b56\u7565\u4ee5\u7b80\u5316\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5927\u5c0f\u548c\u521d\u59cb\u5316\u5bf9\u6027\u80fd\u5f71\u54cd\u6700\u663e\u8457\uff0c\u591a\u6570\u5148\u524d\u7814\u7a76\u82e5\u91c7\u7528\u66ff\u4ee3\u8bbe\u8ba1\u9009\u62e9\u53ef\u83b7\u5f97\u66f4\u597d\u6548\u679c\u3002", "conclusion": "\u4e3a\u4fc3\u8fdb\u65b0\u65b9\u6cd5\u5f00\u53d1\u4e0e\u4e0b\u6e38\u5e94\u7528\u90e8\u7f72\uff0c\u5f00\u6e90RewardUQ Python\u5305\u3002"}}
{"id": "2602.23994", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23994", "abs": "https://arxiv.org/abs/2602.23994", "authors": ["Vrushank Ahire", "Yogesh Kumar", "Anouck Girard", "M. A. Ganaie"], "title": "MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening", "comment": null, "summary": "Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.", "AI": {"tldr": "\u63d0\u51faMINT\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u5c06MRI\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u6784\u8fc1\u79fb\u5230\u8bed\u97f3\u7f16\u7801\u5668\uff0c\u5b9e\u73b0\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u4f9d\u8d56MRI\u626b\u63cf\u7684\u524d\u63d0\u4e0b\uff0c\u4f7f\u8bed\u97f3\u5206\u6790\u83b7\u5f97\u4e0e\u7eaf\u8bed\u97f3\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u7269\u5b66\u4f9d\u636e\uff0c\u4e3a\u5927\u89c4\u6a21\u8ba4\u77e5\u7b5b\u67e5\u63d0\u4f9b\u65b0\u8def\u5f84\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e2d\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u662f\u8870\u8001\u5411\u75f4\u5446\u8f6c\u53d8\u7684\u5173\u952e\u9636\u6bb5\u3002\u7ed3\u6784MRI\u867d\u80fd\u63d0\u4f9b\u53ef\u9760\u751f\u7269\u6807\u5fd7\u7269\uff0c\u4f46\u6210\u672c\u9ad8\u4e14\u9700\u4e13\u4e1a\u8bbe\u5907\uff0c\u96be\u4ee5\u5927\u89c4\u6a21\u5e94\u7528\u3002\u8bed\u97f3\u5206\u6790\u867d\u65e0\u521b\u4fbf\u6377\uff0c\u4f46\u73b0\u6709\u8bed\u97f3\u5206\u7c7b\u5668\u72ec\u7acb\u4e8e\u795e\u7ecf\u5f71\u50cf\u5f00\u53d1\uff0c\u7f3a\u4e4f\u751f\u7269\u5b66\u57fa\u7840\uff0c\u5728\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\uff08CN\uff09\u4e0eMCI\u65f6\u53ef\u9760\u6027\u6709\u9650\u3002\u4e9f\u9700\u4e00\u79cd\u65b9\u6cd5\uff0c\u65e2\u80fd\u5229\u7528MRI\u7684\u751f\u7269\u5b66\u6709\u6548\u6027\uff0c\u53c8\u80fd\u53d1\u6325\u8bed\u97f3\u5206\u6790\u7684\u53ef\u53ca\u6027\u4f18\u52bf\u3002", "method": "MINT\u6846\u67b6\u91c7\u7528\u4e09\u9636\u6bb5\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\uff1a1\uff09\u8bad\u7ec3\u57fa\u4e8e1228\u540d\u53d7\u8bd5\u8005\u7684MRI\u6559\u5e08\u6a21\u578b\uff0c\u6784\u5efaCN\u4e0eMCI\u5206\u7c7b\u7684\u795e\u7ecf\u5f71\u50cf\u5d4c\u5165\u7a7a\u95f4\uff1b2\uff09\u901a\u8fc7\u6b8b\u5dee\u6295\u5f71\u5934\u5c06\u8bed\u97f3\u8868\u5f81\u5bf9\u9f50\u5230\u51bb\u7ed3\u7684\u5f71\u50cf\u6d41\u5f62\uff0c\u7ed3\u5408\u51e0\u4f55\u635f\u5931\u4fdd\u6301\u5f71\u50cf\u7f16\u7801\u5668\u4fdd\u771f\u5ea6\uff1b3\uff09\u63a8\u7406\u65f6\u4f7f\u7528\u51bb\u7ed3\u7684MRI\u5206\u7c7b\u5668\u5bf9\u5bf9\u9f50\u540e\u7684\u8bed\u97f3\u5d4c\u5165\u8fdb\u884c\u5206\u7c7b\uff0c\u65e0\u9700\u626b\u63cf\u4eea\u3002\u5173\u952e\u8bbe\u8ba1\u5305\u62ec\uff1a\u51bb\u7ed3MRI\u6d41\u5f62\u3001\u6b8b\u5dee\u6295\u5f71\u7ed3\u6784\u3001\u51e0\u4f55\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728ADNI-4\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u9f50\u540e\u7684\u8bed\u97f3AUC\u8fbe0.720\uff0c\u4e0e\u7eaf\u8bed\u97f3\u57fa\u7ebf\uff080.711\uff09\u76f8\u5f53\uff0c\u4e14\u65e0\u9700\u5f71\u50cf\u6570\u636e\uff1b\u591a\u6a21\u6001\u878d\u5408AUC\u8fbe0.973\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u72ecMRI\uff080.958\uff09\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0cdropout\u6b63\u5219\u5316\u548c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u662f\u6846\u67b6\u6210\u529f\u7684\u5173\u952e\u8bbe\u8ba1\u3002\u8be5\u5de5\u4f5c\u9996\u6b21\u8bc1\u5b9e\u4e86MRI\u5411\u8bed\u97f3\u7684\u77e5\u8bc6\u8fc1\u79fb\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u5b9e\u73b0\u4e86MRI\u5230\u8bed\u97f3\u7684\u77e5\u8bc6\u8fc1\u79fb\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\uff0c\u5efa\u7acb\u4e86\u65e0\u9700\u63a8\u7406\u671f\u795e\u7ecf\u5f71\u50cf\u7684\u751f\u7269\u5b66grounded\u8def\u5f84\uff0c\u4e3a\u5927\u89c4\u6a21\u8ba4\u77e5\u529f\u80fd\u5206\u8bca\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u751f\u7269\u5b66\u6709\u6548\u6027\u4e0e\u4e34\u5e8a\u53ef\u53ca\u6027\u3002"}}
{"id": "2602.23997", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23997", "abs": "https://arxiv.org/abs/2602.23997", "authors": ["Florent Delgrange"], "title": "Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments", "comment": "AAMAS 2026, Blue Sky Idea Track. 4 pages, 1 Figure", "summary": "The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u57fa\u7840\u4e16\u754c\u6a21\u578b\"\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u5956\u52b1\u6a21\u578b\u3001\u81ea\u9002\u5e94\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5728\u7ebf\u62bd\u8c61\u6821\u51c6\u548c\u6d4b\u8bd5\u65f6\u5408\u6210\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u89e3\u51b3\u5f53\u524d\u4e16\u754c\u6a21\u578b\u5728\u56fa\u5b9a\u73af\u5883\u5047\u8bbe\u4e0b\u65e0\u6cd5\u652f\u6301\u667a\u80fd\u4f53\u5728\u5f00\u653e\u4e16\u754c\u4e2d\u6301\u7eed\u6f14\u8fdb\u7684\u95ee\u9898\uff0c\u65e8\u5728\u5b9e\u73b0\u667a\u80fd\u4f53\u7684\u53ef\u9760\u9002\u5e94\u3001\u53ef\u9a8c\u8bc1\u7a0b\u5e8f\u5408\u6210\u4e0e\u5c11\u6837\u672c\u7b56\u7565\u5b66\u4e60\u3002", "motivation": "\u6807\u51c6\u65b9\u6cd5\u5047\u8bbe\u4efb\u52a1\u548c\u73af\u5883\u56fa\u5b9a\u4e14\u7f3a\u4e4f\u65b0\u9896\u6027\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u4e16\u754c\u6a21\u578b\u652f\u6301\u667a\u80fd\u4f53\u5728\u52a8\u6001\u53d8\u5316\u6761\u4ef6\u4e0b\u81ea\u4e3b\u6f14\u8fdb\u7b56\u7565\u7684\u80fd\u529b\u3002\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u667a\u80fd\u4f53\u5fc5\u987b\u5728\u5f00\u653e\u4e16\u754c\u4e2d\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u3001\u53ef\u9760\u884c\u52a8\u548c\u884c\u4e3a\u81ea\u9002\u5e94\uff0c\u73b0\u6709\u8303\u5f0f\u65e0\u6cd5\u517c\u987e\u8fd9\u4e09\u8005\u3002", "method": "\u63d0\u51fa\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\u7684\u7814\u7a76\u8bae\u7a0b\uff1a1) \u4ece\u89c4\u8303\u4e2d\u5b66\u4e60\u53ef\u5fae\u5206\u5956\u52b1\u6a21\u578b\uff0c\u652f\u6301\u76ee\u6807\u5bfc\u5411\u4f18\u5316\uff1b2) \u5c06\u81ea\u9002\u5e94\u5f62\u5f0f\u9a8c\u8bc1\u673a\u5236\u6df1\u5ea6\u6574\u5408\u81f3\u5b66\u4e60\u5168\u6d41\u7a0b\uff1b3) \u901a\u8fc7\u5728\u7ebf\u62bd\u8c61\u6821\u51c6\u91cf\u5316\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff1b4) \u5728\u6d4b\u8bd5\u65f6\u7531\u9a8c\u8bc1\u5668\u5f15\u5bfc\u8fdb\u884c\u7a0b\u5e8f\u5408\u6210\u4e0e\u52a8\u6001\u4e16\u754c\u6a21\u578b\u751f\u6210\u3002\u56db\u8005\u534f\u540c\u5b9e\u73b0\u8868\u793a\u3001\u5b66\u4e60\u4e0e\u63a8\u7406\u7684\u7edf\u4e00\u3002", "result": "\u8be5\u6846\u67b6\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\uff1a\u5408\u6210\u53ef\u901a\u8fc7\u5f62\u5f0f\u9a8c\u8bc1\u7684\u53ef\u9760\u7a0b\u5e8f\u3001\u4ece\u6781\u5c11\u91cf\u4ea4\u4e92\u6837\u672c\u4e2d\u5feb\u901f\u63a8\u5bfc\u65b0\u7b56\u7565\u3001\u5728\u9002\u5e94\u73af\u5883\u65b0\u9896\u6027\u7684\u540c\u65f6\u4e25\u683c\u4fdd\u6301\u884c\u4e3a\u6b63\u786e\u6027\uff0c\u5e76\u5efa\u7acb\u5b66\u4e60-\u63a8\u7406-\u9002\u5e94\u7684\u95ed\u73af\u673a\u5236\u3002", "conclusion": "\u57fa\u7840\u4e16\u754c\u6a21\u578b\u4f5c\u4e3a\u652f\u6491\u5b66\u4e60\u3001\u63a8\u7406\u4e0e\u9002\u5e94\u7684\u57fa\u8d28\uff0c\u4e0d\u4ec5\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u9ad8\u6027\u80fd\u884c\u4e3a\u80fd\u529b\uff0c\u66f4\u91cd\u8981\u7684\u662f\u8d4b\u4e88\u5176\u89e3\u91ca\u4e0e\u8bba\u8bc1\u884c\u4e3a\u5408\u7406\u6027\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5f00\u653e\u4e16\u754c\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u5b9e\u73b0\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.24012", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.24012", "abs": "https://arxiv.org/abs/2602.24012", "authors": ["Roy Betser", "Eyal Gofer", "Meir Yossef Levi", "Guy Gilboa"], "title": "InfoNCE Induces Gaussian Distribution", "comment": "Accepted to ICLR 2026, Oral", "summary": "Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660eInfoNCE\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u4f1a\u8bf1\u5bfc\u8868\u793a\u7a7a\u95f4\u4ea7\u751f\u9ad8\u65af\u7ed3\u6784\uff0c\u5728\u4e24\u79cd\u4e92\u8865\u7684\u7406\u8bba\u6846\u67b6\u4e0b\u5206\u6790\u8868\u793a\u6295\u5f71\u7684\u6e10\u8fd1\u9ad8\u65af\u6027\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u548cCIFAR-10\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e3a\u5bf9\u6bd4\u5b66\u4e60\u8868\u793a\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u57fa\u7840\u3002", "motivation": "\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u666e\u904d\u89c2\u5bdf\u5230\u8868\u793a\u5448\u73b0\u9ad8\u65af\u5206\u5e03\u7279\u6027\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793aInfoNCE\u76ee\u6807\u51fd\u6570\u4e0e\u9ad8\u65af\u7ed3\u6784\u4e4b\u95f4\u7684\u672c\u8d28\u8054\u7cfb\uff0c\u4e3a\u7406\u89e3\u5bf9\u6bd4\u5b66\u4e60\u8868\u793a\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u652f\u6301\u540e\u7eed\u5e94\u7528\u5f00\u53d1\u3002", "method": "\u7814\u7a76\u91c7\u7528\u53cc\u91cd\u5206\u6790\u6846\u67b6\uff1a(1)\u5728\u4e00\u5b9a\u7684\u5bf9\u9f50\u6027\u548c\u96c6\u4e2d\u6027\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u9ad8\u7ef4\u8868\u793a\u6295\u5f71\u6e10\u8fd1\u670d\u4ece\u591a\u5143\u9ad8\u65af\u5206\u5e03\uff1b(2)\u5728\u66f4\u5bbd\u677e\u7684\u5047\u8bbe\u4e0b\uff0c\u901a\u8fc7\u6dfb\u52a0\u4fc3\u8fdb\u4f4e\u7279\u5f81\u8303\u6570\u548c\u9ad8\u7279\u5f81\u71b5\u7684\u5fae\u5c0f\u6e10\u8fd1\u6d88\u5931\u6b63\u5219\u9879\uff0c\u83b7\u5f97\u76f8\u4f3c\u6e10\u8fd1\u7ed3\u679c\u3002\u5b9e\u9a8c\u5728\u5408\u6210\u6570\u636e\u96c6\u548cCIFAR-10\u4e0a\uff0c\u4f7f\u7528\u591a\u79cd\u7f16\u7801\u5668\u67b6\u6784\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u8bc1\u660eInfoNCE\u76ee\u6807\u786e\u5b9e\u4f1a\u5728\u8868\u793a\u4e2d\u8bf1\u5bfc\u9ad8\u65af\u7ed3\u6784\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728\u591a\u79cd\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u6bd4\u5b66\u4e60\u8868\u793a\u59cb\u7ec8\u8868\u73b0\u51fa\u9ad8\u65af\u884c\u4e3a\uff1b\u6240\u63d0\u51fa\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u5728\u8f83\u5f31\u5047\u8bbe\u4e0b\u540c\u6837\u80fd\u5b9e\u73b0\u9ad8\u65af\u7ed3\u6784\u3002", "conclusion": "\u8be5\u53d1\u73b0\u4e3a\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u8868\u793a\u7684\u9ad8\u65af\u73b0\u8c61\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u89e3\u91ca\uff0c\u6240\u5efa\u7acb\u7684\u9ad8\u65af\u6a21\u578b\u4f7f\u5f97\u5bf9\u5b66\u4e60\u8868\u793a\u7684\u89e3\u6790\u5904\u7406\u6210\u4e3a\u53ef\u80fd\uff0c\u9884\u671f\u5c06\u652f\u6301\u5bf9\u6bd4\u5b66\u4e60\u5728\u5404\u7c7b\u5e94\u7528\u4e2d\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2602.24066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24066", "abs": "https://arxiv.org/abs/2602.24066", "authors": ["Tobias Nygaard"], "title": "pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures", "comment": null, "summary": "Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fapathsig\uff0c\u4e00\u4e2aPyTorch\u539f\u751f\u5e93\uff0c\u7528\u4e8e\u5728\u5b57\u57fa\u4e2d\u9ad8\u6548\u8ba1\u7b97\u8def\u5f84\u7b7e\u540d\u3002\u901a\u8fc7CUDA\u5185\u6838\u5728\u524d\u7f00\u95ed\u5b57\u96c6\u4e0a\u5e76\u884c\u66f4\u65b0\u7b7e\u540d\u7cfb\u6570\uff0c\u8be5\u5e93\u5b9e\u73b0\u4e86\u9ad8GPU\u541e\u5410\u91cf\u548c\u8fd1\u6700\u5c0f\u5cf0\u503c\u5185\u5b58\uff0c\u76f8\u6bd4\u73b0\u6709\u5e93\u5728\u622a\u65ad\u7b7e\u540d\u8ba1\u7b97\u4e0a\u63d0\u901f10-30\u500d\uff0c\u5728\u9700\u8981\u53cd\u5411\u4f20\u64ad\u7684\u8bad\u7ec3\u4e2d\u63d0\u901f4-10\u500d\uff0c\u5e76\u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u5b57\u96c6\u6295\u5f71\u548c\u975e\u5747\u5300\u622a\u65ad\uff0c\u4ee5\u751f\u6210\u66f4\u7d27\u51d1\u7684\u8868\u793a\u3002", "motivation": "\u5c3d\u7ba1\u8def\u5f84\u7b7e\u540d\u5728\u5e8f\u5217\u6570\u636e\u8868\u793a\u4e2d\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u826f\u597d\u6027\u80fd\uff0c\u5e76\u4ece\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668\u53d1\u5c55\u4e3a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u8bad\u7ec3\u7ec4\u4ef6\uff0c\u4f46\u73b0\u6709\u5e93\u5728\u5927\u89c4\u6a21\u57fa\u4e8e\u68af\u5ea6\u7684\u5b66\u4e60\u4e2d\u7f3a\u4e4f\u6240\u9700\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f00\u53d1PyTorch\u539f\u751f\u5e93pathsig\uff0c\u76f4\u63a5\u5728\u5b57\u57fa\u4e2d\u8ba1\u7b97\u8def\u5f84\u7b7e\u540d\uff1b\u5229\u7528CUDA\u5185\u6838\u5728\u524d\u7f00\u95ed\u5b57\u96c6\u4e0a\u5e76\u884c\u66f4\u65b0\u7b7e\u540d\u7cfb\u6570\uff1b\u652f\u6301\u5c06\u65e0\u9650\u7ef4\u7b7e\u540d\u6295\u5f71\u5230\u7528\u6237\u6307\u5b9a\u5b57\u96c6\u4ee5\u53ca\u57fa\u4e8e\u975e\u5747\u5300\u8def\u5f84\u89c4\u5219\u6027\u7684\u5404\u5411\u5f02\u6027\u622a\u65ad\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8GPU\u541e\u5410\u91cf\u548c\u63a5\u8fd1\u6700\u5c0f\u7684\u5cf0\u503c\u5185\u5b58\u5360\u7528\u3002\u4e0e\u5176\u4ed6\u5e93\u76f8\u6bd4\uff0c\u622a\u65ad\u7b7e\u540d\u8ba1\u7b97\u901f\u5ea6\u63d0\u534710-30\u500d\uff0c\u9700\u8981\u53cd\u5411\u4f20\u64ad\u7684\u8bad\u7ec3\u8fc7\u7a0b\u52a0\u901f4-10\u500d\u3002", "conclusion": "pathsig\u901a\u8fc7GPU\u4f18\u5316\u548c\u7075\u6d3b\u622a\u65ad\u7b56\u7565\uff0c\u4e3a\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u7b7e\u540d\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u7ef4\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2602.24069", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24069", "abs": "https://arxiv.org/abs/2602.24069", "authors": ["Ryan DeWolfe"], "title": "Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding", "comment": "13 pages, 6 figures", "summary": "Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCOVE\u2014\u2014\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u9ad8\u7ef4\u8282\u70b9\u5d4c\u5165\u65b9\u6cd5\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\u7a81\u7834\u4f20\u7edf\u4f4e\u7ef4\u7ea6\u675f\uff0c\u5728UMAP\u964d\u7ef4\u540e\u7565\u5fae\u63d0\u5347\u4e86\u805a\u7c7b\u4e0e\u94fe\u8def\u9884\u6d4b\u6027\u80fd\uff0c\u5176UMAP-HDBSCAN\u6d41\u7a0b\u5728\u793e\u533a\u68c0\u6d4b\u57fa\u51c6\u4e0a\u4e0eLouvain\u7b97\u6cd5\u8868\u73b0\u76f8\u5f53\u3002", "motivation": "\u4f20\u7edf\u8282\u70b9\u5d4c\u5165\u65b9\u6cd5\u53d7\u9650\u4e8e\u4f4e\u7ef4\u8868\u793a\u74f6\u9888\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u9ad8\u7ef4\u5d4c\u5165\u7a7a\u95f4\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u63d0\u5347\u8282\u70b9\u5206\u6790\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u53d7\u795e\u7ecf\u5d4c\u5165\u65b9\u6cd5\u542f\u53d1\uff0c\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u5171\u73b0\u4f5c\u4e3a\u76f8\u4f3c\u6027\u6307\u6807\u6784\u5efa\u9ad8\u7ef4\u5d4c\u5165\uff0c\u4e0e\u6269\u6563\u8fc7\u7a0b\u5bc6\u5207\u76f8\u5173\u3002\u91c7\u7528UMAP\u8fdb\u884c\u975e\u7ebf\u6027\u964d\u7ef4\uff0c\u5e76\u6269\u5c55\u793e\u533a\u68c0\u6d4b\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "COVE\u7ecfUMAP\u964d\u7ef4\u540e\uff0c\u5728\u805a\u7c7b\u548c\u94fe\u8def\u9884\u6d4b\u4efb\u52a1\u4e0a\u6027\u80fd\u8f83\u57fa\u7ebf\u65b9\u6cd5\u7565\u6709\u63d0\u5347\u3002\u5728\u6269\u5c55\u7684\u793e\u533a\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCOVE-UMAP-HDBSCAN\u5168\u6d41\u7a0b\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684Louvain\u7b97\u6cd5\u6027\u80fd\u76f8\u8fd1\u3002", "conclusion": "COVE\u9a8c\u8bc1\u4e86\u9ad8\u7ef4\u53ef\u89e3\u91ca\u5d4c\u5165\u7ed3\u5408\u975e\u7ebf\u6027\u964d\u7ef4\u7684\u6709\u6548\u6027\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u5404\u9879\u4efb\u52a1\u6027\u80fd\u8fbe\u5230\u6216\u63a5\u8fd1\u4e3b\u6d41\u7b97\u6cd5\u6c34\u5e73\uff0c\u4e3a\u8282\u70b9\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.24083", "categories": ["cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24083", "abs": "https://arxiv.org/abs/2602.24083", "authors": ["Xinlong Du", "Harsha Honnappa", "Vinayak Rao"], "title": "Neural Diffusion Intensity Models for Point Process Data", "comment": null, "summary": "Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.", "AI": {"tldr": "\u9488\u5bf9Cox\u8fc7\u7a0b\u7684\u975e\u53c2\u6570\u5f3a\u5ea6\u4f30\u8ba1\u548c\u4e8b\u540e\u63a8\u65ad\u96be\u9898\uff0c\u63d0\u51fa\u795e\u7ecf\u6269\u6563\u5f3a\u5ea6\u6a21\u578b(NDIM)\uff0c\u57fa\u4e8e\u795e\u7ecf\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u548c\u6269\u5927\u6ee4\u6ce2\u7406\u8bba\uff0c\u8bc1\u660e\u6761\u4ef6\u5316\u89c2\u6d4b\u540e\u5f3a\u5ea6\u4fdd\u6301\u6269\u6563\u7ed3\u6784\u5e76\u901a\u8fc7\u663e\u5f0f\u6f02\u79fb\u6821\u6b63\u4f7f\u53d8\u5206\u65cf\u5305\u542b\u771f\u5b9e\u540e\u9a8c\uff0c\u5355\u5411\u524d\u5411\u4f20\u64ad\u66ff\u4ee3\u91cd\u590dMCMC\u5b9e\u73b0\u6570\u91cf\u7ea7\u52a0\u901f\u3002", "motivation": "Cox\u8fc7\u7a0b\u867d\u80fd\u5efa\u6a21\u8fc7\u5ea6\u79bb\u6563\u70b9\u8fc7\u7a0b\u6570\u636e\uff0c\u4f46\u5176\u975e\u53c2\u6570\u5f3a\u5ea6\u4f30\u8ba1\u548c\u4e8b\u540e\u63a8\u65ad\u901a\u5e38\u8ba1\u7b97\u96be\u89e3\uff0c\u4f9d\u8d56\u6602\u8d35\u7684MCMC\u65b9\u6cd5\uff0c\u96be\u4ee5\u6269\u5c55\u81f3\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u4e9f\u9700\u9ad8\u6548\u63a8\u65ad\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u53d8\u5206\u63a8\u65ad\u6846\u67b6\uff0c\u5229\u7528\u6269\u5927\u6ee4\u6ce2\u7406\u8bba\u8bc1\u660e\u89c2\u6d4b\u6761\u4ef6\u4e0b\u6f5c\u5f3a\u5ea6\u4ecd\u4fdd\u6301\u6269\u6563\u7ed3\u6784\uff1b\u8bbe\u8ba1\u53ef\u644a\u9500\u7f16\u7801\u5668\u901a\u8fc7\u6a21\u62df\u6f02\u79fb\u6821\u6b63SDE\u5c06\u53ef\u53d8\u957f\u5ea6\u4e8b\u4ef6\u5e8f\u5217\u6620\u5c04\u81f3\u540e\u9a8c\u5f3a\u5ea6\u8def\u5f84\uff0c\u5b9e\u73b0\u5355\u6b21\u524d\u5411\u4f20\u64ad\u3002", "result": "\u7406\u8bba\u4fdd\u8bc1\u53d8\u5206\u65cf\u5305\u542b\u771f\u5b9e\u540e\u9a8c\u4e14ELBO\u6700\u5927\u5316\u7b49\u4ef7\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff1b\u5b9e\u9a8c\u8868\u660e\u80fd\u51c6\u786e\u6062\u590d\u5f3a\u5ea6\u52a8\u6001\uff0c\u76f8\u8f83MCMC\u65b9\u6cd5\u83b7\u5f97\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aCox\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u53d8\u5206\u63a8\u65ad\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u795e\u7ecfSDE\u4e0e\u6f02\u79fb\u6821\u6b63\u673a\u5236\uff0c\u5728\u4fdd\u6301\u63a8\u65ad\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u5927\u89c4\u6a21\u70b9\u8fc7\u7a0b\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.24146", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24146", "abs": "https://arxiv.org/abs/2602.24146", "authors": ["Zitian Li", "Wang Chi Cheung"], "title": "Learning with a Budget: Identifying the Best Arm with Resource Constraints", "comment": "A preliminary version of this work, titled 'Best Arm Identification with Resource Constraints,' was presented at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024). This manuscript extends the original conference paper by providing improved theoretical results and more generalized conclusions, aiming for future journal submission. arXiv admin note: substantial text overlap with arXiv:2402.19090", "summary": "In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \\textit{effective consumption measure", "AI": {"tldr": "\u9488\u5bf9\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u8d44\u6e90\u914d\u7ed9\u9010\u6b21\u6298\u534a\u7b97\u6cd5(SH-RR)\uff0c\u5c06\u8d44\u6e90\u611f\u77e5\u5206\u914d\u673a\u5236\u878d\u5165\u7ecf\u5178\u9010\u6b21\u6298\u534a\u6846\u67b6\uff0c\u7edf\u4e00\u4e86\u968f\u673a\u548c\u786e\u5b9a\u6027\u6d88\u8017\u8bbe\u7f6e\u7684\u7406\u8bba\u5206\u6790\uff0c\u5e76\u5b9a\u4e49\u4e86\u65b0\u7684\u6709\u6548\u6d88\u8017\u5ea6\u91cf\u3002", "motivation": "\u5728\u8bb8\u591a\u5e94\u7528\u573a\u666f\u4e2d\uff0c\u8bc4\u4f30\u4e0d\u540c\u66ff\u4ee3\u65b9\u6848\u7684\u6210\u672c\u6216\u8d44\u6e90\u6d88\u8017\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\u3002\u4f20\u7edf\u6700\u4f73\u81c2\u8bc6\u522b\u65b9\u6cd5\u672a\u8003\u8651\u8d44\u6e90\u9650\u5236\uff0c\u800c\u5b9e\u9645\u8d44\u6e90\u5f80\u5f80\u6709\u9650\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u9ad8\u6548\u8bc6\u522b\u6700\u4f73\u65b9\u6848\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8d44\u6e90\u914d\u7ed9\u7684\u9010\u6b21\u6298\u534a\u7b97\u6cd5(SH-RR)\uff0c\u901a\u8fc7\u5728\u6bcf\u4e00\u8f6e\u4e2d\u6839\u636e\u8d44\u6e90\u7ea6\u675f\u52a8\u6001\u914d\u7ed9\u8d44\u6e90\u7ed9\u5019\u9009\u81c2\uff0c\u5e76\u7ed3\u5408\u7ecf\u5178\u9010\u6b21\u6298\u534a\u7684\u6dd8\u6c70\u673a\u5236\uff0c\u9010\u6b65\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u6700\u7ec8\u8bc6\u522b\u6700\u4f18\u81c2\u3002\u8be5\u7b97\u6cd5\u540c\u65f6\u9002\u7528\u4e8e\u968f\u673a\u548c\u786e\u5b9a\u6027\u8d44\u6e90\u6d88\u8017\u8bbe\u7f6e\u3002", "result": "\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a1) \u63d0\u51fa\u4e86\u7edf\u4e00\u7684SH-RR\u7b97\u6cd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86BAIwRC\u95ee\u9898\uff1b2) \u5728\u968f\u673a\u548c\u786e\u5b9a\u6027\u4e24\u79cd\u8d44\u6e90\u6d88\u8017\u6a21\u578b\u4e0b\u5efa\u7acb\u4e86\u7cfb\u7edf\u7684\u7406\u8bba\u5206\u6790\uff1b3) \u5f15\u5165\u4e86\u65b0\u7684\u6709\u6548\u6d88\u8017\u5ea6\u91cf\u6307\u6807\uff0c\u4e3a\u7b97\u6cd5\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u6269\u5c55\u4e86\u7ecf\u5178\u6700\u4f73\u81c2\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d44\u6e90\u914d\u7ed9\u673a\u5236\u4f7f\u5176\u80fd\u591f\u5904\u7406\u8d44\u6e90\u7ea6\u675f\u573a\u666f\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u51b3\u7b56\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\u548c\u7406\u8bba\u652f\u6491\u3002"}}
{"id": "2602.24178", "categories": ["cs.LG", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.24178", "abs": "https://arxiv.org/abs/2602.24178", "authors": ["Adam R. Klivans", "Konstantinos Stavropoulos", "Arsen Vasilyan"], "title": "Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension", "comment": "30 pages", "summary": "Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.\n  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6784\u9020\u4f4e\u6b21\u5939\u903c\u591a\u9879\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u5728Gaussian\u5206\u5e03\u4e0b\u5bf9k\u4e2a\u534a\u7a7a\u95f4\u7684\u51fd\u6570\u5b9e\u73b0\u4e86poly(k)\u6b21\u903c\u8fd1\uff0c\u76f8\u6bd4\u4e4b\u524d2^O(k)\u6b21\u6709\u6307\u6570\u7ea7\u6539\u8fdb\uff0c\u4e14\u65b9\u6cd5\u66f4\u7b80\u5355\uff0c\u76f4\u63a5\u5229\u7528\u8fb9\u754c\u5149\u6ed1\u6027\u548c\u9ad8\u7ef4\u903c\u8fd1\u7406\u8bba\u3002", "motivation": "\u4f4e\u6b21\u5939\u903c\u591a\u9879\u5f0f\u5728\u5206\u5e03\u504f\u79fb\u3001\u53ef\u6d4b\u8bd5\u5b66\u4e60\u53ca\u6c61\u67d3\u5b66\u4e60\u7b49\u6311\u6218\u6027\u5b66\u4e60\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u610f\u5916\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u6b64\u524d\u5bf9\u57fa\u672c\u51fd\u6570\u7c7b\uff08\u5982k\u534a\u7a7a\u95f4\u51fd\u6570\uff09\u7684\u6784\u9020\u5b58\u5728\u6307\u6570\u7ea7\u6b21\u6570\u4e0a\u754c\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u5229\u7528\u76ee\u6807\u51fd\u6570\u8fb9\u754c\u7684\u5e73\u6ed1\u6027\u6784\u9020\u5939\u903cLipschitz\u51fd\u6570\uff0c\u7ed3\u5408\u9ad8\u7ef4\u903c\u8fd1\u7406\u8bba\uff0c\u907f\u514d\u4f7f\u7528\u590d\u6742\u7684FT-\u78e8\u5149\u6cd5\uff0c\u8bc1\u660e\u8fc7\u7a0b\u7b80\u6d01\u76f4\u63a5\u3002", "result": "1) \u5bf9Gaussian\u5206\u5e03\u4e0bk\u534a\u7a7a\u95f4\u51fd\u6570\u83b7\u5f97poly(k)\u6b21\u5939\u903c\u591a\u9879\u5f0f\uff0c\u76f8\u6bd4\u4e4b\u524d2^O(k)\u6b21\u5b9e\u73b0\u6307\u6570\u7ea7\u63d0\u5347\uff1b2) \u5bf9\u4f4e\u7ef4\u591a\u9879\u5f0f\u9608\u503c\u51fd\u6570\uff08PTFs\uff09\u83b7\u5f97\u53cc\u91cd\u6307\u6570\u7ea7\u6539\u8fdb\uff0c\u4e14\u65e0\u9700Kane\u7684FT-\u78e8\u5149\u6280\u672f\u3002", "conclusion": "\u672c\u65b9\u6cd5\u4e3a\u5939\u903c\u591a\u9879\u5f0f\u6784\u9020\u63d0\u4f9b\u4e86\u666e\u9002\u6027\u6539\u8fdb\uff0c\u7279\u522b\u5bf9\u4f4e\u7ef4\u5149\u6ed1\u8fb9\u754c\u51fd\u6570\u7c7b\uff0c\u5728\u6b21\u6570\u4e0a\u53d6\u5f97\u7a81\u7834\u6027\u4f18\u5316\uff0c\u4e3a\u9ad8\u7ef4\u5b66\u4e60\u7406\u8bba\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2602.24182", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24182", "abs": "https://arxiv.org/abs/2602.24182", "authors": ["Sikata Sengupta", "Guangyi Liu", "Omer Gottesman", "Joseph W Durham", "Michael Kearns", "Aaron Roth", "Michael Caldara"], "title": "Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers", "comment": null, "summary": "Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.", "AI": {"tldr": "\u672c\u6587\u5c06\u5c65\u7ea6\u4e2d\u5fc3\u7684\u5bb9\u5668\u6574\u5408\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u5927\u89c4\u6a21\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u57fa\u4e8e\u96f6\u548c\u535a\u5f08\u7406\u8bba\u63d0\u51fa\u6700\u5c0f\u6700\u5927\u4f18\u5316\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u5904\u7406\u901f\u5ea6\u3001\u8d44\u6e90\u4f7f\u7528\u548c\u7a7a\u95f4\u5229\u7528\u7387\u7b49\u7ade\u4e89\u76ee\u6807\uff0c\u6ee1\u8db3\u5b9e\u9645\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u89e3\u51b3\u65f6\u95f4\u5e73\u5747\u89e3\u7684\u632f\u8361\u884c\u4e3a\uff0c\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u5c55\u73b0\u51fa\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5bb9\u5668\u5f0f\u5c65\u7ea6\u4e2d\u5fc3\u9700\u4f18\u5316\u7269\u54c1\u5728\u4eba\u4e0e\u673a\u5668\u4eba\u5de5\u4f5c\u7ad9\u95f4\u7684\u6d41\u8f6c\u4ee5\u91ca\u653e\u7a7a\u95f4\u5e76\u63d0\u5347\u5bb9\u5668\u5229\u7528\u7387\uff0c\u6b64\u8fc7\u7a0b\u6d89\u53ca\u5904\u7406\u901f\u5ea6\u3001\u8d44\u6e90\u6d88\u8017\u548c\u7a7a\u95f4\u5229\u7528\u7387\u7b49\u591a\u4e2a\u7ade\u4e89\u76ee\u6807\u7684\u6743\u8861\uff0c\u540c\u65f6\u53d7\u9650\u4e8e\u5b9e\u9645\u8fd0\u8425\u7ea6\u675f\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u548c\u52a8\u6001\u7cfb\u7edf\u884c\u4e3a\u5e26\u6765\u7684\u6311\u6218\uff0c\u4e9f\u9700\u65b0\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u7814\u7a76\u8005\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5927\u89c4\u6a21\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff08MORL\uff09\u4efb\u52a1\uff0c\u5229\u7528\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7684\u6700\u65b0\u7406\u8bba\u8fdb\u5c55\uff0c\u57fa\u4e8e\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u6700\u4f73\u54cd\u5e94\u548c\u65e0\u9057\u61be\u52a8\u529b\u5b66\u5b9e\u73b0\u539f\u5219\u6027\u6700\u5c0f\u6700\u5927\u7b56\u7565\u5b66\u4e60\u3002\u8fdb\u4e00\u6b65\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5904\u7406\u8bef\u5dee\u62b5\u6d88\u95ee\u9898\uff0c\u89e3\u51b3\u65f6\u95f4\u5e73\u5747\u89e3\u7684\u632f\u8361\u884c\u4e3a\uff0c\u786e\u4fdd\u8fd4\u56de\u5355\u6b21\u8fed\u4ee3\u7684\u62c9\u683c\u6717\u65e5\u503c\u63a5\u8fd1\u535a\u5f08\u6700\u5c0f\u6700\u5927\u503c\u3002", "result": "\u5728\u73b0\u5b9e\u4ed3\u5e93\u4eff\u771f\u4e2d\u7684\u7b56\u7565\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6743\u8861\u5404\u7ade\u4e89\u76ee\u6807\uff0c\u5b9e\u8bc1\u53d1\u73b0\u5b66\u4e60\u5230\u7684\u5355\u4e00\u7b56\u7565\u80fd\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\uff08\u5c3d\u7ba1\u65e0\u7406\u8bba\u4fdd\u8bc1\uff09\u3002\u6240\u63d0\u6846\u67b6\u53ef\u8fd4\u56de\u62c9\u683c\u6717\u65e5\u503c\u63a5\u8fd1\u6700\u5c0f\u6700\u5927\u503c\u7684\u5355\u6b21\u8fed\u4ee3\u89e3\uff0c\u6709\u6548\u5904\u7406\u632f\u8361\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u9a8c\u8bc1\u4e86\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u6700\u5c0f\u6700\u5927\u4f18\u5316\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u5de5\u4e1a\u7cfb\u7edf\u590d\u6742\u51b3\u7b56\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u5904\u7406\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u548c\u591a\u76ee\u6807\u6743\u8861\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c55\u793a\u4e86\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.24201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24201", "abs": "https://arxiv.org/abs/2602.24201", "authors": ["Egor Antipov", "Alessandro Palma", "Lorenzo Consoli", "Stephan G\u00fcnnemann", "Andrea Dittadi", "Fabian J. Theis"], "title": "Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics", "comment": null, "summary": "Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u7684\u5355\u4e00\u52a8\u529b\u5b66\u6846\u67b6\uff0c\u9ad8\u6548\u4f30\u8ba1\u5bc6\u5ea6\u6bd4\uff0c\u5728\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u5b66\u7684\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u4e0e\u6279\u6b21\u6821\u6b63\u8bc4\u4f30\u3002", "motivation": "\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u662f\u6982\u7387\u5efa\u6a21\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u53ef\u5b9e\u73b0\u4e0d\u540c\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e0b\u6837\u672c\u4f3c\u7136\u7684\u6bd4\u8f83\u3002\u5f52\u4e00\u5316\u6d41\u7b49\u7cbe\u786e\u4f3c\u7136\u6a21\u578b\u867d\u5177\u524d\u666f\uff0c\u4f46\u8ba1\u7b97\u6602\u8d35\uff0c\u9700\u4e3a\u6bcf\u4e2a\u5206\u5e03\u5355\u72ec\u6a21\u62df\u4f3c\u7136\u79ef\u5206\u3002", "method": "\u5229\u7528\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u6280\u672f\uff0c\u63a8\u5bfc\u51fa\u6cbf\u751f\u6210\u8f68\u8ff9\u8ffd\u8e2a\u5bc6\u5ea6\u6bd4\u7684\u5355\u4e00\u52a8\u529b\u5b66\u516c\u5f0f\uff0c\u907f\u514d\u5bf9\u6bcf\u4e2a\u5206\u5e03\u8fdb\u884c\u72ec\u7acb\u8ba1\u7b97\u3002", "result": "\u5728\u95ed\u5f0f\u6bd4\u7387\u4f30\u8ba1\u7684\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u7ade\u4e89\u6027\u80fd\uff1b\u652f\u6301\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u5b66\u4e2d\u7684\u591a\u79cd\u4efb\u52a1\uff0c\u5305\u62ec\u8de8\u5b9e\u9a8c\u6761\u4ef6\u7684\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u548c\u6279\u6b21\u6821\u6b63\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5355\u4e00\u52a8\u529b\u5b66\u516c\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u6a21\u62df\u6570\u636e\u4e0e\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u5b66\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u6982\u7387\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2602.24207", "categories": ["cs.LG", "cs.CY", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24207", "abs": "https://arxiv.org/abs/2602.24207", "authors": ["Gabriele Farina", "Juan Carlos Perdomo"], "title": "The Stability of Online Algorithms in Performative Prediction", "comment": null, "summary": "The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5728performative prediction\u73af\u5883\u4e2d\uff0c\u4efb\u4f55\u65e0\u9057\u61be\u7b97\u6cd5\u90fd\u4f1a\u6536\u655b\u81f3\u4e00\u4e2aperformatively stable equilibrium\uff0c\u65e0\u9700\u5bf9\u6a21\u578b\u5f71\u54cd\u6570\u636e\u5206\u5e03\u7684\u673a\u5236\u65bd\u52a0\u4efb\u4f55\u9650\u5236\u3002", "motivation": "\u7b97\u6cd5\u9884\u6d4b\u5728\u51b3\u7b56\u4e2d\u4f1a\u4ea7\u751f\u53cd\u9988\u5faa\u73af\uff1a\u90e8\u7f72\u7684\u6a21\u578b\u4f1a\u6539\u53d8\u6570\u636e\u5206\u5e03\uff0c\u800c\u8be5\u5206\u5e03\u53c8\u7528\u4e8e\u6a21\u578b\u91cd\u8bad\u7ec3\u3002\u8fd9\u4e00\u52a8\u6001\u5173\u7cfb\u5df2\u88abPerdomo\u7b49\u4eba\u5f62\u5f0f\u5316\u4e3aperformative prediction\u3002\u6b64\u524d\u8be5\u9886\u57df\u7684\u79ef\u6781\u7ed3\u679c\u5747\u4f9d\u8d56\u4e8e\u5bf9\u6a21\u578b\u5f71\u54cd\u5206\u5e03\u7684\u5f3a\u5047\u8bbe\u9650\u5236\u3002", "method": "\u901a\u8fc7\u9785\u8bba\u5206\u6790\u4e0e\u968f\u673a\u5316\u6280\u672f\uff0c\u907f\u514d\u4e86\u5bf9\u6a21\u578b\u5f71\u54cd\u5206\u5e03\u65b9\u5f0f\u7684\u4efb\u4f55\u524d\u63d0\u5047\u8bbe\uff0c\u4ece\u800c\u7ed5\u8fc7\u4e86\u5bfb\u627e\u7a33\u5b9a\u6a21\u578b\u7684\u76f8\u5173\u56f0\u96be\u6027\u7ed3\u679c\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u662f\u4e00\u4e2a\u65e0\u6761\u4ef6\u5f52\u7ea6\uff1a\u4efb\u4f55\u5728performative\u8bbe\u7f6e\u4e2d\u90e8\u7f72\u7684\u65e0\u9057\u61be\u7b97\u6cd5\u90fd\u4f1a\u6536\u655b\u5230\uff08\u6df7\u5408\uff09performatively stable equilibrium\u2014\u2014\u5373\u6a21\u578b\u4e3b\u52a8\u5851\u9020\u6570\u636e\u5206\u5e03\uff0c\u4f7f\u5176\u81ea\u8eab\u9884\u6d4b\u5728\u4e8b\u540e\u770b\u6765\u8fbe\u5230\u6700\u4f18\u7684\u89e3\u3002", "conclusion": "\u8be5\u7406\u8bba\u63ed\u793a\u4e86\u68af\u5ea6\u4e0b\u964d\u7b49\u5e38\u89c1\u7b97\u6cd5\u4e3a\u4f55\u5929\u7136\u5177\u6709\u7a33\u5b9a\u6548\u5e94\u5e76\u80fd\u9632\u6b62\u5931\u63a7\u53cd\u9988\u5faa\u73af\u3002\u7814\u7a76\u65e8\u5728\u4fc3\u8fdb\u5728\u7ebf\u4f18\u5316\u4e0eperformativity\u4e4b\u95f4\u7684\u672a\u6765\u6280\u672f\u8f6c\u79fb\u3002"}}
{"id": "2602.24209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24209", "abs": "https://arxiv.org/abs/2602.24209", "authors": ["Mohsen Tajgardan", "Atena Shiranzaei", "Mahdi Rabbani", "Reza Khoshkangini", "Mahtab Jamali"], "title": "An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks", "comment": null, "summary": "Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.", "AI": {"tldr": "\u9488\u5bf9\u7269\u8054\u7f51\u6570\u636e\u5f02\u8d28\u6027\u6311\u6218\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u5f02\u5e38\u68c0\u6d4b\u4e0e\u8bbe\u5907\u8bc6\u522b\u4e24\u4e2a\u4e92\u8865\u6570\u636e\u96c6\u7684\u5171\u4eab\u7279\u5f81\u5e76\u4fdd\u7559\u7279\u5b9a\u7279\u5f81\uff0c\u7ed3\u5408SHAP\u53ef\u89e3\u91caAI\u6280\u672f\uff0c\u5728\u771f\u5b9e\u7269\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u63d0\u4f9b\u4e86\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u5728\u80fd\u529b\u3001\u6570\u636e\u683c\u5f0f\u548c\u901a\u4fe1\u7ea6\u675f\u65b9\u9762\u7684\u5f02\u8d28\u6027\u5bfc\u81f4\u7279\u5f81\u5f02\u6784\u6027\uff0c\u4e25\u91cd\u5f71\u54cd\u8054\u90a6\u5b66\u4e60\u7684\u5168\u5c40\u6a21\u578b\u6027\u80fd\u4e0e\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002\u5728\u65e0\u9700\u96c6\u4e2d\u6570\u636e\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u573a\u666f\u4e2d\uff0c\u7279\u5f81\u5dee\u5f02\u4f7f\u6a21\u578b\u8bad\u7ec3\u590d\u6742\u5316\uff0c\u963b\u788d\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u5b9e\u9645\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7684\u6709\u6548\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5171\u4eab\u7279\u5f81\u878d\u5408\u7684\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u4e24\u4e2a\u72ec\u7acb\u7269\u8054\u7f51\u6570\u636e\u96c6\uff08\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6\u4e0e\u8bbe\u5907\u8bc6\u522b\u6570\u636e\u96c6\uff09\u7684\u5171\u4eab\u7279\u5f81\u8fdb\u884c\u534f\u540c\u8bad\u7ec3\uff0c\u540c\u65f6\u4fdd\u62a4\u5404\u6570\u636e\u96c6\u7279\u6709\u7279\u5f81\u3002\u5f15\u5165SHAP\u7b49\u53ef\u89e3\u91caAI\u6280\u672f\uff0c\u8bc6\u522b\u5f71\u54cd\u672c\u5730\u6a21\u578b\u51b3\u7b56\u7684\u5173\u952e\u7279\u5f81\uff0c\u589e\u5f3a\u6846\u67b6\u900f\u660e\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u771f\u5b9e\u7269\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528\u4e92\u8865\u6570\u636e\u96c6\u5171\u4eab\u7279\u5f81\u4f18\u5316\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u5b9e\u901a\u8fc7\u5171\u4eab\u4e92\u8865\u6570\u636e\u96c6\u7279\u5f81\u53ef\u6709\u6548\u514b\u670d\u7269\u8054\u7f51\u6570\u636e\u5f02\u8d28\u6027\uff0c\u4f18\u5316\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6027\u80fd\uff0c\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u5728\u5f02\u6784\u7269\u8054\u7f51\u573a\u666f\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u4e0e\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2602.24231", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24231", "abs": "https://arxiv.org/abs/2602.24231", "authors": ["Hongrui Xie", "Junyu Cao", "Kan Xu"], "title": "Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference", "comment": "30 pages, 3 figure, AISTATS 2026 accepted paper", "summary": "In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u5f00\u521b\u6027\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\uff08CMAB\uff09\u4e2d\u9057\u61be\u6700\u5c0f\u5316\u4e0e\u7edf\u8ba1\u529f\u6548\u4e4b\u95f4\u7684\u6743\u8861\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5MixCombKL\u548cMixCombUCB\uff0c\u5206\u522b\u5728\u5b8c\u5168\u53cd\u9988\u548c\u534a\u53cd\u9988\u673a\u5236\u4e0b\u5b9e\u73b0\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u5b66\u4e60\uff0c\u5e76\u5efa\u7acb\u4e86\u591a\u76ee\u6807\u51b3\u7b56\u7684\u7ec4\u5408\u5b9e\u9a8c\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9057\u61be\u6700\u5c0f\u5316\uff0c\u4f46\u5728\u5b9e\u9645\u5b9e\u9a8c\u8bbe\u8ba1\u4e2d\uff08\u5982A/B\u6d4b\u8bd5\u3001\u63a8\u8350\u7cfb\u7edf\uff09\uff0c\u8fd8\u9700\u8981\u5bf9\u5956\u52b1\u5dee\u8ddd\u8fdb\u884c\u51c6\u786e\u7edf\u8ba1\u63a8\u65ad\u3002\u8fd9\u5c31\u4ea7\u751f\u4e86\u6839\u672c\u6027\u51b2\u7a81\uff1a\u51cf\u5c11\u9057\u61be\u9700\u8981\u53cd\u590d\u5229\u7528\u9ad8\u5956\u52b1\u81c2\uff0c\u800c\u51c6\u786e\u7684\u7edf\u8ba1\u63a8\u65ad\u9700\u8981\u5145\u5206\u63a2\u7d22\u6b21\u4f18\u52a8\u4f5c\u3002\u672c\u6587\u65e8\u5728\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u8fd9\u79cd\u6743\u8861\uff0c\u4e3a\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u8bbe\u8ba1\u5efa\u7acb\u7406\u8bba\u57fa\u7840\u3002", "method": "1. \u901a\u8fc7\u5e15\u7d2f\u6258\u6700\u4f18\u6982\u5ff5\u5f62\u5f0f\u5316\u9057\u61be\u4e0e\u7edf\u8ba1\u529f\u6548\u7684\u6743\u8861\u5173\u7cfb\uff1b2. \u5efa\u7acbCMAB\u4e2d\u5e15\u7d2f\u6258\u9ad8\u6548\u5b66\u4e60\u7684\u7b49\u4ef7\u6761\u4ef6\uff1b3. \u9488\u5bf9\u4e0d\u540c\u4fe1\u606f\u7ed3\u6784\uff08\u5b8c\u5168\u53cd\u9988vs\u534a\u53cd\u9988\uff09\u8bbe\u8ba1\u4e24\u79cd\u7b97\u6cd5\uff1aMixCombKL\uff08\u9002\u7528\u4e8e\u5b8c\u5168\u53cd\u9988\uff09\u548cMixCombUCB\uff08\u9002\u7528\u4e8e\u534a\u53cd\u9988\uff09\uff1b4. \u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\uff0c\u8bc1\u660e\u7b97\u6cd5\u5728\u6709\u9650\u65f6\u95f4\u5185\u540c\u65f6\u8fbe\u5230\u9057\u61be\u548c\u4f30\u8ba1\u8bef\u5dee\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u3002", "result": "1. \u7406\u8bba\u8bc1\u660e\u4e24\u79cd\u7b97\u6cd5\u5747\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\uff1b2. \u83b7\u5f97\u9057\u61be\u548c\u81c2\u95f4\u5dee\u8ddd\u4f30\u8ba1\u8bef\u5dee\u7684\u6709\u9650\u65f6\u95f4\u4fdd\u8bc1\uff1b3. \u53d1\u73b0\u66f4\u4e30\u5bcc\u7684\u53cd\u9988\uff08\u534a\u53cd\u9988\uff09\u663e\u8457\u6536\u7d27\u53ef\u8fbe\u6210\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff1b4. \u6838\u5fc3\u6536\u76ca\u6765\u6e90\u4e8e\u6240\u63d0\u65b9\u6cd5\u4e0b\u4f30\u8ba1\u7cbe\u5ea6\u7684\u63d0\u5347\u3002", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u591a\u76ee\u6807\u51b3\u7b56\u539f\u5219\u6027\u6846\u67b6\uff0c\u9996\u6b21\u63ed\u793a\u4e86\u9057\u61be\u6700\u5c0f\u5316\u4e0e\u7edf\u8ba1\u529f\u6548\u4e4b\u95f4\u7684\u5185\u5728\u6743\u8861\u673a\u5236\uff0c\u4e3a\u9700\u8981\u5728\u63a2\u7d22-\u5229\u7528\u4e0e\u7edf\u8ba1\u63a8\u65ad\u4e4b\u95f4\u5e73\u8861\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u7b97\u6cd5\u3002"}}
