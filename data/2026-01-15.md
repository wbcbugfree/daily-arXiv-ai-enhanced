<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 61]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.IR](#cs.IR) [Total: 12]
- [cs.LG](#cs.LG) [Total: 46]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DeliberationBench: When Do More Voices Hurt? A Controlled Study of Multi-LLM Deliberation Protocols](https://arxiv.org/abs/2601.08835)
*Vaarunay Kaushal,Taranveer Singh*

Main category: cs.CL

TL;DR: 最佳单一模型输出选择基线在多LLM deliberation 任务中显著超越三种 deliberation 协议，胜率约为 82.5% 而 deliberation 协议仅约 13.8%，差距约 6 倍，且计算成本高于基线。


<details>
  <summary>Details</summary>
Motivation: 评估多模型 deliberation 是否真能提升结果质量，以及在受控基准下对比更简单的池中最佳输出选择策略的价值，质疑“复杂性即质量”的假设，并提供可控的评估基准 DELIBERATIONBENCH。

Method: 将三种 deliberation 协议与一个强基线（从模型输出池中选取最佳回应）进行对比；在 270 道题目、3 个随机种子下共计 810 次评估；以胜率衡量输出优劣，并比较计算成本。

Result: 最佳单一基线的胜率为 82.5% ± 3.3%，显著高于最佳 deliberation 协议的 13.8% ± 2.6%（6.0× 的差距，p < 0.01），且成本比基线高出 1.5–2.5 倍。

Conclusion: 研究结果挑战了“复杂性提升质量”的假设，表明在该多-LLM 系统的受控场景下，简单的最佳输出选择往往优于复杂的 deliberation 策略，需要重新审视多模型协作的设计原则。

Abstract: Multi-agent systems where Large Language Models (LLMs) deliberate to form consensus have gained significant attention, yet their practical value over simpler methods remains under-scrutinized. We introduce DELIBERATIONBENCH, a controlled benchmark evaluating three deliberation protocols against a strong baseline of selecting the best response from a pool of model outputs. Across 270 questions and three independent seeds (810 total evaluations), we find a striking negative result: the best-single baseline achieves an 82.5% +- 3.3% win rate, dramatically outperforming the best deliberation protocol(13.8% +- 2.6%). This 6.0x performance gap is statistically significant (p < 0.01) and comes at 1.5-2.5x higher computational cost. Our findings challenge assumptions that complexity enhances quality in multi-LLM systems.

</details>


### [2] [A Review: PTSD in Pre-Existing Medical Condition on Social Media](https://arxiv.org/abs/2601.08836)
*Zaber Al Hassan Ayon,Nur Hafieza Ismail,Nur Shazwani Kamarudin*

Main category: cs.CL

TL;DR: 系统综述评估 PTSD 与慢性疾病在社交媒体中的交互，利用 NLP/ML 检测潜在 PTSD 并探讨在线支持对 coping 的作用，强调将慢性病纳入 PTSD 研究与治疗，以及社媒监测与干预潜力。


<details>
  <summary>Details</summary>
Motivation: 慢性病患者中的 PTSD 影响广泛且往往被忽视，社交媒体提供日常表达的海量数据，可用于识别风险、理解经验并支持干预。

Method: 系统性文献回顾，覆盖 2008-2024 年，聚焦 X（推特）与 Facebook 等社交平台；结合自然语言处理与机器学习用于 PTSD 识别；综合定性与定量结果，讨论社媒在监测与干预中的作用与局限。

Result: 发现社媒数据能揭示慢性病与 PTSD 的特定挑战；NLP/ML 在识别潜在 PTSD 方面的准确率约 74%–90%；在线互助社区对 coping 策略与早期干预具有促进作用；强调将慢性病因素纳入 PTSD 的研究与治疗框架，并提出未来研究方向与临床含义。

Conclusion: 强调社媒在监测高风险人群中的潜力，尤其是将慢性病背景纳入 PTSD 研究与干预设计；未来需发展跨平台、伦理合规、可推广的干预策略及更严格的验证。

Abstract: Post-Traumatic Stress Disorder (PTSD) is a multifaceted mental health condition, particularly challenging for individuals with pre-existing medical conditions. This review critically examines the intersection of PTSD and chronic illnesses as expressed on social media platforms. By systematically analyzing literature from 2008 to 2024, the study explores how PTSD manifests and is managed in individuals with chronic conditions such as cancer, heart disease, and autoimmune disorders, with a focus on online expressions on platforms like X (formally known as Twitter) and Facebook. Findings demonstrate that social media data offers valuable insights into the unique challenges faced by individuals with both PTSD and chronic illnesses. Specifically, natural language processing (NLP) and machine learning (ML) techniques can identify potential PTSD cases among these populations, achieving accuracy rates between 74% and 90%. Furthermore, the role of online support communities in shaping coping strategies and facilitating early interventions is highlighted. This review underscores the necessity of incorporating considerations of pre-existing medical conditions in PTSD research and treatment, emphasizing social media's potential as a monitoring and support tool for vulnerable groups. Future research directions and clinical implications are also discussed, with an emphasis on developing targeted interventions.

</details>


### [3] [Recursive Knowledge Synthesis for Multi-LLM Systems: Stability Analysis and Tri-Agent Audit Framework](https://arxiv.org/abs/2601.08839)
*Toshiyuki Shigemura*

Main category: cs.CL

TL;DR: 提出一个三主体跨验证框架以实现多模型大语言系统的稳定性与可解释性分析，通过三种异质LLM在递归交互循环中实现递归知识合成（RKS），在47次公开部署环境下评估稳定性，结果表明RRS约0.78，TS在68%试验中保持≥0.8，约89%试验收敛，支持透明度审计作为收缩算子、提升稳定性；贡献包括三主体框架、基于固定点理论的RKS模型、以及公开环境下的互模稳定性评估。


<details>
  <summary>Details</summary>
Motivation: 解决多模型LLM系统的稳定性与可解释性挑战，构建协同推理框架以提升安全性与透明度，并在真实公共部署场景中验证。

Method: 将三种异质LLM用于语义生成、分析一致性检查与透明度审计，构成递归交互循环，提出RKS模型并以固定点理论为基础；在47次公开访问的LLM部署中进行系统稳定性的实证评估，使用RRS、TS、DDR、CSR等指标。

Result: 平均RRS 0.78±0.06；TS≥0.8在约68%试验中维持；约89%试验收敛；透明度审计可作为收缩算子；在现实、非API公开环境下进行评估。

Conclusion: 初步证据表明安全可控、人工监督的多LLM架构可在现实公开环境中实现稳定的递归知识合成；对三主体框架、RKS模型及互模稳定性评估作出贡献。

Abstract: This paper presents a tri-agent cross-validation framework for analyzing stability and explainability in multi-model large language systems. The architecture integrates three heterogeneous LLMs-used for semantic generation, analytical consistency checking, and transparency auditing-into a recursive interaction cycle. This design induces Recursive Knowledge Synthesis (RKS), where intermediate representations are continuously refined through mutually constraining transformations irreducible to single-model behavior. Across 47 controlled trials using public-access LLM deployments (October 2025), we evaluated system stability via four metrics: Reflex Reliability Score (RRS), Transparency Score (TS), Deviation Detection Rate (DDR), and Correction Success Rate (CSR). The system achieved mean RRS = 0.78+-0.06 and maintained TS >= 0.8 in about 68% of trials. Approximately 89% of trials converged, supporting the theoretical prediction that transparency auditing acts as a contraction operator within the composite validation mapping. The contributions are threefold: (1) a structured tri-agent framework for coordinated reasoning across heterogeneous LLMs, (2) a formal RKS model grounded in fixed-point theory, and (3) empirical evaluation of inter-model stability under realistic, non-API public-access conditions. These results provide initial empirical evidence that a safety-preserving, humansupervised multi-LLM architecture can achieve stable recursive knowledge synthesis in realistic, publicly deployed environments.

</details>


### [4] [Consistency-Aware Editing for Entity-level Unlearning in Language Models](https://arxiv.org/abs/2601.08840)
*Xiaoqi Han,Víctor Gutiérrez-Basulto,Ru Li,Xiaoli Li,Jiye Liang,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 提出一致性感知的编辑（CAE）框架，以实现对实体级别的“忘记”在大语言模型中的高效、鲁棒更新。通过聚合目标实体相关的多样化提示（属性、关系、对手性改写），联合学习低秩更新并引入一致性正则以对齐不同提示的编辑方向，从而提高遗忘的全面性并减少对无关知识的干扰，在RWKU和ToFU评估中与基线相比实现更高的遗忘准确性和鲁棒性，并实现仅用几十个提示即可实现可扩展的实体移除。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在训练数据中可能记住敏感、受版权保护或有害信息的风险，需实现对特定实体的全面、可控遗忘。现有编辑方法多面向实例级更新，难以从根本上消除与实体相关的全部知识，且对改写的同义表述鲁棒性不足。

Method: 提出一致性感知编辑（CAE）框架：① 以目标实体为中心，聚合关于该实体的多类提示（属性、关系、对抗性改写等）；② 以低秩更新为核心，通过一致性正则对不同提示的编辑方向进行对齐，形成稳定的全局更新；③ 同时考虑实体知识在模型内部的存储位置与需要的提示数量，提升可扩展性。

Result: 在RWKU与ToFU基准上，CAE在遗忘准确性与鲁棒性方面显著优于传统的遗忘/编辑方法，揭示了模型内部对实体知识的存储与删除的一致性规律，并可通过仅仅若干（数十）个精心选择的提示实现可扩展的实体删除。

Conclusion: CAE为实体级遗忘提供了一个高效、鲁棒且可扩展的解决方案，促进对LLMs内部知识表示与删除机制的理解，并为安全、受控的后训练编辑与隐私保护场景提供实用工具。

Abstract: Large language models (LLMs) risk retaining sensitive, copyrighted, or harmful information from their training data. Entity-level unlearning addresses this issue by removing all knowledge of a specific entity while preserving the model's overall capabilities. Existing approaches typically rely on full-model fine-tuning or prompt-based interventions, which can be computationally expensive or brittle when handling paraphrased queries. Recently, model editing has emerged as an efficient alternative for updating knowledge in LLMs, offering a promising direction for unlearning. However, existing editing techniques are typically designed for instance-level updates, modifying responses to specific attributes of an entity rather than eliminating all knowledge associated with the entity. In this paper, we investigate how editing techniques can be adapted for effective and efficient entity-level unlearning. To this end, we introduce a novel consistency-aware editing (CAE) framework. CAE aggregates a diverse set of prompts related to a target entity, including its attributes, relations, and adversarial paraphrases. It then jointly learns a low-rank update guided by a consistency regularizer that aligns the editing directions across prompts. This promotes robust and comprehensive forgetting while minimizing interference with unrelated knowledge. We further examine where different entities are stored within the model and how many diverse prompts are needed for successful unlearning. We evaluate CAE on two challenging benchmarks, RWKU and ToFU, and demonstrate that it (i) provides insights into how entity-level knowledge is internally represented and deleted in LLMs, (ii) significantly improves forgetting accuracy and robustness over traditional unlearning and editing baselines, and (iii) enables scalable entity removal using only tens of carefully selected prompts.

</details>


### [5] [Triples and Knowledge-Infused Embeddings for Clustering and Classification of Scientific Documents](https://arxiv.org/abs/2601.08841)
*Mihael Arcan*

Main category: cs.CL

TL;DR: 将结构化知识（主体-谓词-对象三元组）与无结构文本结合，用于论文聚类和分类，提升分类性能；摘要对聚类最优，混合表示对分类有益；轻量化编码器在聚类表现好，SciBERT在结构化输入分类表现佳。


<details>
  <summary>Details</summary>
Motivation: 应对海量科学文献的组织与理解，探究如何将结构化知识（SPO三元组）融入文本表示，以提升论文聚类和分类的效果。

Method: 提出一个模块化管线，包括无监督聚类和有监督分类，使用多种文档表示：原始摘要、提取的三元组、以及两者的混合格式。使用经过筛选的 arXiv 语料，從摘要中提取关系三元组，构建4种文本表示，并用4个前沿 transformer 模型嵌入：MiniLM、MPNet、SciBERT、SPECTER。以 KMeans、GMM、HDBSCAN 进行聚类评估，并对 arXiv 学科进行分类微调。

Result: 聚类方面，全文摘要文本产生最连贯的簇；混合表示在分类任务上带来一致的提升，分类准确率最高可达 92.6%，宏观 F1 达 0.925。对于聚类，轻量化编码器（MiniLM、MPNet）优于领域模型（SciBERT、SPECTER）；在结构化输入分类方面，SciBERT 表现最佳。

Conclusion: 结合无结构文本与结构化知识可获得互补收益，推动对科学文献的语义组织与知识注入表达的探索。

Abstract: The increasing volume and complexity of scientific literature demand robust methods for organizing and understanding research documents. In this study, we explore how structured knowledge, specifically, subject-predicate-object triples, can enhance the clustering and classification of scientific papers. We propose a modular pipeline that combines unsupervised clustering and supervised classification over multiple document representations: raw abstracts, extracted triples, and hybrid formats that integrate both. Using a filtered arXiv corpus, we extract relational triples from abstracts and construct four text representations, which we embed using four state-of-the-art transformer models: MiniLM, MPNet, SciBERT, and SPECTER. We evaluate the resulting embeddings with KMeans, GMM, and HDBSCAN for unsupervised clustering, and fine-tune classification models for arXiv subject prediction. Our results show that full abstract text yields the most coherent clusters, but that hybrid representations incorporating triples consistently improve classification performance, reaching up to 92.6% accuracy and 0.925 macro-F1. We also find that lightweight sentence encoders (MiniLM, MPNet) outperform domain-specific models (SciBERT, SPECTER) in clustering, while SciBERT excels in structured-input classification. These findings highlight the complementary benefits of combining unstructured text with structured knowledge, offering new insights into knowledge-infused representations for semantic organization of scientific documents.

</details>


### [6] [Rubric-Conditioned LLM Grading: Alignment, Uncertainty, and Robustness](https://arxiv.org/abs/2601.08843)
*Haotian Deng,Chris Farber,Jiyoon Lee,David Tang*

Main category: cs.CL

TL;DR: LLM-judges can align with expert grading on binary rubrics but struggle as rubric granularity increases; a consensus-based deferral improves accuracy by filtering low-confidence cases, at the cost of coverage.


<details>
  <summary>Details</summary>
Motivation: Evaluate the reliability of rubric-conditioned LLM judges for Automated Short-Answer Grading (ASAG) to determine (i) alignment with expert judgments across rubric complexities, (ii) the accuracy–uncertainty tradeoff via deferral, and (iii) robustness to input perturbations and adversarial actions, informing deployment.

Method: Empirical evaluation on SciEntsBank and using Qwen 2.5-72B as the judging model. Assesses alignment across rubric granularities, implements a consensus-based deferral mechanism to manage uncertainty, and tests robustness under random perturbations and adversarial perturbations. Analyzes a Trust Curve to relate confidence, coverage, and accuracy.

Result: Alignment between LLM judgments and expert judgments is strong for binary tasks but degrades as rubric granularity increases. The Trust Curve shows that filtering low-confidence predictions improves accuracy on the remaining subset. The model is robust to prompt injection but sensitive to synonym substitutions.

Conclusion: Rubric-conditioned LLM judges have notable potential for automated grading but exhibit limitations with fine-grained rubrics and lexical perturbations. Uncertainty estimation and selective deferral are valuable for reliable deployment; robustness to lexical perturbations and methods to mitigate synonym vulnerability warrant further work.

Abstract: Automated short-answer grading (ASAG) remains a challenging task due to the linguistic variability of student responses and the need for nuanced, rubric-aligned partial credit. While Large Language Models (LLMs) offer a promising solution, their reliability as automated judges in rubric-based settings requires rigorous assessment. In this paper, we systematically evaluate the performance of LLM-judges for rubric-based short-answer grading. We investigate three key aspects: the alignment of LLM grading with expert judgment across varying rubric complexities, the trade-off between uncertainty and accuracy facilitated by a consensus-based deferral mechanism, and the model's robustness under random input perturbations and adversarial attacks. Using the SciEntsBank benchmark and Qwen 2.5-72B, we find that alignment is strong for binary tasks but degrades with increased rubric granularity. Our "Trust Curve" analysis demonstrates a clear trade-off where filtering low-confidence predictions improves accuracy on the remaining subset. Additionally, robustness experiments reveal that while the model is resilient to prompt injection, it is sensitive to synonym substitutions. Our work provides critical insights into the capabilities and limitations of rubric-conditioned LLM judges, highlighting the importance of uncertainty estimation and robustness testing for reliable deployment.

</details>


### [7] [Emissions and Performance Trade-off Between Small and Large Language Models](https://arxiv.org/abs/2601.08844)
*Anandita Garg,Uma Gaba,Deepan Muthirayan,Anish Roy Chowdhury*

Main category: cs.CL

TL;DR: 四项任务中，微调后的SLM在性能上可与LLM相当，同时推理阶段的碳排放显著降低，显示小模型在环境友好性方面具备潜力。


<details>
  <summary>Details</summary>
Motivation: 应对大型语言模型在训练与推理阶段带来的高碳足迹，探索在保持关键性能的前提下，利用较小模型实现更低环境成本的可能性。

Method: 对所选六项任务（覆盖自然语言处理、推理与编程）中的LLM与微调后的SLM进行对比分析，衡量性能表现与推理阶段碳排放，分析在各任务中的性能-排放权衡。

Result: 在六项任务中，有四项任务中SLMs维持了与LLMs相近的性能，同时推理过程的碳排放显著降低。

Conclusion: 小型、经微调的语言模型对降低资源密集型LLM的环境影响具有可观潜力，支持向绿色AI的转向。

Abstract: The advent of Large Language Models (LLMs) has raised concerns about their enormous carbon footprint, starting with energy-intensive training and continuing through repeated inference. This study investigates the potential of using fine-tuned Small Language Models (SLMs) as a sustainable alternative for predefined tasks. Here, we present a comparative analysis of the performance-emissions trade-off between LLMs and fine-tuned SLMs across selected tasks under Natural Language Processing, Reasoning and Programming. Our results show that in four out of the six selected tasks, SLMs maintained comparable performances for a significant reduction in carbon emissions during inference. Our findings demonstrate the viability of smaller models in mitigating the environmental impact of resource-heavy LLMs, thus advancing towards sustainable, green AI.

</details>


### [8] [OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG](https://arxiv.org/abs/2601.09028)
*Fengran Mo,Zhan Su,Yuchen Hui,Jinghan Zhang,Jia Ao Sun,Zheyuan Liu,Chao Zhang,Tetsuya Sakai,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 提出 OpenDecoder，通过显式评估 retrieved 信息的质量特征（相关性分数、排名分数、QPP 分数）来增强 RAG，对噪声上下文更鲁棒，在五个基准数据集上优于基线，且可灵活嵌入后训练和任意外部指标。


<details>
  <summary>Details</summary>
Motivation: 检索信息的相关性和质量具有波动性，简单地假设检索信息总是相关会影响生成质量，因此需要将信息质量作为显式信号纳入生成过程以提高鲁棒性。

Method: 提出 OpenDecoder，将三种显式评价信息作为质量指示特征引入生成过程；通过将相关性、排名和 QPP 分数整合进解码或训练阶段，使模型对噪声上下文更具鲁棒性；该框架可与 LLM 的后训练结合，并支持与任意外部指标联用。

Result: 在五个基准数据集上实验显示，OpenDecoder 在有效性和鲁棒性方面优于多种基线方法，证实所提出的显式质量信号对提高 RAG 生成质量的有效性。

Conclusion: 该研究提出的范式具备良好灵活性，可用于 LLM 的后训练阶段，并可整合任意外部指标，凸显显式检索质量评估信号在 RAG 系统中的价值。

Abstract: The development of large language models (LLMs) has achieved superior performance in a range of downstream tasks, including LLM-based retrieval-augmented generation (RAG). The quality of generated content heavily relies on the usefulness of the retrieved information and the capacity of LLMs' internal information processing mechanism to incorporate it in answer generation. It is generally assumed that the retrieved information is relevant to the question. However, the retrieved information may have a variable degree of relevance and usefulness, depending on the question and the document collection. It is important to take into account the relevance of the retrieved information in answer generation. In this paper, we propose OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. We aim to build a RAG model that is more robust to varying levels of noisy context. Three types of explicit evaluation information are considered: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. Importantly, this paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.

</details>


### [9] [Directional Attractors in LLM Reasoning: How Similarity Retrieval Steers Iterative Summarization Based Reasoning](https://arxiv.org/abs/2601.08846)
*Cagatay Tekin,Charbel Barakat,Luis Joseph Luna Limgenco*

Main category: cs.CL

TL;DR: InftyThink with Cross-Chain Memory 引入基于嵌入的语义缓存来增强迭代推理中的长程推理，同时控制上下文增长；在结构化任务上提升准确性，但在异质域测试中暴露局限，呈现嵌入空间中的定向偏置吸引子。


<details>
  <summary>Details</summary>
Motivation: 解决上下文窗口增长导致的重复推理和上下文拥塞问题，提供一种通过记忆提升自我改进推理能力的方案，尤其用于需要跨步推理的长序列任务。

Method: 引入跨链记忆的嵌入式语义缓存（lemmas），在每一步推理时检索最相似的已存推理模式并据此条件化推理；通过缓存减少对上下文窗口的持续扩张，同时在不同推理链之间形成可复用的语义模式。

Result: 实验证明在 MATH500、AIME2024、GPQA-Diamond 上，语义 lemma 检索能提升结构化领域的准确性；但在包含异质域的测试中暴露失败模式。对推理轨迹的几何分析显示缓存检索引入嵌入空间的定向偏置，形成“固定点”与“断裂点”等吸引子，既能提升基线准确性，也可能降低基线准确性。总体揭示了相似性记忆在自我提升推理中的潜在收益与限制。

Conclusion: 语义缓存有助于提升自我改进的推理能力，但需谨慎管理以避免嵌入空间的诱导偏差导致性能波动。未来工作应关注缓解吸引子效应、提升跨域鲁棒性以及更稳健的缓存更新与去相关化策略。

Abstract: Iterative summarization based reasoning frameworks such as InftyThink enable long-horizon reasoning in large language models (LLMs) by controlling context growth, but they repeatedly regenerate similar reasoning strategies across tasks. We introduce InftyThink with Cross-Chain Memory, an extension that augments iterative reasoning with an embedding-based semantic cache of previously successful reasoning patterns. At each reasoning step, the model retrieves and conditions on the most semantically similar stored lemmas, guiding inference without expanding the context window indiscriminately. Experiments on MATH500, AIME2024, and GPQA-Diamond demonstrate that semantic lemma retrieval improves accuracy in structured domains while exposing failure modes in tests that include heterogeneous domains. Geometric analyses of reasoning trajectories reveal that cache retrieval induces directional biases in embedding space, leading to consistent fix (improve baseline accuracy) and break (degradation in baseline accuracy) attractors. Our results highlight both the benefits and limits of similarity-based memory for self-improving LLM reasoning.

</details>


### [10] [SpectraQuery: A Hybrid Retrieval-Augmented Conversational Assistant for Battery Science](https://arxiv.org/abs/2601.09036)
*Sreya Vangara,Jagjit Nanda,Yan-Kai Tzeng,Eric Darve*

Main category: cs.CL

TL;DR: Hybrid SpectraQuery framework unifies a relational Raman DB with a vector-indexed literature corpus via a SUQL-inspired design to answer open-ended questions with SQL and literature retrieval, achieving high correctness and grounding.


<details>
  <summary>Details</summary>
Motivation: Bridge structured experimental data and unstructured literature to enable joint reasoning and robust scientific workflow support.

Method: Hybrid query system combining semantic parsing, retrieval-augmented generation, and coordinated SQL plus literature retrieval operations; uses a Structured and Unstructured Query Language inspired design.

Result: SQL correctness ~80% fully correct; synthesized answers 93-97% grounded with 10-15 retrieved passages; expert evaluation 4.1-4.6/5 across accuracy, relevance, grounding, clarity.

Conclusion: Hybrid retrieval architectures can meaningfully support scientific workflows by linking data and discourse for high-volume experimental datasets.

Abstract: Scientific reasoning increasingly requires linking structured experimental data with the unstructured literature that explains it, yet most large language model (LLM) assistants cannot reason jointly across these modalities. We introduce SpectraQuery, a hybrid natural-language query framework that integrates a relational Raman spectroscopy database with a vector-indexed scientific literature corpus using a Structured and Unstructured Query Language (SUQL)-inspired design. By combining semantic parsing with retrieval-augmented generation, SpectraQuery translates open-ended questions into coordinated SQL and literature retrieval operations, producing cited answers that unify numerical evidence with mechanistic explanation. Across SQL correctness, answer groundedness, retrieval effectiveness, and expert evaluation, SpectraQuery demonstrates strong performance: approximately 80 percent of generated SQL queries are fully correct, synthesized answers reach 93-97 percent groundedness with 10-15 retrieved passages, and battery scientists rate responses highly across accuracy, relevance, grounding, and clarity (4.1-4.6/5). These results show that hybrid retrieval architectures can meaningfully support scientific workflows by bridging data and discourse for high-volume experimental datasets.

</details>


### [11] [Scalable and Reliable Evaluation of AI Knowledge Retrieval Systems: RIKER and the Coherent Simulated Universe](https://arxiv.org/abs/2601.08847)
*JV Roig*

Main category: cs.CL

TL;DR: RIKER 提出一种基于 paradigm inversion 的基准与可复现方法，通过从已知结构化 ground truth 生成文档来评估知识系统，使评分可确定、可扩展且免人工注释，具抗污染性。


<details>
  <summary>Details</summary>
Motivation: 解决评测知识系统时的核心难题：静态基准易污染、LLM 评测者存在系统性偏见、ground truth 人工标注成本高。

Method: 采用 paradigm inversion：用已知 ground truth 生成文档，而非从文档中提取 ground truth；利用可再生语料、无需人工注释或参考模型，提供可重复、可扩展且抗污染的评测流程，适用于从结构化信息生成评测材料的场景。

Result: 对 33 种模型、超过 2100 亿令牌进行了评测，发现：上下文长度宣称的可用容量常被高估，超过约 32K 令牌后显著劣化；跨文档聚合难度显著高于单文档提取； grounding 能力与抗幻觉能力是分离的，擅长找出存在事实的模型并不一定会避免捏造不存在的事实。

Conclusion: 提供领域无关的评测构建方法学，适用于任何可以从结构化 ground truth 生成合成文档的场景，实现可扩展、抗污染的评测。

Abstract: Evaluating knowledge systems (LLMs, RAG, knowledge graphs, etc) faces fundamental challenges: static benchmarks are vulnerable to contamination, LLM-based judges exhibit systematic biases, and ground truth extraction requires expensive human annotation. We present RIKER (Retrieval Intelligence and Knowledge Extraction Rating), both a benchmark and a replicable methodology based on paradigm inversion - generating documents from known ground truth rather than extracting ground truth from documents. This approach enables deterministic scoring and scalable evaluation without human annotation or reference models, and contamination resistance through regenerable corpora. Our evaluation of 33 models using over 21 billion tokens reveals that context length claims frequently exceed usable capacity, with significant degradation beyond 32K tokens; cross-document aggregation proves substantially harder than single-document extraction; and grounding ability and hallucination resistance are distinct capabilities - models excelling at finding facts that exist may still fabricate facts that do not. Beyond the specific benchmark, we contribute a domain-agnostic methodology for constructing scalable and contamination-resistant evaluations wherever synthetic documents can be generated from structured ground truth.

</details>


### [12] [PediaMind-R1: A Temperament-Aware Language Model for Personalized Early Childhood Care Reasoning via Cognitive Modeling and Preference Alignment](https://arxiv.org/abs/2601.08848)
*Zihe Zhang,Can Zhang,Yanheng Xu,Xin Hu,Jichao Leng*

Main category: cs.CL

TL;DR: 本论文提出一个面向育儿场景的领域专用大语言模型PediaMind-R1，通过Thomas-Chess理论的 temperament 构建婴幼儿（0-3岁）知识图谱，并采用两阶段训练（有监督微调以教授结构化链式推理，及GRPO对齐以强化逻辑一致性、领域专业性与同理心育儿策略）。结合 temperament 敏感的测试与人工评估，显示模型能解读 temperament 并进行个性化推理。


<details>
  <summary>Details</summary>
Motivation: 解决通用对话系统在育儿领域缺乏个性化、情境化指导的问题；通过引入专业心理学理论来提升模型的可解释性、可操作性与信任度。

Method: 1) 构建0-3岁婴幼儿的 temperament 知识图谱，基于 Thomas-Chess 结构化理论；2) 两阶段训练：先进行监督微调以教授结构化链式推理；3) 应用 GRPO 对齐，强化逻辑一致性、领域专业性与同理心育儿策略；4) 评估框架包括 temperament 敏感的多项选择测试与人工评估。

Result: 模型能够较准确地解读早期儿童 temperament，并主动参与个性化推理与育儿策略推荐；评估表明在逻辑一致性、领域专业性与同理心育儿策略方面有提升。

Conclusion: 将垂直领域建模与心理学理论相结合，促进面向用户的LLM在敏感育儿场景中的主动个性化应用；未来需关注跨文化泛化、隐私与伦理问题，并提升数据透明度与可重复性。

Abstract: This paper presents PediaMind-R1, a domain-specialized large language model designed to achieve active personalization in intelligent parenting scenarios. Unlike conventional systems that provide generic suggestions, PediaMind-R1 draws on insights from developmental psychology. It introduces temperament theory from the Thomas-Chess framework and builds a temperament knowledge graph for infants and toddlers (0-3 years). Our two-stage training pipeline first uses supervised fine-tuning to teach structured chain-of-thought reasoning, and then applies a GRPO-based alignment stage to reinforce logical consistency, domain expertise, and empathetic caregiving strategies. We further design an evaluation framework comprising temperament-sensitive multiple-choice tests and human assessments. The results demonstrate that PediaMind-R1 can accurately interpret early childhood temperament profiles and proactively engage in individualized reasoning. This work highlights the value of integrating vertical-domain modeling with psychological theory. It offers a novel approach to developing user-centered LLMs that advance the practice of active personalization in sensitive caregiving contexts.

</details>


### [13] [Gaming the Answer Matcher: Examining the Impact of Text Manipulation on Automated Judgment](https://arxiv.org/abs/2601.08849)
*Manas Khatore,Sumana Sridharan,Kevork Sulahian,Benjamin J. Smith,Shi Feng*

Main category: cs.CL

TL;DR: 自动化答案匹配对策略性操控鲁棒，二元评分较连续评分更稳健，且在有参考答案时可作为替代人工评估的可行选项。


<details>
  <summary>Details</summary>
Motivation: 解决自由文本回答的规模化评估问题，同时需对抗猜测、啰嗦等操纵以避免对正确性评估的偏见。

Method: 系统性地诱导考生模型生成冗长回答、提供多重答案以及在回答前后嵌入冲突答案等，并比较二元评分与连续评分在不同操纵下的鲁棒性。

Result: 上述操纵未提升分数，甚至常常降低分数；二元评分对攻击更鲁棒于连续评分。

Conclusion: 答案匹配总体对简单文本操控具鲁棒性，在有参考答案时可作为LLM作为评审或人工评估的可行替代方案。

Abstract: Automated answer matching, which leverages LLMs to evaluate free-text responses by comparing them to a reference answer, shows substantial promise as a scalable and aligned alternative to human evaluation. However, its reliability requires robustness against strategic attacks such as guesswork or verbosity that may artificially inflate scores without improving actual correctness. In this work, we systematically investigate whether such tactics deceive answer matching models by prompting examinee models to: (1) generate verbose responses, (2) provide multiple answers when unconfident, and (3) embed conflicting answers with the correct answer near the start of their response. Our results show that these manipulations do not increase scores and often reduce them. Additionally, binary scoring (which requires a matcher to answer with a definitive "correct" or "incorrect") is more robust to attacks than continuous scoring (which requires a matcher to determine partial correctness). These findings show that answer matching is generally robust to inexpensive text manipulation and is a viable alternative to traditional LLM-as-a-judge or human evaluation when reference answers are available.

</details>


### [14] [Más contexto no es mejor. Paradoja de la dilución vectorial en RAG corporativos](https://arxiv.org/abs/2601.08851)
*Alex Dantart*

Main category: cs.CL

TL;DR: 对RAG的Contextualized Chunking通过注入摘要来增强上下文，但引入向量稀释，导致局部信息被冲淡；注入比例呈倒U形关系：中等注入提升召回率约18%，超过临界阈值CIR>0.4时对特定查询的准确率下降约22%；提出计算最优注入比的理论框架。


<details>
  <summary>Details</summary>
Motivation: 解决在RAG中通过注入摘要扩展全局上下文的同时保持局部细节的问题，避免向量稀释导致性能下降

Method: 对多种注入比进行实验评估，比较Recall和Precision；分析CIR（Vector Dilution Threshold）对性能的影响；提出理论框架用于计算最优注入比

Result: 中等注入提高Recall +18%；超过CIR>0.4阈值，特定查询的Precision下降约22%。观察到倒U型曲线

Conclusion: 提出一个理论框架来计算最优注入比，以在RAG中平衡全局上下文和局部信息

Abstract: Técnicas recientes de "Contextualized Chunking" inyectan resúmenes para mejorar el contexto en RAG, pero introducen una "dilución vectorial" que opaca el contenido local. Evaluando distintos ratios de inyección, demostramos una curva en "U invertida": una inyección moderada mejora el "Recall" (+18%), pero superar un umbral crítico (CIR > 0.4) reduce la precisión en un 22% para consultas específicas. Proponemos un marco teórico para calcular el ratio óptimo de inyección. --
  Recent "Contextualized Chunking" techniques inject summaries to improve RAG context but introduce "vector dilution" drowning out local content. Evaluating various injection ratios, we demonstrate an "inverted U" curve: moderate injection boosts Recall (+18%), but exceeding a critical threshold (CIR > 0.4) drops precision by 22% for specific queries. We propose a theoretical framework to calculate the optimal injection ratio.

</details>


### [15] [NewsScope: Schema-Grounded Cross-Domain News Claim Extraction with Open Models](https://arxiv.org/abs/2601.08852)
*Nidhi Pandya*

Main category: cs.CL

TL;DR: NewsScope 是一个跨域的数据集、基准和微调模型，用于按模式约束的新闻主张抽取，显示在跨领域泛化和离线部署方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决自动化新闻核验中需要结构化且符合预定义模式的主张抽取，但现有方法在模式合规性或跨域泛化方面不足。

Method: 构建 NewsScope 数据集（455 篇文章，覆盖政治、健康、科学/环境、商业；395 in-domain、60 out-of-source）；使用 LLaMA 3.1 8B + LoRA 微调，315 个训练示例；在 80 条 in-domain 和 60 条 out-of-source 测试集上评估；对 400 条主张进行人工评估；引入数值锚定过滤器；公开权重模型实现离线部署，成本约 15 美元按需计算。

Result: 人类评估准确度 89.4%（对比 GPT-4o-mini 的 93.7%，p=0.07）， NewsScope 在政治主张上表现更佳（94.3% 对 87.8%）；加入数值锚定过滤后提高至 91.6%，将两者差距缩小至 2.1 个百分点；160 条 claim 的标注者间一致性为 94.6% 的正向一致性；开源模型支持离线部署，成本低，代码和基准公开。

Conclusion: 开放权重模型可离线部署，成本低，研究工作公开发布，便于复现与比较。

Abstract: Automated news verification requires structured claim extraction, but existing approaches either lack schema compliance or generalize poorly across domains. This paper presents NewsScope, a cross-domain dataset, benchmark, and fine-tuned model for schema-grounded news claim extraction. The dataset contains 455 articles across politics, health, science/environment, and business, consisting of 395 in-domain articles and 60 out-of-source articles for generalization testing. LLaMA 3.1 8B was fine-tuned using LoRA on 315 training examples and evaluated on held-out in-domain (80 articles) and out-of-source (60 articles) test sets. Human evaluation on 400 claims shows NewsScope achieves 89.4% human-evaluated accuracy compared to GPT-4o-mini's 93.7% (p=0.07). NewsScope outperforms GPT-4o-mini on political claims (94.3% vs. 87.8%). A numeric grounding filter further improves accuracy to 91.6%, narrowing the gap to 2.1 percentage points. Inter-annotator agreement studies (160 claims) confirm labeling reliability (94.6% positive agreement on SUPPORTED judgments). The open-weight model enables offline deployment at approximately $15 on-demand compute (or $0 on free tiers). Code and benchmark are publicly released.

</details>


### [16] [Evaluating Role-Consistency in LLMs for Counselor Training](https://arxiv.org/abs/2601.08892)
*Eric Rudolph,Natalie Engert,Jens Albrecht*

Main category: cs.CL

TL;DR: 本研究提出对抗性数据集以测试大型语言模型在虚拟咨询场景中的角色一致性与对话连贯性，聚焦 Vicuna 模型并与其他开源模型进行对比。


<details>
  <summary>Details</summary>
Motivation: 在线心理咨询培训日益重要，需确保模型在被赋予特定角色时仍能维持角色设定与对话连贯性，且能抵御对抗性诱导；在 VirCo 的基础上扩展评估与对比。

Method: 基于 VirCo 构建对抗性数据集，评估 Vicuna 与多种开源 LLM 在虚拟客户端互动中的角色一致性与对话连贯性；使用多项评估指标对比当前研究与早期研究结果。

Result: 对 Vicuna 的角色一致性与对话连贯性进行了评估，并与早期研究结果进行比较；不同开源模型在维持角色一致性方面存在差异；对抗性数据集揭示了模型鲁棒性中的不足。

Conclusion: 提出对抗性数据集与评估框架，为评估与提升 LLM 在虚拟咨询训练中的角色一致性提供基线，支持未来模型改进与训练策略的比较分析。

Abstract: The rise of online counseling services has highlighted the need for effective training methods for future counselors. This paper extends research on VirCo, a Virtual Client for Online Counseling, designed to complement traditional role-playing methods in academic training by simulating realistic client interactions. Building on previous work, we introduce a new dataset incorporating adversarial attacks to test the ability of large language models (LLMs) to maintain their assigned roles (role-consistency). The study focuses on evaluating the role consistency and coherence of the Vicuna model's responses, comparing these findings with earlier research. Additionally, we assess and compare various open-source LLMs for their performance in sustaining role consistency during virtual client interactions. Our contributions include creating an adversarial dataset, evaluating conversation coherence and persona consistency, and providing a comparative analysis of different LLMs.

</details>


### [17] [Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models](https://arxiv.org/abs/2601.08955)
*Youwei Liu,Jian Wang,Hanlin Wang,Beichen Guo,Wenjie Li*

Main category: cs.CL

TL;DR: ITP 提出一个 Imagine-then-Plan 框架，通过与学习到的世界模型交互生成多步想象轨迹，结合自适应前瞻长度与部分可观测且可想象的 MDP 来驱动策略学习，包含训练自由与强化学习变体，在多任务基准上显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型多为单步或固定-horizon 评估，导致对复杂任务的前瞻性规划能力未被充分挖掘。需要一个统一框架在不同任务阶段自适应地调整前瞻视野，以提升推理与规划能力。

Method: 在世界模型中进行多步想象，策略模型与世界模型交互产生多步轨迹；引入自适应看前机制，通过权衡最终目标与任务进展实现前瞻长度自适应；想象轨迹用于提供未来后果信号（如进展、冲突）并与当前观测融合，定义部分可观测且可想象的马尔可夫决策过程；提供训练无关（training-free）和基于强化学习的变体；在多任务基准上进行广泛实验。

Result: ITP 显著优于竞争基线，分析表明自适应看前显著提升推理能力，展现对复杂任务的适应性与泛化潜力。

Conclusion: 将想象轨迹与当前观测融合形成的新型推理框架提升了策略学习的前瞻性能力，适用于更广泛的复杂任务场景，且提供了对未来结果的丰富信号。

Abstract: Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (\texttt{ITP}), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with the learned world model, yielding multi-step ``imagined'' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, formulating a partially \textit{observable} and \textit{imaginable} Markov decision process to guide policy learning. We instantiate \texttt{ITP} with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that \texttt{ITP} significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents' reasoning capability, providing valuable insights into addressing broader, complex tasks.

</details>


### [18] [Entropy Sentinel: Continuous LLM Accuracy Monitoring from Decoding Entropy Traces in STEM](https://arxiv.org/abs/2601.09001)
*Pedro Memoli Buffa,Luciano Del Corro*

Main category: cs.CL

TL;DR: Inference-time output-entropy signals can estimate domain-level accuracy under distribution shift, enabling scalable monitoring and targeted data acquisition.


<details>
  <summary>Details</summary>
Motivation: Two coupled challenges in deploying LLMs: monitoring under drift and improving performance by prioritizing data acquisition to close gaps. The work investigates a lightweight, inference-time signal to estimate slice-level accuracy under domain shift.

Method: Compute an output-entropy profile from final-layer next-token probabilities (top-k logprobs) for each response, summarize with eleven statistics, train a lightweight classifier to predict instance correctness, and average predicted probabilities to estimate domain accuracy across domains.

Result: Evaluated on ten STEM reasoning benchmarks with exhaustive train/test compositions across nine LLMs (3B–20B) from six families. Estimates often track held-out benchmark accuracy and show near-monotonic domain ordering for several models. Output-entropy profiles provide an accessible signal for scalable monitoring and data acquisition.

Conclusion: Output-entropy profiles are a practical signal for monitoring model performance under domain drift and for guiding targeted data acquisition to close performance gaps.

Abstract: Deploying LLMs raises two coupled challenges: (1) monitoring - estimating where a model underperforms as traffic and domains drift - and (2) improvement - prioritizing data acquisition to close the largest performance gaps. We test whether an inference-time signal can estimate slice-level accuracy under domain shift. For each response, we compute an output-entropy profile from final-layer next-token probabilities (from top-k logprobs) and summarize it with eleven statistics. A lightweight classifier predicts instance correctness, and averaging predicted probabilities yields a domain-level accuracy estimate. We evaluate on ten STEM reasoning benchmarks with exhaustive train/test compositions (k in {1,2,3,4}; all "10 choose k" combinations), across nine LLMs from six families (3B-20B). Estimates often track held-out benchmark accuracy, and several models show near-monotonic ordering of domains. Output-entropy profiles are thus an accessible signal for scalable monitoring and for targeting data acquisition.

</details>


### [19] [TranslateGemma Technical Report](https://arxiv.org/abs/2601.09012)
*Mara Finkelstein,Isaac Caswell,Tobias Domhan,Jan-Thorsten Peter,Juraj Juraska,Parker Riley,Daniel Deutsch,Cole Dilanni,Colin Cherry,Eleftheria Briakou,Elizabeth Nielsen,Jiaming Luo,Kat Black,Ryan Mullins,Sweta Agrawal,Wenda Xu,Erin Kats,Stephane Jaskiewicz,Markus Freitag,David Vilar*

Main category: cs.CL

TL;DR: TranslateGemma 在 Gemma 3 基础上通过两阶段微调与强化学习，显著提升多语言机器翻译性能，同时保持与增强多模态能力，小模型也具备较高效率，开放发布。


<details>
  <summary>Details</summary>
Motivation: 提升 Gemma 3 的跨语言翻译能力与效率，结合高质量合成平行数据、人工数据与奖励模型驱动的强化学习，追求更高翻译质量与通用性。

Method: 两阶段微调：1) 监督微调，利用高质量大规模合成平行数据与人工翻译数据；2) 强化学习阶段，使用 MetricX-QE、AutoMQM 等奖励模型的集合优化翻译质量；评估覆盖 WMT25（10 语言对）和 WMT24++（55 语言对），并测试多模态能力。

Result: 自动评估指标在所有规模上相较基线 Gemma 3 显著提升；较小的 TranslateGemma 模型常接近甚至超越更大基线模型，且在 Vistra 图像翻译基准上有提升；人类评估在 WMT25 上验证有效性；模型实现对外开放发布。

Conclusion: TranslateGemma 提供强大且可扩展的开源 MT 工具，兼具高翻译质量与多模态能力，并在不同规模上实现更高效率，利于研究社区的发展。

Abstract: We present TranslateGemma, a suite of open machine translation models based on the Gemma 3 foundation models. To enhance the inherent multilingual capabilities of Gemma 3 for the translation task, we employ a two-stage fine-tuning process. First, supervised fine-tuning is performed using a rich mixture of high-quality large-scale synthetic parallel data generated via state-of-the-art models and human-translated parallel data. This is followed by a reinforcement learning phase, where we optimize translation quality using an ensemble of reward models, including MetricX-QE and AutoMQM, targeting translation quality. We demonstrate the effectiveness of TranslateGemma with human evaluation on the WMT25 test set across 10 language pairs and with automatic evaluation on the WMT24++ benchmark across 55 language pairs. Automatic metrics show consistent and substantial gains over the baseline Gemma 3 models across all sizes. Notably, smaller TranslateGemma models often achieve performance comparable to larger baseline models, offering improved efficiency. We also show that TranslateGemma models retain strong multimodal capabilities, with enhanced performance on the Vistra image translation benchmark. The release of the open TranslateGemma models aims to provide the research community with powerful and adaptable tools for machine translation.

</details>


### [20] [Multicultural Spyfall: Assessing LLMs through Dynamic Multilingual Social Deduction Game](https://arxiv.org/abs/2601.09017)
*Haryo Akbarianto Wibowo,Alaa Elsetohy,Qinrong Cui,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 提出以 Spyfall 为基础的动态基准测试 framework，用于评估多语言和跨文化能力，发现与 Chatbot Arena 的排名相关，但在非英语场景存在显著差距，且具备可扩展、抗数据泄露及具文化细化特征的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有静态基准容易导致数据饱和与信息泄露，难以全面评估模型的策略对话、跨文化与语言适应能力，亟需一种可扩展、抗泄露且具文化敏感性的动态基准。

Method: 采用社交推理游戏 Spyfall 作为评估框架。模型需通过策略性对话来识别秘密特工或避免被识别，使用具有文化相关性的地点或地方美食等线索进行互动，评估在不同语言中的规则遵循、策略性与实体本地化能力。

Result: 实验结果显示，基于游戏的排名与 Chatbot Arena 的排名高度一致，但在非英语场景中普遍存在性能差距：模型在处理本地化实体和跨语言的规则遵循/策略完整性方面较弱。该方法具有可扩展、抗泄露、对文化差异更具敏感性的优势，可作为传统 NLP 基准的替代。

Conclusion: 基于游戏的评估为 NLP 基准提供了可扩展、抗泄露且文化细化的替代方案，能够更好地捕捉跨语言与跨文化的能力差异。相关数据集及历史记录可在 HuggingFace 的文化 Spyfall 数据集中获取。

Abstract: The rapid advancement of Large Language Models (LLMs) has necessitated more robust evaluation methods that go beyond static benchmarks, which are increasingly prone to data saturation and leakage. In this paper, we propose a dynamic benchmarking framework for evaluating multilingual and multicultural capabilities through the social deduction game Spyfall. In our setup, models must engage in strategic dialogue to either identify a secret agent or avoid detection, utilizing culturally relevant locations or local foods. Our results show that our game-based rankings align closely with the Chatbot Arena. However, we find a significant performance gap in non-English contexts: models are generally less proficient when handling locally specific entities and often struggle with rule-following or strategic integrity in non-English languages. We demonstrate that this game-based approach provides a scalable, leakage-resistant, and culturally nuanced alternative to traditional NLP benchmarks. The game history can be accessed here https://huggingface.co/datasets/haryoaw/cultural-spyfall.

</details>


### [21] [Can LLMs interpret figurative language as humans do?: surface-level vs representational similarity](https://arxiv.org/abs/2601.09041)
*Samhita Bollepally,Aurora Sloman-Moll,Takashi Yamauchi*

Main category: cs.CL

TL;DR: LLMs show surface alignment with human judgments on interpreting language but diverge in deeper representational understanding for figurative and socio-pragmatic language; GPT-4 best among tested models, yet all struggle with idioms, slang, and sarcasm.


<details>
  <summary>Details</summary>
Motivation: Evaluate how instruction-tuned LLMs align with human judgments in interpreting figurative and socially grounded language and identify limitations across model sizes.

Method: Experiment with 240 dialogue-based sentences across six traits (conventionality, sarcasm, funny, emotional, idiomacy, slang). Each sentence paired with 40 interpretive questions. Humans and four LLMs (GPT-4, Gemma-2-9B, Llama-3.2, Mistral-7B) rated on a 10-point Likert scale. Analyze surface-level vs representational-level alignment.

Result: Humans and LLMs align superficially but diverge at the representational level, especially for idioms and Gen Z slang. GPT-4 most closely mirrors human representational patterns; all models struggle with context-dependent and socio-pragmatic expressions like sarcasm, slang, and idiomacy.

Conclusion: LLMs exhibit partial alignment with human judgments, with GPT-4 leading but still limited in handling figurative and socio-pragmatic language; highlights need for improvements in context sensitivity and social pragmatics.

Abstract: Large language models generate judgments that resemble those of humans. Yet the extent to which these models align with human judgments in interpreting figurative and socially grounded language remains uncertain. To investigate this, human participants and four instruction-tuned LLMs of different sizes (GPT-4, Gemma-2-9B, Llama-3.2, and Mistral-7B) rated 240 dialogue-based sentences representing six linguistic traits: conventionality, sarcasm, funny, emotional, idiomacy, and slang. Each of the 240 sentences was paired with 40 interpretive questions, and both humans and LLMs rated these sentences on a 10-point Likert scale. Results indicated that humans and LLMs aligned at the surface level with humans, but diverged significantly at the representational level, especially in interpreting figurative sentences involving idioms and Gen Z slang. GPT-4 most closely approximates human representational patterns, while all models struggle with context-dependent and socio-pragmatic expressions like sarcasm, slang, and idiomacy.

</details>


### [22] [Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers](https://arxiv.org/abs/2601.09049)
*Kaiyu He,Zhang Mian,Peilin Wu,Xinya Du,Zhiyu Chen*

Main category: cs.CL

TL;DR: Grokking in parameter-sharing transformers forms a Generalization Circuit, but this circuit does not equate to a new reasoning paradigm; transferability remains limited and high unseen accuracy can arise independently of grokking under certain data regimes.


<details>
  <summary>Details</summary>
Motivation: Investigate whether grokked models outperform non-grokked ones on downstream tasks and whether the computational cost of grokking is justified, by mechanistically examining the Generalization Circuit and knowledge integration.

Method: Empirical/mechanistic analysis comparing inference paths of grokked vs non-grokked models on in-distribution compositional queries, testing their ability to transfer when integrating new knowledge, and exploring the relationship between prolonged training, memory integration, and generalization to unseen cases.

Result: (i) Inference paths for grokked and non-grokked models on in-distribution queries are identical, suggesting grokking does not signal a new reasoning paradigm but integrates memorized atomic facts into existing paths. (ii) High accuracy on unseen cases after long training and the emergence of a particular reasoning path can occur independently under certain data regimes. (iii) Even a mature circuit has limited transferability when integrating new knowledge, so grokked transformers do not achieve full mastery of compositional logic.

Conclusion: Grokking reflects memorized facts merged into established reasoning paths rather than a wholesale acquisition of new reasoning; transferability remains constrained, implying that waiting for grokking may be insufficient for robust compositional generalization and alternative methods are needed.

Abstract: While Large Language Models (LLMs) excel at factual retrieval, they often struggle with the "curse of two-hop reasoning" in compositional tasks. Recent research suggests that parameter-sharing transformers can bridge this gap by forming a "Generalization Circuit" during a prolonged "grokking" phase. A fundamental question arises: Is a grokked model superior to its non-grokked counterparts on downstream tasks? Furthermore, is the extensive computational cost of waiting for the grokking phase worthwhile? In this work, we conduct a mechanistic study to evaluate the Generalization Circuit's role in knowledge assimilation and transfer. We demonstrate that: (i) The inference paths established by non-grokked and grokked models for in-distribution compositional queries are identical. This suggests that the "Generalization Circuit" does not represent the sudden acquisition of a new reasoning paradigm. Instead, we argue that grokking is the process of integrating memorized atomic facts into an naturally established reasoning path. (ii) Achieving high accuracy on unseen cases after prolonged training and the formation of a certain reasoning path are not bound; they can occur independently under specific data regimes. (iii) Even a mature circuit exhibits limited transferability when integrating new knowledge, suggesting that "grokked" Transformers do not achieve a full mastery of compositional logic.

</details>


### [23] [SITA: Learning Speaker-Invariant and Tone-Aware Speech Representations for Low-Resource Tonal Languages](https://arxiv.org/abs/2601.09050)
*Tianyi Xu,Xuan Ouyang,Binwei Yao,Shoua Xiong,Sara Misurelli,Maichou Lor,Junjie Hu*

Main category: cs.CL

TL;DR: 提出 SITA，一种轻量化的自适应训练方案， aims to使预训练 wav2vec 风格编码器对性别变化不敏感且保留音调信息，用于低资源音调语言；在 Hmong 上提升跨性别词汇检索并保持 ASR 精度，且对 Mandarin 也有同样的提升。


<details>
  <summary>Details</summary>
Motivation: 低资源且高度音调化的语言在现代语音技术中未得到充分支持，需学习鲁棒且音调敏感的表示；现有多语言编码器常对音调表示不足，同时对性别等干扰变量敏感。

Method: 采用 SITA 的分阶段多目标训练： (i) 跨性别对比学习，以实现跨说话者的词汇一致性；同时引入音调排斥损失，显式分离同词不同音调的表征以防止音调崩溃； (ii) 引入以 CTC 为基础的辅助 ASR 目标并进行蒸馏，以稳定识别相关结构；在预训练 wav2vec 风格编码器上进行微调。

Result: 在有 curated 的 Hmong 词汇语料上，SITA 提高跨性别的词汇检索准确性，同时相对一个基于 XLS-R 的教师模型保持可用的 ASR 准确度；将同样的方案迁移到 Mandarin 时也获得类似增益，表明该方法具有对音调语言的通用性和可插拔性。

Conclusion: SITA 提供一种通用的、可插拔的适应性训练范式，用于将多语言语音编码器定制为对音调语言友好且对性别等干扰因素鲁棒的表示，适用于低资源语言场景。

Abstract: Tonal low-resource languages are widely spoken yet remain underserved by modern speech technology. A key challenge is learning representations that are robust to nuisance variation such as gender while remaining tone-aware for different lexical meanings. To address this, we propose SITA, a lightweight adaptation recipe that enforces Speaker-Invariance and Tone-Awareness for pretrained wav2vec-style encoders. SITA uses staged multi-objective training: (i) a cross-gender contrastive objective encourages lexical consistency across speakers, while a tone-repulsive loss prevents tone collapse by explicitly separating same-word different-tone realizations; and (ii) an auxiliary Connectionist Temporal Classification (CTC)-based ASR objective with distillation stabilizes recognition-relevant structure. We evaluate primarily on Hmong, a highly tonal and severely under-resourced language where off-the-shelf multilingual encoders fail to represent tone effectively. On a curated Hmong word corpus, SITA improves cross-gender lexical retrieval accuracy, while maintaining usable ASR accuracy relative to an ASR-adapted XLS-R teacher. We further observe similar gains when transferring the same recipe to Mandarin, suggesting SITA is a general, plug-in approach for adapting multilingual speech encoders to tonal languages.

</details>


### [24] [Efficient Multilingual Dialogue Processing via Translation Pipelines and Distilled Language Models](https://arxiv.org/abs/2601.09059)
*Santiago Martínez Novoa,Nicolás Rozo Fajardo,Diego Alejandro González Vargas,Nicolás Bedoya Figueroa*

Main category: cs.CL

TL;DR: 提出一个三阶段的翻译驱动跨语言对话摘要与问答系统，使用2.55B参数蒸馏模型进行多任务文本生成，并通过翻译-再翻译策略在九种Indic语言上实现竞争性性能， Marathi、Tamil、Hindi的QnA表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 在健康领域的跨语言信息获取中，低资源语言缺乏任务微调所需的对齐数据。通过翻译与知识蒸馏的组合，利用紧凑模型在多语言环境下实现高效且可扩展的问答与摘要能力。

Method: 三阶段流程：1) Indic语言→英语的前向翻译；2) 使用2.55B参数的蒸馏模型进行多任务文本生成；3) 将结果翻译回源语言。并结合知识蒸馏提升模型紧凑性与泛化。

Result: 在九种语言上获得强势表现，尤其 Marathi 86.7% QnA、Tamil 86.7% QnA、Hindi 80.0% QnA，显示翻译驱动方法在低资源语言上的有效性，且无需针对特定任务进行微调。

Conclusion: 翻译驱动的多任务学习结合知识蒸馏策略能够让紧凑模型在低资源语言上达到接近任务微调的性能，适用于大规模跨语言健康对话摘要与问答任务。

Abstract: This paper presents team Kl33n3x's multilingual dialogue summarization and question answering system developed for the NLPAI4Health 2025 shared task. The approach employs a three-stage pipeline: forward translation from Indic languages to English, multitask text generation using a 2.55B parameter distilled language model, and reverse translation back to source languages. By leveraging knowledge distillation techniques, this work demonstrates that compact models can achieve highly competitive performance across nine languages. The system achieved strong win rates across the competition's tasks, with particularly robust performance on Marathi (86.7% QnA), Tamil (86.7% QnA), and Hindi (80.0% QnA), demonstrating the effectiveness of translation-based approaches for low-resource language processing without task-specific fine-tuning.

</details>


### [25] [Beyond Consensus: Perspectivist Modeling and Evaluation of Annotator Disagreement in NLP](https://arxiv.org/abs/2601.09065)
*Yinuo Xu,David Jurgens*

Main category: cs.CL

TL;DR: 本综述将争议感知NLP视为有价值信号，提出从数据、任务、标注者因素的源头出发的领域无关分类；并给出统一的以预测目标和 pooling 结构为框架的建模范式，强调从单纯达成共识到显式建模争议以及标注者关系的结构化建模。


<details>
  <summary>Details</summary>
Motivation:  annotator disagreement 在主观性与歧义任务中广泛存在，早期将其视作噪声，近来逐步被视为反映解释差异的有意义信号，需要统一的分析框架。

Method: 提出领域无关的争议源头分类（数据、任务、标注者），并在一个以预测目标和 pooling 结构为核心的通用框架下整合建模方法；对评估指标进行梳理；讨论公平性评估多为描述性而非规范性；总结开放挑战与未来方向。

Result: 提供一个统一的争议感知NLP视角，显示从以共识为目标转向显式建模争议和标注者之间关系的趋势；整理了评估指标并对当前实践的局限性给出见解。

Conclusion: 未来方向包括整合多源变异、发展争议感知的可解释性框架，以及在Perspectivist建模下权衡实际应用的折中。

Abstract: Annotator disagreement is widespread in NLP, particularly for subjective and ambiguous tasks such as toxicity detection and stance analysis. While early approaches treated disagreement as noise to be removed, recent work increasingly models it as a meaningful signal reflecting variation in interpretation and perspective. This survey provides a unified view of disagreement-aware NLP methods. We first present a domain-agnostic taxonomy of the sources of disagreement spanning data, task, and annotator factors. We then synthesize modeling approaches using a common framework defined by prediction targets and pooling structure, highlighting a shift from consensus learning toward explicitly modeling disagreement, and toward capturing structured relationships among annotators. We review evaluation metrics for both predictive performance and annotator behavior, and noting that most fairness evaluations remain descriptive rather than normative. We conclude by identifying open challenges and future directions, including integrating multiple sources of variation, developing disagreement-aware interpretability frameworks, and grappling with the practical tradeoffs of perspectivist modeling.

</details>


### [26] [Mi:dm 2.0 Korea-centric Bilingual Language Models](https://arxiv.org/abs/2601.09066)
*Donghoon Shin,Sejung Lee,Soonmin Bae,Hwijung Ryu,Changwon Ok,Hoyoun Jung,Hyesung Ji,Jeehyun Lim,Jehoon Lee,Ji-Eun Han,Jisoo Baik,Mihyeon Kim,Riwoo Chung,Seongmin Lee,Wonjae Park,Yoonseok Heo,Youngkyung Seo,Seyoun Won,Boeun Kim,Cheolhun Heo,Eunkyeong Lee,Honghee Lee,Hyeongju Ju,Hyeontae Seo,Jeongyong Shim,Jisoo Lee,Junseok Koh,Junwoo Kim,Minho Lee,Minji Kang,Minju Kim,Sangha Nam,Seongheum Park,Taehyeong Kim,Euijai Ahn,Hong Seok Jeung,Jisu Shin,Jiyeon Kim,Seonyeong Song,Seung Hyun Kong,Sukjin Hong,Taeyang Yun,Yu-Seon Kim,A-Hyun Lee,Chae-Jeong Lee,Hye-Won Yu,Ji-Hyun Ahn,Song-Yeon Kim,Sun-Woo Jung,Eunju Kim,Eunji Ha,Jinwoo Baek,Yun-ji Lee,Wanjin Park,Jeong Yeop Kim,Eun Mi Kim,Hyoung Jun Park,Jung Won Yoon,Min Sung Noh,Myung Gyo Oh,Wongyoung Lee,Yun Jin Park,Young S. Kwon,Hyun Keun Kim,Jieun Lee,YeoJoo Park*

Main category: cs.CL

TL;DR: Mi:dm 2.0 系列为 KT 推出的韩国本地化大语言模型（11.5B Base 与 2.3B Mini），通过高质量数据和韩国文化对齐实现良好零-shot和多任务性能，MIT 许可，面向韩国产业、公共服务和教育。


<details>
  <summary>Details</summary>
Motivation: 解决现有 LLM 在韩国语数据稀缺、文化对齐不足、以及应用场景适配等方面的短板，推动 K-intelligence 的发展。

Method: 建立数据清洗、合成数据、课程式数据混合、韩国优化分词器的完整数据与模型开发管线；采用深度扩展的 Base 配置与资源受限场景的 Mini 配置；在 KMMLU 等基准上实现领先表现；公开可用。

Result: 在韩国特定基准上达到 state-of-the-art，KMMLU 零-shot上表现突出，内部评估覆盖语言、 humanities、社会科学等任务；公开发布，模型在 HuggingFace 上可用。

Conclusion: 通过高质量数据、文化对齐和两种规模的模型，KT 旨在推动韩国行业、公共服务与教育的 AI 采用，促进本地 AI 社群的发展，并为 K-intelligence 的愿景奠定基础。

Abstract: We introduce Mi:dm 2.0, a bilingual large language model (LLM) specifically engineered to advance Korea-centric AI. This model goes beyond Korean text processing by integrating the values, reasoning patterns, and commonsense knowledge inherent to Korean society, enabling nuanced understanding of cultural contexts, emotional subtleties, and real-world scenarios to generate reliable and culturally appropriate responses. To address limitations of existing LLMs, often caused by insufficient or low-quality Korean data and lack of cultural alignment, Mi:dm 2.0 emphasizes robust data quality through a comprehensive pipeline that includes proprietary data cleansing, high-quality synthetic data generation, strategic data mixing with curriculum learning, and a custom Korean-optimized tokenizer to improve efficiency and coverage. To realize this vision, we offer two complementary configurations: Mi:dm 2.0 Base (11.5B parameters), built with a depth-up scaling strategy for general-purpose use, and Mi:dm 2.0 Mini (2.3B parameters), optimized for resource-constrained environments and specialized tasks. Mi:dm 2.0 achieves state-of-the-art performance on Korean-specific benchmarks, with top-tier zero-shot results on KMMLU and strong internal evaluation results across language, humanities, and social science tasks. The Mi:dm 2.0 lineup is released under the MIT license to support extensive research and commercial use. By offering accessible and high-performance Korea-centric LLMs, KT aims to accelerate AI adoption across Korean industries, public services, and education, strengthen the Korean AI developer community, and lay the groundwork for the broader vision of K-intelligence. Our models are available at https://huggingface.co/K-intelligence. For technical inquiries, please contact midm-llm@kt.com.

</details>


### [27] [From Symbolic to Natural-Language Relations: Rethinking Knowledge Graph Construction in the Era of Large Language Models](https://arxiv.org/abs/2601.09069)
*Kanyao Han,Yushang Lai*

Main category: cs.CL

TL;DR: 主张将知识图谱中的关系从符号标签转为自然语言描述，并在保留最小结构骨架的前提下提出混合设计原则以实现更灵活的上下文感知关系表示。


<details>
  <summary>Details</summary>
Motivation: 现实世界的关系具有上下文性、细微性和不确定性，离散符号化关系造成信息丢失；LLMs的崛起促使以自然语言形式表达知识，并通过提示推理更偏好自由文本；因此需要重新设计关系表示，而不仅仅是更高效填充现有符号 schemas。

Method: 提出混合设计原则，保留最小结构化骨架，同时引入以自然语言描述的关系、可上下文感知的表示，以及与传统符号化接口的兼容性。

Result: 作为一份定位性论文，给出理论论证和设计原则，未给出大量实验结果；强调从符号到自然语言描述的关系表示的可行性与潜在优势。

Conclusion: 自然语言描述的关系与结构骨架的结合，能更好地契合LLMs的推理和知识获取模式，利于未来的可扩展和上下文敏感的知识图谱设计。

Abstract: Knowledge graphs (KGs) have commonly been constructed using predefined symbolic relation schemas, typically implemented as categorical relation labels. This design has notable shortcomings: real-world relations are often contextual, nuanced, and sometimes uncertain, and compressing it into discrete relation labels abstracts away critical semantic detail. Nevertheless, symbolic-relation KGs remain widely used because they have been operationally effective and broadly compatible with pre-LLM downstream models and algorithms, in which KG knowledge could be retrieved or encoded into quantified features and embeddings at scale. The emergence of LLMs has reshaped how knowledge is created and consumed. LLMs support scalable synthesis of domain facts directly in concise natural language, and prompting-based inference favors context-rich free-form text over quantified representations. This position paper argues that these changes call for rethinking the representation of relations themselves rather than merely using LLMs to populate conventional schemas more efficiently. We therefore advocate moving from symbolic to natural-language relation descriptions, and we propose hybrid design principles that preserve a minimal structural backbone while enabling more flexible and context-sensitive relational representations.

</details>


### [28] [How Many Human Judgments Are Enough? Feasibility Limits of Human Preference Evaluation](https://arxiv.org/abs/2601.09084)
*Wilson Y. Lee*

Main category: cs.CL

TL;DR: 当偏好信号在提示跨域扩散时，按比例分配样本量在统计性上是极小-极大（minimax）最优的；大多数比较处于扩散状态，需远多于常见的判断次数才能检测到小幅改进；经过精心设计的基准可以通过降低提示变异约1.5倍提升检测能力；许多无效或负向评估往往来自样本不足而非模型等价性，因此评估设计需显式考虑效应大小、预算与协议。


<details>
  <summary>Details</summary>
Motivation: 量化需要多少人类判断才能可靠地检测小幅改进，并理解评估设计对可检测性的影响。

Method: 理论分析在信号扩散条件下给出最优分配（minimax），并对大规模人类偏好数据集（覆盖聊天、图像生成、带执行反馈的代码生成等）进行实证分析，比较普通与“经手工筛选/控变量”的基准在偏好边际和方差上的差异。

Result: 在扩散信号 regime 中，任意分配策略都无法显著提升可检测性；大多数比较的边际优势很小，需要的判断数远超常规样本量；经过精心设计的基准能降低提示层方差约1.5倍，从而提高检测能力。

Conclusion: 结论通常由功效不足导致的无效评估所致，请在设计中明确考虑效应大小、预算和评测协议，以避免错误地认为模型之间无差异。

Abstract: Human preference evaluations are widely used to compare generative models, yet it remains unclear how many judgments are required to reliably detect small improvements. We show that when preference signal is diffuse across prompts (i.e., all prompt types are similarly informative), proportional allocation is minimax-optimal: no allocation strategy substantially improves detectability. Empirical analysis of large-scale human preference datasets shows that most comparisons fall into this diffuse regime, exhibiting small preference margins that require far more judgments than typically collected, even in well-sampled comparisons. These limits persist across evaluation protocols and modalities, including chat, image generation, and code generation with execution feedback. In contrast, curated benchmarks that reduce prompt induced variability systematically induce larger margins and improve detectability through a $1.5\times$ reduction in prompt-level variance. Our results show that inconclusive or negative human evaluation outcomes frequently reflect underpowered evaluation rather than model equivalence, underscoring the need to account explicitly for effect size, budget, and protocol design.

</details>


### [29] [SubTokenTest: A Practical Benchmark for Real-World Sub-token Understanding](https://arxiv.org/abs/2601.09089)
*Shuyang Hou,Yi Hu,Muhan Zhang*

Main category: cs.CL

TL;DR: SubTokenTest 是一个用于评估大语言模型子标记理解能力的综合基准，覆盖十项任务、四个领域，揭示分词导致的子标记失败，并考察测试阶段的规模扩展对性能的影响，以及隐藏状态中字符信息的编码模式。


<details>
  <summary>Details</summary>
Motivation: 现有模型的分词机制在子标记层面存在局限，影响在文本地图、结构化表格等现实应用中的精确理解。需要一个聚焦子标记理解的实用基准来分离子标记推理与高阶推理的干扰。

Method: 设计 SubTokenTest，包含十项任务，覆盖四个领域，尽量与实际应用相关且在实现上将子标记推理与复杂推理解耦；对九种先进的 LLM 进行评估；研究测试时扩大输入规模对子标记推理的影响；通过对隐藏状态的分析，探究字符级信息的编码方式。

Result: 对九种高级 LLM 的全面评估显示，不同模型在子标记理解上存在显著差异，测试时扩展对性能有一定提升，且隐藏层表征中存在可观的字符级信息编码模式，但分词相关的失误仍然制约现实场景的应用。

Conclusion: SubTokenTest 为诊断和改进 LLM 的子标记理解提供了一个实用工具，强调需要改进分词策略或子标记表征以提升在现实任务中的鲁棒性；未来工作可在模型架构、训练数据和评估方法等方面进一步深化。

Abstract: Recent advancements in large language models (LLMs) have significantly enhanced their reasoning capabilities. However, they continue to struggle with basic character-level tasks, such as counting letters in words, a problem rooted in their tokenization process. While existing benchmarks have highlighted this weakness through basic character operations, such failures are often dismissed due to lacking practical relevance. Yet, many real-world applications, such as navigating text-based maps or interpreting structured tables, rely heavily on precise sub-token understanding. In this regard, we introduce SubTokenTest, a comprehensive benchmark that assesses sub-token understanding through practical, utility-driven tasks. Our benchmark includes ten tasks across four domains and isolates tokenization-related failures by decoupling performance from complex reasoning. We provide a comprehensive evaluation of nine advanced LLMs. Additionally, we investigate the impact of test-time scaling on sub-token reasoning and explore how character-level information is encoded within the hidden states.

</details>


### [30] [Contrastive Bi-Encoder Models for Multi-Label Skill Extraction: Enhancing ESCO Ontology Matching with BERT and Attention Mechanisms](https://arxiv.org/abs/2601.09119)
*Yongming Sun*

Main category: cs.CL

TL;DR: 提出一个零样本技能提取框架：以LLM从ESCO定义合成训练数据，基于ESCO二级类别进行层级约束的多技能生成，使用对比式双编码器在共享嵌入空间对齐工作广告句子与技能描述，外加RoBERTa二分类过滤提升精确度；在中文零样本任务中实现F1@5=0.72，优于TF-IDF和标准BERT，具可扩展性与数据高效性。


<details>
  <summary>Details</summary>
Motivation: 高精度将非结构化工作广告映射到标准技能本体（如ESCO）是扩展多标签分类（XMLC）的问题，但监督数据稀缺且成本高，尤其在非英语环境中广告语言与正式技能定义差异显著，需要零样本或低资源的解决方案。

Method: （1）利用大语言模型从ESCO定义中合成训练样本；（2）基于ESCO Level-2类别进行层级约束的多技能生成，以提升语义一致性；（3）在合成语料上训练对比式双编码器，将工作广告句子与ESCO技能描述映射到共同嵌入空间，编码器对BERT进行BiLSTM和注意力池化改造以更好处理冗长信息丰富的需求陈述；（4）引入基于RoBERTa的上游二分类筛选，剔除非技能句子以提升端到端精度。

Result: 实验证据表明：层级约束的生成在流畅性与判别性方面优于无约束的配对；所构建的多标签模型在真实中文工作广告上的零样本迁移效果良好，达到F1@5=0.72，并优于TF-IDF和标准BERT基线。

Conclusion: 提出的流水线为劳动经济与人力资本分析中的技能编码提供可扩展且数据高效的解决路径，尤其在跨语言、低资源场景下的自动化技能提取具有实际应用潜力。

Abstract: Fine-grained labor market analysis increasingly relies on mapping unstructured job advertisements to standardized skill taxonomies such as ESCO. This mapping is naturally formulated as an Extreme Multi-Label Classification (XMLC) problem, but supervised solutions are constrained by the scarcity and cost of large-scale, taxonomy-aligned annotations--especially in non-English settings where job-ad language diverges substantially from formal skill definitions. We propose a zero-shot skill extraction framework that eliminates the need for manually labeled job-ad training data. The framework uses a Large Language Model (LLM) to synthesize training instances from ESCO definitions, and introduces hierarchically constrained multi-skill generation based on ESCO Level-2 categories to improve semantic coherence in multi-label contexts. On top of the synthetic corpus, we train a contrastive bi-encoder that aligns job-ad sentences with ESCO skill descriptions in a shared embedding space; the encoder augments a BERT backbone with BiLSTM and attention pooling to better model long, information-dense requirement statements. An upstream RoBERTa-based binary filter removes non-skill sentences to improve end-to-end precision. Experiments show that (i) hierarchy-conditioned generation improves both fluency and discriminability relative to unconstrained pairing, and (ii) the resulting multi-label model transfers effectively to real-world Chinese job advertisements, achieving strong zero-shot retrieval performance (F1@5 = 0.72) and outperforming TF--IDF and standard BERT baselines. Overall, the proposed pipeline provides a scalable, data-efficient pathway for automated skill coding in labor economics and workforce analytics.

</details>


### [31] [Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment](https://arxiv.org/abs/2601.09120)
*Chen-Wei Liang,Bin Guo,Zhen-Yuan Wei,Mu-Jiang-Shan Wang*

Main category: cs.CL

TL;DR: 一个三阶段的专利权利要求生成框架，解决跨司法区域泛化、语义关系建模和质量评估问题，通过关系感知相似性分析、领域自适应权利要求生成和统一质量评估，显著提升与基准的各项指标。


<details>
  <summary>Details</summary>
Motivation: 现有专利权利要求生成系统在跨司法区域泛化、与现有文献/前案之间的语义关系建模，以及对生成质量的可靠评估方面存在不足，需要一个能够跨域自适应、关系建模与统一评估的综合框架。

Method: 提出三阶段框架：1) 关系感知的相似性分析，使用八个专门头的多头注意力进行显式关系建模；2) 领域自适应的权利要求生成，采用课程学习和跨五个专利领域的动态LoRA适配器选择；3) 统一的质量评估，在评估维度之间引入跨注意力实现综合评价。数据集：USPTO HUPD、EPO、Patent-CE基准。

Result: 在多个数据集上取得显著提升：相较GPT-4o，ROUGE-L提升7.6点；相较Llama-3.1-8B，BERTScore提升8.3%；与人类专家的相关性提升为0.847（优于前0.623的独立评估模型）。跨司法区域性能保持率为89.4%，高于基线的76.2%。

Conclusion: 所提出框架为自动化专利起诉工作流提供了一个综合解决方案，提高跨域泛化、语义关系建模和质量评估的一致性与可靠性。

Abstract: Current patent claim generation systems face three fundamental limitations: poor cross-jurisdictional generalization, inadequate semantic relationship modeling between claims and prior art, and unreliable quality assessment. We introduce a novel three-stage framework that addresses these challenges through relationship-aware similarity analysis, domain-adaptive claim generation, and unified quality assessment. Our approach employs multi-head attention with eight specialized heads for explicit relationship modeling, integrates curriculum learning with dynamic LoRA adapter selection across five patent domains, and implements cross-attention mechanisms between evaluation aspects for comprehensive quality assessment. Extensive experiments on USPTO HUPD dataset, EPO patent collections, and Patent-CE benchmark demonstrate substantial improvements: 7.6-point ROUGE-L gain over GPT-4o, 8.3\% BERTScore enhancement over Llama-3.1-8B, and 0.847 correlation with human experts compared to 0.623 for separate evaluation models. Our method maintains 89.4\% cross-jurisdictional performance retention versus 76.2\% for baselines, establishing a comprehensive solution for automated patent prosecution workflows.

</details>


### [32] [Identity-Robust Language Model Generation via Content Integrity Preservation](https://arxiv.org/abs/2601.09141)
*Miao Zhang,Kelly Chen,Md Mehrab Tanjim,Rumi Chunara*

Main category: cs.CL

TL;DR: 提出一个训练-free的身份鲁棒生成框架，能在保留语义要素的同时中和非关键身份信息，从而显著降低因用户身份线索引发的核心输出质量下降。


<details>
  <summary>Details</summary>
Motivation: LLMs的输出在不同社会人口属性下存在差异，影响准确性、实用性与安全性，需解决身份信息对核心生成质量的负面影响，而非单纯关注刻板印象或表征偏差。

Method: 一个轻量级、无需额外训练的框架，通过选择性中和非关键身份信息来实现身份鲁棒性，同时保留语义关键属性；在四个基准和18种身份上评估。

Result: 平均降低77%的身份相关偏差，相较于未改动的提示，且比基于提示的防御降低45%。

Conclusion: 填补了在提示层面上减轻身份线索对核心生成质量影响的研究空缺，提供无训练成本的身份鲁棒生成方案。

Abstract: Large Language Model (LLM) outputs often vary across user sociodemographic attributes, leading to disparities in factual accuracy, utility, and safety, even for objective questions where demographic information is irrelevant. Unlike prior work on stereotypical or representational bias, this paper studies identity-dependent degradation of core response quality. We show empirically that such degradation arises from biased generation behavior, despite factual knowledge being robustly encoded across identities. Motivated by this mismatch, we propose a lightweight, training-free framework for identity-robust generation that selectively neutralizes non-critical identity information while preserving semantically essential attributes, thus maintaining output content integrity. Experiments across four benchmarks and 18 sociodemographic identities demonstrate an average 77% reduction in identity-dependent bias compared to vanilla prompting and a 45% reduction relative to prompt-based defenses. Our work addresses a critical gap in mitigating the impact of user identity cues in prompts on core generation quality.

</details>


### [33] [OrthoGeoLoRA: Geometric Parameter-Efficient Fine-Tuning for Structured Social Science Concept Retrieval on theWeb](https://arxiv.org/abs/2601.09185)
*Zeqiang Wang,Xinyue Wu,Chenxi Li,Zixi Chen,Nishanth Sastry,Jon Johnson,Suparna De*

Main category: cs.CL

TL;DR: OrthoGeoLoRA 将 LoRA 的低秩更新限制为正交分量形式，解决 gauge 自由度、尺度歧义和秩崩溃等问题；通过几何化参数化实现 ΔW = BΣA^⊤ 的李代数样式分解，并在 Stiefel 流形上约束因子正交，兼容标准优化器与现有微调管线。并提出面向欧洲社会科学术语库（ELSST）的分层概念检索基准，在多语言句子编码器上的实验显示该方法在相同低秩预算下优于标准 LoRA 和多种强 PEFT 变体，提升社会科学信息系统中的资源受限场景的可行性。


<details>
  <summary>Details</summary>
Motivation: 标准的 LoRA 更新形式 ΔW = BA^T 存在几何缺陷： gauge 自由、尺度歧义以及容易出现秩坍塌；在 Web4Good 生态中的中小机构对计算和能耗有严格约束，需更稳定、参数更少的微调方案来实现基础模型的高效适配。

Method: 提出 OrthoGeoLoRA，通过约束低秩因子使其具备正交性，形成低秩更新的 SVD 形式 ΔW = BΣA^⊤，其中 B、A 的列向量正交（在 Stiefel 流形上）。实现了对该约束的几何重参数化，使其可与常用优化器（如 Adam）及现有微调管线无缝结合。并新增一个针对数字资源库中社会科学资源的分层概念检索基准，基于欧洲社会科学语言同义词库（ELSST）。

Result: 在多语言句子编码器的实验中，OrthoGeoLoRA 在相同的低秩预算下，显著优于标准 LoRA 与若干强力的 PEFT 变体，在排序指标上表现更好。ELSST 基准显示该方法在分层概念检索任务上的鲁棒性与效率提升，表现在对社会科学资源的组织与检索效果上。

Conclusion: OrthoGeoLoRA 提供一种更高效且鲁棒的参数高效微调路径，显著缓解 LoRA 的几何问题（ gauge、尺度与秩坍塌），在资源受限环境中也能实现更好的适配效果，促进 foundation 模型在社会科学和数字信息系统中的广泛应用。

Abstract: Large language models and text encoders increasingly power web-based information systems in the social sciences, including digital libraries, data catalogues, and search interfaces used by researchers, policymakers, and civil society. Full fine-tuning is often computationally and energy intensive, which can be prohibitive for smaller institutions and non-profit organizations in the Web4Good ecosystem. Parameter-Efficient Fine-Tuning (PEFT), especially Low-Rank Adaptation (LoRA), reduces this cost by updating only a small number of parameters. We show that the standard LoRA update $ΔW = BA^\top$ has geometric drawbacks: gauge freedom, scale ambiguity, and a tendency toward rank collapse. We introduce OrthoGeoLoRA, which enforces an SVD-like form $ΔW = BΣA^\top$ by constraining the low-rank factors to be orthogonal (Stiefel manifold). A geometric reparameterization implements this constraint while remaining compatible with standard optimizers such as Adam and existing fine-tuning pipelines. We also propose a benchmark for hierarchical concept retrieval over the European Language Social Science Thesaurus (ELSST), widely used to organize social science resources in digital repositories. Experiments with a multilingual sentence encoder show that OrthoGeoLoRA outperforms standard LoRA and several strong PEFT variants on ranking metrics under the same low-rank budget, offering a more compute- and parameter-efficient path to adapt foundation models in resource-constrained settings.

</details>


### [34] [ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection](https://arxiv.org/abs/2601.09195)
*Tao Liu,Taiqiang Wu,Runming Yang,Shaoning Sun,Junjie Wang,Yujiu Yang*

Main category: cs.CL

TL;DR: ProFit通过选择性屏蔽低概率标记来缓解单一参考答案对SFT的过拟合问题，利用高概率标记承载核心逻辑、低概率标记可替换的特性，在不显著增加数据/计算成本的情况下提升推理与数学任务的表现。


<details>
  <summary>Details</summary>
Motivation: 解决SFT在语言的一对多本质下对单一参考答案的过拟合问题；直接引入多参考答案成本高昂，需寻找高效且具备对核心逻辑的保护性改进。

Method: 基于 token 概率与语义重要性的内在联系，ProFit 通过对低概率标记进行选择性屏蔽，降低对表层表达的过拟合风险；采用阈值或概率分布驱动的屏蔽策略，在训练阶段保留高概率、核心逻辑标记，抑制低概率、可替换表达的学习影响。

Result: 实验表明，ProFit在通用推理和数学基准上持续优于传统SFT基线，体现出在保留核心结构的同时抑制表层多样性对性能的积极作用。

Conclusion: 通过聚焦核心逻辑的高概率标记并屏蔽低概率标记，ProFit实现了更高效的单参考过拟合缓解路径，适用于提升SFT在需要强推理能力的场景的泛化性。

Abstract: Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. However, traditional SFT often ignores the one-to-many nature of language by forcing alignment with a single reference answer, leading to the model overfitting to non-core expressions. Although our empirical analysis suggests that introducing multiple reference answers can mitigate this issue, the prohibitive data and computational costs necessitate a strategic shift: prioritizing the mitigation of single-reference overfitting over the costly pursuit of answer diversity. To achieve this, we reveal the intrinsic connection between token probability and semantic importance: high-probability tokens carry the core logical framework, while low-probability tokens are mostly replaceable expressions. Based on this insight, we propose ProFit, which selectively masks low-probability tokens to prevent surface-level overfitting. Extensive experiments confirm that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.

</details>


### [35] [A.X K1 Technical Report](https://arxiv.org/abs/2601.09200)
*Sung Jun Cheon,Jaekyung Cho,Seongho Choi,Hyunjun Eun,Seokhwan Jo,Jaehyun Jun,Minsoo Kang,Jin Kim,Jiwon Kim,Minsang Kim,Sungwan Kim,Seungsik Kim,Tae Yoon Kim,Youngrang Kim,Hyeongmun Lee,Sangyeol Lee,Sungeun Lee,Youngsoon Lee,Yujin Lee,Seongmin Ok,Chanyong Park,Hyewoong Park,Junyoung Park,Hyunho Yang,Subin Yi,Soohyun Bae,Dhammiko Arya,Yongseok Choi,Sangho Choi,Dongyeon Cho,Seungmo Cho,Gyoungeun Han,Yong-jin Han,Seokyoung Hong,Hyeon Hwang,Wonbeom Jang,Minjeong Ju,Wonjin Jung,Keummin Ka,Sungil Kang,Dongnam Kim,Joonghoon Kim,Jonghwi Kim,SaeRom Kim,Sangjin Kim,Seongwon Kim,Youngjin Kim,Seojin Lee,Sunwoo Lee,Taehoon Lee,Chanwoo Park,Sohee Park,Sooyeon Park,Yohan Ra,Sereimony Sek,Seungyeon Seo,Gun Song,Sanghoon Woo,Janghan Yoon,Sungbin Yoon*

Main category: cs.CL

TL;DR: A.X K1 是一款 5190 亿参数的 MoE 语言模型，基于约 10 万亿 tokens 的数据训练，采用缩放律优化训练配置与词表规模，通过 Think-Fusion 实现对“思考/非思考”模式的可控切换，在广泛评测中与主流开源模型竞争，且在韩语基准上具显著优势。


<details>
  <summary>Details</summary>
Motivation: 解决推理能力与推理推断效率之间的权衡，在固定计算预算下提升可推理性与部署灵活性；通过混合专家架构和大规模数据提升推理质量，并引入对推理过程的显式控制以适应多场景应用。

Method: 采用 519B 参数的 Mixture-of-Experts（MoE）架构；基于缩放规律来优化训练配置（如学习率、批量、并行度等）和词表规模；使用约 10 万亿 token 的多阶段数据处理管线完成大规模预训练；提出 Think-Fusion 训练方案，使模型内部实现对“thinking（推理/思考）”与“non-thinking（非推理/捷径）”模式的用户可控切换，可能通过门控策略、任务设计或提示控制来实现。

Result: 经广泛评测，A.X K1 的性能与领先的开源模型保持竞争力，同时在韩语相关基准上表现出明显优势，显示高容量MoE与可控推理在实际任务中的有效性。

Conclusion: 该工作表明将缩放规律、混合专家架构与可控推理思路结合，能够在保持推理效率的同时提升推理能力，并为跨语言部署提供潜在优势。未来可进一步披露具体实现细节、扩展多语种评估，以及对推理成本和延迟的系统分析。

Abstract: We introduce A.X K1, a 519B-parameter Mixture-of-Experts (MoE) language model trained from scratch. Our design leverages scaling laws to optimize training configurations and vocabulary size under fixed computational budgets. A.X K1 is pre-trained on a corpus of approximately 10T tokens, curated by a multi-stage data processing pipeline. Designed to bridge the gap between reasoning capability and inference efficiency, A.X K1 supports explicitly controllable reasoning to facilitate scalable deployment across diverse real-world scenarios. We propose a simple yet effective Think-Fusion training recipe, enabling user-controlled switching between thinking and non-thinking modes within a single unified model. Extensive evaluations demonstrate that A.X K1 achieves performance competitive with leading open-source models, while establishing a distinctive advantage in Korean-language benchmarks.

</details>


### [36] [UserLM-R1: Modeling Human Reasoning in User Language Models with Multi-Reward Reinforcement Learning](https://arxiv.org/abs/2601.09215)
*Feng Zhang,Shijia Li,Chunmao Zhang,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Jingwen Xu,Han Liu*

Main category: cs.CL

TL;DR: 提出 UserLM-R1，一种具备推理能力的用户语言模型，用于跨领域用户仿真和对话策略，通过静态/动态画像与目标驱动推理，结合监督微调与多奖励强化学习，在对抗性场景中优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有用户仿真器依赖静态、上下文无关的画像，难以适应新场景且缺乏对人类策略思维的建模，易被对手操控，降低泛化与鲁棒性。

Method: 建立包含静态角色与动态场景目标的综合用户画像；提出以目标为导向的决策策略，在产生回应前输出高质量推理理由，并通过监督微调与多奖励强化学习对推理和策略能力进行细化与提升。

Result: 实验显示 UserLM-R1 在竞争基线上表现更优，尤其在更具挑战性的对抗性集合上。

Conclusion: 通过将结构化画像、前置推理、以及强化学习结合起来，提升跨场景泛化和对抗性鲁棒性，证明该框架在用户仿真任务中的潜力。

Abstract: User simulators serve as the critical interactive environment for agent post-training, and an ideal user simulator generalizes across domains and proactively engages in negotiation by challenging or bargaining. However, current methods exhibit two issues. They rely on static and context-unaware profiles, necessitating extensive manual redesign for new scenarios, thus limiting generalizability. Moreover, they neglect human strategic thinking, leading to vulnerability to agent manipulation. To address these issues, we propose UserLM-R1, a novel user language model with reasoning capability. Specifically, we first construct comprehensive user profiles with both static roles and dynamic scenario-specific goals for adaptation to diverse scenarios. Then, we propose a goal-driven decision-making policy to generate high-quality rationales before producing responses, and further refine the reasoning and improve strategic capabilities with supervised fine-tuning and multi-reward reinforcement learning. Extensive experimental results demonstrate that UserLM-R1 outperforms competitive baselines, particularly on the more challenging adversarial set.

</details>


### [37] [When to Trust: A Causality-Aware Calibration Framework for Accurate Knowledge Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2601.09241)
*Jing Ren,Bowen Li,Ziqi Xu,Xinkun Zhang,Haytham Fayek,Xiaodong Li*

Main category: cs.CL

TL;DR: Ca2KG对KG-RAG引入因果感知校准，通过对照性提示与面板式重评分实现更好校准性，同时保持或提升准确性。


<details>
  <summary>Details</summary>
Motivation: KG-RAG在检索子图不完整或不可靠时易过度自信，需在高风险场景中提升校准性与可解释性。

Method: 将对照性提示整合以揭示检索相关的不确定性，并采用面板式重评分机制在干预间实现预测稳定性。

Result: 在两组复杂问答数据集上，Ca2KG显著提升校准性，同时保持或提升预测准确性。

Conclusion: 提供一种可推广的KG-RAG校准框架，平衡解释性、可靠性与准确性，适用于高风险应用。

Abstract: Knowledge Graph Retrieval-Augmented Generation (KG-RAG) extends the RAG paradigm by incorporating structured knowledge from knowledge graphs, enabling Large Language Models (LLMs) to perform more precise and explainable reasoning. While KG-RAG improves factual accuracy in complex tasks, existing KG-RAG models are often severely overconfident, producing high-confidence predictions even when retrieved sub-graphs are incomplete or unreliable, which raises concerns for deployment in high-stakes domains. To address this issue, we propose Ca2KG, a Causality-aware Calibration framework for KG-RAG. Ca2KG integrates counterfactual prompting, which exposes retrieval-dependent uncertainties in knowledge quality and reasoning reliability, with a panel-based re-scoring mechanism that stabilises predictions across interventions. Extensive experiments on two complex QA datasets demonstrate that Ca2KG consistently improves calibration while maintaining or even enhancing predictive accuracy.

</details>


### [38] [TeachPro: Multi-Label Qualitative Teaching Evaluation via Cross-View Graph Synergy and Semantic Anchored Evidence Encoding](https://arxiv.org/abs/2601.09246)
*Xiangqian Wang,Yifan Jia,Yang Xiang,Yumin Zhang,Yanbin Wang,Ke Liu*

Main category: cs.CL

TL;DR: 提出 TeachPro，一种多标签学习框架，对五个教学维度进行诊断性评估，给出高粒度分析与新基准数据集。


<details>
  <summary>Details</summary>
Motivation: 标准化学生评价常因信度低、选项有限、以及回应扭曲而受限，现有方法多将开放式评论简化为二元情感，忽略如内容清晰度、反馈及时性、教师举止等具体关切，难以指导教学改进。

Method: 提出 Dimension-Anchored Evidence Encoder：(i) 预训练文本编码实现定性反馈的上下文嵌入；(ii) prompt 模块将五个教学维度表示为可学习的语义锚点；(iii) 交叉注意力在结构化语义空间中对齐证据与维度。进一步提出 Cross-View Graph Synergy Network，包含 Syntactic Branch（提取句法依赖）与 Semantic Branch（基于 BERT 相似性图建模潜在关系）。BiAffine 融合对齐句法与语义单位，微分正则化促成正交/互补表征。最后通过跨注意力将维度锚定证据与多视角评论表示连接。并给出具有 expert qualitative annotations 与多标签分数的新基准数据集。

Result: 大量实验表明 TeachPro 在诊断粒度和鲁棒性方面优于基线，在多种评估设置下均表现出色。

Conclusion: TeachPro 提供更高粒度的诊断分析与鲁棒性，配套新基准数据集，支持对教学质量的多维评估与改进。

Abstract: Standardized Student Evaluation of Teaching often suffer from low reliability, restricted response options, and response distortion. Existing machine learning methods that mine open-ended comments usually reduce feedback to binary sentiment, which overlooks concrete concerns such as content clarity, feedback timeliness, and instructor demeanor, and provides limited guidance for instructional improvement.We propose TeachPro, a multi-label learning framework that systematically assesses five key teaching dimensions: professional expertise, instructional behavior, pedagogical efficacy, classroom experience, and other performance metrics. We first propose a Dimension-Anchored Evidence Encoder, which integrates three core components: (i) a pre-trained text encoder that transforms qualitative feedback annotations into contextualized embeddings; (ii) a prompt module that represents five teaching dimensions as learnable semantic anchors; and (iii) a cross-attention mechanism that aligns evidence with pedagogical dimensions within a structured semantic space. We then propose a Cross-View Graph Synergy Network to represent student comments. This network comprises two components: (i) a Syntactic Branch that extracts explicit grammatical dependencies from parse trees, and (ii) a Semantic Branch that models latent conceptual relations derived from BERT-based similarity graphs. BiAffine fusion module aligns syntactic and semantic units, while a differential regularizer disentangles embeddings to encourage complementary representations. Finally, a cross-attention mechanism bridges the dimension-anchored evidence with the multi-view comment representations. We also contribute a novel benchmark dataset featuring expert qualitative annotations and multi-label scores. Extensive experiments demonstrate that TeachPro offers superior diagnostic granularity and robustness across diverse evaluation settings.

</details>


### [39] [When to Invoke: Refining LLM Fairness with Toxicity Assessment](https://arxiv.org/abs/2601.09250)
*Jing Ren,Bowen Li,Ziqi Xu,Renqiang Luo,Shuo Yu,Xin Ye,Haytham Fayek,Xiaodong Li,Feng Xia*

Main category: cs.CL

TL;DR: FairToT是一个推理时（inference-time）的、通过提示引导的公平性增强框架。它在毒性评估中检测潜在的人口统计相关偏差情形，并在必要时进行额外评估；引入两种可解释的公平性指示器来提升推理的一致性，而无需对模型参数进行修改。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在处理含隐性仇恨表达等微妙表达时的不一致性与偏见，强调何时触发纠正机制以实现公平和可信的评估。

Method: 通过提示引导的毒性评估流程；在推理阶段识别可能出现人口统计相关变异的情形；提出两种可解释的公平性指示器以判断是否需要额外评估；不修改模型参数，即进行推理时的 refinements。

Result: 在基准数据集上，FairToT能够降低群体层面的差异，同时保持毒性预测的稳定性与一致性。

Conclusion: 推理时的“再评估/修正”策略为提升LLM毒性评估公平性提供一种高效、实用的方案。

Abstract: Large Language Models (LLMs) are increasingly used for toxicity assessment in online moderation systems, where fairness across demographic groups is essential for equitable treatment. However, LLMs often produce inconsistent toxicity judgements for subtle expressions, particularly those involving implicit hate speech, revealing underlying biases that are difficult to correct through standard training. This raises a key question that existing approaches often overlook: when should corrective mechanisms be invoked to ensure fair and reliable assessments? To address this, we propose FairToT, an inference-time framework that enhances LLM fairness through prompt-guided toxicity assessment. FairToT identifies cases where demographic-related variation is likely to occur and determines when additional assessment should be applied. In addition, we introduce two interpretable fairness indicators that detect such cases and improve inference consistency without modifying model parameters. Experiments on benchmark datasets show that FairToT reduces group-level disparities while maintaining stable and reliable toxicity predictions, demonstrating that inference-time refinement offers an effective and practical approach for fairness improvement in LLM-based toxicity assessment systems. The source code can be found at https://aisuko.github.io/fair-tot/.

</details>


### [40] [MCGA: A Multi-task Classical Chinese Literary Genre Audio Corpus](https://arxiv.org/abs/2601.09270)
*Yexing Du,Kaiyuan Liu,Bihe Zhang,Youcheng Pan,Bo Yang,Liangyu Huo,Xiyuan Zhang,Jian Xie,Daojing He,Yang Xiang,Ming Liu,Bin Qin*

Main category: cs.CL

TL;DR: 提出多任务的古典中文文学体裁音频语料 MCGA，覆盖六个任务（ASR、S2TT、SEC、SQA、SU、SR），对十种多模态大语言模型进行评测，发现现有模型在该数据集上仍存在显著挑战，同时提出用于 SEC 的评估指标和衡量语音-文本能力一致性的指标，并开源数据和代码。


<details>
  <summary>Details</summary>
Motivation: 弥补中文古典研究在音频模态方面的数据匮乏，建立覆盖多任务的评测语料，促进多模态大语言模型在 CCS 领域的音频理解与生成能力研究。

Method: 构建 MCGA 数据集，涵盖六类任务，面向古典中文文学体裁的音频内容；对十种多模态大语言模型进行系统评测；提出 SEC 评估指标和语音-文本一致性指标；对外发布数据与代码。

Result: 当前模型在 MCGA 测试集上仍面临较大挑战，多模态音频任务的性能提升空间广阔；六任务设定覆盖音频理解与生成的关键维度。

Conclusion: MCGA 及其评测框架有助于推动具有更鲁棒音频能力的 CCS 面向多模态的 MLLMs 的发展，公开数据与代码可促进后续研究与基线建立。

Abstract: With the rapid advancement of Multimodal Large Language Models (MLLMs), their potential has garnered significant attention in Chinese Classical Studies (CCS). While existing research has primarily focused on text and visual modalities, the audio corpus within this domain remains largely underexplored. To bridge this gap, we propose the Multi-task Classical Chinese Literary Genre Audio Corpus (MCGA). It encompasses a diverse range of literary genres across six tasks: Automatic Speech Recognition (ASR), Speech-to-Text Translation (S2TT), Speech Emotion Captioning (SEC), Spoken Question Answering (SQA), Speech Understanding (SU), and Speech Reasoning (SR). Through the evaluation of ten MLLMs, our experimental results demonstrate that current models still face substantial challenges when processed on the MCGA test set. Furthermore, we introduce an evaluation metric for SEC and a metric to measure the consistency between the speech and text capabilities of MLLMs. We release MCGA and our code to the public to facilitate the development of MLLMs with more robust multidimensional audio capabilities in CCS. MCGA Corpus: https://github.com/yxduir/MCGA

</details>


### [41] [ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering](https://arxiv.org/abs/2601.09280)
*Chaerin Lee,Sohee Park,Hyunsik Na,Daseon Choi*

Main category: cs.CL

TL;DR: 提出了一种区域优先的知识图谱推理框架 ReGraM，通过以查询为对齐的子图来约束逐步推理，显著提升医疗问答的 factual accuracy 与降低幻觉率。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么遍历完整 KG 要么执行大规模检索，导致噪音高和多跳推理不稳定，核心挑战是识别并推理出与每个查询相关的证据子集。

Method: 构建与查询对齐的子图，进行在局部区域内的逐步推理；多证据感知模式；强调区域构造与跳步骤推理的对齐；避免对整图依赖。

Result: 在七个医疗 QA 基准上超过强基线 KGARevion，MCQ 提升 8.04% 的绝对准确率，SAQ 提升 4.50%，幻觉率降低 42.9%；消融表明区域构造对跳步推理是主要驱动因素。

Conclusion: 区域优先的 KG 推理是提升医疗 QA 事实准确性与一致性的有效范式。

Abstract: Recent studies in medical question answering (Medical QA) have actively explored the integration of large language models (LLMs) with biomedical knowledge graphs (KGs) to improve factual accuracy. However, most existing approaches still rely on traversing the entire KG or performing large-scale retrieval, which introduces substantial noise and leads to unstable multi-hop reasoning. We argue that the core challenge lies not in expanding access to knowledge, but in identifying and reasoning over the appropriate subset of evidence for each query. ReGraM is a region-first knowledge graph reasoning framework that addresses this challenge by constructing a query-aligned subgraph and performing stepwise reasoning constrained to this localized region under multiple evidence aware modes. By focusing inference on only the most relevant portion of the KG, ReGraM departs from the assumption that all relations are equally useful an assumption that rarely holds in domain-specific medical settings. Experiments on seven medical QA benchmarks demonstrate that ReGraM consistently outperforms a strong baseline (KGARevion), achieving an 8.04% absolute accuracy gain on MCQ, a 4.50% gain on SAQ, and a 42.9% reduction in hallucination rate. Ablation and qualitative analyses further show that aligning region construction with hop-wise reasoning is the primary driver of these improvements. Overall, our results highlight region-first KG reasoning as an effective paradigm for improving factual accuracy and consistency in medical QA.

</details>


### [42] [Understanding or Memorizing? A Case Study of German Definite Articles in Language Models](https://arxiv.org/abs/2601.09313)
*Jonathan Drechsel,Erisa Bytyqi,Steffen Herbold*

Main category: cs.CL

TL;DR: 通过 GRADIEND 研究德语定冠词在性别和格对齐中的学习机制，发现对特定性别-格的更新常波及其他设置，且相关神经元在多种设置中重叠；结果倾向于记忆性而非严格的规则推理。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型在形态-句法一致性任务中是依赖抽象规则还是记忆性关联。以德语定冠词（性别+格）作为测试对象，因为其形式由性别和格共同决定，便于区分不同机制。

Method: 使用梯度可解释性方法 GRADIEND，学习针对性别-格的定冠词转移的参数更新方向，观察在不同性别-格设置之间的更新是否转移和神经元层面的共性。

Result: 针对某一性别-格的更新常影响其他性别-格设置，且在最易受影响的神经元中存在跨设定的显著重叠，表明学习到的并非单纯独立的规则转换，而包含可迁移的记忆性表示。

Conclusion: 证据支持模型在德语定冠词的形态编码中包含记忆成分，不能仅靠严格的规则化推理；未来工作可进一步量化规则性与记忆性的比例，以及在更多语言/结构上的泛化。

Abstract: Language models perform well on grammatical agreement, but it is unclear whether this reflects rule-based generalization or memorization. We study this question for German definite singular articles, whose forms depend on gender and case. Using GRADIEND, a gradient-based interpretability method, we learn parameter update directions for gender-case specific article transitions. We find that updates learned for a specific gender-case article transition frequently affect unrelated gender-case settings, with substantial overlap among the most affected neurons across settings. These results argue against a strictly rule-based encoding of German definite articles, indicating that models at least partly rely on memorized associations rather than abstract grammatical rules.

</details>


### [43] [Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework](https://arxiv.org/abs/2601.09342)
*Ewelina Gajewska,Katarzyna Budzynska,Jarosław A Chudziak*

Main category: cs.CL

TL;DR: Proposes a contextualized, multi-agent moderation framework for implicitly hateful speech using a central Moderator Agent and dynamic Community Agents, leveraging socio-cultural knowledge to improve accuracy and fairness, outperforming prompting baselines on ToxiGen, with balanced accuracy as the fairness metric.


<details>
  <summary>Details</summary>
Motivation: Address limitations of prompt-based moderation (zero-/few-/chain-of-thought prompting) and the need for identity-aware, context-sensitive detection; ensure fairness across demographic groups by incorporating socio-cultural knowledge.

Method: Architectural design: Moderator Agent plus Community Agents per demographic group; integrate publicly available knowledge sources to provide socio-cultural context; perform consultative moderation; evaluate against prompting baselines on ToxiGen; use balanced accuracy as central metric.

Result: Significant improvements in classification accuracy and fairness across all target groups; outperformance of state-of-the-art prompting methods and alternative approaches on ToxiGen dataset.

Conclusion: Identity-aware, context-rich, community-driven moderation framework can enhance both accuracy and fairness in hate-speech detection; socio-cultural knowledge integration is effective.

Abstract: This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents representing specific demographic groups. Our approach explicitly integrates socio-cultural context from publicly available knowledge sources, enabling identity-aware moderation that surpasses state-of-the-art prompting methods (zero-shot prompting, few-shot prompting, chain-of-thought prompting) and alternative approaches on a challenging ToxiGen dataset. We enhance the technical rigour of performance evaluation by incorporating balanced accuracy as a central metric of classification fairness that accounts for the trade-off between true positive and true negative rates. We demonstrate that our community-driven consultative framework significantly improves both classification accuracy and fairness across all target groups.

</details>


### [44] [Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs](https://arxiv.org/abs/2601.09365)
*Biswesh Mohapatra,Théo Charlot,Giovanni Duca,Mayank Palan,Laurent Romary,Justine Cassell*

Main category: cs.CL

TL;DR: 评估在情境对话中建立并利用共同基础以引用共享实体的能力，比较不同表示方法，并提出改进策略。


<details>
  <summary>Details</summary>
Motivation: 为解决对话系统中 grounding 的可持续引用问题，研究如何显式表示与存储共同基础。

Method: 在情境对话中测试多种共同基础表示方法，评估模型建立并利用关系性引用的能力；提出改进建立与使用的策略。

Result: 不同表示方法对共同基础的建立与利用存在差异，所提出的改进策略能提升后续对话中的引用稳定性与一致性。

Conclusion: 显式、可检索的共同基础表示对实现 grounded 理解至关重要，本文提供了具体方法与改进路径。

Abstract: Common ground plays a critical role in situated spoken dialogues, where interlocutors must establish and maintain shared references to entities, events, and relations to sustain coherent interaction. For dialog systems, the ability to correctly ground conversational content in order to refer back to it later is particularly important. Prior studies have demonstrated that LLMs are capable of performing grounding acts such as requesting clarification or producing acknowledgments, yet relatively little work has investigated how common ground can be explicitly represented and stored for later use. Without such mechanisms, it remains unclear whether acknowledgment or clarification behaviors truly reflect a grounded understanding. In this work, we evaluate a model's ability to establish and exploit common ground through relational references to entities within the shared context in a situational dialogue. We test multiple methods for representing common ground in situated dialogues and further propose approaches to improve both the establishment of common ground and its subsequent use in the conversation.

</details>


### [45] [Relation Extraction Capabilities of LLMs on Clinical Text: A Bilingual Evaluation for English and Turkish](https://arxiv.org/abs/2601.09367)
*Aidana Aidynkyzy,Oğuz Dikenelli,Oylum Alatlı,Şebnem Bora*

Main category: cs.CL

TL;DR: 首个英-土并行临床RE数据集；评估提示方法与基线；提出Relation-Aware Retrieval (RAR)；LLM提示明显优于微调模型；英文优于土耳其语；RAR在ICL中表现最佳，English 0.906、Turkish 0.888；结合DeepSeek-V3结构化推理后英语提升至0.918 F1。


<details>
  <summary>Details</summary>
Motivation: 弥补非英语临床信息抽取标注数据稀缺，首次对英语-土耳其语环境下的LLM在临床关系抽取任务进行系统评估，探究提示与检索策略对性能的影响。

Method: 构建首个英语-土耳其语并行的临床RE数据集，源自2010 i2b2/VA关系分类语料；系统评估多种提示策略（多样化的进行中学习ICL与链式推理CoT）并与微调基线（如PURE）比较；提出基于对比学习的Relation-Aware Retrieval (RAR) 用于示例检索，同时考虑句子级与关系级语义；使用Gemini 1.5 Flash等模型并引入DeepSeek-V3的结构化推理提示以提升性能。

Result: 提示驱动的LLM在多数场景优于微调模型；英文表现优于土耳其语；在ICL方法中，RAR达到最高性能，英语0.906、土耳其语0.888；将RAR与DeepSeek-V3的结构化推理结合后，英文F1提升至0.918。

Conclusion: 强调高质量演示检索的重要性，以及检索与提示技术在弥合临床NLP资源差距方面的潜力，尤其在非英语场景中。

Abstract: The scarcity of annotated datasets for clinical information extraction in non-English languages hinders the evaluation of large language model (LLM)-based methods developed primarily in English. In this study, we present the first comprehensive bilingual evaluation of LLMs for the clinical Relation Extraction (RE) task in both English and Turkish. To facilitate this evaluation, we introduce the first English-Turkish parallel clinical RE dataset, derived and carefully curated from the 2010 i2b2/VA relation classification corpus. We systematically assess a diverse set of prompting strategies, including multiple in-context learning (ICL) and Chain-of-Thought (CoT) approaches, and compare their performance to fine-tuned baselines such as PURE. Furthermore, we propose Relation-Aware Retrieval (RAR), a novel in-context example selection method based on contrastive learning, that is specifically designed to capture both sentence-level and relation-level semantics. Our results show that prompting-based LLM approaches consistently outperform traditional fine-tuned models. Moreover, evaluations for English performed better than their Turkish counterparts across all evaluated LLMs and prompting techniques. Among ICL methods, RAR achieves the highest performance, with Gemini 1.5 Flash reaching a micro-F1 score of 0.906 in English and 0.888 in Turkish. Performance further improves to 0.918 F1 in English when RAR is combined with a structured reasoning prompt using the DeepSeek-V3 model. These findings highlight the importance of high-quality demonstration retrieval and underscore the potential of advanced retrieval and prompting techniques to bridge resource gaps in clinical natural language processing.

</details>


### [46] [The Imperfective Paradox in Large Language Models](https://arxiv.org/abs/2601.09373)
*Bolei Ma,Yusuke Miyao*

Main category: cs.CL

TL;DR: LLMs 未能真正掌握事件的体裁语义，表现出对目标导向事件的幻觉性完成偏差；ImperfectiveNLI 诊断数据集揭示了这类结构性缺陷；提示策略虽能降低幻觉，却引发对有效蕴涵的错误拒绝。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否具备复合事件语义的结构性理解，还是仅依赖表面概率线索；通过 Imperfective Paradox 对比不同语义类别，评估现有模型的体裁感知能力。

Method: 设计 ImperfectiveNLI 诊断数据集，覆盖多样语义类别；在公开权重的开源模型上评估；进行内部表征分析以区分过程与结果；使用提示干预尝试削弱幻觉并观察副作用。

Result: 模型普遍存在目标导向事件的完成幻觉（teleological bias），对显式文本否定也会被覆盖；内部嵌入确能区分过程与结果，但推断决策受强对目标实现的先验偏好支配；提示干预能减少幻觉完成，但同时增加对有效蕴涵的错误拒绝。

Conclusion: 当前的 LLMs 缺乏对体相的结构性觉察，表现为更像预测性叙事引擎而非严格的逻辑推理者；要实现真实的体相推理需引入显式的体相知识、更强的结构化推理能力或定向的训练信号，单纯的提示调整尚不能从根本解决问题。

Abstract: Do Large Language Models (LLMs) genuinely grasp the compositional semantics of events, or do they rely on surface-level probabilistic heuristics? We investigate the Imperfective Paradox, a logical phenomenon where the past progressive aspect entails event realization for activities (e.g., running $\to$ ran) but not for accomplishments (e.g., building $\nrightarrow$ built). We introduce ImperfectiveNLI, a diagnostic dataset designed to probe this distinction across diverse semantic classes. Evaluating state-of-the-art open-weight models, we uncover a pervasive Teleological Bias: models systematically hallucinate completion for goal-oriented events, often overriding explicit textual negation. Representational analyses show that while internal embeddings often distinguish process from result, inference decisions are dominated by strong priors about goal attainment. We further find that prompting-based interventions reduce hallucinated completions but also increase incorrect rejections of valid entailments. Our findings suggest that current LLMs lack structural aspectual awareness, operating as predictive narrative engines rather than faithful logical reasoners.

</details>


### [47] [Ability Transfer and Recovery via Modularized Parameters Localization](https://arxiv.org/abs/2601.09398)
*Songyao Jin,Kun Zhou,Wenqi Li,Peng Wang,Biwei Huang*

Main category: cs.CL

TL;DR: ACT is a selective, activation-guided method to transfer only a small subset of channels responsible for specific abilities in LLMs, enabling recovery of forgotten skills and merging multiple specialized models with minimal interference.


<details>
  <summary>Details</summary>
Motivation: To understand how abilities are distributed in LLM parameters and mitigate catastrophic forgetting when fine-tuning or continual pre-training by localizing and transferring only the most relevant parameter channels.

Method: Analyze module activations across layers for domain- and language-specific inputs in closely related models; find that ability-related activations concentrate in a small set of channels (<5%). Propose ACT to identify these channels via activation differences and transfer only their parameters, followed by lightweight compatibility fine-tuning.

Result: ACT can recover forgotten abilities while preserving retained skills and can merge multiple specialized models into a single model with minimal interference; code and data to be released.

Conclusion: Abilities in LLMs are sparsely distributed across a tiny subset of channels; activation-guided channel transfer is an effective strategy for targeted ability transfer and multi-ability integration with limited forgetting or interference.

Abstract: Large language models can be continually pre-trained or fine-tuned to improve performance in specific domains, languages, or skills, but this specialization often degrades other capabilities and may cause catastrophic forgetting. We investigate how abilities are distributed within LLM parameters by analyzing module activations under domain- and language-specific inputs for closely related models. Across layers and modules, we find that ability-related activations are highly concentrated in a small set of channels (typically <5\%), and these channels are largely disentangled with good sufficiency and stability. Building on these observations, we propose ACT (Activation-Guided Channel-wise Ability Transfer), which localizes ability-relevant channels via activation differences and selectively transfers only the corresponding parameters, followed by lightweight fine-tuning for compatibility. Experiments on multilingual mathematical and scientific reasoning show that ACT can recover forgotten abilities while preserving retained skills. It can also merge multiple specialized models to integrate several abilities into a single model with minimal interference. Our code and data will be publicly released.

</details>


### [48] [Structured Knowledge Representation through Contextual Pages for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.09402)
*Xinze Li,Zhenghao Liu,Haidong Xin,Yukun Yan,Shuo Wang,Zheni Zeng,Sen Mei,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: PAGER通过页驱动的自组织知识表示，在RAG中用LLM构建结构化认知大纲并逐槽填充相关文档，生成一页式语境输入以引导回答，从而实现对知识的高质量、信息密集且冲突更少的表示，优于所有RAG基线。


<details>
  <summary>Details</summary>
Motivation: 现有RAG中的迭代式知识积累往往缺乏统一的组织结构，导致知识表示不够全面、易产生冲突。需要一个结构化、可扩展的知识表示框架来提升对知识的整合与利用效率。

Method: 提出PAGER：1) 让LLM生成一个给定问题的结构化认知大纲，包含多个槽位以表示不同知识维度；2) 迭代检索并 refin e 相关文档以填充每个槽位；3) 汇总为一页式的知识页面，作为引导回答的上下文输入。

Result: 在多项知识密集型基准和主干模型上，PAGER持续优于所有RAG基线；分析显示其知识表示更高质量、信息密度更高、冲突更少，且更有效地利用外部知识。

Conclusion: PAGER提供一个结构化、页级的知识表示范式，提升RAG的问答与推理能力；并且代码开源，便于复现与进一步研究。

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by incorporating external knowledge. Recently, some works have incorporated iterative knowledge accumulation processes into RAG models to progressively accumulate and refine query-related knowledge, thereby constructing more comprehensive knowledge representations. However, these iterative processes often lack a coherent organizational structure, which limits the construction of more comprehensive and cohesive knowledge representations. To address this, we propose PAGER, a page-driven autonomous knowledge representation framework for RAG. PAGER first prompts an LLM to construct a structured cognitive outline for a given question, which consists of multiple slots representing a distinct knowledge aspect. Then, PAGER iteratively retrieves and refines relevant documents to populate each slot, ultimately constructing a coherent page that serves as contextual input for guiding answer generation. Experiments on multiple knowledge-intensive benchmarks and backbone models show that PAGER consistently outperforms all RAG baselines. Further analyses demonstrate that PAGER constructs higher-quality and information-dense knowledge representations, better mitigates knowledge conflicts, and enables LLMs to leverage external knowledge more effectively. All code is available at https://github.com/OpenBMB/PAGER.

</details>


### [49] [Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing](https://arxiv.org/abs/2601.09421)
*Filip Trhlik,Andrew Caines,Paula Buttery*

Main category: cs.CL

TL;DR: BabyLMs can serve as effective low-cost proxies for pre-model debiasing, mirroring bias formation and debiasing outcomes of larger LMs, enabling rapid and economical research (≈30 GPU-hours vs >500).


<details>
  <summary>Details</summary>
Motivation: Democratize pre-model debiasing research by reducing training costs while preserving bias acquisition dynamics observed in larger models; investigate whether compact models can approximate bias formation and responses to debiasing.

Method: Compare BabyLMs (compact BERT-like models trained on small corpora) with standard BERT models across intrinsic bias formation, learning dynamics, and multiple intra-model and post-model debiasing methods; perform pre-model debiasing experiments focusing on gender imbalance and toxicity.

Result: BabyLMs exhibit bias formation and performance trajectories closely aligned with BERT; correlations in bias under various debiasing methods persist; replication of prior findings and new insights on gender imbalance and toxicity; pre-training cost reduced from >500 GPU-hours to <30 GPU-hours.

Conclusion: BabyLMs serve as an effective sandbox for large-scale LM debiasing, enabling faster and cheaper exploration to develop fairer LMs and democratize pre-model debiasing research.

Abstract: Pre-trained language models (LMs) have, over the last few years, grown substantially in both societal adoption and training costs. This rapid growth in size has constrained progress in understanding and mitigating their biases. Since re-training LMs is prohibitively expensive, most debiasing work has focused on post-hoc or masking-based strategies, which often fail to address the underlying causes of bias. In this work, we seek to democratise pre-model debiasing research by using low-cost proxy models. Specifically, we investigate BabyLMs, compact BERT-like models trained on small and mutable corpora that can approximate bias acquisition and learning dynamics of larger models. We show that BabyLMs display closely aligned patterns of intrinsic bias formation and performance development compared to standard BERT models, despite their drastically reduced size. Furthermore, correlations between BabyLMs and BERT hold across multiple intra-model and post-model debiasing methods. Leveraging these similarities, we conduct pre-model debiasing experiments with BabyLMs, replicating prior findings and presenting new insights regarding the influence of gender imbalance and toxicity on bias formation. Our results demonstrate that BabyLMs can serve as an effective sandbox for large-scale LMs, reducing pre-training costs from over 500 GPU-hours to under 30 GPU-hours. This provides a way to democratise pre-model debiasing research and enables faster, more accessible exploration of methods for building fairer LMs.

</details>


### [50] [Improving Symbolic Translation of Language Models for Logical Reasoning](https://arxiv.org/abs/2601.09446)
*Ramya Keerthy Thatikonda,Jiuzhou Han,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 通过错误类型划分、用大模型数据对小模型进行微调、引入两阶段的增量推理（谓词生成与FOL翻译）以及谓词元数错误的验证模块，显著提升小型语言模型在NL到FOL的翻译与逻辑推理中的正确性与覆盖率。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在将自然语言翻译为一阶逻辑并借助外部求解器进行推理时，易产生格式与翻译错误，且自我迭代纠错能力受限。需提出更可控、可验证的符号推理流程以提升可靠性。

Method: 1) 将常见错误进行分类；2) 使用大型语言模型合成数据对小模型进行微调；3) 引入增量推理，将推理分为谓词生成与FOL翻译两阶段以提高生成质量；4) 增设验证模块，针对谓词的元数错误进行修正；5) 在三类模型、四个逻辑推理数据集上评估，利用谓词指标衡量生成质量。

Result: 该框架实现了错误率降低、谓词覆盖率提升、推理性能改善，尤其通过分阶段控制与验证提高了小LM的可控性与可靠性。

Conclusion: 综合微调、增量推理与验证模块的组合使小型LM更接近可依赖的符号推理系统，为可获取的符号推理提供了有效路径与实证支持。

Abstract: The use of formal language for deductive logical reasoning aligns well with language models (LMs), where translating natural language (NL) into first-order logic (FOL) and employing an external solver results in a verifiable and therefore reliable reasoning system. However, smaller LMs often struggle with this translation task, frequently producing incorrect symbolic outputs due to formatting and translation errors. Existing approaches typically rely on self-iteration to correct these errors, but such methods depend heavily on the capabilities of the underlying model. To address this, we first categorize common errors and fine-tune smaller LMs using data synthesized by large language models. The evaluation is performed using the defined error categories. We introduce incremental inference, which divides inference into two stages, predicate generation and FOL translation, providing greater control over model behavior and enhancing generation quality as measured by predicate metrics. This decomposition framework also enables the use of a verification module that targets predicate-arity errors to further improve performance. Our study evaluates three families of models across four logical-reasoning datasets. The comprehensive fine-tuning, incremental inference, and verification modules reduce error rates, increase predicate coverage, and improve reasoning performance for smaller LMs, moving us closer to developing reliable and accessible symbolic-reasoning systems.

</details>


### [51] [SlidesGen-Bench: Evaluating Slides Generation via Computational and Quantitative Metrics](https://arxiv.org/abs/2601.09487)
*Yunqiao Yang,Wenbo Li,Houxing Ren,Zimu Lu,Ke Wang,Zhiyuan Huang,Zhuofan Zong,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: SlidesGen-Bench provides a universal, quantitative, and reliable benchmark for evaluating slide generation across diverse systems, with a human-aligned dataset (Slides-Align1.5k) and metrics in Content, Aesthetics, and Editability; code and data released.


<details>
  <summary>Details</summary>
Motivation: Evaluation of heterogeneous slide-generation systems is difficult due to lack of unified, calibrated metrics; existing protocols yield incomparable scores or rely on subjective proxies.

Method: Ground evaluation in the visual/rendering domain; define three quantitative axes (Content, Aesthetics, Editability) for slides; propose reproducible metrics; construct Slides-Align1.5k with human preferences across nine systems and seven scenarios; evaluate correlation with human judgments.

Result: SlidesGen-Bench aligns more closely with human judgments than prior pipelines; provides reproducible, architecture-agnostic evaluation; code/data available at GitHub.

Conclusion: A practical, standardizable benchmark enabling fair cross-system comparison in slide generation; prompts future work on expanding coverage and refining metrics.

Abstract: The rapid evolution of Large Language Models (LLMs) has fostered diverse paradigms for automated slide generation, ranging from code-driven layouts to image-centric synthesis. However, evaluating these heterogeneous systems remains challenging, as existing protocols often struggle to provide comparable scores across architectures or rely on uncalibrated judgments. In this paper, we introduce SlidesGen-Bench, a benchmark designed to evaluate slide generation through a lens of three core principles: universality, quantification, and reliability. First, to establish a unified evaluation framework, we ground our analysis in the visual domain, treating terminal outputs as renderings to remain agnostic to the underlying generation method. Second, we propose a computational approach that quantitatively assesses slides across three distinct dimensions - Content, Aesthetics, and Editability - offering reproducible metrics where prior works relied on subjective or reference-dependent proxies. Finally, to ensure high correlation with human preference, we construct the Slides-Align1.5k dataset, a human preference aligned dataset covering slides from nine mainstream generation systems across seven scenarios. Our experiments demonstrate that SlidesGen-Bench achieves a higher degree of alignment with human judgment than existing evaluation pipelines. Our code and data are available at https://github.com/YunqiaoYang/SlidesGen-Bench.

</details>


### [52] [MVSS: A Unified Framework for Multi-View Structured Survey Generation](https://arxiv.org/abs/2601.09504)
*Yinqi Liu,Yueqi Zhu,Yongkang Zhang,Xinfeng Li,Feiran Liu,Yufei Sun,Xin Wang,Renzhao Liang,Yidong Wang,Cunxiang Wang*

Main category: cs.CL

TL;DR: MVSS introduces a structure-first, multi-view framework for automatic survey generation that jointly builds a hierarchical topic tree, constraint-based comparison tables, and text generation, achieving expert-like organization and citation grounding.


<details>
  <summary>Details</summary>
Motivation: Existing automatic survey methods are largely linear and struggle to model hierarchical topic structures and structured methodological comparisons, leading to gaps relative to expert surveys.

Method: MVSS constructs a conceptual topic tree first, then generates comparison tables constrained by the tree, and finally generates survey text using both as structural constraints, enabling alignment among structure, tables, and narrative with citation grounding.

Result: Empirical evaluation on 76 computer science topics shows MVSS outperforms existing methods in organization and evidence grounding, achieving performance comparable to expert surveys.

Conclusion: A structure-first, multi-view framework effectively unifies hierarchical structure, structured comparisons, and narrative text, reducing gaps with expert surveys and enabling better organized, evidence-grounded surveys.

Abstract: Scientific surveys require not only summarizing large bodies of literature, but also organizing them into clear and coherent conceptual structures. Existing automatic survey generation methods typically focus on linear text generation and struggle to explicitly model hierarchical relations among research topics and structured methodological comparisons, resulting in gaps in structural organization compared to expert-written surveys. We propose MVSS, a multi-view structured survey generation framework that jointly generates and aligns citation-grounded hierarchical trees, structured comparison tables, and survey text. MVSS follows a structure-first paradigm: it first constructs a conceptual tree of the research domain, then generates comparison tables constrained by the tree, and finally uses both as structural constraints for text generation. This enables complementary multi-view representations across structure, comparison, and narrative. We introduce an evaluation framework assessing structural quality, comparative completeness, and citation fidelity. Experiments on 76 computer science topics show MVSS outperforms existing methods in organization and evidence grounding, achieving performance comparable to expert surveys.

</details>


### [53] [SERM: Self-Evolving Relevance Model with Agent-Driven Learning from Massive Query Streams](https://arxiv.org/abs/2601.09515)
*Chenglong Wang,Canjia Li,Xingzhao Zhu,Yifu Huo,Huiyu Wang,Weixiong Lin,Yun Yang,Qiaozhi He,Tianhua Zhou,Xiaojia Chang,Jingbo Zhu,Tong Xiao*

Main category: cs.CL

TL;DR: SERM uses two cooperative multi-agent modules—the sample miner and relevance annotator—to enable self-evolution of relevance models for dynamic query streams, achieving gains in large-scale industrial settings.


<details>
  <summary>Details</summary>
Motivation: Real-world query streams are non-stationary, causing relevance models to struggle to generalize. Self-evolution is promising but faces two challenges in large-scale systems: sparse informative samples and unreliable pseudo-labels.

Method: SERM comprises two complementary multi-agent components: (i) a multi-agent sample miner that detects distributional shifts and identifies informative training samples, and (ii) a multi-agent relevance annotator that provides reliable labels via a two-level agreement framework. The approach is evaluated in a large-scale industrial setting with billions of daily user requests.

Result: SERM achieves significant performance gains through iterative self-evolution, validated by extensive offline multilingual evaluations and online testing in a real-world, high-volume environment.

Conclusion: The proposed SERM framework effectively enables self-evolution for relevance models in dynamic, large-scale query streams by combining shift-aware sample mining with reliable label annotation, yielding substantial offline and online gains.

Abstract: Due to the dynamically evolving nature of real-world query streams, relevance models struggle to generalize to practical search scenarios. A sophisticated solution is self-evolution techniques. However, in large-scale industrial settings with massive query streams, this technique faces two challenges: (1) informative samples are often sparse and difficult to identify, and (2) pseudo-labels generated by the current model could be unreliable. To address these challenges, in this work, we propose a Self-Evolving Relevance Model approach (SERM), which comprises two complementary multi-agent modules: a multi-agent sample miner, designed to detect distributional shifts and identify informative training samples, and a multi-agent relevance annotator, which provides reliable labels through a two-level agreement framework. We evaluate SERM in a large-scale industrial setting, which serves billions of user requests daily. Experimental results demonstrate that SERM can achieve significant performance gains through iterative self-evolution, as validated by extensive offline multilingual evaluations and online testing.

</details>


### [54] [Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats](https://arxiv.org/abs/2601.09555)
*Manyi Zhang,Ji-Fu Li,Zhongao Sun,Haoli Bai,Hui-Ling Zhen,Zhenhua Dong,Xianzhi Yu*

Main category: cs.CL

TL;DR: MXFP 8 位几乎无损，MXFP 4 位显著下降；PTQ 在 MXFP 下受格式兼容性影响显著；趋势在不同模型族和模态间高度一致，语言模型主导量化敏感性；MXFP4 的缩放因子是关键误差源，前缩放优化可缓解。


<details>
  <summary>Details</summary>
Motivation: 当前的大规模语言模型量化研究大多聚焦整数量化，缺乏对 Microscale Floating-Point (MXFP) 格式在后训练量化（PTQ）中的系统性评估与指南。

Method: 系统性评估：覆盖约7种 PTQ 算法、15项评测基准、3个大模型家族；比较不同 MXFP 格式对量化的影响，分析不同算法在格式间的兼容性与有效性；考察跨模态模型中语言编码器与视觉编码器对量化敏感性的贡献。

Result: MXFP8 近似无损表现；MXFP4 易造成明显精度下降；PTQ 效果高度依赖格式兼容性，某些算法范式在多格式下普遍更有效；跨模型与跨模态结果呈现高度一致性，尤其语言模型对量化敏感性贡献大于视觉编码器；MXFP4 的缩放因子是主要误差源，通过简单的前置缩放优化可显著缓解。

Conclusion: 为将现有 PTQ 方法迁移到 MXFP 量化提供实用指南，强调格式选择、算法范式和缩放策略在 MXFP 下的影响与可操作性。

Abstract: Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. To address this gap, this work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. The key findings include: 1) MXFP8 consistently achieves near-lossless performance, while MXFP4 introduces substantial accuracy degradation and remains challenging; 2) PTQ effectiveness under MXFP depends strongly on format compatibility, with some algorithmic paradigms being consistently more effective than others; 3) PTQ performance exhibits highly consistent trends across model families and modalities, in particular, quantization sensitivity is dominated by the language model rather than the vision encoder in multimodal LLMs; 4) The scaling factor of quantization is a critical error source in MXFP4, and a simple pre-scale optimization strategy can significantly mitigate its impact. Together, these results provide practical guidance on adapting existing PTQ methods to MXFP quantization.

</details>


### [55] [Dialogue Telemetry: Turn-Level Instrumentation for Autonomous Information Gathering](https://arxiv.org/abs/2601.09570)
*Dimitris Panagopoulos,Adolfo Perrusquia,Weisi Guo*

Main category: cs.CL

TL;DR: 提出对话遥测（Dialogue Telemetry, DT），通过两类信号—进展估计器（PE）和阻塞指标（SI）—在每次问答后对信息获取进行量化监控。并在LLM仿真SAR情境中验证，能区分高效与停滞对话，并将信号引入强化学习策略以提升性能。


<details>
  <summary>Details</summary>
Motivation: 在自治信息检索对话中缺乏逐轮观测量来监控信息获取效率与检测无效提问的发生产，存在仪表化缺口。需要一个模型无关、可在任意问答对后输出的指标，以便监控和诊断。

Method: 提出两种模型无关信号：进展估计器（PE）量化每一类别的剩余信息潜力（包含比特级变体）；阻塞指数（SI）检测可观测的失败模式，即对同义语义相近、增益边际低的类别进行重复探问。SI无需因果诊断即可为监控提供信号。以LLM仿真进行的受控SAR灵感访谈验证DT，区分高效/停滞对话，并将DT信号整合到RL策略中以评估下游效用。

Result: DT在不同情景下提供可解释的逐轮观测量，能区分高效与停滞对话，并通过将信号融入RL策略来提升在有运营成本的停滞情景下的策略表现。

Conclusion: DT为信息获取对话提供可解释、模型无关的逐轮仪表化，便于监控与策略改进，具备在其他领域的拓展潜力。

Abstract: Autonomous systems conducting schema-grounded information-gathering dialogues face an instrumentation gap, lacking turn-level observables for monitoring acquisition efficiency and detecting when questioning becomes unproductive. We introduce Dialogue Telemetry (DT), a measurement framework that produces two model-agnostic signals after each question-answer exchange: (i) a Progress Estimator (PE) quantifying residual information potential per category (with a bits-based variant), and (ii) a Stalling Index (SI) detecting an observable failure signature characterized by repeated category probing with semantically similar, low-marginal-gain responses. SI flags this pattern without requiring causal diagnosis, supporting monitoring in settings where attributing degradation to specific causes may be impractical. We validate DT in controlled search-and-rescue (SAR)-inspired interviews using large language model (LLM)-based simulations, distinguishing efficient from stalled dialogue traces and illustrating downstream utility by integrating DT signals into a reinforcement learning (RL) policy. Across these settings, DT provides interpretable turn-level instrumentation that improves policy performance when stalling carries operational costs.

</details>


### [56] [DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing](https://arxiv.org/abs/2601.09609)
*Qian Cao,Yahui Liu,Wei Bi,Yi Zhao,Ruihua Song,Xiting Wang,Ruiming Tang,Guorui Zhou,Han Li*

Main category: cs.CL

TL;DR: 在强化学习（RL）驱动的LLM生成中引入半结构化的长链式推理（CoT）与“多样性规划分支”和群体感知多样性奖励，以在开放性任务中提升输出多样性，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: RL对LLM输出的多样性有负面影响，现有方法缺乏显式的、多样性驱动的探索机制，倾向于优化效率和平均性能，忽视创意写作等任务的多样性需求。

Method: 将生成过程分解为明确计划的中间步骤（半结构化的长CoT），在规划阶段通过“多样性规划分支”引入有目的的分歧，并结合基于群体的多样性奖励，鼓励不同轨迹的探索。

Result: 在创意写作基准上，所提方法显著提升输出多样性且未降低生成质量，实验结果持续优于现有基线方法。

Conclusion: 通过在规划阶段引入有约束的分歧和群体感知的多样性奖励，RL驱动的LLM能够在保持质量的同时显著提高输出多样性，适用于需要创造性输出的场景。

Abstract: Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. We introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.

</details>


### [57] [TaxoBell: Gaussian Box Embeddings for Self-Supervised Taxonomy Expansion](https://arxiv.org/abs/2601.09633)
*Sahil Mishra,Srinitish Srinivasan,Srikanta Bedathur,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 通过将箱嵌入映射到多变量高斯分布，TaxoBell 在建模不确定性与多义性方面改善对 taxonomies 的扩展，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 手工扩展本体成本高且无法跟上新概念的出现；基于点嵌入的对称相似性难以有效捕捉“属于”关系。盒子嵌入虽具包含性和互斥性表达能力，但存在梯度不稳定、缺乏语义不确定性建模、难以表达歧义等问题。

Method: 提出 TaxoBell，将盒子几何与多变量高斯分布相互映射：均值编码语义位置，协方差编码不确定性。采用能量（energy-based）优化以实现稳定梯度、鲁棒处理模糊概念，并实现可解释的分层推理。通过消融与误差分析验证各组成部分的重要性。

Result: 在五个基准数据集上与八个先进基线相比，TaxoBell 在 MRR 提升约19%，Recall@k 提升约25%；并通过误差分析与消融研究揭示模型的优点与局限。

Conclusion: TaxoBell 有效建模 taxonomy 扩展中的不确定性和歧义，提升性能并实现可解释的层级推理；同时揭示了能量化训练与盒子-高斯映射下的潜在坑点，为未来改进提供方向。

Abstract: Taxonomies form the backbone of structured knowledge representation across diverse domains, enabling applications such as e-commerce catalogs, semantic search, and biomedical discovery. Yet, manual taxonomy expansion is labor-intensive and cannot keep pace with the emergence of new concepts. Existing automated methods rely on point-based vector embeddings, which model symmetric similarity and thus struggle with the asymmetric "is-a" relationships that are fundamental to taxonomies. Box embeddings offer a promising alternative by enabling containment and disjointness, but they face key issues: (i) unstable gradients at the intersection boundaries, (ii) no notion of semantic uncertainty, and (iii) limited capacity to represent polysemy or ambiguity. We address these shortcomings with TaxoBell, a Gaussian box embedding framework that translates between box geometries and multivariate Gaussian distributions, where means encode semantic location and covariances encode uncertainty. Energy-based optimization yields stable optimization, robust modeling of ambiguous concepts, and interpretable hierarchical reasoning. Extensive experimentation on five benchmark datasets demonstrates that TaxoBell significantly outperforms eight state-of-the-art taxonomy expansion baselines by 19% in MRR and around 25% in Recall@k. We further demonstrate the advantages and pitfalls of TaxoBell with error analysis and ablation studies.

</details>


### [58] [Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection](https://arxiv.org/abs/2601.09692)
*Tianyi Niu,Justin Chih-Yao Chen,Genta Indra Winata,Shi-Xiong Zhang,Supriyo Chakraborty,Sambit Sahu,Yue Zhang,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: 在没有 ground-truth 标签的数据场景下，提出通过生成数据训练的路由器（RGD），并比较查询-答案路由器与查询-仅路由器的鲁棒性，最终提出鲁棒的 CASCAL 路由器。


<details>
  <summary>Details</summary>
Motivation: 解决真实场景中分布未知、标签缺乏时如何选择合适的子模型的问题；探索通过生成数据来训练路由器的可行性。

Method: 定义 RGD 设置，使用高层任务描述由生成器 LLMs 生成查询-答案对；在四个基准、12个模型上评估查询-答案与查询-仅路由器；分析生成器特征（是否能回答自问的问题、产生的问句是否能区分模型表现），并通过过滤提升数据质量；提出 CASCAL——一个基于查询的路由器，通过共识投票估计模型正确性，并通过分层聚类识别模型的技能细分。

Result: 查询-答案路由器在生成器质量下降时退化速度快于查询-仅路由器；对生成器的两点特性进行筛选后，生成数据质量提升；CASCAL 在弱生成器数据上仍具鲁棒性，且在对比中比最优的查询-答案路由器高出 4.6% 绝对准确率。

Conclusion: 要获得高质量的路由决策，生成器需要对自己的问题给出准确回答且生成的问题能使模型池之间具备区分度；通过筛选可提升生成数据质量；CASCAL 作为查询-无标签路由器的有效替代，在低质量生成数据场景下更具鲁棒性，显著提升路由准确性。

Abstract: Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.

</details>


### [59] [LLMs can Compress LLMs: Adaptive Pruning by Agents](https://arxiv.org/abs/2601.09694)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CL

TL;DR: Agent-guided pruning for LLMs uses an adaptive, self-reflecting LLM agent to select per-iteration layer pruning, guided by layer sensitivity profiles from Wanda-like metrics and gradient scores. It includes rollback to maintain quality and achieves ~45% sparsity with significant gains over structured pruning on Qwen3-4B/8B (MMLU +56%, FreebaseQA factual retention +19x, perplexity degradation -69%), without retraining and in a model-agnostic way.


<details>
  <summary>Details</summary>
Motivation: Existing post-training pruning methods rely on fixed or hand-crafted layer-wise sparsity heuristics and suffer from severe knowledge degradation, especially factual knowledge, when pruning LLMs. There is a need for adaptive, knowledge-preserving pruning that can operate without retraining.

Method: Construct layer-wise sensitivity using a combination of activation-weight metrics (Wanda-inspired) and gradient importance, normalized to z-scores for cross-model comparison. An LLM agent with self-reflection evaluates pruning outcomes, iteratively refines the pruning strategy across iterations. A checkpoint rollback mechanism reverts the model if perplexity degrades beyond a threshold. The approach targets about 45% sparsity on Qwen3 (4B/8B) and is model-agnostic, requiring no retraining.

Result: On Qwen3 models (4B and 8B), achieving ~45% sparsity, the method yields 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation compared with structured pruning baselines, with only 2-4 rollbacks across 21-40 pruning iterations.

Conclusion: Foundation models can effectively guide the compression of other foundation models via adaptive, self-reflecting pruning agents that preserve critical knowledge pathways and avoid retraining; the approach is model-agnostic and achieves substantial performance gains at moderate sparsity.

Abstract: As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.

</details>


### [60] [Empathy Applicability Modeling for General Health Queries](https://arxiv.org/abs/2601.09696)
*Shan Randhawa,Agha Ali Raza,Kentaro Toyama,Julie Hui,Mustafa Naseem*

Main category: cs.CL

TL;DR: 提出 Empathy Applicability Framework (EAF)，在临床对话中对患者查询的共情适用性进行前置分类与预测，建立双注释数据集及基于人类与GPT的对齐分析，显著优于基线并为异步医疗中的同理沟通提供前置支持。


<details>
  <summary>Details</summary>
Motivation: 弥补现有研究多聚焦于对医生回应的事后共情标签，而缺乏对共情需求的预测性与前置建模，尤其在一般健康查询场景中。

Method: 提出理论框架EAF，对患者查询在临床、情境、语言线索层面的信息进行整合，按情感反应与解读的适用性进行分类。构建真实患者查询数据集，双重注释（人类与GPT-4o）。在具有人工共识的子集上分析人机对齐。训练分类器以预测共情适用性，基于人类标注和GPT注释的模型进行比较，优于启发式与零-shot基线。通过错误分析揭示隐性痛苦、临床严重性歧义、情境困难等挑战，并提出多注释建模、临床医生参与校准、以及文化多样性注释的需求。

Result: 在基于人类标注与GPT注释的预测任务中，分类器展现出较强的预测性能，并显著超越启发式和零-shot基线；在人机共识子集上观察到显著的人机对齐。

Conclusion: EAF提供一种在生成响应前识别共情需求的框架，建立 anticipatory empathy 建模的基准，并有助于提升异步医疗场景中的同理沟通。

Abstract: LLMs are increasingly being integrated into clinical workflows, yet they often lack clinical empathy, an essential aspect of effective doctor-patient communication. Existing NLP frameworks focus on reactively labeling empathy in doctors' responses but offer limited support for anticipatory modeling of empathy needs, especially in general health queries. We introduce the Empathy Applicability Framework (EAF), a theory-driven approach that classifies patient queries in terms of the applicability of emotional reactions and interpretations, based on clinical, contextual, and linguistic cues. We release a benchmark of real patient queries, dual-annotated by Humans and GPT-4o. In the subset with human consensus, we also observe substantial human-GPT alignment. To validate EAF, we train classifiers on human-labeled and GPT-only annotations to predict empathy applicability, achieving strong performance and outperforming the heuristic and zero-shot LLM baselines. Error analysis highlights persistent challenges: implicit distress, clinical-severity ambiguity, and contextual hardship, underscoring the need for multi-annotator modeling, clinician-in-the-loop calibration, and culturally diverse annotation. EAF provides a framework for identifying empathy needs before response generation, establishes a benchmark for anticipatory empathy modeling, and enables supporting empathetic communication in asynchronous healthcare.

</details>


### [61] [Value-Aware Numerical Representations for Transformer Language Models](https://arxiv.org/abs/2601.09706)
*Andreea Dutulescu,Stefan Ruseti,Mihai Dascalu*

Main category: cs.CL

TL;DR: 提出一种数值感知的表示方法：在标准分词输入中增加一个前缀嵌入，该嵌入显式条件化数值大小，使模型直接获得数量级信息；兼容现有分词器与解码器式 Transformer。


<details>
  <summary>Details</summary>
Motivation: Transformer 在数学推理任务中表现良好，但在基本数值理解与算术操作方面脆弱，因为数字被作为符号标记处理，未显式编码数值大小，导致系统性错误。

Method: 通过引入一个专用前缀 token，其嵌入与底层数值条件化相关，向模型输入空间注入数量级信息；该机制可与现有分词器和解码器式 Transformer 架构兼容。

Result: 在算术任务上，该方法在多种数值格式、任务和操作数长度上均优于基线，显示显式编码数值大小是提高数值鲁棒性的有效且高效途径。

Conclusion: 显式编码数值大小的表示方法能够提升语言模型的数值鲁棒性，且实现成本低，兼容性好。

Abstract: Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model's input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [62] [ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue](https://arxiv.org/abs/2601.08950)
*Mayank Sharma,Roy Pea,Hari Subramonyam*

Main category: cs.AI

TL;DR: ConvoLearn 脚本数据集将知识建构式学习纳入人工智能教育场景，通过半合成对话和 QLoRA 微调，将大语言模型的教学行为引导到知识建构策略，并通过教师评估验证其效果。


<details>
  <summary>Details</summary>
Motivation: 解决教育场景中 LLM 的基础 pedagogical 限制，如偏向给出答案而非促进对话式学习，需将 AI 助教对齐到认知参与、形成性评估、问责制、文化响应性、元认知与权力动态等六大维度的知识建构取向。

Method: 构建一个包含 1250 组导师-学生对话的 semi-synthetic 数据集（每组 20 回合），主题为初中地球科学；对话由人类教师与模拟学生的受控交互生成，并覆盖六大教学维度。使用 QLoRA 对 Mistral 7B 进行微调。通过 31 名教师的人工评估，将微调后的模型与基线模型及 Claude Sonnet 4.5 进行对比。

Result: 微调模型在知识建构取向上表现显著提升。教师评估中，微调后的 Mistral 7B 平均分为 4.10（SD=1.03），高于基线 2.59（SD=1.11）和 Claude Sonnet 4.5 的 2.87（SD=1.29）。数据集与评估框架显示构建性 AI 助教的可行性与潜在价值。

Conclusion: 提出一个可操作的框架，用于未来 constructivist AI tutor 的开发与评估，并证明以知识建构为导向的对话型微调可以显著改变 LLM 的教学行为。

Abstract: In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.

</details>


### [63] [ART: Action-based Reasoning Task Benchmarking for Medical AI Agents](https://arxiv.org/abs/2601.08988)
*Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji*

Main category: cs.AI

TL;DR: ART introduces a real-world EHR-based Action-based Reasoning Task benchmark for medical AI agents, targeting retrieval, aggregation, and conditional logic errors. It reveals near-perfect retrieval but substantial gaps in aggregation and threshold reasoning across 600 tasks evaluated on GPT-4o-mini and Claude 3.5 Sonnet; proposes a four-stage pipeline (scenario identification, task generation, quality audit, evaluation) to generate clinically validated tasks.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks inadequately assess action-based reasoning over EHRs, particularly threshold evaluation, temporal aggregation, and conditional logic, leading to overestimated real-world readiness of clinical AI agents.

Method: Four-stage pipeline: (1) scenario identification from real patient data references; (2) task generation that encodes action-based reasoning prompts; (3) quality audit to ensure clinical validity and difficulty; (4) evaluation on large task set (600 tasks) using multiple LLMs/models, with error taxonomy.

Result: The study reports near-perfect retrieval after prompt refinement; substantial gaps in aggregation (28–64%) and threshold reasoning (32–38%) across the evaluated models.

Conclusion: ART reveals critical failure modes in action-oriented EHR reasoning, enabling more reliable clinical AI agents and reducing cognitive load in high-demand care settings; a foundational step toward safer and effective AI-assisted clinical decision making.

Abstract: Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, we identify three dominant error categories: retrieval failures, aggregation errors, and conditional logic misjudgments. Our four-stage pipeline -- scenario identification, task generation, quality audit, and evaluation -- produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28--64%) and threshold reasoning (32--38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings

</details>


### [64] [The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments](https://arxiv.org/abs/2601.09032)
*Logan Ritchie,Sushant Mehta,Nick Heiner,Mason Yu,Edwin Chen*

Main category: cs.AI

TL;DR: Frontier LLM agents were evaluated on 150 workplace tasks in a realistic e-commerce RL environment, revealing a hierarchy of agentic capabilities (tool use, planning, adaptability, groundedness, common-sense). Even the best models fail ~40% of tasks with failures clustering by capability, implying fundamental gaps in practical deployment. The authors propose a task-centric RL design methodology, detailed failure analyses, and discuss implications for future agent development.


<details>
  <summary>Details</summary>
Motivation: To assess how current frontier LLM-based agents perform on diverse, realistic workplace tasks and to identify the core capabilities needed for real-world deployment, guiding evaluation protocols and agent design.

Method: Empirical evaluation of multiple frontier AI models on 150 tasks within Surge's e-commerce reinforcement learning environment. Systematic failure analysis to map failures onto a five-element hierarchy of capabilities; a task-centric RL design methodology emphasizing diversity and domain-expert contributions.

Result: Models exhibit coherent multi-step behaviors but fail about 40% of tasks. Failures cluster along a hierarchy: tool use and planning are weakest in weaker models; stronger models falter on tasks requiring contextual inference beyond explicit instructions. A task-centric design approach and detailed failure analysis are proposed, highlighting domain-expert input and environment diversity as key to robust evaluation.

Conclusion: Current frontier models demonstrate plausible multi-step task execution but still lag human-level performance in realistic settings. Key gaps exist in tool use, planning, adaptability, groundedness, and common-sense reasoning. Addressing these gaps requires redesigned evaluation environments and targeted capability development.

Abstract: The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.

</details>


### [65] [Programming over Thinking: Efficient and Robust Multi-Constraint Planning](https://arxiv.org/abs/2601.09097)
*Derrick Goh Xin Deik,Quanyu Long,Zhengyuan Liu,Nancy F. Chen,Wenya Wang*

Main category: cs.AI

TL;DR: SCOPE通过将推理与代码执行解耦，生成可重复使用的求解器函数，以应对多约束规划的挑战，在准确性、成本和延迟方面实现了显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决纯推理方法在多约束规划中的不一致与高成本，以及将编码/求解器策略硬编码到特定问题的局限性，需提供可泛化、可复用且成本更低的框架。

Method: 提出Scalable Code Planning Engine（SCOPE），将查询特定的推理与通用代码执行分离，生成一致、可复用的求解器函数，输入参数的变动对求解器影响最小，支持跨多问题的可扩展性。

Result: 在 TravelPlanner 任务上，使用 GPT-4o 时达到 93.1% 的成功率，相比最佳基线 CoT 提升 61.6%，推理成本降低约 1.4x，推理时间下降约 4.67x。

Conclusion: SCOPE实现了多约束规划的可扩展、低成本、高效推理，且求解器函数具重复性和可重用性；证据来自 TravelPlanner 的实验，代码已开源。

Abstract: Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.

</details>


### [66] [DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model](https://arxiv.org/abs/2601.09100)
*Lixiang Zhang,Chenggong Zhao,Qing Gao,Xiaoke Zhao,Gengyi Bai,Jinhu Lv*

Main category: cs.AI

TL;DR: 以双系统（快思维/慢思维）大规模语言模型(DScheLLM)实现动态作业车间调度，利用精调的OpenPangu嵌入式7B模型与LoRA，在快速模式下高效生成高质量调度，在慢速模式下生成可与求解器兼容且格式良好的决策输入；为面对多尺度扰动提供通用、可适应的调度框架，是将LLM应用于动态车间调度的早期研究。


<details>
  <summary>Details</summary>
Motivation: 克服传统方法对事件特定模型和显式解析公式的依赖，缺乏对未知扰动的适应性和泛化能力；需要一种能处理不同尺度扰动的动态调度方法，利用大语言模型在推理中的灵活性提升调度鲁棒性。

Method: 构建统一的基于LLM的框架，采用双系统（快思/慢思）推理，使用运筹学求解器生成的真实日程来构建快、慢两种推理模式的训练数据；对Huawei OpenPangu Embedded-7B模型进行LoRA微调，在混合推理范式下训练；在标准 job shop 调度基准上评估，验证两种模式的作用。

Result: 快速模式能高效地产生高质量的调度，慢模式能输出可被求解器直接使用且格式良好的决策输入；这项工作是在动态环境中将LLM应用于作业车间调度的早期研究之一，显示出对智能、自适应调度优化的潜力。

Conclusion: LLM驱动的动态调度结合双系统推理在面对不同尺度扰动时具有更好的适应性；为基于LLM的调度提供普适框架，推动将大模型应用于复杂生产调度的研究与实践。

Abstract: Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.

</details>


### [67] [AviationLMM: A Large Multimodal Foundation Model for Civil Aviation](https://arxiv.org/abs/2601.09105)
*Wenbin Li,Jingling Wu,Xiaoyong Lin. Jing Chen,Cong Chen*

Main category: cs.AI

TL;DR: 提出 AviationLMM 作为面向民航的多模态基础模型愿景，目标整合多源数据以提升态势感知、推理与生成能力，并提出实现路径与研究议题。


<details>
  <summary>Details</summary>
Motivation: 现有民航AI多为孤岛化解决方案，难以融合语音、雷达、传感器、文本等异质数据，导致态势感知不足、实时决策受限及用户体验不佳。

Method: 提出一个面向民航的多模态基础模型架构，输入包括空地语音、监控雷达、机载遥测、视频和结构化文本等，进行跨模态对齐与融合，输出涵盖态势摘要、风险告警、预测诊断和多模态事件重建等灵活任务。并明确未来在数据获取、对齐/融合、预训练、推理、信任性、隐私、对缺失模态的鲁棒性及合成场景生成等方面的研究机会。

Result: 该工作目前属于愿景性/设计性论文，给出架构设计与研究议题，但尚未给出实证结果或系统实现。

Conclusion: 通过明确设计蓝图与研究挑战，旨在推动民航基础模型的发展，构建一个更具整合性、可信赖且隐私保护的航空AI生态系统。

Abstract: Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.

</details>


### [68] [PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?](https://arxiv.org/abs/2601.09152)
*Yiwen Tu,Xuan Liu,Lianhui Qin,Haojian Jin*

Main category: cs.AI

TL;DR: PRA is an AI agent that simulates individual users' privacy concerns and responses to real-world news by grounding in personal histories and cognitive theory, with a judge-based evaluation; it outperforms baselines on Hacker News data and generalizes across domains.


<details>
  <summary>Details</summary>
Motivation: To move beyond population-level sentiment and model individual privacy reasoning, leveraging privacy theory and cognitive processes to generate user-specific reactions and comments.

Method: Constructs a per-user 'privacy mind' and activates privacy memories via a contextual filter to emulate bounded rationality. Generates synthetic comments reflecting likely responses to new privacy scenarios. Uses an LLM-as-a-Judge calibrated to a privacy concern taxonomy to assess faithfulness of the generated reasoning.

Result: Empirical experiments on real-world Hacker News discussions show PRA outperforms baseline agents in predicting privacy concerns and captures transferable reasoning patterns across AI, e-commerce, and healthcare domains.

Conclusion: Demonstrates feasibility of user-centric privacy reasoning simulation and cross-domain transfer, suggesting utility for privacy-aware agent interactions and analyses.

Abstract: This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's "privacy mind", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of generated reasoning. Experiments on real-world Hacker News discussions show that \PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.

</details>


### [69] [Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback](https://arxiv.org/abs/2601.09182)
*JungMin Yun,JuneHyoung Kwon,MiHyeon Kim,YoungBin Kim*

Main category: cs.AI

TL;DR: 本文提出将LLMs从直接生成评审转变为辅助和教育人类评审员的范式，通过两大系统提升评审质量与可持续性。


<details>
  <summary>Details</summary>
Motivation: AI研究快速扩张导致评审人员短缺与评审质量下降的风险，亟需提升评审教育与能力建设，建立高质量同行评审的核心原则。

Method: 确立高质量评审的核心原则；提出两套互补系统：(i) LLM辅助的指导/导师系统，培养评审员的长期能力；(ii) LLM辅助的反馈系统，帮助评审员提高评审质量。

Result: 作为立场论文，未提供实证结果，提出对现有LLM自动化生成评审的批判，给出人机协作的框架，预计提升评审者专业水平和学术生态的可持续性。

Conclusion: 将LLMs定位为辅助工具、教育工具，推动学术评审的长期能力建设与质量提升，呼吁在学术生态中广泛采用以人-机协作为核心的方法。

Abstract: The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.

</details>


### [70] [Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models](https://arxiv.org/abs/2601.09260)
*Yan Liu,Feng Zhang,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Han Liu,Yangdong Deng*

Main category: cs.AI

TL;DR: 将离散的推理步骤重新建模为连续的概率流，量化每一步对答案的贡献，从而提高推理效率与正确性的折中。


<details>
  <summary>Details</summary>
Motivation: 当前链式推理多以一个不可分的序列实现，缺乏对逐步信息增益的量化与指导，导致冗余探索与稀疏监督/昂贵外部校验的难题。

Method: 提出 CoT-Flow，将推理步骤视为流动的概率变量；提出两种方法：flow-guided decoding（基于贪婪的概率流解码，选取信息高效的推理路径）和 flow-based reinforcement learning（使用无校验器的密集奖励函数进行强化学习）。

Result: 在具有挑战性的基准上，CoT-Flow 能在推理效率与推理性能之间取得更优的平衡，优于对比方法。

Conclusion: 通过将推理步骤量化为信息贡献的连续流，CoT-Flow 有望提升可解释性与效率，同时提供可证伪的改进路径。

Abstract: High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.

</details>


### [71] [RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering](https://arxiv.org/abs/2601.09269)
*Wencheng Ye,Liang Peng,Xiaoyang Yuan,Yi Bin,Pengpeng Zeng,Hengyu Jin,Heng Tao Shen*

Main category: cs.AI

TL;DR:  RISER是一种基于路由器的激活空间干预框架，通过自适应地组合可重用的推理向量来引导LLM推理，具有参数高效、无需微调的特性。


<details>
  <summary>Details</summary>
Motivation: 现有的激活干预多为静态、手工设计，难以适应复杂推理的动态性；需要一种参数高效且能自适应地 steering 推理过程的方法.

Method: 构建一个可重复使用的推理向量库；使用一个轻量级的路由器按输入动态组合这些向量；路由器通过强化学习在任务级奖励下进行优化，产生可解释的潜在认知原语的组合

Result: 在七项基准上，RISER相比基础模型实现3.4-6.5%的平均零-shot准确率提升；在Token效率方面超越CoT风格推理，提升约2-3倍；并展现出鲁棒的准确性提升。分析还表明，RISER能自主将多个向量组合为可解释、精准的控制策略

Conclusion: RISER证明了通过在激活空间自适应干预来实现可控且高效的LLM推理的可行性，为后续在推理过程中的可控性和效率提升提供了方向。

Abstract: Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.

</details>


### [72] [$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation](https://arxiv.org/abs/2601.09274)
*Jian Zhang,Yu He,Zhiyuan Wang,Zhangqi Wang,Kai He,Fangzhi Xu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: A^3-Bench 提出一个面向科学推理的记忆驱动基准，通过锚点与吸引子两个尺度的记忆激活来评估推理过程，给出 SAPM 注释方法、AAUI 度量以及双尺度记忆评估框架，并通过多模型实验验证记忆激活对推理性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有基准多关注最终答案或逐步连贯性，未充分揭示人类推理中的记忆驱动机制（需要激活锚点与吸引子并在多步推理中整合），因此需要一个能分析记忆激活的基准来推动科学推理研究。

Method: 1) 使用 SAPM 过程（主体、锚点与吸引子、问题、记忆发展）对 2,198 道科学推理题进行注释；2) 提出双尺度记忆评估框架，结合锚点与吸引子进行记忆测度；3) 引入 AAUI（Anchor--Attractor Utilization Index）指标，用以衡量记忆激活率；4) 在多种基础模型与范式下开展实验，验证基准并分析记忆激活对推理的影响。

Result: 验证表明记忆激活与推理性能存在显著关联；对不同模型与范式的表现进行了系统分析，揭示了记忆驱动的科学推理的关键特征与规律。

Conclusion: A^3-Bench 成功建立了面向记忆驱动推理的评测框架，提供用于测量记忆激活的工具与指标，为理解与提升科学推理中的记忆机制提供了有价值的基线与分析路径。

Abstract: Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.

</details>


### [73] [STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models](https://arxiv.org/abs/2601.09281)
*Jingjing Zhou,Gaoxiang Cong,Li Su,Liang Li*

Main category: cs.AI

TL;DR: STaR是一种无参数、推理时即时移除的隐私保护框架，针对大型推理模型在链式推理中的隐私泄露问题。通过语义感知检测识别敏感内容、采用安全前缀注入全局约束、执行轨迹感知的内容抑制以及逐-token 自适应过滤，保障推理全过程的隐私。提出了两类评估指标：多解码一致性评估（MCS）与多粒度成员攻击评估（MIA），并在R-TOFU基准上实现对隐私保护的全面、稳定的无泄漏与最小性能损失的权衡。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在多步推理中会将敏感信息深嵌于推理过程的中间步骤，造成隐私泄露。现有的无学习/无忘记方法多聚焦最终答案，无法消除中间步骤的敏感内容；需要在推理链全程实现隐私保护。

Method: 1) 语义感知检测敏感内容 2) 安全前缀注入以强制全局安全约束 3) 轨迹感知的抑制，动态屏蔽整条推理链中的敏感信息 4) 逐字/逐词自适应过滤，阻止直接和改写的敏感符号在生成中出现

Result: 在R-TOFU基准上，STaR实现了全面且稳定的无泄漏，且对模型性能影响最小；相较基线，在解码策略多样性下仍保持一致性（MCS），并在答案与推理链层面上提供更强的隐私保护（MIA）。

Conclusion: STaR为LRMs的隐私保护推理树立了新的范式，通过在推理链各环节强制抑制及过滤敏感信息，解决了以往只对最终答案进行无忘记的不足，且通过MCS和MIA等新评估方法给出全面的隐私保护效果评估。

Abstract: Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.

</details>


### [74] [Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing](https://arxiv.org/abs/2601.09282)
*Leszek Sliwko,Jolanta Mizeria-Pietraszko*

Main category: cs.AI

TL;DR: 通过自然语言提示实现的语义软亲和性调度，利用大模型和Kubernetes调度扩展实现，显示出高解析准确性和与基线相比的优越性，但存在LLM延迟等生产化挑战。


<details>
  <summary>Details</summary>
Motivation: 缩小集群作业分配的可用性差距，让用户用自然语言表达意图来影响调度决策，尤其是在软亲和性和复杂/定量场景下。

Method: 构建一个原型系统，包含集群状态缓存和意图分析器（使用AWS Bedrock），通过Kubernetes调度扩展器将LLM用于解析自然语言分配提示（软亲和性偏好）。评估基于真实数据集的子集准确性，以及六种场景下的调度质量，与基线引擎比较。

Result: LLM在顶级模型上达到>95%的子集准确性，显著优于基线。原型在六个场景中实现了优于或等同于标准Kubernetes的放置，尤其在复杂与定量场景及冲突的软偏好处理中表现突出。实验还指出LLM延迟是瓶颈，需异步处理以便生产化。总体验证语义软亲和性用于简化工作负载编排的可行性。

Conclusion: 证明使用LLMs进行语义软亲和性调度的可行性与潜力；但要达到生产就绪需解决同步延迟等问题，未来可通过异步推理、缓存、改进提示等提升性能与鲁棒性。

Abstract: Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.

</details>


### [75] [Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning](https://arxiv.org/abs/2601.09536)
*Dongjie Cheng,Yongqi Li,Zhixin Ma,Hongru Cai,Yupeng Hu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.AI

TL;DR: 提出统一的生成式多模态推理框架，通过在推理过程中生成中间图像来统一多模态推理技能； Omni-R1 采用两阶段 SFT+RL 框架（感知对齐与感知奖励）实现功能性图像生成， Omni-R1-Zero 则通过文本推理数据自举逐步视觉化，减少多模态标注依赖。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型要么仅做文本推理，要么沿用单一任务特定的推理模式，难以泛化到需要多样化推理技能的场景（如定位、标记对象等）。需要一个能够统一多模态推理技能的框架。

Method: 提出统一生成式多模态推理：在推理过程中通过生成中间图像来表示和执行推理步骤。具体实现为 Omni-R1：一个两阶段的监督微调+强化学习（SFT+RL）框架，加入感知对齐损失和感知奖励以实现功能性图像生成；以及 Omni-R1-Zero：利用文本推理数据自举出逐步可视化的中间表示，从而在没有多模态标注的情况下实现推理。

Result: 实验结果表明，Omni-R1 在广泛的多模态任务上实现了统一的生成式推理能力；Omni-R1-Zero 的性能与平均水平上可达到甚至超过 Omni-R1，表现出对生成式多模态推理的有力支撑。

Conclusion: 统一的生成式多模态推理是一个有前景的方向，且通过从文本数据自举中间视觉化的方式，进一步降低了多模态标注的依赖，具备广泛适用性和跨任务泛化潜力。

Abstract: Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.

</details>


### [76] [Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning](https://arxiv.org/abs/2601.09667)
*Zhiyuan Hu,Yunhai Hu,Juncheng Liu,Shuyue Stella Li,Yucheng Wang,Zhen Xu,See-Kiong Ng,Anh Tuan Luu,Xinxing Xu,Bryan Hooi,Cynthia Breazeal,Hae Won Park*

Main category: cs.AI

TL;DR: 提出 MATTRL：在推理时为多智能体系统注入结构化文本经验，通过多专家团队协作、检索与整合测试时经验并就最终决策达成共识，提升鲁棒性与性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，训练代价高、稳定性差，原因包括队友共同适应带来的非平稳性，以及奖励稀疏高方差。需要在推理阶段引入结构化经验以提高稳定性和性能。

Method: 构建由多名专家组成的讨论团队，在推理阶段检索并整合测试时的经验，进行跨回合多轮对话并达成共识以生成决策；研究分配回合级经验池（credit assignment）以引导将经验再注入对话。

Result: 在医学、数学、教育等挑战性基准上，相比多智能体基线平均提升3.67%，相较单智能体基线提升8.67%；通过消融实验比较不同的回合级信用分配方案及其对训练结果的影响，显示该框架在分布偏移下的稳定性和有效性。

Conclusion: MATTRL为无须额外训练即可实现分布偏移鲁棒的多智能体推理提供了一条稳定、有效且高效的路径，适合在推理阶段提升多智能体协作性能。

Abstract: Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\% over a multi-agent baseline, and by 8.67\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [77] [Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas](https://arxiv.org/abs/2601.08901)
*Yuexi Shen,Minqian Liu,Dawei Zhou,Lifu Huang*

Main category: cs.IR

TL;DR: 提出“ Ideation Space ”等结构化知识表征并结合层次子空间检索与分解式新颖性评估，以提高学术文献检索的精准度与新颖性判定。


<details>
  <summary>Details</summary>
Motivation: 解决现有嵌入方法混淆概念维度、无法进行细粒度检索，以及LLM评估易受拍马/阿谀 bias，提出一个三维度知识表征以测量概念距离并捕捉创意转化。

Method: 通过对比学习学习研究问题、方法论、核心发现三维向量；提出层次子空间检索框架实现高效的目标化文献检索；提出分解式新颖性评估算法以识别创意的具体新颖性维度。

Result: 在多项指标上显著提升：Recall@30 0.329（比基线提升16.7%）；Ideation Transition Retrieval的Hit Rate@30为0.643；新颖性评估与专家评判的相关性为0.37。

Conclusion: 为加速和评估科学发现提供一条有前景的新范式，适于未来在文献检索与创新评估领域扩展。

Abstract: Scientific discovery is a cumulative process and requires new ideas to be situated within an ever-expanding landscape of existing knowledge. An emerging and critical challenge is how to identify conceptually relevant prior work from rapidly growing literature, and assess how a new idea differentiates from existing research. Current embedding approaches typically conflate distinct conceptual aspects into single representations and cannot support fine-grained literature retrieval; meanwhile, LLM-based evaluators are subject to sycophancy biases, failing to provide discriminative novelty assessment. To tackle these challenges, we introduce the Ideation Space, a structured representation that decomposes scientific knowledge into three distinct dimensions, i.e., research problem, methodology, and core findings, each learned through contrastive training. This framework enables principled measurement of conceptual distance between ideas, and modeling of ideation transitions that capture the logical connections within a proposed idea. Building upon this representation, we propose a Hierarchical Sub-Space Retrieval framework for efficient, targeted literature retrieval, and a Decomposed Novelty Assessment algorithm that identifies which aspects of an idea are novel. Extensive experiments demonstrate substantial improvements, where our approach achieves Recall@30 of 0.329 (16.7% over baselines), our ideation transition retrieval reaches Hit Rate@30 of 0.643, and novelty assessment attains 0.37 correlation with expert judgments. In summary, our work provides a promising paradigm for future research on accelerating and evaluating scientific discovery.

</details>


### [78] [Fine Grained Evaluation of LLMs-as-Judges](https://arxiv.org/abs/2601.08919)
*Sourav Saha,Mandar Mitra*

Main category: cs.IR

TL;DR: LLMs can serve as relevance judges for IR and can highlight relevant passages, using a Wikipedia/INEX test collection; performance is strongest with human supervision.


<details>
  <summary>Details</summary>
Motivation: Extend prior work on LLMs as judges by evaluating not only document-level relevance but also passage-level justification, using a standardized Wikipedia-based INEX test collection to compare against human assessors.

Method: Utilize the INEX Wikipedia-based test collection; prompt LLMs to judge document relevance and to highlight passages responding to the query; compare LLM-derived judgments and highlighted passages with human relevance assessments and their highlighted passages to assess both correctness and justifications.

Result: LLMs-as-judges show potential but perform best under human supervision; passage-level justification is attainable but not always perfectly aligned with human rationales.

Conclusion: LLMs can assist IR relevance assessment and provide explanations, but a human-in-the-loop remains advisable for reliable results; prompts and evaluation of rationale quality are important avenues for improvement.

Abstract: A good deal of recent research has focused on how Large Language Models
  (LLMs) may be used as `judges' in place of humans to evaluate the quality
  of the output produced by various text / image processing systems. Within
  this broader context, a number of studies have investigated the specific
  question of how effectively LLMs can be used as relevance assessors for
  the standard ad hoc task in Information Retrieval (IR). We extend these
  studies by looking at additional questions. Most importantly, we use a
  Wikipedia based test collection created by the INEX initiative, and
  prompt LLMs to not only judge whether documents are relevant /
  non-relevant, but to highlight relevant passages in documents that it
  regards as useful. The human relevance assessors involved in creating
  this collection were given analogous instructions, i.e., they were asked
  to highlight all passages within a document that respond to the
  information need expressed in a query. This enables us to evaluate the
  quality of LLMs as judges not only at the document level, but to also
  quantify how often these `judges' are right for the right reasons.
  Our findings suggest that LLMs-as-judges work best under human
  supervision.

</details>


### [79] [LLMs Meet Isolation Kernel: Lightweight, Learning-free Binary Embeddings for Fast Retrieval](https://arxiv.org/abs/2601.09159)
*Zhibo Zhang,Yang Xu,Kai Ming Ting,Cam-Tu Nguyen*

Main category: cs.IR

TL;DR: IKE is a learning-free binary embedding method that converts LLM embeddings into binary codes via an ensemble of random partitions (Isolation Kernel), enabling fast, memory-efficient retrieval while maintaining accuracy and outperforming CSR and other compression methods in efficiency-accuracy tradeoffs.


<details>
  <summary>Details</summary>
Motivation: LLM embeddings are high-dimensional, causing substantial storage and retrieval overhead. While methods like Matryoshka Representation Learning (MRL) and Contrastive Sparse Representation (CSR) reduce dimensions, they can degrade retrieval accuracy. A lightweight, accurate, and fast retrieval approach is needed.

Method: IKE constructs an ensemble of random, diverse partitions using Isolation Kernel to estimate a kernel in the LLM embedding space. The embedding is transformed into a binary code without any learning phase. The ensemble mitigates accuracy loss as it grows, enabling robust retrieval with bitwise operations for low memory and fast computation.

Result: Empirical results on multiple text retrieval datasets show up to 16.7x faster retrieval and 16x lower memory usage compared with using raw LLM embeddings, while achieving comparable or better accuracy. Compared to CSR and other compression methods, IKE consistently achieves the best balance between retrieval efficiency and effectiveness.

Conclusion: IKE provides a lightweight, learning-free binary embedding strategy that significantly improves retrieval efficiency (latency and memory) without sacrificing accuracy, offering a favorable trade-off over CSR and related compression approaches.

Abstract: Large language models (LLMs) have recently enabled remarkable progress in text representation. However, their embeddings are typically high-dimensional, leading to substantial storage and retrieval overhead. Although recent approaches such as Matryoshka Representation Learning (MRL) and Contrastive Sparse Representation (CSR) alleviate these issues to some extent, they still suffer from retrieval accuracy degradation. This paper proposes \emph{Isolation Kernel Embedding} or IKE, a learning-free method that transforms an LLM embedding into a binary embedding using Isolation Kernel (IK). IKE is an ensemble of diverse (random) partitions, enabling robust estimation of ideal kernel in the LLM embedding space, thus reducing retrieval accuracy loss as the ensemble grows. Lightweight and based on binary encoding, it offers low memory footprint and fast bitwise computation, lowering retrieval latency. Experiments on multiple text retrieval datasets demonstrate that IKE offers up to 16.7x faster retrieval and 16x lower memory usage than LLM embeddings, while maintaining comparable or better accuracy. Compared to CSR and other compression methods, IKE consistently achieves the best balance between retrieval efficiency and effectiveness.

</details>


### [80] [Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models](https://arxiv.org/abs/2601.09286)
*Hanze Guo,Jianxun Lian,Xiao Zhou*

Main category: cs.IR

TL;DR: 提出 SaD（Sparse and Dense）双视角框架，通过稀疏与密集视图对齐来提升全局信噪比（SNR），解决稀疏数据下的信号-噪声瓶颈；可在简单的矩阵分解模型上达到SOTA，且具备插件化特性，能广泛应用于现有推荐模型。


<details>
  <summary>Details</summary>
Motivation: 在不流行项和强数据稀疏场景下，基于参数的密集嵌入模型遭遇全局SNR上限。需要将密集的语义表达能力与稀疏交互模式的结构信号结合起来，以提升推荐性能。

Method: 提出 SaD，采用轻量级的双向对齐机制：密集视图通过注入语义相关性来丰富稀疏视图，稀疏视图通过显式的结构信号来正则化密集模型；理论分析表明对齐两种视图可获得严格优于单视图的全局SNR；实现上是一个轻量的联合优化/对齐过程，且可无缝应用于现有模型。

Result: 大量实验表明，在双视图对齐下，即使是简单的矩阵分解风格的密集模型也能达到或接近SOTA；在真实基准上持续优于强基线，并在 BarsMatch 基准中排名第一；代码公开。

Conclusion: SaD是可插拔的，能够对现有推荐模型无缝接入，重新强调CF在双视角协同中的潜力。

Abstract: Collaborative Filtering (CF) remains the cornerstone of modern recommender systems, with dense embedding--based methods dominating current practice. However, these approaches suffer from a critical limitation: our theoretical analysis reveals a fundamental signal-to-noise ratio (SNR) ceiling when modeling unpopular items, where parameter-based dense models experience diminishing SNR under severe data sparsity. To overcome this bottleneck, we propose SaD (Sparse and Dense), a unified framework that integrates the semantic expressiveness of dense embeddings with the structural reliability of sparse interaction patterns. We theoretically show that aligning these dual views yields a strictly superior global SNR. Concretely, SaD introduces a lightweight bidirectional alignment mechanism: the dense view enriches the sparse view by injecting semantic correlations, while the sparse view regularizes the dense model through explicit structural signals. Extensive experiments demonstrate that, under this dual-view alignment, even a simple matrix factorization--style dense model can achieve state-of-the-art performance. Moreover, SaD is plug-and-play and can be seamlessly applied to a wide range of existing recommender models, highlighting the enduring power of collaborative filtering when leveraged from dual perspectives. Further evaluations on real-world benchmarks show that SaD consistently outperforms strong baselines, ranking first on the BarsMatch leaderboard. The code is publicly available at https://github.com/harris26-G/SaD.

</details>


### [81] [LISP -- A Rich Interaction Dataset and Loggable Interactive Search Platform](https://arxiv.org/abs/2601.09366)
*Jana Isabelle Friese,Andreas Konstantin Kruff,Philipp Schaer,Norbert Fuhr,Nicola Ferro*

Main category: cs.IR

TL;DR: 提供一个可重用的人机信息检索(IIR)搜索行为数据集与基础设施，支持可重复研究


<details>
  <summary>Details</summary>
Motivation: 研究个体差异和情境因素对IIR中搜索行为的影响，以及开发或验证能够考虑此类变异性的用户仿真器

Method: 数据集包含61名参与者、122个会话的详细交互日志，以及感知速度、主题兴趣、搜索专长和人口统计信息等用户特征；提供完备的研究设置、一个基于网页的感知速度测试，以及一个可用于开展类似用户研究的框架；资源为开放获取，便于重复性研究与资源共享

Result: 构建并发布了可重用的数据集与实验基础设施，促进可重复研究，支持IIR领域的资源共享与用户仿真器的开发/验证；通过示例分析展示数据集潜力

Conclusion: 有助于理解搜索行为的个体差异和情境因素，推进对IIR用户模型的改进与评估，并促进研究者之间的复现性与资源共享

Abstract: We present a reusable dataset and accompanying infrastructure for studying human search behavior in Interactive Information Retrieval (IIR). The dataset combines detailed interaction logs from 61 participants (122 sessions) with user characteristics, including perceptual speed, topic-specific interest, search expertise, and demographic information. To facilitate reproducibility and reuse, we provide a fully documented study setup, a web-based perceptual speed test, and a framework for conducting similar user studies. Our work allows researchers to investigate individual and contextual factors affecting search behavior, and to develop or validate user simulators that account for such variability. We illustrate the datasets potential through an illustrative analysis and release all resources as open-access, supporting reproducible research and resource sharing in the IIR community.

</details>


### [82] [Dissecting Judicial Reasoning in U.S. Copyright Damage Awards](https://arxiv.org/abs/2601.09459)
*Pei-Chi Lo,Thomas Y. Lu*

Main category: cs.IR

TL;DR: Discourse-based LLM methodology (RST + agentic workflow) parses judicial opinions to quantify reasoning in copyright damage awards, revealing cross-circuit variations and improving empirical analysis.


<details>
  <summary>Details</summary>
Motivation: Address unpredictability in damages reasoning due to varying interpretations and factor weightings across circuits under the 1976 Copyright Act; fills a gap in empirical legal scholarship on how reasoning is applied.

Method: Three-stage pipeline: Dataset Construction, Discourse Analysis, Agentic Feature Extraction. Uses Rhetorical Structure Theory (RST) to parse opinions into hierarchical discourse structures and an agentic workflow to extract and label reasoning components with corresponding discourse subtrees.

Result: Discourse-augmented LLM analysis outperforms traditional methods and uncovers unquantified variations in factor weighting across circuits; demonstrates methodological and practical gains.

Conclusion: The framework advances computational legal analysis and provides actionable insights for practitioners, scholars, and policymakers facing inconsistencies in copyright law.

Abstract: Judicial reasoning in copyright damage awards poses a core challenge for computational legal analysis. Although federal courts follow the 1976 Copyright Act, their interpretations and factor weightings vary widely across jurisdictions. This inconsistency creates unpredictability for litigants and obscures the empirical basis of legal decisions. This research introduces a novel discourse-based Large Language Model (LLM) methodology that integrates Rhetorical Structure Theory (RST) with an agentic workflow to extract and quantify previously opaque reasoning patterns from judicial opinions. Our framework addresses a major gap in empirical legal scholarship by parsing opinions into hierarchical discourse structures and using a three-stage pipeline, i.e., Dataset Construction, Discourse Analysis, and Agentic Feature Extraction. This pipeline identifies reasoning components and extract feature labels with corresponding discourse subtrees. In analyzing copyright damage rulings, we show that discourse-augmented LLM analysis outperforms traditional methods while uncovering unquantified variations in factor weighting across circuits. These findings offer both methodological advances in computational legal analysis and practical insights into judicial reasoning, with implications for legal practitioners seeking predictive tools, scholars studying legal principle application, and policymakers confronting inconsistencies in copyright law.

</details>


### [83] [Bridging Semantic Understanding and Popularity Bias with LLMs](https://arxiv.org/abs/2601.09478)
*Renqiang Luo,Dong Zhang,Yupeng Gao,Wen Shi,Mingliang Hou,Jiaying Liu,Zhe Wang,Shuo Yu*

Main category: cs.IR

TL;DR: 提出 FairLRM 框架，通过对 popularity bias 进行项-端与用户端分解，借助带结构化指令的提示让大语言模型（RecLLM）具备对偏差的语义理解，从而提升公平性与推荐准确性；实现于 GitHub。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法多聚焦多样性或长尾覆盖，未充分挖掘偏差的因果语义层面，导致去偏效果和推荐准确性受限。

Method: 将偏差分解为 item-side 与 user-side 两个分量，使用结构化的指令式提示引导 RecLLM 对全局物品分布与个体偏好进行语义理解；超越表层的多样性/去偏目标，提升对偏差根源的语义解释能力。

Result: 实验表明该框架显著提升公平性和推荐准确性，且具有更强的语义理解能力；实现代码公开。

Conclusion: 引入语义层面的偏差理解，提供更可信的去偏方法；FairLRM 为推荐系统中的 popularity bias 提供新的语义化解决路径。

Abstract: Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems, where popular items are often favored at the expense of niche content. Most existing debiasing methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. Consequently, such shallow interpretations limit both their debiasing effectiveness and recommendation accuracy. In this paper, we propose FairLRM, a novel framework that bridges the gap in the semantic understanding of popularity bias with Recommendation via Large Language Model (RecLLM). FairLRM decomposes popularity bias into item-side and user-side components, using structured instruction-based prompts to enhance the model's comprehension of both global item distributions and individual user preferences. Unlike traditional methods that rely on surface-level features such as "diversity" or "debiasing", FairLRM improves the model's ability to semantically interpret and address the underlying bias. Through empirical evaluation, we show that FairLRM significantly enhances both fairness and recommendation accuracy, providing a more semantically aware and trustworthy approach to enhance the semantic understanding of popularity bias. The implementation is available at https://github.com/LuoRenqiang/FairLRM.

</details>


### [84] [Unifying Search and Recommendation in LLMs via Gradient Multi-Subspace Tuning](https://arxiv.org/abs/2601.09496)
*Jujia Zhao,Zihan Wang,Shuaiqun Pan,Suzan Verberne,Zhaochun Ren*

Main category: cs.IR

TL;DR: 提出 Gradient Multi-Subspace Tuning (GEMS)，通过多子空间分解和空域投影在参数高效微调中实现 S&R 的统一建模，缓解梯度干扰并保护通用知识，从而在搜索与推荐任务上提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决在将搜索与推荐统一建模时，参数高效微调（PEFT）面临的梯度冲突与对通用领域知识的漂移问题，提升端到端优化的可行性与扩展性。

Method: 1) 多子空间分解：将共享与任务特定的优化信号分解到互补的低秩子空间，降低梯度干扰。2) 空域投影：将参数更新约束在与通用领域知识正交的子空间，抑制对通用知识的过拟合与知识漂移。

Result: 在基准数据集上，GEMS 在搜索与推荐任务上持续优于现有最优 baselines，显示出更强的有效性。

Conclusion: GEMS 有效缓解梯度冲突并保护通用领域知识，适合在 LLM 框架下实现 S&R 的高效统一建模，具备良好扩展性。

Abstract: Search and recommendation (S&R) are core to online platforms, addressing explicit intent through queries and modeling implicit intent from behaviors, respectively. Their complementary roles motivate a unified modeling paradigm. Early studies to unify S&R adopt shared encoders with task-specific heads, while recent efforts reframe item ranking in both S&R as conditional generation. The latter holds particular promise, enabling end-to-end optimization and leveraging the semantic understanding of LLMs. However, existing methods rely on full fine-tuning, which is computationally expensive and limits scalability. Parameter-efficient fine-tuning (PEFT) offers a more practical alternative but faces two critical challenges in unifying S&R: (1) gradient conflicts across tasks due to divergent optimization objectives, and (2) shifts in user intent understanding caused by overfitting to fine-tuning data, which distort general-domain knowledge and weaken LLM reasoning. To address the above issues, we propose Gradient Multi-Subspace Tuning (GEMS), a novel framework that unifies S&R with LLMs while alleviating gradient conflicts and preserving general-domain knowledge. GEMS introduces (1) \textbf{Multi-Subspace Decomposition}, which disentangles shared and task-specific optimization signals into complementary low-rank subspaces, thereby reducing destructive gradient interference, and (2) \textbf{Null-Space Projection}, which constrains parameter updates to a subspace orthogonal to the general-domain knowledge space, mitigating shifts in user intent understanding. Extensive experiments on benchmark datasets show that GEMS consistently outperforms the state-of-the-art baselines across both search and recommendation tasks, achieving superior effectiveness.

</details>


### [85] [TEMPO: A Realistic Multi-Domain Benchmark for Temporal Reasoning-Intensive Retrieval](https://arxiv.org/abs/2601.09523)
*Abdelrahman Abdallah,Mohammed Ali,Muhammad Abdul-Mageed,Adam Jatowt*

Main category: cs.IR

TL;DR: TEMPO 是首個結合時間推理與跨時期檢索的基準，覆蓋 13 個領域，共 1,730 個需要深度時間推理的複雜查詢，並提供 3,976 個步驟分解與對應的金標文檔，用於多步檢索評估，還引入 Temporal Coverage@k 及 Temporal Precision@k 等新穩健評估指標。對 12 種檢索系統的評估顯示現有方法在時間屬性上的證據完整性與推理還有顯著挑戰；最佳模型 DiVeR 的表現也僅達到 32.0 的 NDCG@10 與 71.4% 的 Temporal Coverage@10。代碼與數據可在 GitHub 上獲得。


<details>
  <summary>Details</summary>
Motivation: 現有的時間維度檢索基準多聚焦於簡單的事實檢索，缺乏對時間演變與跨時期證據綜合的推理能力。實際場景常需對時間演變進行推理與證據整合，因此需要能在時間軸上連貫地檢索與組裝證據的基準。

Method: (1) 提供 1,730 個需要深度時間推理的複雜查詢，涵蓋追蹤變化、辨識趨勢、跨時期證據比較等能力；(2) 以步驟化檢索規劃，包含 3,976 個分解步驟，並將金標文檔分配給各步驟以進行多跳評估；(3) 引入新穎的時間相關指標 Temporal Coverage@k 與 Temporal Precision@k，評估結果是否涵蓋所需時間段；

Result: 對 12 種檢索系統的評估顯示顯著挑戰：最佳模型 DiVeR 在 NDCG@10 上僅 32.0，Temporal Coverage@10 為 71.4%，說明在檢索 temporally complete 證據方面仍具高難度。

Conclusion: TEMPO 提供一個具有挑戰性的基準，旨在推動檢索與 RAG 系統在時間推理能力上的提升。研究方同時提供代碼與數據以促進再現與擴展。

Abstract: Existing temporal QA benchmarks focus on simple fact-seeking queries from news corpora, while reasoning-intensive retrieval benchmarks lack temporal grounding. However, real-world information needs often require reasoning about temporal evolution and synthesizing evidence across time periods. We introduce TEMPO, the first benchmark combining temporal reasoning with reasoning-intensive retrieval across 13 domains. TEMPO features: (1) 1,730 complex queries requiring deep temporal reasoning such as tracking changes, identifying trends, or comparing cross-period evidence; (2) step-wise retrieval planning with 3,976 decomposed steps and gold documents mapped to each step for multi-hop evaluation; and (3) novel temporal metrics including Temporal Coverage@k and Temporal Precision@k measuring whether results span required time periods. Evaluation of 12 retrieval systems reveals substantial challenges: the best model (DiVeR) achieves only 32.0 NDCG@10 and 71.4\% Temporal Coverage@10, demonstrating difficulty in retrieving temporally complete evidence. We believe TEMPO provides a challenging benchmark for improving temporal reasoning in retrieval and RAG systems. Our code and data are available at https://github.com/tempo-bench/Tempo. See also our official website: https://tempo-bench.github.io/.

</details>


### [86] [SpatCode: Rotary-based Unified Encoding Framework for Efficient Spatiotemporal Vector Retrieval](https://arxiv.org/abs/2601.09530)
*Bingde Hu,Enhao Pan,Wanjing Zhou,Yang Gao,Zunlei Feng,Hao Zhong*

Main category: cs.IR

TL;DR: 提出一个统一的时空向量检索框架，将时空和语义嵌入一个一致的相似性空间，具备对连续数据流的可扩展性。核心贡献包括：时空旋转编码、循环增量更新以及基于权重的多模态检索权重自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的时空检索多为对传统向量检索系统的扩展，需外部筛选或专门索引来处理时间和空间约束，导致低效、架构复杂且对异质模态的灵活性不足。需一个与数据流协同、可扩展且对多模态友好的统一框架。

Method: (1) 基于旋转嵌入的统一编码：将时间和位置信息嵌入旋转位置向量中，形成统一的时空语义表示；(2) 循环增量更新机制：实现滑动窗口更新，在不进行全局重新编码或索引重建的前提下高效更新；(3) 加权兴趣检索算法：自适应调整不同模态的权重，实现上下文感知和个性化检索。

Result: 在多个真实数据集上的广泛实验表明，该框架在检索准确率和效率上显著优于现有基线，并对动态数据演化具有鲁棒性。

Conclusion: 所提出的方法在智能系统中的可扩展时空信息检索方面具有有效性和实用性。

Abstract: Spatiotemporal vector retrieval has emerged as a critical paradigm in modern information retrieval, enabling efficient access to massive, heterogeneous data that evolve over both time and space. However, existing spatiotemporal retrieval methods are often extensions of conventional vector search systems that rely on external filters or specialized indices to incorporate temporal and spatial constraints, leading to inefficiency, architectural complexity, and limited flexibility in handling heterogeneous modalities. To overcome these challenges, we present a unified spatiotemporal vector retrieval framework that integrates temporal, spatial, and semantic cues within a coherent similarity space while maintaining scalability and adaptability to continuous data streams. Specifically, we propose (1) a Rotary-based Unified Encoding Method that embeds time and location into rotational position vectors for consistent spatiotemporal representation; (2) a Circular Incremental Update Mechanism that supports efficient sliding-window updates without global re-encoding or index reconstruction; and (3) a Weighted Interest-based Retrieval Algorithm that adaptively balances modality weights for context-aware and personalized retrieval. Extensive experiments across multiple real-world datasets demonstrate that our framework substantially outperforms state-of-the-art baselines in both retrieval accuracy and efficiency, while maintaining robustness under dynamic data evolution. These results highlight the effectiveness and practicality of the proposed approach for scalable spatiotemporal information retrieval in intelligent systems.

</details>


### [87] [Examining DOM Coordinate Effectiveness For Page Segmentation](https://arxiv.org/abs/2601.09543)
*Jason Carpenter,Faaiq Bilal,Eman Ramadan,Zhi-Li Zhang*

Main category: cs.IR

TL;DR: DOM坐标在网页分割中的作用被重新评估，简单向量往往优于复杂向量，且视觉坐标并非必要，正确匹配的向量、聚类算法和页面可达到74%的分割准确率，比原始应用提升约20%。


<details>
  <summary>Details</summary>
Motivation: 填补网页数据提取中对坐标特征的系统性理解缺口，评估DOM坐标、视觉坐标在网页分割中的效果，以提高大规模网页数据的提取与检索性能。

Method: 以网页DOM坐标为研究对象，比较单坐标及多坐标向量、视觉坐标与DOM坐标的表现，结合不同聚类算法和页面进行实验，评估分割准确性。

Result: 结论包括：1）无“一刀切”的最优向量；2）视觉坐标平均劣于DOM坐标约20-30%；3）单坐标向量在多数情况下优于包含68.2%顶级向量的复杂向量；4）若向量、聚类算法与页面匹配得当，可达74%分割准确率，较朴素应用提升约20%。

Conclusion: 结果质疑当前主流的分割向量设计，表明可通过针对DOM坐标的聚类优化实现更高的网页分割效果，并强调需要机制来匹配最佳方法以应用于不同页面。

Abstract: Web pages form a cornerstone of available data for daily human consumption and with the rise of LLM-based search and learning systems a treasure trove of valuable data. The scale of this data and its unstructured format still continue to grow requiring ever more robust automated extraction and retrieval mechanisms. Existing work, leveraging the web pages Document Object Model (DOM), often derives clustering vectors from coordinates informed by the DOM such as visual placement or tree structure. The construction and component value of these vectors often go unexamined. Our work proposes and examines DOM coordinates in a detail to understand their impact on web page segmentation. Our work finds that there is no one-size-fits-all vector, and that visual coordinates under-perform compared to DOM coordinates by about 20-30% on average. This challenges the necessity of including visual coordinates in clustering vectors. Further, our work finds that simple vectors, comprised of single coordinates, fare better than complex vectors constituting 68.2% of the top performing vectors of the pages examined. Finally, we find that if a vector, clustering algorithm, and page are properly matched, one can achieve overall high segmentation accuracy at 74%. This constitutes a 20% improvement over a naive application of vectors. Conclusively, our results challenge the current orthodoxy for segmentation vector creation, opens up the possibility to optimize page segmentation via clustering on DOM coordinates, and highlights the importance of finding mechanisms to match the best approach for web page segmentation.

</details>


### [88] [MM-BRIGHT: A Multi-Task Multimodal Benchmark for Reasoning-Intensive Retrieval](https://arxiv.org/abs/2601.09562)
*Abdelrahman Abdallah,Mohamed Darwish Mounis,Mahmoud Abdalla,Mahmoud SalahEldin Kasem,Mostafa Farouk Senussi,Mohamed Mahmoud,Mohammed Ali,Adam Jatowt,Hyun-Soo Kang*

Main category: cs.IR

TL;DR: MM-BRIGHT 是首个用于多模态推理密集检索的基准，包含 2,803 个真实查询，覆盖 29 个领域，设有四类任务，现有模型在各任务均表现不足，显示明显提升空间。


<details>
  <summary>Details</summary>
Motivation: 现实检索场景中查询往往包含多模态信息（如图表、截图、示意图等），仅文本匹配无法充分推理出相关文档，因此需要评估和推动将视觉推理能力整合到检索模型中的研究。现有文本为主的基准无法覆盖这类推理密集的多模态检索场景。

Method: 提出 MM-BRIGHT 基准数据集，包含 2,803 条真实查询，覆盖 29 个技术领域，设计四个任务层级：text-to-text、multimodal-to-text、multimodal-to-image、multimodal-to-multimodal；提供基线评测并比较 BM25、DiVeR、Nomic-Vision 等模型在不同任务上的性能。

Result: 基线结果显示显著性能差距：文本检索的 BM25 在 text-only 任务上仅获得 8.5 nDCG@10；在 multimodal-to-text 任务中，最强的多模态模型 Nomic-Vision 也仅达到 27.6 nDCG@10，甚至低于文字模型 DiVeR 的 32.2。

Conclusion: 表明当前方法在推理密集型多模态检索任务上仍有较大提升空间，MM-BRIGHT 具备成为下一代多模态推理检索模型测试床的潜力；研究数据与代码公开，促进领域发展。

Abstract: Existing retrieval benchmarks primarily consist of text-based queries where keyword or semantic matching is usually sufficient. Many real-world queries contain multimodal elements, particularly, images such as diagrams, charts, and screenshots that require intensive reasoning to identify relevant documents. To address this gap, we introduce MM-BRIGHT, the first multimodal benchmark for reasoning-intensive retrieval. Our dataset consists of 2,803 real-world queries spanning 29 diverse technical domains, with four tasks of increasing complexity: text-to-text, multimodal-to-text, multimodal-to-image, and multimodal-to-multimodal retrieval. Extensive evaluation reveals that state-of-the-art models struggle across all tasks: BM25 achieves only 8.5 nDCG@10 on text-only retrieval, while the best multimodal model Nomic-Vision reaches just 27.6 nDCG@10 on multimodal-to-text retrieval actually underperforming the best text-only model (DiVeR: 32.2). These results highlight substantial headroom and position MM-BRIGHT as a testbed for next-generation retrieval models that better integrate visual reasoning. Our code and data are available at https://github.com/mm-bright/MM-BRIGHT. See also our official website: https://mm-bright.github.io/.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [89] [Spectral Generative Flow Models: A Physics-Inspired Replacement for Vectorized Large Language Models](https://arxiv.org/abs/2601.08893)
*Andrew Kiruluta*

Main category: cs.LG

TL;DR: 提出 Spectral Generative Flow Models (SGFMs)，以场论与小波域为基础替代 Transformer/扩散模型，通过受约束的随机场演化来生成文本与视频，强调局部算子、谱投影与 Navier–Stokes 式传输，实现稀疏性、尺度分离与物理结构偏置。


<details>
  <summary>Details</summary>
Motivation: 解决基于自注意力的变换模型在长期依赖、跨模态一致性、计算效率方面的局限；通过物理结构与多尺度表示提升长期一致性、通用性与归纳偏置。

Method: 将生成过程建模为在多尺度小波基中的受约束随机偏微分方程的演化；用局部算子、谱投影取代全局自注意力，用 Navier–Stokes 风格的输运实现稳定、相干的传播；提出场论本体论将文本与视频统一为 SPDE 的轨迹；小波域表示带来稀疏性与计算效率；约束性随机流确保稳定性、相干性与不确定性传播。

Result: 当前为概念性框架与理论构想，尚未给出实验结果；声称可实现长期一致性、跨模态通用性及物理结构化的归纳偏置，但需通过实证研究与实现验证。

Conclusion: SGFMs 提出一种新型的生成范式，将场论、谱域表示与受约束随机过程结合，区别于自回归与扩散模型。未来的研究需在训练目标、数值实现、以及与传统基线的对比评估中进行验证。

Abstract: We introduce Spectral Generative Flow Models (SGFMs), a physics-inspired alternative to transformer-based large language models. Instead of representing text or video as sequences of discrete tokens processed by attention, SGFMs treat generation as the evolution of a continuous field governed by constrained stochastic dynamics in a multiscale wavelet basis. This formulation replaces global attention with local operators, spectral projections, and Navier--Stokes-like transport, yielding a generative mechanism grounded in continuity, geometry, and physical structure.
  Our framework provides three key innovations: (i) a field-theoretic ontology in which text and video are unified as trajectories of a stochastic partial differential equation; (ii) a wavelet-domain representation that induces sparsity, scale separation, and computational efficiency; and (iii) a constrained stochastic flow that enforces stability, coherence, and uncertainty propagation. Together, these components define a generative architecture that departs fundamentally from autoregressive modeling and diffusion-based approaches. SGFMs offer a principled path toward long-range coherence, multimodal generality, and physically structured inductive bias in next-generation generative models.

</details>


### [90] [XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation](https://arxiv.org/abs/2601.08896)
*Sahaj Raj Malla,Shreeyash Kayastha,Rumi Suwal,Harish Chandra Bhandari,Rajendra Adhikari*

Main category: cs.LG

TL;DR: XGBoost回归用于NEPSE日度对数收益的一步 ahead预测，20滞后扩展窗口最优，RMSE 0.01345、MAE 0.009814、方向准确率65.15%，超越ARIMA与岭回归基准。


<details>
  <summary>Details</summary>
Motivation: 在波动性高的新兴市场指数中捕捉非线性动态，提供一个可复现的预测基准。

Method: 特征工程：滞后对数收益（最多30天）、滚动波动、14期RSI；XGBoost回归；Optuna超参优化；时间序列交叉验证；回测：扩展窗口与固定长度滑动窗口；评估指标：RMSE、MAE、R^2、方向性准确率；对数收益与重构收盘价。

Result: 最优配置为扩展窗口20滞后；RMSE=0.013450，MAE=0.009814，方向准确率=65.15%，R^2偏低但稳定，显示对非线性动态的建模优势。

Conclusion: 证实梯度提升集成在新兴市场高波动时间序列中的有效性，提供可复现的NEPSE预测基准；强调相对误差减少和方向性预测，结合特征重要性分析提升解释性。

Abstract: This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling window schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R-squared), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration, an expanding window with 20 lags, outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R-squared remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.

</details>


### [91] [Breaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation](https://arxiv.org/abs/2601.08963)
*Adrita Das,Peiran Jiang,Dantong Zhu,Barnabas Poczos,Jose Lugo-Martinez*

Main category: cs.LG

TL;DR: 将直接去噪扩散模型（DDDM）置于反向转移核（RTK）框架之下，给出确定性去噪的理论解释，统一确定性与随机扩散的本质，提升数值稳定性、样本一致性及SE(3)等变性保持，在分子生成任务中实现更快收敛与更高结构保真性。


<details>
  <summary>Details</summary>
Motivation: 解决DDDM在逆过程中的随机性带来的方差、长采样时间和去噊动态图的结构感知不足等瓶颈；提供一个统一的理论框架来连接确定性与随机性扩散过程。

Method: 将DDDM的逆过程表达为近似核算子，并应用RTK框架，将直接去噪视为在噪声样本与干净样本之间的结构化运输映射；通过引入RTK约束实现数值稳定性、消除随机方差、设计可扩展且保留SE(3)对称性的去噪器。

Result: 在GEOM-DRUGS数据集上，RTK引导的确定性去噪实现更快的收敛与更高的结构保真性，同时保持化学有效性；相比随机扩散模型，表现出更好的采样效率与稳定性。

Conclusion: 从理论到实践均提供了显著深入的理解，RTK视角为分子扩散任务的高效、可扩展与稳健性提供了新路线，并伴随代码、模型和数据集的公开。

Abstract: Diffusion models have emerged as a powerful class of generative models for molecular design, capable of capturing complex structural distributions and achieving high fidelity in 3D molecule generation. However, their widespread use remains constrained by long sampling trajectories, stochastic variance in the reverse process, and limited structural awareness in denoising dynamics. The Directly Denoising Diffusion Model (DDDM) mitigates these inefficiencies by replacing stochastic reverse MCMC updates with deterministic denoising step, substantially reducing inference time. Yet, the theoretical underpinnings of such deterministic updates have remained opaque. In this work, we provide a principled reinterpretation of DDDM through the lens of the Reverse Transition Kernel (RTK) framework by Huang et al. 2024, unifying deterministic and stochastic diffusion under a shared probabilistic formalism. By expressing the DDDM reverse process as an approximate kernel operator, we show that the direct denoising process implicitly optimizes a structured transport map between noisy and clean samples. This perspective elucidates why deterministic denoising achieves efficient inference. Beyond theoretical clarity, this reframing resolves several long-standing bottlenecks in molecular diffusion. The RTK view ensures numerical stability by enforcing well-conditioned reverse kernels, improves sample consistency by eliminating stochastic variance, and enables scalable and symmetry-preserving denoisers that respect SE(3) equivariance. Empirically, we demonstrate that RTK-guided deterministic denoising achieves faster convergence and higher structural fidelity than stochastic diffusion models, while preserving chemical validity across GEOM-DRUGS dataset. Code, models, and datasets are publicly available in our project repository.

</details>


### [92] [Continuous Fairness On Data Streams](https://arxiv.org/abs/2601.08976)
*Subhodeep Ghosh,Zhihui Du,Angela Bonifati,Manish Kumar,David Bader,Senjuti Basu Roy*

Main category: cs.LG

TL;DR: Introduces block-level fairness within sliding windows for streaming data, with sketch-based monitoring and optimal reordering to enforce fairness on finer granularity; demonstrates real-time performance and substantial fairness improvements over window-level fairness.


<details>
  <summary>Details</summary>
Motivation: Window-level fairness can be too coarse for large windows in data streams. A finer granularity (block-level) fairness guarantee within each window is desirable to ensure timely and consistent fairness across time.

Method: Define a block-level fairness model within sliding windows. Develop sketch-based data structures to monitor attribute distributions with minimal overhead. Devise optimal, efficient reordering algorithms to fix fairness violations within the current window, with theoretical guarantees.

Result: Empirical evaluation on four real-world streams shows millisecond-level processing and ~30K queries/sec throughput. Reordering improves block-level fairness by up to 95% in some cases and 50–60% on average. Qualitative study favors block-level over window-level fairness.

Conclusion: Block-level fairness provides finer-grained, scalable fairness guarantees in streaming settings, with real-time monitoring and effective reordering mechanisms supported by theoretical guarantees and empirical validation.

Abstract: We study the problem of enforcing continuous group fairness over windows in data streams. We propose a novel fairness model that ensures group fairness at a finer granularity level (referred to as block) within each sliding window. This formulation is particularly useful when the window size is large, making it desirable to enforce fairness at a finer granularity. Within this framework, we address two key challenges: efficiently monitoring whether each sliding window satisfies block-level group fairness, and reordering the current window as effectively as possible when fairness is violated. To enable real-time monitoring, we design sketch-based data structures that maintain attribute distributions with minimal overhead. We also develop optimal, efficient algorithms for the reordering task, supported by rigorous theoretical guarantees. Our evaluation on four real-world streaming scenarios demonstrates the practical effectiveness of our approach. We achieve millisecond-level processing and a throughput of approximately 30,000 queries per second on average, depending on system parameters. The stream reordering algorithm improves block-level group fairness by up to 95% in certain cases, and by 50-60% on average across datasets. A qualitative study further highlights the advantages of block-level fairness compared to window-level fairness.

</details>


### [93] [Physics-Guided Counterfactual Explanations for Large-Scale Multivariate Time Series: Application in Scalable and Interpretable SEP Event Prediction](https://arxiv.org/abs/2601.08999)
*Pranjal Patil,Anli Ji,Berkay Aydin*

Main category: cs.LG

TL;DR: 提出物理引导的反事实解释框架用于时间序列分类，专门针对太阳高能粒子事件预测，能生成物理上可行且可解释的反事实，显著降低 DTW 距离、提高稀疏性、并缩短运行时间，相比 DiCE 等基线具有更高的可解释性和领域可用性。


<details>
  <summary>Details</summary>
Motivation: 解决高频多变量时间序列的可解释性，同时确保生成的反事实遵循物理规律，使其在科学应用中更具可操作性。

Method: 提出 Physics-Guided Counterfactual Explanation 框架，结合时序反事实生成、领域物理约束和高效优化，以提升解的相似性、稀疏性和计算效率，并应用于 SEP 预测任务。

Result: 在 SEP 预测上实现 >80% 的 DTW 距离下降（提升近邻性）、更高的稀疏性、运行时间降低约50%，相对于 DiCE 等最先进基线。

Conclusion: 框架可生成物理可行且有效的反事实解释，为在大规模数据环境中的反事实生成提供可扩展路径，并提升科学领域中的可解释性与可操作性。

Abstract: Accurate prediction of solar energetic particle events is vital for safeguarding satellites, astronauts, and space-based infrastructure. Modern space weather monitoring generates massive volumes of high-frequency, multivariate time series (MVTS) data from sources such as the Geostationary perational Environmental Satellites (GOES). Machine learning (ML) models trained on this data show strong predictive power, but most existing methods overlook domain-specific feasibility constraints. Counterfactual explanations have emerged as a key tool for improving model interpretability, yet existing approaches rarely enforce physical plausibility. This work introduces a Physics-Guided Counterfactual Explanation framework, a novel method for generating counterfactual explanations in time series classification tasks that remain consistent with underlying physical principles. Applied to solar energetic particles (SEP) forecasting, this framework achieves over 80% reduction in Dynamic Time Warping (DTW) distance increasing the proximity, produces counterfactual explanations with higher sparsity, and reduces runtime by nearly 50% compared to state-of-the-art baselines such as DiCE. Beyond numerical improvements, this framework ensures that generated counterfactual explanations are physically plausible and actionable in scientific domains. In summary, the framework generates counterfactual explanations that are both valid and physically consistent, while laying the foundation for scalable counterfactual generation in big data environments.

</details>


### [94] [Universal Dynamics of Warmup Stable Decay: understanding WSD beyond Transformers](https://arxiv.org/abs/2601.09000)
*Annalisa Belloni,Lorenzo Noci,Antonio Orvieto*

Main category: cs.LG

TL;DR: WSD学习率调度的路径在Adam优化下的Pythia式语言模型与CIFAR10的小型CNN上的比较显示，训练信号、优化轨迹要素和尖锐度动态高度相似，暗示高维损失景观在旧/新非凸问题之间存在共性；为研究优化几何性提供新线索。


<details>
  <summary>Details</summary>
Motivation: 探究WSD在非Transformer语言模型中的表现是否具有普遍性，以及学习率调度作为理解损失景观几何的新视角是否可推广到其他非凸优化问题。

Method: 将Adam在Pythia-like语言模型上的WSD路径，与对比CNN在CIFAR10上的路径进行对比分析，关注训练信号、优化轨迹特征和尖锐度动态的定性一致性。

Result: 在两种不同体系结构中，训练信号、优化路径特征和尖锐度动态呈现高度定性相似性。

Conclusion: 结果提示高维优化问题的损失景观具有普遍的几何特征，跨越旧与新型非凸问题；为未来研究提供研究方向，聚焦景观几何在深度学习训练中的作用。

Abstract: The Warmup Stable Decay (WSD) learning rate scheduler has recently become popular, largely due to its good performance and flexibility when training large language models. It remains an open question whether the remarkable performance of WSD - using a decaying learning rate for only a fraction of training compared to cosine decay - is a phenomenon specific to transformer-based language models that can potentially offer new theoretical insights into their training dynamics. Inspired by the usage of learning rate schedulers as a new lens into understanding landscape geometry (e.g., river valley, connected minima, progressive sharpening), in this work we compare the WSD path of the Adam optimizer on a Pythia-like language model to that of a small CNN trained to classify CIFAR10 images. We observe most training signals, optimizer path features, and sharpness dynamics to be qualitatively similar in such architectures. This consistency points to shared geometric characteristics of the loss landscapes of old and new nonconvex problems, and hints to future research questions around the geometry of high dimensional optimization problems.

</details>


### [95] [Meta-learning to Address Data Shift in Time Series Classification](https://arxiv.org/abs/2601.09018)
*Samuel Myren,Nidhi Parikh,Natalie Klein*

Main category: cs.LG

TL;DR: Meta-learning generally offers faster, more stable adaptation to data shift in time-series classification, especially in data-scarce regimes and with smaller models; benefits diminish with more data and larger models; alignment between training and test distributions is the key factor, not mere task diversity; SeisTask benchmark introduced.


<details>
  <summary>Details</summary>
Motivation: Data shift in real-world time-series degrades traditional deep learning. There is a need to evaluate whether meta-learning can provide rapid, label-efficient adaptation across varying scenarios and to establish a standard benchmark for adaptive learning in time-series.

Method: Systematic comparison of traditional deep learning (TDL), fine-tuning, and optimization-based meta-learning algorithms on time-series classification. Introduction of SeisTask, a controlled, task-oriented seismic benchmark. Experiments vary data availability, model capacity, and task diversity to assess adaptation speed, stability, and overfitting.

Result: Meta-learning achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller models. As data availability and model capacity increase, the advantage diminishes and TDL with fine-tuning attains comparable performance. Task alignment between training and test distributions, rather than diversity alone, drives meta-learning gains.

Conclusion: The work provides a systematic evaluation of when meta-learning outperforms TDL under data shift in time-series, clarifies the conditions under which it is advantageous, and introduces SeisTask as a benchmark to advance adaptive learning research in time-series domains.

Abstract: Across engineering and scientific domains, traditional deep learning (TDL) models perform well when training and test data share the same distribution. However, the dynamic nature of real-world data, broadly termed \textit{data shift}, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. Here, we systematically compare TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. We introduce a controlled, task-oriented seismic benchmark (SeisTask) and show that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, we examine how task diversity influences meta-learning and find that alignment between training and test distributions, rather than diversity alone, drives performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.

</details>


### [96] [SCaLE: Switching Cost aware Learning and Exploration](https://arxiv.org/abs/2601.09042)
*Neelkamal Bhuyan,Debankur Mukherjee,Adam Wierman*

Main category: cs.LG

TL;DR: SCaLE: 首个在高维动态二次击中成本和 ℓ2 切换成本、带噪声带罚的带目信号下实现分布无关子线性动态遗憾的算法；并给出谱分析的动态遗憾分解与实验验证。


<details>
  <summary>Details</summary>
Motivation: 解决带来在线凸优化中动态成本可扩展的问题，特别是在高维、含动态二次击中成本与 ℓ2 切换成本且反馈含噪声的情景下，仍能获得子线性动态遗憾且对环境分布无关。

Method: 提出 SCaLE 算法，并进行谱遗憾分析，将遗憾分解为特征值误差驱动的遗憾和特征基向量扰动驱动的遗憾；在噪声带反馈的带来设置下实现鲁棒性分析。

Result: 给出在广义随机环境下的分布无关子线性动态遗憾界；谱分析揭示两类误差对遗憾的贡献；大量数值实验与在线学习基线比较，验证算法效果并显示统计一致性。

Conclusion: SCaLE 提供了一个在带噪声带来带高维结构成本的情况下实现动态遗憶的理论与实证框架，通过谱分解提升对遗憾来源的理解，并支持广义随机环境下的鲁棒性。

Abstract: This work addresses the fundamental problem of unbounded metric movement costs in bandit online convex optimization, by considering high-dimensional dynamic quadratic hitting costs and $\ell_2$-norm switching costs in a noisy bandit feedback model. For a general class of stochastic environments, we provide the first algorithm SCaLE that provably achieves a distribution-agnostic sub-linear dynamic regret, without the knowledge of hitting cost structure. En-route, we present a novel spectral regret analysis that separately quantifies eigenvalue-error driven regret and eigenbasis-perturbation driven regret. Extensive numerical experiments, against online-learning baselines, corroborate our claims, and highlight statistical consistency of our algorithm.

</details>


### [97] [Deep Incomplete Multi-View Clustering via Hierarchical Imputation and Alignment](https://arxiv.org/abs/2601.09051)
*Yiming Du,Ziyu Wang,Jian Li,Rui Ning,Lusi Li*

Main category: cs.LG

TL;DR: DIMVC-HIA is a deep IMVC framework that combines hierarchical imputation, energy-based semantic alignment, and contrastive assignment alignment with view-specific encoders and a shared clustering predictor to handle incomplete multi-view data, yielding improved clustering under missingness.


<details>
  <summary>Details</summary>
Motivation: IMVC faces three core challenges: (i) imputing missing views without bias that preserves semantic consistency across views; (ii) maintaining intra-cluster compactness; (iii) ensuring cross-view consistency of cluster assignments.

Method: 1) Use view-specific autoencoders to extract latent features and a view-shared clustering predictor for soft cluster assignments. 2) Hierarchical imputation: first infer missing cluster assignments from cross-view contrastive similarity, then reconstruct missing features using intra-view and intra-cluster statistics. 3) Energy-based semantic alignment to promote intra-cluster compactness by minimizing energy variance around low-energy cluster anchors. 4) Contrastive assignment alignment to strengthen cross-view consistency and produce confident, well-separated predictions.

Result: Experiments on benchmark datasets show superior clustering performance across varying levels of missingness compared to baselines.

Conclusion: DIMVC-HIA effectively integrates hierarchical imputation, energy-based alignment, and contrastive assignment alignment to address incomplete multi-view clustering, achieving robust performance under missing data and improved cross-view consistency.

Abstract: Incomplete multi-view clustering (IMVC) aims to discover shared cluster structures from multi-view data with partial observations. The core challenges lie in accurately imputing missing views without introducing bias, while maintaining semantic consistency across views and compactness within clusters. To address these challenges, we propose DIMVC-HIA, a novel deep IMVC framework that integrates hierarchical imputation and alignment with four key components: (1) view-specific autoencoders for latent feature extraction, coupled with a view-shared clustering predictor to produce soft cluster assignments; (2) a hierarchical imputation module that first estimates missing cluster assignments based on cross-view contrastive similarity, and then reconstructs missing features using intra-view, intra-cluster statistics; (3) an energy-based semantic alignment module, which promotes intra-cluster compactness by minimizing energy variance around low-energy cluster anchors; and (4) a contrastive assignment alignment module, which enhances cross-view consistency and encourages confident, well-separated cluster predictions. Experiments on benchmarks demonstrate that our framework achieves superior performance under varying levels of missingness.

</details>


### [98] [MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting](https://arxiv.org/abs/2601.09085)
*Kangda Wei,Ruihong Huang*

Main category: cs.LG

TL;DR: MMR-GRPO 在 GRPO 框架中引入最大边际相关度，通过基于完成多样性的重加权奖励来提升学习信号，能在峰值性能相当的前提下显著降低训练步数和墙钟时间。


<details>
  <summary>Details</summary>
Motivation: GRPO 常需使用多次完成以提供学习信号，导致计算成本高且边际收益随重复解下降。需要通过提高完成的语义多样性来提升每次更新的信息量与收敛速度。

Method: 将 Maximal Marginal Relevance 应用于奖励加权，使不同完成的语义多样性直接影响其贡献大小，从而引导模型偏向高信息量、互补性强的解集合。

Result: 在模型规模为1.5B、7B、8B的三种模型、三种 GRPO 变体和五个数学推理基准上，MMR-GRPO 实现了峰值性能相当的同时，平均减少训练步数47.9%，墙钟时间70.2%，且各组别间结果稳定一致。

Conclusion: 该方法对降低训练成本、提升学习效率具有鲁棒性，且将发布代码、训练模型与实验协议以便复现实验。

Abstract: Group Relative Policy Optimization (GRPO) has become a standard approach for training mathematical reasoning models; however, its reliance on multiple completions per prompt makes training computationally expensive. Although recent work has reduced the number of training steps required to reach peak performance, the overall wall-clock training time often remains unchanged or even increases due to higher per-step cost. We propose MMR-GRPO, which integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity. Our key insight is that semantically redundant completions contribute limited marginal learning signal; prioritizing diverse solutions yields more informative updates and accelerates convergence. Extensive evaluations across three model sizes (1.5B, 7B, 8B), three GRPO variants, and five mathematical reasoning benchmarks show that MMR-GRPO achieves comparable peak performance while requiring on average 47.9% fewer training steps and 70.2% less wall-clock time. These gains are consistent across models, methods, and benchmarks. We will release our code, trained models, and experimental protocols.

</details>


### [99] [Resolving Predictive Multiplicity for the Rashomon Set](https://arxiv.org/abs/2601.09071)
*Parian Haghighat,Hadis Anahideh,Cynthia Rudin*

Main category: cs.LG

TL;DR: Rashomon set causes predictive multiplicity where multiple equally accurate models disagree in predictions. Proposes three post-hoc remedies—outlier correction, local patching, and pairwise reconciliation—to reduce prediction inconsistency. These can be used together or separately and distilled into a single interpretable model; experiments show reduced disagreement with competitive accuracy.


<details>
  <summary>Details</summary>
Motivation: In high-stakes applications, having multiple models with similar accuracy but different predictions erodes trust. Reducing predictive multiplicity improves consistency and reliability without sacrificing performance.

Method: 1) Outlier correction: fix labels that no good models can predict correctly to reduce local variance. 2) Local patching: in a test-point vicinity, detect and correct biases using a validation set to reduce local disagreement. 3) Pairwise reconciliation: identify model pairs that disagree around the test point and adjust predictions to reduce bias. These can be combined and the reconciled predictions distilled into a single interpretable model.

Result: Across multiple datasets, the methods reduce disagreement metrics while maintaining competitive accuracy.

Conclusion: The approaches either individually or jointly reduce predictive multiplicity, yielding more consistent predictions and enabling deployment of a single interpretable model; future work could explore interactions, scalability, and applicability to diverse model classes.

Abstract: The existence of multiple, equally accurate models for a given predictive task leads to predictive multiplicity, where a ``Rashomon set'' of models achieve similar accuracy but diverges in their individual predictions. This inconsistency undermines trust in high-stakes applications where we want consistent predictions. We propose three approaches to reduce inconsistency among predictions for the members of the Rashomon set. The first approach is \textbf{outlier correction}. An outlier has a label that none of the good models are capable of predicting correctly. Outliers can cause the Rashomon set to have high variance predictions in a local area, so fixing them can lower variance. Our second approach is local patching. In a local region around a test point, models may disagree with each other because some of them are biased. We can detect and fix such biases using a validation set, which also reduces multiplicity. Our third approach is pairwise reconciliation, where we find pairs of models that disagree on a region around the test point. We modify predictions that disagree, making them less biased. These three approaches can be used together or separately, and they each have distinct advantages. The reconciled predictions can then be distilled into a single interpretable model for real-world deployment. In experiments across multiple datasets, our methods reduce disagreement metrics while maintaining competitive accuracy.

</details>


### [100] [SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache](https://arxiv.org/abs/2601.09083)
*Chi-Chih Chang,Siqi Zhu,Zhichen Zeng,Haibin Lin,Jiaxuan You,Mohamed S. Abdelfattah,Ziheng Jiang,Xuehai Qian*

Main category: cs.LG

TL;DR: 提出基于逐树缓存的推演加速方法SRT，用于在策略梯度强化学习中对语言模型进行推演解码（speculative decoding），在不损害分布一致性的前提下显著降低推理延迟，最大实现约2.08x的墙钟加速，且可嵌入到PPO、GRPO、DAPO等标准RL管线及多轮对话场景。


<details>
  <summary>Details</summary>
Motivation: 对语言模型的on-policy RL中，rollout成本高、延迟大，需在保持分布正确性的同时提升效率。

Method: 为每个提示构建一个树结构缓存，存储先前生成的连续文本。在生成时，当前策略以该树作为草案模型进行推演解码（draft model）。通过在线从正在进行的rollout更新缓存，并在GPU空闲时主动执行run-ahead推演。将SRT集成到标准RL管线（如PPO、GRPO、DAPO）和多轮对话设置中。

Result: 显著降低生成与步延迟、降低每token推理成本，在 rollout 阶段实现最高约2.08x的墙钟时间加速。

Conclusion: SRT能够在不牺牲分布正确性的前提下，为语言模型的on-policy RL提供有效的推演加速，易于与现有RL管线集成，适用于多轮对话等场景。

Abstract: We present Speculative Rollout with Tree-Structured Cache (SRT), a simple, model-free approach to accelerate on-policy reinforcement learning (RL) for language models without sacrificing distributional correctness. SRT exploits the empirical similarity of rollouts for the same prompt across training steps by storing previously generated continuations in a per-prompt tree-structured cache. During generation, the current policy uses this tree as the draft model for performing speculative decoding. To keep the cache fresh and improve draft model quality, SRT updates trees online from ongoing rollouts and proactively performs run-ahead generation during idle GPU bubbles. Integrated into standard RL pipelines (\textit{e.g.}, PPO, GRPO and DAPO) and multi-turn settings, SRT consistently reduces generation and step latency and lowers per-token inference cost, achieving up to 2.08x wall-clock time speedup during rollout.

</details>


### [101] [Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning](https://arxiv.org/abs/2601.09088)
*Shaotian Yan,Kaiyuan Liu,Chen Shen,Bing Wang,Sinan Fan,Jun Zhang,Yue Wu,Zheng Wang,Jieping Ye*

Main category: cs.LG

TL;DR: DASD-4B-Thinking 提出一种增强的序列级蒸馏训练管线，基于开源推理模型，在数学、科学推理和代码生成等挑战性基准上达到 SOTA，且训练样本极少（448K），公开模型与数据集。


<details>
  <summary>Details</summary>
Motivation: 批判性地重新审视以 SFT 为核心的教师输出蒸馏，指出现有方法未充分体现蒸馏本质：学习教师的完整输出分布以提升泛化，暴露出三大问题：1) 教师序列分布表示不足；2) 教师输出与学生学习能力不匹配；3) 教师强制训练导致暴露偏差。强调需建立教师-学生交互的蒸馏框架。

Method: 提出一组增强的序列级蒸馏训练管线，改进教师分布表示、对齐学生学习能力、缓解暴露偏差，并解决教师-学生间交互缺失的问题；与现有 SFT 导向的过滤策略不同，强调通过蒸馏学习教师的完整输出分布来提升泛化。摘要未给出具体技术细节，但核心在于扩展教师-学生互动的蒸馏框架。

Result: 在开放源代码模型中，与同等规模的模型相比，在数学、科学推理和代码生成等任务上达到最先进水平；甚至优于若干更大规模模型；仅使用 448K 训练样本，显著低于现有开源努力；公开发布模型与训练数据。

Conclusion: 强调蒸馏核心原理的重要性与可行性，证明增强的序列级蒸馏可实现高效、低成本的强大推理能力，并促进社区研究。

Abstract: In this report, we introduce DASD-4B-Thinking, a lightweight yet highly capable, fully open-source reasoning model. It achieves SOTA performance among open-source models of comparable scale across challenging benchmarks in mathematics, scientific reasoning, and code generation -- even outperforming several larger models. We begin by critically reexamining a widely adopted distillation paradigm in the community: SFT on teacher-generated responses, also known as sequence-level distillation. Although a series of recent works following this scheme have demonstrated remarkable efficiency and strong empirical performance, they are primarily grounded in the SFT perspective. Consequently, these approaches focus predominantly on designing heuristic rules for SFT data filtering, while largely overlooking the core principle of distillation itself -- enabling the student model to learn the teacher's full output distribution so as to inherit its generalization capability. Specifically, we identify three critical limitations in current practice: i) Inadequate representation of the teacher's sequence-level distribution; ii) Misalignment between the teacher's output distribution and the student's learning capacity; and iii) Exposure bias arising from teacher-forced training versus autoregressive inference. In summary, these shortcomings reflect a systemic absence of explicit teacher-student interaction throughout the distillation process, leaving the essence of distillation underexploited. To address these issues, we propose several methodological innovations that collectively form an enhanced sequence-level distillation training pipeline. Remarkably, DASD-4B-Thinking obtains competitive results using only 448K training samples -- an order of magnitude fewer than those employed by most existing open-source efforts. To support community research, we publicly release our models and the training dataset.

</details>


### [102] [Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.09093)
*Zhixiang Liang,Beichen Huang,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: STEP通过步级推理评估与显存感知裁剪，在生成过程中动态裁剪不良轨迹，显著降低端到端延迟并提升推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性或置信度的裁剪信号不能可靠反映轨迹质量，长推理链条与多次采样带来高计算与延迟，需要更直接的轨迹质量信号和内存感知裁剪。

Method: 训练一个轻量级的步级打分器来估计每步的轨迹质量，并设计GPU显存感知的裁剪策略，在KV缓存被占满时触发裁剪以降低延迟；通过与自洽(Self-Consistency)基线比较，在多项推理基准上评估。

Result: 在挑战性推理基准上，STEP平均将端到端推理延迟减少约45%-70%，同时提高推理准确性；代码公开发布。

Conclusion: STEP通过步级评估与内存感知裁剪，能有效提升大语言模型推理的效率与质量，适合降低实时推理成本的场景。

Abstract: Large Language Models (LLMs) can enhance reasoning capabilities through test-time scaling by generating multiple traces. However, the combination of lengthy reasoning traces with multiple sampling introduces substantial computation and high end-to-end latency. Prior work on accelerating this process has relied on similarity-based or confidence-based pruning, but these signals do not reliably indicate trace quality. To address these limitations, we propose STEP: Step-level Trace Evaluation and Pruning, a novel pruning framework that evaluates reasoning steps using hidden states and dynamically prunes unpromising traces during generation. We train a lightweight step scorer to estimate trace quality, and design a GPU memory-aware pruning strategy that triggers pruning as the GPU memory is saturated by KV cache to reduce end-to-end latency. Experiments across challenging reasoning benchmarks demonstrate that STEP reduces end-to-end inference latency by 45%-70% on average compared to self-consistency while also improving reasoning accuracy. Our code is released at: https://github.com/Supercomputing-System-AI-Lab/STEP

</details>


### [103] [Enhancing Imbalanced Electrocardiogram Classification: A Novel Approach Integrating Data Augmentation through Wavelet Transform and Interclass Fusion](https://arxiv.org/abs/2601.09103)
*Haijian Shao,Wei Liu,Xing Deng,Daze Lu*

Main category: cs.LG

TL;DR: 通过波形变换的特征融合在 ECG 分类中同时缓解类不平衡和噪声问题，在 CPSC 2018 数据集上获得优异性能，声称超越现有算法。


<details>
  <summary>Details</summary>
Motivation: ECG 数据存在严重的类不平衡和噪声干扰，深度学习在此背景下的鲁棒性受限；现有过采样/信号增强方法对 ECG 的有效性尚无明确共识，需要一种能同时处理两方面挑战的统一解决方案。

Method: 应用基于小波变换的特征融合，聚焦类间融合以构建训练和测试特征库；将原始数据与其特征库合并，生成更平衡的训练与测试数据集；在 CPSC 2018 数据集上进行评估，声称该融合方法在 ECG 分类上达到更高的准确率，并超过现有算法。

Result: 对 Normal、AF、I-AVB、LBBB、RBBB、PAC、PVC、STD、STE 九个类别的识别准确率分别为 99%、98%、97%、98%、96%、92%、93%、未给出、未给出；总体平均准确率在 92%-98% 区间，宣称超越所有已知算法。

Conclusion: 所提出的波形变换基础的互类融合数据融合策略，在 CPSC 2018 数据集上显著提升了 ECG 分类性能，达到或接近当前领域的最佳水平。

Abstract: Imbalanced electrocardiogram (ECG) data hampers the efficacy and resilience of algorithms in the automated processing and interpretation of cardiovascular diagnostic information, which in turn impedes deep learning-based ECG classification. Notably, certain cardiac conditions that are infrequently encountered are disproportionately underrepresented in these datasets. Although algorithmic generation and oversampling of specific ECG signal types can mitigate class skew, there is a lack of consensus regarding the effectiveness of such techniques in ECG classification. Furthermore, the methodologies and scenarios of ECG acquisition introduce noise, further complicating the processing of ECG data. This paper presents a significantly enhanced ECG classifier that simultaneously addresses both class imbalance and noise-related challenges in ECG analysis, as observed in the CPSC 2018 dataset. Specifically, we propose the application of feature fusion based on the wavelet transform, with a focus on wavelet transform-based interclass fusion, to generate the training feature library and the test set feature library. Subsequently, the original training and test data are amalgamated with their respective feature databases, resulting in more balanced training and test datasets. Employing this approach, our ECG model achieves recognition accuracies of up to 99%, 98%, 97%, 98%, 96%, 92%, and 93% for Normal, AF, I-AVB, LBBB, RBBB, PAC, PVC, STD, and STE, respectively. Furthermore, the average recognition accuracy for these categories ranges between 92\% and 98\%. Notably, our proposed data fusion methodology surpasses any known algorithms in terms of ECG classification accuracy in the CPSC 2018 dataset.

</details>


### [104] [EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge](https://arxiv.org/abs/2601.09142)
*Shijian Ma,Yan Lin,Yi Yang*

Main category: cs.LG

TL;DR: 提出 EvasionBench 数据集（3万训练样本、1千测试样本，Cohen’s Kappa 0.835，覆盖三种回避级别）以及基于多模型冲突的边界样本挖掘标注框架；通过 judge 决标签，提升 evasive 答案检测的泛化能力；4B 参数模型 Eva-4B 达到 81.3% 准确率，较基线提升 25 点，接近前沿 LLM 性能且推理成本更低。


<details>
  <summary>Details</summary>
Motivation: 缺乏大规模、可重复标注的一致基准来训练和评估对 Earnings Call 回避性回答的检测模型；对强大 LLM 的标注分歧可揭示难样本，使训练更具目标性。

Method: 建立多模型标注框架：两名强注释者对样本独立标注，发现并挑选冲突的边界样本；由第三方 judge 对冲突样本进行最终判定标签；用该数据训练 Eva-4B，并与单模型蒸馏进行对比，分析冲突样本对泛化和正则化的影响。

Result: 相较单模型蒸馏，提升约 2.4%；经 judge 解决的样本提升泛化能力，尽管训练损失更高（0.421 对 0.393），显示 disagreement mining 具有隐式正则化效果； Eva-4B（4B）达 81.3% 的准确率，比基线高 25 个百分点，接近前沿 LLM 的性能，同时显著降低推理成本。

Conclusion: 通过冲突挖掘来发现高价值训练样本，并结合 judge 决策实现数据整合，能提升小模型在复杂回避检测任务中的表现，同时以更低成本趋近前沿模型，填补领域缺失的大规模基准。

Abstract: Detecting evasive answers in earnings calls is critical for financial transparency, yet progress is hindered by the lack of large-scale benchmarks. We introduce EvasionBench, comprising 30,000 training samples and 1,000 human-annotated test samples (Cohen's Kappa 0.835) across three evasion levels. Our key contribution is a multi-model annotation framework leveraging a core insight: disagreement between frontier LLMs signals hard examples most valuable for training. We mine boundary cases where two strong annotators conflict, using a judge to resolve labels. This approach outperforms single-model distillation by 2.4 percent, with judge-resolved samples improving generalization despite higher training loss (0.421 vs 0.393) - evidence that disagreement mining acts as implicit regularization. Our trained model Eva-4B (4B parameters) achieves 81.3 percent accuracy, outperforming its base by 25 percentage points and approaching frontier LLM performance at a fraction of inference cost.

</details>


### [105] [Discrete Solution Operator Learning for Geometry-Dependent PDEs](https://arxiv.org/abs/2601.09143)
*Jinshuai Bai,Haolin Li,Zahra Sharif Khodaei,M. H. Aliabadi,YuanTong Gu,Xi-Qiao Feng*

Main category: cs.LG

TL;DR: 提出离散解算子学习DiSOL，通过对求解器进行可学习的阶段分解，模仿经典离散化流程来处理几何引起的离散结构变化。实现对几何敏感问题的稳定、准确预测，具备在分布外几何和断边/拓扑变化下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子学习依赖于在连续函数空间上的平滑变化假设；而工程问题中，几何结构的离散变化（拓扑变化、边界类型变化、有效计算域变化）破坏该假设，需引入面向离散求解过程的表示与学习。

Method: DiSOL将求解器分解为可学习阶段，仿照离散化过程：局部贡献编码、分尺度组装、在嵌入网格上的隐式解重建。通过保持过程级一致性来适应几何相关的离散结构。

Result: 在泊松、对流扩散、线性弹性及时空热传导等几何相关问题上，DiSOL在分布内外几何（包括不连续边界和拓扑变化）下均能提供稳定、准确的预测。证实了在几何主导的情形下，程序性算子表示的必要性，且DiSOL构成科学机器学习的互补方向。

Conclusion: 需要面向几何-dominated regimes的程序化算子表示；DiSOL展示了将求解过程离散化为可学习组件的可行性与优势。

Abstract: Neural operator learning accelerates PDE solution by approximating operators as mappings between continuous function spaces. Yet in many engineering settings, varying geometry induces discrete structural changes, including topological changes, abrupt changes in boundary conditions or boundary types, and changes in the effective computational domain, which break the smooth-variation premise. Here we introduce Discrete Solution Operator Learning (DiSOL), a complementary paradigm that learns discrete solution procedures rather than continuous function-space operators. DiSOL factorizes the solver into learnable stages that mirror classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, thereby preserving procedure-level consistency while adapting to geometry-dependent discrete structures. Across geometry-dependent Poisson, advection-diffusion, linear elasticity, as well as spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes. These results highlight the need for procedural operator representations in geometry-dominated regimes and position discrete solution operator learning as a distinct, complementary direction in scientific machine learning.

</details>


### [106] [KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education](https://arxiv.org/abs/2601.09156)
*Woojin Kim,Changkwon Lee,Hyeoncheol Kim*

Main category: cs.LG

TL;DR: 提出面向知识追踪的对因解释生成方法 KTCF，并通过后处理将解释转化为教育指令，提升预测性能并降低学习负担。


<details>
  <summary>Details</summary>
Motivation: 解决教育领域对可解释且可操作的AI辅助教学需求，利用对因解释的局部性和因果性特征，提升教育决策的可理解性与实施性。

Method: 提出 KTCF：在知识概念关系下生成对因解释；并设计一个后处理阶段将对因解释转化为一序列教育指令的过程。大规模数据集实验，比较现有方法，指标提升范围为 5.7%–34%。

Result: KTCF 在多项指标上优于现有方法，表现具鲁棒性；后处理方案生成的教育指令在降低学习负担方面具有良好定性证据。

Conclusion: 对教育领域中的AI应用具有更高的责任性和实用性；未来工作可在教育学视角的概念化和利益相关者导向方法上进一步深化。

Abstract: Using Artificial Intelligence to improve teaching and learning benefits greater adaptivity and scalability in education. Knowledge Tracing (KT) is recognized for student modeling task due to its superior performance and application potential in education. To this end, we conceptualize and investigate counterfactual explanation as the connection from XAI for KT to education. Counterfactual explanations offer actionable recourse, are inherently causal and local, and easy for educational stakeholders to understand who are often non-experts. We propose KTCF, a counterfactual explanation generation method for KT that accounts for knowledge concept relationships, and a post-processing scheme that converts a counterfactual explanation into a sequence of educational instructions. We experiment on a large-scale educational dataset and show our KTCF method achieves superior and robust performance over existing methods, with improvements ranging from 5.7% to 34% across metrics. Additionally, we provide a qualitative evaluation of our post-processing scheme, demonstrating that the resulting educational instructions help in reducing large study burden. We show that counterfactuals have the potential to advance the responsible and practical use of AI in education. Future works on XAI for KT may benefit from educationally grounded conceptualization and developing stakeholder-centered methods.

</details>


### [107] [Efficient Clustering in Stochastic Bandits](https://arxiv.org/abs/2601.09162)
*G Dhinesh Chandran,Kota Srinivas Reddy,Srikrishna Bhashyam*

Main category: cs.LG

TL;DR: 提出在固定置信度设定下的 Bandit Clustering（BC）问题，允许同簇内的分布不同，拓展至向量参数的广义分布；提出高效的 EBC 与简化变体 EBC-H，在每步仅向最近优解方向前进以替代全优化的采样策略，保持渐近最优性并显著降低计算成本；通过对合成及真实数据的仿真验证其渐近最优性与相较现有方法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 BC 结果多假设簇内臂为高斯分布且需要在每一步求解完整优化问题，计算成本高，且簇内臂可能具有不同的分布。需要在更广的向量参数分布下的鲁棒性与低计算成本之间取得平衡，且要在固定置信度条件下可靠地完成簇并集。

Method: 将 BC 问题建模在固定置信度框架；提出 EBC 算法，在每一步仅朝着最优值的方向迈出一个梯度/步长（而非完整求解优化问题），以实现计算效率；提出 EBC-H，进一步简化采样规则，选臂基于停止规则中得到的量；通过理论分析或仿真证明其渐近最优性，并通过与现有算法的对比展示其更低的 per-sample 运行时间。

Result: 在渐近意义上，EBC 保证最优性；EBC-H 作为简单变体也表现出良好性能。实证结果显示，EBC 及 EBC-H 相较于现有方法在计算成本和样本效率上具显著优势，且在合成与真实数据集上呈现性能提升。

Conclusion: EBC 与 EBC-H 为固定置信度下的带臂聚类提供一种高效且鲁棒的解法，适用于具有向量参数分布的簇内臂并不要求高斯假设，显著降低计算成本的同时保持渐近最优性，具有良好实用性与扩展性。

Abstract: We study the Bandit Clustering (BC) problem under the fixed confidence setting, where the objective is to group a collection of data sequences (arms) into clusters through sequential sampling from adaptively selected arms at each time step while ensuring a fixed error probability at the stopping time. We consider a setting where arms in a cluster may have different distributions. Unlike existing results in this setting, which assume Gaussian-distributed arms, we study a broader class of vector-parametric distributions that satisfy mild regularity conditions. Existing asymptotically optimal BC algorithms require solving an optimization problem as part of their sampling rule at each step, which is computationally costly. We propose an Efficient Bandit Clustering algorithm (EBC), which, instead of solving the full optimization problem, takes a single step toward the optimal value at each time step, making it computationally efficient while remaining asymptotically optimal. We also propose a heuristic variant of EBC, called EBC-H, which further simplifies the sampling rule, with arm selection based on quantities computed as part of the stopping rule. We highlight the computational efficiency of EBC and EBC-H by comparing their per-sample run time with that of existing algorithms. The asymptotic optimality of EBC is supported through simulations on the synthetic datasets. Through simulations on both synthetic and real-world datasets, we show the performance gain of EBC and EBC-H over existing approaches.

</details>


### [108] [Multi-Teacher Ensemble Distillation: A Mathematical Framework for Probability-Domain Knowledge Aggregation](https://arxiv.org/abs/2601.09165)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出一个基于公理的运算符框架，用于多教师知识蒸馏，证明存在多种满足五公理的聚合算子，给出多种无关性和性能界限。


<details>
  <summary>Details</summary>
Motivation: 解决多教师知识蒸馏中聚合算子并非唯一的核心问题，并在异质教师设置下提供理论保障与实现灵活性；通过公理化统一聚合行为的理论边界。

Method: 定义五条公理：凸性、正性、连续性、权重单调性、温度一致性；证明存在且不唯一的满足这些公理的算子族；给出对所有满足公理的算子族的无关性保证；对于线性权重的聚合，推导经典的方差约简及在独立与相关误差情形下的扩展；给出 Jensen 型界、对数损失界和安全衰减性质。

Result: 证明存在多个满足公理的算子族；给出算子无关性保证，以及在多教师聚合下的方差与系统偏差降低、以及相关的界限与稳健性结果；线性权重情形下重现经典方差降低并可扩展到相关误差场景。

Conclusion: 该框架为多教师知识蒸馏提供理论基础，允许多种实现策略并兼容来自不同前沿模型的教师集合，促进对聚合算子的理解与实践应用。

Abstract: Building on the probability-domain distillation framework of Sparse-KD, we develop an axiomatic, operator-theoretic framework for multi-teacher ensemble knowledge distillation. Rather than prescribing a specific aggregation formula, we define five core axioms governing valid knowledge aggregation operators, encompassing convexity, positivity, continuity, weight monotonicity, and temperature coherence. We prove the existence and non-uniqueness of operator families satisfying these axioms, establishing that multiple distinct aggregation mechanisms conform to the same foundational principles.
  Within this framework, we establish operator-agnostic guarantees showing that multi-teacher aggregation reduces both stochastic variance and systematic supervisory bias under heterogeneous teachers, while providing Jensen-type bounds, log-loss guarantees, and safety attenuation properties. For aggregation operators linear in teacher weights, we further establish classical ensemble variance-reduction results under standard independence assumptions, with extensions to correlated-error regimes. The framework provides theoretical grounding for multi-teacher distillation from diverse frontier models while admitting multiple valid implementation strategies.

</details>


### [109] [DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix](https://arxiv.org/abs/2601.09166)
*Sidhant R. Nair,Tanmay Sen,Mrinmay Sen*

Main category: cs.LG

TL;DR: 在差分隐私联邦学习中提出服务器端的二阶优化 DP-FedSOFIM，使用 Fisher 信息矩阵作为自然梯度预条件器，通过 Sherman–Morrison 公式实现高效逆运算，内存与计算复杂度均为 O(d)，在 CIFAR-10 上对比第一阶基线表现更优，且隐私通过后处理定理得到保护。


<details>
  <summary>Details</summary>
Motivation: 解决在严格隐私预算下 DP-FL 收敛慢的问题，以及现有二阶方法（如 DP-FedNew）需要 O(d^2) 内存，不利于高维模型。

Method: 在服务器端实施二阶优化，采用 Fisher 信息矩阵作为自然梯度的预条件器；利用 Sherman–Morrison 公式实现高效矩阵逆，降低内存与计算复杂度至 O(d)；通过后处理定理确保隐私保护。

Result: 在 CIFAR-10 上的多种隐私设定中，DP-FedSOFIM 的测试准确率优于多种第一阶基线。

Conclusion: 在保护隐私的同时保持二阶优化的收敛优势，且实现了可接受的内存和计算成本。

Abstract: Differentially private federated learning (DP-FL) suffers from slow convergence under tight privacy budgets due to the overwhelming noise introduced to preserve privacy. While adaptive optimizers can accelerate convergence, existing second-order methods such as DP-FedNew require O(d^2) memory at each client to maintain local feature covariance matrices, making them impractical for high-dimensional models. We propose DP-FedSOFIM, a server-side second-order optimization framework that leverages the Fisher Information Matrix (FIM) as a natural gradient preconditioner while requiring only O(d) memory per client. By employing the Sherman-Morrison formula for efficient matrix inversion, DP-FedSOFIM achieves O(d) computational complexity per round while maintaining the convergence benefits of second-order methods. Our analysis proves that the server-side preconditioning preserves (epsilon, delta)-differential privacy through the post-processing theorem. Empirical evaluation on CIFAR-10 demonstrates that DP-FedSOFIM achieves superior test accuracy compared to first-order baselines across multiple privacy regimes.

</details>


### [110] [BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning](https://arxiv.org/abs/2601.09172)
*Pengyang Shao,Naixin Zhai,Lei Chen,Yonghui Yang,Fengbin Zhu,Xun Yang,Meng Wang*

Main category: cs.LG

TL;DR: BalDRO 提出一个平衡的语言模型去忘框架，通过最小上界（min-sup）将不可忘记的样本放大权重以实现更均衡的遗忘效果。提供 BalDRO-G（离散 GroupDRO 近似）与 BalDRO-DV（连续 Donsker-Varadhan 对偶）两种实现，实现在不显著牺牲模型效用的前提下提升遗忘质量。


<details>
  <summary>Details</summary>
Motivation: 当前遗忘集存在样本层面的不平衡性：不同样本的遗忘难度差异很大，导致异步遗忘（部分知识未被充分擦除，部分被过度遗忘）。需要高效且稳定地实现对所有样本的均衡遗忘。

Method: 将遗忘问题建模为一个最小上界的过程：内步识别强调难以遗忘的样本的最坏分布，外步在该分布下更新模型参数。具体实现包括两种变体：BalDRO-G 基于离散 GroupDRO，聚焦高损失子集；BalDRO-DV 基于连续的 Donsker-Varadhan 对偶，允许在标准训练管线中进行平滑自适应加权。

Result: 在 TOFU 与 MUSE 数据集上的实验表明，BalDRO 在遗忘质量与模型效用两方面均优于现有方法，并且提供了可复现实验代码。

Conclusion: 通过最小上界的对偶框架实现的样本平衡遗忘具有较强的实用性，BalDRO 的两种变体为不同需求提供了可选方案，促进可复现实验。

Abstract: As Large Language Models (LLMs) increasingly shape online content, removing targeted information from well-trained LLMs (also known as LLM unlearning) has become critical for web governance. A key challenge lies in sample-wise imbalance within the forget set: different samples exhibit widely varying unlearning difficulty, leading to asynchronous forgetting where some knowledge remains insufficiently erased while others become over-forgotten. To address this, we propose BalDRO, a novel and efficient framework for balanced LLM unlearning. BalDRO formulates unlearning as a min-sup process: an inner step identifies a worst-case data distribution that emphasizes hard-to-unlearn samples, while an outer step updates model parameters under this distribution. We instantiate BalDRO via two efficient variants: BalDRO-G, a discrete GroupDRO-based approximation focusing on high-loss subsets, and BalDRO-DV, a continuous Donsker-Varadhan dual method enabling smooth adaptive weighting within standard training pipelines. Experiments on TOFU and MUSE show that BalDRO significantly improves both forgetting quality and model utility over existing methods, and we release code for reproducibility.

</details>


### [111] [Geometric Stability: The Missing Axis of Representations](https://arxiv.org/abs/2601.09173)
*Prashant C. Raju*

Main category: cs.LG

TL;DR: 提出几何稳定性及其测量框架Shesha，用以评估表示几何在扰动下的鲁棒性；结果显示稳定性与相似性几乎不相关，且稳定性能提供独立的预测力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有分析偏重相似性，无法评估结构的鲁棒性；需要一个量化系统保持几何结构的维度，以辅助安全监控、可控性、模型选择及跨生物系统的审计。

Method: 提出Shesha框架来衡量几何稳定性，在7领域共2463个配置上评估，与CKA等相似性指标比较；通过去除前若干主成分观察两者关系；在多领域应用中测试稳定性对漂移检测、线性可控性预测和迁移性解耦等能力。

Result: 稳定性与相似性相关性约为0.01，且二者机制上不同；相似性在移除前若干主成分后崩溃，而稳定性保持对细粒度流形结构的敏感性；对安全监控，稳定性相比CKA漂移检测提高约2倍并过滤掉导致非功能性警报的噪声；对可控性，监督稳定性对线性可控性预测的相关性约0.89–0.96；对模型选择，稳定性与迁移性解耦，揭示迁移优化的几何成本；跨生物领域，如CRISPR扰动的一致性与神经-行为耦合也具预测能力。

Conclusion: 几何稳定性为表示审计提供一个必要的补充维度，帮助识别不仅表示了什么，也能衡量结构在扰动下保持的可靠性，从而更全面地评估计算与生物系统的表示。

Abstract: Analysis of learned representations has a blind spot: it focuses on $similarity$, measuring how closely embeddings align with external references, but similarity reveals only what is represented, not whether that structure is robust. We introduce $geometric$ $stability$, a distinct dimension that quantifies how reliably representational geometry holds under perturbation, and present $Shesha$, a framework for measuring it. Across 2,463 configurations in seven domains, we show that stability and similarity are empirically uncorrelated ($ρ\approx 0.01$) and mechanistically distinct: similarity metrics collapse after removing the top principal components, while stability retains sensitivity to fine-grained manifold structure. This distinction yields actionable insights: for safety monitoring, stability acts as a functional geometric canary, detecting structural drift nearly 2$\times$ more sensitively than CKA while filtering out the non-functional noise that triggers false alarms in rigid distance metrics; for controllability, supervised stability predicts linear steerability ($ρ= 0.89$-$0.96$); for model selection, stability dissociates from transferability, revealing a geometric tax that transfer optimization incurs. Beyond machine learning, stability predicts CRISPR perturbation coherence and neural-behavioral coupling. By quantifying $how$ $reliably$ systems maintain structure, geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems.

</details>


### [112] [$D^2Prune$: Sparsifying Large Language Models via Dual Taylor Expansion and Attention Distribution Awareness](https://arxiv.org/abs/2601.09176)
*Lang Xiong,Ning Liu,Ao Ren,Yuheng Bai,Haining Fang,BinYan Zhang,Zhe Jiang,Yujuan Tan,Duo Liu*

Main category: cs.LG

TL;DR: D^2Prune 通过双泰勒展开的权重与激活扰动建模及注意力分布的动态更新实现对大语言模型的高效剪枝，兼顾激活分布漂移与注意力长尾特征；在多种模型上优于SOTA，并具跨模态泛化。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的剪枝面临两大挑战：校准数据与测试数据之间的激活分布漂移导致误差估计不准确；注意力模块存在明显的长尾激活分布特征，难以通过简单剪枝保留。需实现更精确的误差估计并保护注意力的长尾模式。

Method: 提出双泰勒展开方法，联合建模权重与激活扰动以实现精确误差估计，从而在剪枝过程中正确选择掩码并更新权重以最小化误差；并提出注意力感知的动态更新策略，通过最小化注意力分布的KL散度与重构误差的联合目标，保持长尾注意力模式。

Result: 在 OPT-125M、LLaMA2/3、Qwen3 等模型上，D^2Prune 持续优于SOTA；动态注意力更新策略也可泛化到 ViT 的 DeiT，在 ImageNet-1K 上取得更高精度。

Conclusion: D^2Prune 通过耦合的权重-激活误差建模与注意力分布约束，实现更高效鲁棒的剪枝，具跨模态泛化潜力。

Abstract: Large language models (LLMs) face significant deployment challenges due to their massive computational demands. % While pruning offers a promising compression solution, existing methods suffer from two critical limitations: (1) They neglect activation distribution shifts between calibration data and test data, resulting in inaccurate error estimations; (2) They overlook the long-tail distribution characteristics of activations in the attention module. To address these limitations, this paper proposes a novel pruning method, $D^2Prune$. First, we propose a dual Taylor expansion-based method that jointly models weight and activation perturbations for precise error estimation, leading to precise pruning mask selection and weight updating and facilitating error minimization during pruning. % Second, we propose an attention-aware dynamic update strategy that preserves the long-tail attention pattern by jointly minimizing the KL divergence of attention distributions and the reconstruction error. Extensive experiments show that $D^2Prune$ consistently outperforms SOTA methods across various LLMs (e.g., OPT-125M, LLaMA2/3, and Qwen3). Moreover, the dynamic attention update mechanism also generalizes well to ViT-based vision models like DeiT, achieving superior accuracy on ImageNet-1K.

</details>


### [113] [From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences](https://arxiv.org/abs/2601.09220)
*Xinzi Tan,Kejian Zhang,Junhan Yu,Doudou Zhou*

Main category: cs.LG

TL;DR: 提出一种基于多变量霍克斯过程理论的 Hawkes Attention，用按类型的神经核函数调制查询、键和值投影，实现事件时间和内容信息的联合建模，适用于标记时序点过程（MTPP）及时间序列预测，实验显示优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有 Transformer 主要通过位置编码引入时间信息，往往依赖统一或参数化的衰减结构，难以捕捉异质性和类型特定的时间效应，需一种能够同时建模时间相关性（时间维度）和事件类型间相互作用的新注意力机制。

Method: 提出 Hawkes Attention：基于多变量霍克斯过程理论，使用可学习的按类型神经核函数来调制 Query、Key、Value 投影，替代传统注意力中的相应部分；通过核函数实现时间相关性与类型间激励模式的耦合，统一事件时间与内容交互，可直接用于 MTPP 及时间序列结构。

Result: 实验结果表明该注意力在 MTPP 任务及相关时间序列预测任务上优于基线方法，展示了在时间敏感性和类型特征建模方面的提升。

Conclusion: Hawkes Attention 能够统一时序信息与内容交互，学习时间相关行为和类型特定的激励模式，适用于通用 MTPP 及时间序列预测等场景，具有良好的扩展性与潜在解释性。

Abstract: Marked Temporal Point Processes (MTPPs) arise naturally in medical, social, commercial, and financial domains. However, existing Transformer-based methods mostly inject temporal information only via positional encodings, relying on shared or parametric decay structures, which limits their ability to capture heterogeneous and type-specific temporal effects. Inspired by this observation, we derive a novel attention operator called Hawkes Attention from the multivariate Hawkes process theory for MTPP, using learnable per-type neural kernels to modulate query, key and value projections, thereby replacing the corresponding parts in the traditional attention. Benefited from the design, Hawkes Attention unifies event timing and content interaction, learning both the time-relevant behavior and type-specific excitation patterns from the data. The experimental results show that our method achieves better performance compared to the baselines. In addition to the general MTPP, our attention mechanism can also be easily applied to specific temporal structures, such as time series forecasting.

</details>


### [114] [GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization](https://arxiv.org/abs/2601.09233)
*Zhengyang Zhao,Lu Ma,Yizhen Jiang,Xiaochen Ma,Zimo Meng,Chengyu Shen,Lexiang Tang,Haoze Sun,Peng Pei,Wentao Zhang*

Main category: cs.LG

TL;DR: 将 SFT/RL 的后训练问题转为基于 Gibbs 能量的有限温度框架 GIFT，通过将监督视为有限温度能量势，打通后训练管线中的目标一致性，从而提升 RL 初始化效果并更接近全局最优。


<details>
  <summary>Details</summary>
Motivation: SFT+RL 的分布崩溃和优化失配问题导致探索受限，现有统一框架不足以在后训练阶段保持 base priors 与目标一致性，需重新建模后训练管线。

Method: 提出 Gibbs Initialization with Finite Temperature (GIFT)，将 SFT 表述为有限温度的能量势，形成一个分布桥接，在整个后训练流程中保持目标的一致性；并在 RL 初始化阶段使用 GIFT 的分布进行初始化；提供开源代码。

Result: 实验表明 GIFT 相较于标准 SFT 及其它基线在 RL 初始化场景下显著优于对比，具备数学上对后训练全局最优性的通道。

Conclusion: GIFT 为后训练提供一个原理性、可控的温度-能量框架，缓解分布崩溃，提升全局优化潜力。

Abstract: The prevailing post-training paradigm for Large Reasoning Models (LRMs)--Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL)--suffers from an intrinsic optimization mismatch: the rigid supervision inherent in SFT induces distributional collapse, thereby exhausting the exploration space necessary for subsequent RL. In this paper, we reformulate SFT within a unified post-training framework and propose Gibbs Initialization with Finite Temperature (GIFT). We characterize standard SFT as a degenerate zero-temperature limit that suppresses base priors. Conversely, GIFT incorporates supervision as a finite-temperature energy potential, establishing a distributional bridge that ensures objective consistency throughout the post-training pipeline. Our experiments demonstrate that GIFT significantly outperforms standard SFT and other competitive baselines when utilized for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training. Our code is available at https://github.com/zzy1127/GIFT.

</details>


### [115] [Reward Learning through Ranking Mean Squared Error](https://arxiv.org/abs/2601.09236)
*Chaitanya Kharyal,Calarina Muslimani,Matthew E. Taylor*

Main category: cs.LG

TL;DR: 提出了基于评分的强化学习方法R4，结合排名均方误差(rMSE)和可微排序，利用教师给出的离散评分来学习奖励函数。


<details>
  <summary>Details</summary>
Motivation: 奖励设计是现实世界强化学习中的主要瓶颈。评分型人类反馈相比二元偏好提供更丰富且潜在更易于获得的监督，能够在不手工设定奖励函数的前提下提升学习效率。

Method: R4 使用rMSE：将教师的离散评分视为序数目标；从轨迹-评分数据集中随机抽取一组轨迹，预测它们的回报；通过可微分排序算子（软排序）对预测回报进行排序，得到软排序分数；最小化预测软排序分数与教师评分之间的均方误差。并给出理论保证：在温和假设下，解集具有最小性和完备性。

Result: 在模拟人类反馈的实验中，R4 在 OpenAI Gym 与 DeepMind Control Suite 的机器人行走/控制任务上，与现有的评级和偏好RL方法相比，性能相当或更好，且所需的反馈显著更少。

Conclusion: R4 不仅在实验上展现出与现有方法竞争的性能，还提供了形式化的最小性与完备性保证，证明了评分型反馈在RL中的潜力与可行性。

Abstract: Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., "bad," "neutral," "good"). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher's ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.

</details>


### [116] [XLinear: A Lightweight and Accurate MLP-Based Model for Long-Term Time Series Forecasting with Exogenous Inputs](https://arxiv.org/abs/2601.09237)
*Xinyang Chen,Huidong Jin,Yu Huang,Zaiwen Feng*

Main category: cs.LG

TL;DR: XLinear 是一种基于 MLP 的轻量级时序预测模型，通过一个来自内生变量的全局 token 与外生变量交互，以及 sigmoid 激活的 MLP 提取时序与变量依赖，提升带外生输入的预测性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界中变量的重要性并非对称，外生数据成本低且可单向影响内生变量；现有 Transformer 计算成本高且易产生排列不变性，Patch 方案虽更高效但可能忽视局部时序模式，因此需要一种高效且能跨时序维度与外生变量有效交互的模型。

Method: 提出以来自内生变量的全局 token 作为核心枢纽，与外生变量交互；使用 sigmoid 激活的 MLP 提取时序模式与变变量依赖；通过预测头整合信号以预测内生序列。

Result: 在七个标准基准和五个含外生输入的真实世界数据集上评估，XLinear 相比于现有 SOTA 模型在多变量预测和受外生输入影响的单变量预测中实现更高的准确性和效率。

Conclusion: XLinear 提供一个高效、轻量的带外生输入的时序预测方案，通过全局内生变量作为信息枢纽实现跨变量依赖建模，兼顾精度与计算资源。

Abstract: Despite the prevalent assumption of uniform variable importance in long-term time series forecasting models, real world applications often exhibit asymmetric causal relationships and varying data acquisition costs. Specifically, cost-effective exogenous data (e.g., local weather) can unilaterally influence dynamics of endogenous variables, such as lake surface temperature. Exploiting these links enables more effective forecasts when exogenous inputs are readily available. Transformer-based models capture long-range dependencies but incur high computation and suffer from permutation invariance. Patch-based variants improve efficiency yet can miss local temporal patterns. To efficiently exploit informative signals across both the temporal dimension and relevant exogenous variables, this study proposes XLinear, a lightweight time series forecasting model built upon MultiLayer Perceptrons (MLPs). XLinear uses a global token derived from an endogenous variable as a pivotal hub for interacting with exogenous variables, and employs MLPs with sigmoid activation to extract both temporal patterns and variate-wise dependencies. Its prediction head then integrates these signals to forecast the endogenous series. We evaluate XLinear on seven standard benchmarks and five real-world datasets with exogenous inputs. Compared with state-of-the-art models, XLinear delivers superior accuracy and efficiency for both multivariate forecasts and univariate forecasts influenced by exogenous inputs.

</details>


### [117] [RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning](https://arxiv.org/abs/2601.09253)
*Zehua Liu,Shuqi Liu,Tao Zhong,Mingxuan Yuan*

Main category: cs.LG

TL;DR: 提出 Reward Informed Fine-Tuning (RIFT)，在自生成样本上通过标量奖励重加权损失，利用正负轨迹进行学习，提出稳定的损失形式以避免训练不稳定；实验在数学基准上显示对比 RFT 的数据高效且鲁棒性更好。


<details>
  <summary>Details</summary>
Motivation: SFT 与 RFT 在数据利用上存在低效：SFT 依赖昂贵的专家数据，RFT 只保留正样本，丢弃负样本，导致数据利用率低。需充分利用自生成的正负样本以提升对齐效果。

Method: 在自生成样本上引入标量奖励来重加权损失，将负轨迹转化为可利用信息；不同于硬阈值的 RFT，RIFT 通过混合正负轨迹并调整损失权重实现学习；提出一个稳定化的损失形式，避免直接相乘导致损失发散，从而实现数值稳健与高效优化。

Result: 在多种基模型的数学基准上进行广泛实验，RIFT 持续优于 RFT，表现为数据高效且鲁棒。

Conclusion: RIFT 是一种对齐任务中利用混合质量自生成数据的鲁棒且数据高效的替代方案，适用于无监督或弱监督数据情景。

Abstract: While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike the hard thresholding of RFT, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both the positive and negative trajectories from the model outputs. To overcome the training collapse caused by naive reward integration, where direct multiplication yields an unbounded loss, we introduce a stabilized loss formulation that ensures numerical robustness and optimization efficiency. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT. Our results demonstrate that RIFT is a robust and data-efficient alternative for alignment using mixed-quality, self-generated data.

</details>


### [118] [Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability](https://arxiv.org/abs/2601.09261)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 提出 EIUR 框架，利用元认知调控（MTR）及自我诊断来评估体验可信度，在不可观测的反馈可靠性环境中提升 epistemic identifiability；在强化学习与监督学习中显示了校准性怀疑与内部信念动力学的分离等现象。


<details>
  <summary>Details</summary>
Motivation: 在反馈可靠性不可观测的设定下，鲁棒优化的收敛不必然带来正确信念的收敛，系统需要判断是否应从某次体验中学习，从而解决因自我循环的数据生成导致的偏见与错信。

Method: 提出模块化 Monitor-Trust-Regulator(MTR) 分解，并以自我诊断实现元认知调控，形成一个 slowly varying 的体验-信任变量，用软性地调节学习更新；无需外部可靠性标签或显式腐败模型。

Result: 在 EIUR 场景下，自诊断与 MTR 机制提升了 epistemic identifiability；在强化学习中实现经过校准的怀疑与对系统性奖励腐败的恢复；在监督学习中揭示性能恢复不等同于 epistemic 恢复，内部信念可能因早期误导数据而被锁定，需通过内省诊断探测。

Conclusion: MTR 与自我诊断提供一个组织化的抽象和可操作的设计模板，用于在不可观测可靠性条件下进行内在可靠性评估与自治学习。

Abstract: Learning under unobservable feedback reliability poses a distinct challenge beyond optimization robustness: a system must decide whether to learn from an experience, not only how to learn stably. We study this setting as Epistemic Identifiability under Unobservable Reliability (EIUR), where each experience has a latent credibility, reliable and unreliable feedback can be locally indistinguishable, and data are generated in a closed loop by the learner's own evolving beliefs and actions. In EIUR, standard robust learning can converge stably yet form high-confidence, systematically wrong beliefs.
  We propose metacognitive regulation as a practical response: a second, introspective control loop that infers experience credibility from endogenous evidence in the learner's internal dynamics. We formalize this as a modular Monitor-Trust-Regulator (MTR) decomposition and instantiate it with self-diagnosis, which maintains a slowly varying experience-trust variable that softly modulates learning updates, without exogenous reliability labels or an explicit corruption model.
  Empirically, in the EIUR regimes studied here, self-diagnosis is associated with improved epistemic identifiability. In reinforcement learning, it enables calibrated skepticism and recovery under systematically corrupted rewards. In supervised learning, it exposes a critical dissociation: performance recovery does not imply epistemic recovery. Accuracy can rebound while internal belief dynamics remain locked-in by early misleading data, a failure detectable only through introspective diagnostics. Together, MTR and self-diagnosis provide an organizing abstraction and a concrete design template for intrinsic reliability assessment in autonomous learning under unobservable reliability.

</details>


### [119] [Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction](https://arxiv.org/abs/2601.09285)
*Mianzhi Pan,JianFei Li,Peishuo Liu,Botian Wang,Yawen Ouyang,Yiming Rong,Hao Zhou,Jianbing Zhang*

Main category: cs.LG

TL;DR: 提出 MOF-LLM，基于块级生成与空间先验，通过 CPT、SFT、RL 和 SAPO 提升 MOF 三维结构预测的准确性与采样效率。


<details>
  <summary>Details</summary>
Motivation: MOFs 的高原子复杂性与三维结构预测挑战，以及现有 LLM 在这类模块化结构任务中的局限性。

Method: 采用块级分解的 MOF 架构，进行空间感知的持续预训练（CPT）、结构化监督微调（SFT）以及匹配驱动的强化学习（RL），并引入 Soft Adaptive Policy Optimization（SAPO）以优化结构稳定性。

Result: 在 Qwen-3 8B 模型上，MOF-LLM 在预测准确性与采样效率方面超越去噪基方法和其它 LLM 方法，显著提高空间推理能力。

Conclusion: 通过引入显式空间先验和稳健的策略优化，MOF-LLM 有望提升复杂材料结构的端到端生成与预测能力。

Abstract: Metal-organic frameworks (MOFs) are porous crystalline materials with broad applications such as carbon capture and drug delivery, yet accurately predicting their 3D structures remains a significant challenge. While Large Language Models (LLMs) have shown promise in generating crystals, their application to MOFs is hindered by MOFs' high atomic complexity. Inspired by the success of block-wise paradigms in deep generative models, we pioneer the use of LLMs in this domain by introducing MOF-LLM, the first LLM framework specifically adapted for block-level MOF structure prediction. To effectively harness LLMs for this modular assembly task, our training paradigm integrates spatial-aware continual pre-training (CPT), structural supervised fine-tuning (SFT), and matching-driven reinforcement learning (RL). By incorporating explicit spatial priors and optimizing structural stability via Soft Adaptive Policy Optimization (SAPO), our approach substantially enhances the spatial reasoning capability of a Qwen-3 8B model for accurate MOF structure prediction. Comprehensive experiments demonstrate that MOF-LLM outperforms state-of-the-art denoising-based and LLM-based methods while exhibiting superior sampling efficiency.

</details>


### [120] [Single-Round Clustered Federated Learning via Data Collaboration Analysis for Non-IID Data](https://arxiv.org/abs/2601.09304)
*Sota Sugawara,Yuji Kawamata,Akihiro Toyoda,Tomoru Nakayama,Yukihiko Okada*

Main category: cs.LG

TL;DR: DC-CFL是一种单轮聚合的聚簇联邦学习框架，通过DC分析来完成客户端聚类和簇内学习，在仅用一次通信轮的情况下实现接近多轮基线的精度。


<details>
  <summary>Details</summary>
Motivation: 在统计异质性强的情形下，传统CFL需要多轮通信来估计簇和更新模型，成本高，DC-CFL旨在在有限通信轮数下获得类似性能。

Method: 通过计算客户端标签分布之间的全变差距离来量化客户端间相似性；使用层次聚类进行簇的划分；利用DC分析进行簇内学习。

Result: 在多组公开数据集的代表性非独立同分布条件下，DC-CFL在单轮通信下达到接近多轮基线的准确率。

Conclusion: 在通信轮数受限的场景，DC-CFL是一个实用的协同AI模型开发替代方案；可能促进在资源受限环境中的分布式学习应用。

Abstract: Federated Learning (FL) enables distributed learning across multiple clients without sharing raw data. When statistical heterogeneity across clients is severe, Clustered Federated Learning (CFL) can improve performance by grouping similar clients and training cluster-wise models. However, most CFL approaches rely on multiple communication rounds for cluster estimation and model updates, which limits their practicality under tight constraints on communication rounds. We propose Data Collaboration-based Clustered Federated Learning (DC-CFL), a single-round framework that completes both client clustering and cluster-wise learning, using only the information shared in DC analysis. DC-CFL quantifies inter-client similarity via total variation distance between label distributions, estimates clusters using hierarchical clustering, and performs cluster-wise learning via DC analysis. Experiments on multiple open datasets under representative non-IID conditions show that DC-CFL achieves accuracy comparable to multi-round baselines while requiring only one communication round. These results indicate that DC-CFL is a practical alternative for collaborative AI model development when multiple communication rounds are impractical.

</details>


### [121] [GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR](https://arxiv.org/abs/2601.09361)
*Jiaying Zhang,Lei Shi,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.LG

TL;DR: GeoRA：一种几何感知的低秩适配方法，用于强化学习可验证奖励的参数高效微调，在 Qwen/Llama 上实现 SOTA 性能并提升泛化和抗遗忘能力。


<details>
  <summary>Details</summary>
Motivation: RLVR 的优化动力学与几何结构与 SFT 场景不同，现有 PiSSA、MiLoRA 等方法在 RLVR 情况下易导致谱崩溃、优化不稳和硬件效率瓶颈，亟需考虑更新子空间的几何特性。

Method: GeoRA 在几何约束子空间内通过 SVD 提取主要方向，初始化适配器并冻结残余分量，保持预训练几何结构，利用密集算子实现高效 GPU 计算，兼顾效率和稳定性。

Result: 在 Qwen 与 Llama 上的实验表明，GeoRA 减少了几何错配导致的优化瓶颈，优于常用低秩基线，达到或接近 SOTA；在跨域任务中展现更强的泛化能力与对灾忘的鲁棒性。

Conclusion: GeoRA 提供一种兼顾几何一致性、数值稳定性与计算效率的 RLVR 参数高效化方案，适合大规模推理模型的长期优化。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. However, existing parameter-efficient methods, such as PiSSA and MiLoRA, are designed for Supervised Fine-Tuning (SFT) and do not account for the distinct optimization dynamics and geometric structures of RLVR. Applying these methods directly leads to spectral collapse and optimization instability, which severely limit model performance. Meanwhile, alternative approaches that leverage update sparsity encounter significant efficiency bottlenecks on modern hardware due to unstructured computations. To address these challenges, we propose GeoRA (Geometry-Aware Low-Rank Adaptation), which exploits the anisotropic and compressible nature of RL update subspaces. GeoRA initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This method preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama demonstrate that GeoRA mitigates optimization bottlenecks caused by geometric misalignment. It consistently outperforms established low-rank baselines on key mathematical benchmarks, achieving state-of-the-art (SOTA) results. Moreover, GeoRA shows superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.

</details>


### [122] [Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps](https://arxiv.org/abs/2601.09428)
*Siyi Li,Joseph G. Lambourne,Longfei Zhang,Pradeep Kumar Jayaraman,Karl. D. D. Willis*

Main category: cs.LG

TL;DR: 提出一种通过简单几何构造序列生成CAD轮廓的新方法，结合了偏移、旋转、求交等操作；引入“构造序列”来增强设计者输入的表达力，且通过强化学习进一步提升多项指标的表现。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图到最终轮廓的生成品质问题，借鉴语言模型中的“推理链/链式思维”，将设计输入逐步转化为可控的参数化形状，并实现高精度浮点编辑。

Method: 从设计者给出的初始几何开始，依次进行简单几何构造（曲线偏移、旋转、求交等），逐步构建点和曲线；把构造序列视为参数化约束，降低自由度到少量可调参数；对构造序列应用强化学习以优化序列选择。

Result: 构造序列显著提升生成质量，类似推理链的效果；将自由度约束为可编辑的参数值，支持浮点数精度的参数化编辑；RL在多项指标上取得改进，包括部分未显式优化的指标。

Conclusion: 构造序列是CAD轮廓生成的有效策略，配合强化学习可带来更广泛的性能提升，且与参数化CAD约束兼容，便于设计师进行精确调整。

Abstract: We introduce a new method of generating Computer Aided Design (CAD) profiles via a sequence of simple geometric constructions including curve offsetting, rotations and intersections. These sequences start with geometry provided by a designer and build up the points and curves of the final profile step by step. We demonstrate that adding construction steps between the designer's input geometry and the final profile improves generation quality in a similar way to the introduction of a chain of thought in language models. Similar to the constraints in a parametric CAD model, the construction sequences reduce the degrees of freedom in the modeled shape to a small set of parameter values which can be adjusted by the designer, allowing parametric editing with the constructed geometry evaluated to floating point precision. In addition we show that applying reinforcement learning to the construction sequences gives further improvements over a wide range of metrics, including some which were not explicitly optimized.

</details>


### [123] [On the Hardness of Computing Counterfactual and Semifactual Explanations in XAI](https://arxiv.org/abs/2601.09455)
*André Artelt,Martin Olsen,Kevin Tierney*

Main category: cs.LG

TL;DR: Abstract surveys the computational complexity of generating counterfactual and semi-factual explanations, showing that such explanations are often computationally hard and hard to approximate under certain assumptions, with implications for XAI practice and AI regulation.


<details>
  <summary>Details</summary>
Motivation: Explainability is crucial for deploying ML models in high-stakes settings; understanding the computational feasibility of generating explanations informs both research directions and policy.

Method: Literature review of existing complexity results on counterfactual/semi-factual explanations plus new inapproximability proofs under specified assumptions; theoretical analysis of hardness and approximation limits.

Result: Demonstrates that generating explanations is often computationally hard; provides stronger inapproximability results indicating that even approximating explanations is hard under certain assumptions.

Conclusion: Complexity results have important implications for the XAI community and policymakers, highlighting trade-offs between explainability and computational feasibility, and suggesting a need for policy that accounts for such limitations.

Abstract: Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. We provide an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. We strengthen the argument for this considerably by further contributing our own inapproximability results showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. We discuss the implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI.

</details>


### [124] [Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting](https://arxiv.org/abs/2601.09467)
*Tianye Li,Qi Liu,Hao Li,Lei Chen,Wencong Cheng,Fei Zheng,Xiangao Xia,Ya Wang,Gang Huang,Weiwei Wang,Xuan Tong,Ziqing Zu,Yi Fang,Shenming Fu,Jiang Jiang,Haochen Li,Mingxing Li,Jiangjiang Xia*

Main category: cs.LG

TL;DR: 提出 Shifted Earth Transformer（Searth Transformer）及 Relay Autoregressive（RAR）微调策略，以物理信息驱动的全局窗口自注意力处理地球球面几何与经向周期性，提升全球中等期天气预报的准确性与效率；并基于此开发 YanTian，能在显著更低的计算成本下实现高于某些基准的性能、并延长 Z500 的可预报时间。


<details>
  <summary>Details</summary>
Motivation: 现有基于 Transformer 的全球天气预报模型多采用以视觉为中心的架构，忽略地球的球面几何与经向周期性；常规自回归训练成本高、难以在有限算力下扩展预报时间。需要一种在几何约束与计算效率之间取得折衷的新方法。

Method: 提出 Searth Transformer，将经向周期性与纬向边界融入窗口自注意力，确保物理一致的全球信息交换；引入 Relay Autoregressive（RAR）微调策略，在受限内存和计算预算下实现长距大气演化学习。基于此构建 YanTian。

Result: YanTian 在高分辨率预报方面超越欧洲中期天气预报中心（HRES）的高分辨率预报，且在1°分辨率下与前沿 AI 模型竞争力强，同时相比标准自回归微调，计算成本约低200倍；对 Z500 的预报领先期为 10.3 天，超过 HRES 的 9 天。

Conclusion: 该工作为全球尺度地球物理环流系统的预测建模提供稳健的算法基础，拓展了地球系统科学的研究路径，同时证明了在几何约束与高效微调策略下的 Transformer 架构在中等期天气预测中的潜力。

Abstract: Accurate global medium-range weather forecasting is fundamental to Earth system science. Most existing Transformer-based forecasting models adopt vision-centric architectures that neglect the Earth's spherical geometry and zonal periodicity. In addition, conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation. To address these challenges, we propose the Shifted Earth Transformer (Searth Transformer), a physics-informed architecture that incorporates zonal periodicity and meridional boundaries into window-based self-attention for physically consistent global information exchange. We further introduce a Relay Autoregressive (RAR) fine-tuning strategy that enables learning long-range atmospheric evolution under constrained memory and computational budgets. Based on these methods, we develop YanTian, a global medium-range weather forecasting model. YanTian achieves higher accuracy than the high-resolution forecast of the European Centre for Medium-Range Weather Forecasts and performs competitively with state-of-the-art AI models at one-degree resolution, while requiring roughly 200 times lower computational cost than standard autoregressive fine-tuning. Furthermore, YanTian attains a longer skillful forecast lead time for Z500 (10.3 days) than HRES (9 days). Beyond weather forecasting, this work establishes a robust algorithmic foundation for predictive modeling of complex global-scale geophysical circulation systems, offering new pathways for Earth system science.

</details>


### [125] [FairGU: Fairness-aware Graph Unlearning in Social Network](https://arxiv.org/abs/2601.09469)
*Renqiang Luo,Yongshuai Yang,Huafei Huang,Qing Qing,Mingliang Hou,Ziqi Xu,Yi Yu,Jingjing Zhou,Feng Xia*

Main category: cs.LG

TL;DR: 提出 FairGU，一种公平性感知的图去学习框架，在删除节点后保持模型效用与敏感属性公平性，并防止敏感属性被放大或结构暴露；在多数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图去学习在隐私保护方面重要，但对敏感属性的公平性保护不足，可能导致与传统图学习相比的公平性劣化。

Method: 引入专门的公平性模块与数据保护策略，联合优化以保持效用与公平性；设计约束与损失函数，防止敏感属性放大或结构暴露，考虑 deleted-node 情境下的鲁棒去学习。

Result: 在多组真实数据集上，FairGU 在准确性与公平性指标上均优于最先进的图去学习方法及公平性增强基线。

Conclusion: 揭示当前去学习实践中未充分关注的公平性风险，提供鲁棒且公平的解决方案，代码开放在 GitHub。

Abstract: Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks, enabling models to remove the influence of deleted nodes and thereby better safeguard user information. However, we observe that existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared with traditional graph learning methods. To address this gap, we introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Through extensive experiments on multiple real-world datasets, we demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics. Our findings highlight a previously overlooked risk in current unlearning practices and establish FairGU as a robust and equitable solution for the next generation of socially sustainable networked systems. The codes are available at https://github.com/LuoRenqiang/FairGU.

</details>


### [126] [SimMerge: Learning to Select Merge Operators from Similarity Signals](https://arxiv.org/abs/2601.09473)
*Oliver Bolton,Aakanksha,Arash Ahmadian,Sara Hooker,Marzieh Fadaee,Beyza Ermis*

Main category: cs.LG

TL;DR: SIMMERGE 提供一个基于可查询探针的预测性合并选择框架，通过少量无标签信号来预测 2 路合并的性能，从而选出最佳合并算子、模型子集和顺序，显著降低合并的搜索成本并能扩展到多路合并与大模型。


<details>
  <summary>Details</summary>
Motivation: 要将多个大语言模型合并以提升性能，但合并过程成本高昂且难以扩展，需在算子选择、模型子集与合并顺序上做出复杂决策；现有方法通常依赖昂贵的“合并-评估”搜索。需要可迁移且无标签的信号来预测合并效果。

Method: 从小规模的无标注探针出发，计算功能性与结构性特征，建立预测模型来估计给定 2 路合并的性能；利用该预测结果选择最佳合并算子、子集与合并顺序，避免实际大量评估；并提出一个 bandit 变体，支持在运行时添加新任务、模型与算子。

Result: 在 7B 参数的 2 路合并上，SIMMERGE 的预测性选择超越了标准合并算子；具有对多路合并和 111B 参数模型的泛化能力，且无需重新训练；bandit 变体可在线扩展新任务/模型/算子。

Conclusion: 学习“如何合并”是实现可扩展模型组合的务实路径，特别是在检查点目录规模庞大、评估预算有限的场景。

Abstract: Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance. This makes it a valuable tool in LLM development, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, as successful merging requires choosing the right merge operator, selecting the right models, and merging them in the right order. This often leads researchers to run expensive merge-and-evaluate searches to select the best merge. In this work, we provide an alternative by introducing \simmerge{}, \emph{a predictive merge-selection method} that selects the best merge using inexpensive, task-agnostic similarity signals between models. From a small set of unlabeled probes, we compute functional and structural features and use them to predict the performance of a given 2-way merge. Using these predictions, \simmerge{} selects the best merge operator, the subset of models to merge, and the merge order, eliminating the expensive merge-and-evaluate loop. We demonstrate that we surpass standard merge-operator performance on 2-way merges of 7B-parameter LLMs, and that \simmerge{} generalizes to multi-way merges and 111B-parameter LLM merges without retraining. Additionally, we present a bandit variant that supports adding new tasks, models, and operators on the fly. Our results suggest that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.

</details>


### [127] [Terminally constrained flow-based generative models from an optimal control perspective](https://arxiv.org/abs/2601.09474)
*Weiguo Gao,Ming Li,Qianxiao Li*

Main category: cs.LG

TL;DR: 提出 TOCFlow：在预训练流模型的端点受限分布采样中，将最优控制与几何感知结合，通过 HJB 确定值函数和最优反馈控制；在不同控制惩罚下实现参考分布的极限行为，并给出一个无需矩阵求逆、沿黎曼梯度的标量阻尼因子以捕捉曲率的采样引导方法。


<details>
  <summary>Details</summary>
Motivation: 解决高维受限分布下对预训练流模型的采样难题，单纯的欧氏引导或投影难以保留几何结构和生成质量。通过将端点约束问题置于最优控制框架，并在端点协同帧中实现几何一致的采样策略

Method: 基于哈密顿-雅可比-贝尔曼(HJB)方程，推导最优反馈控制作为哈密顿量的极小化解；研究控制惩罚项对终端分布的影响（惩罚增大→回到参考分布，惩罚减小→终端分布收敛至广义Wasserstein投影到约束流形）。提出 TOCFlow：一种几何感知的采样时间引导，在端点协同帧内跟踪参考轨迹，给出沿黎曼梯度的标量阻尼因子以捕捉二阶曲率，无需矩阵求逆；计算成本等价于普通梯度引导，具 Gauss-Newton 式几何一致性

Result: 给出理论结果：值函数由 HJB 表述，最优反馈为哈密顿量极小化解；控制惩罚项的极限行为明确：高惩罚使采样接近参考分布，低惩罚实现对约束的广义 Wasserstein 投影。实验上，在三类高维科学任务（达西流、受约束的轨迹规划、具有 Kolmogorov 谱尺度的湍流快照生成）上，TOCFlow 相较于欧几里得引导和投影基线在约束满足性上显著提升，同时保持了预训练流模型的生成质量。

Conclusion: TOCFlow 提供一种几何感知且计算高效的端点约束采样引导，适用于大规模高维受约束分布采样场景，能够在保留模型生成能力的同时提升约束遵循性，并具备与高斯-牛顿等价的二阶信息感知能力。

Abstract: We address the problem of sampling from terminally constrained distributions with pre-trained flow-based generative models through an optimal control formulation. Theoretically, we characterize the value function by a Hamilton-Jacobi-Bellman equation and derive the optimal feedback control as the minimizer of the associated Hamiltonian. We show that as the control penalty increases, the controlled process recovers the reference distribution, while as the penalty vanishes, the terminal law converges to a generalized Wasserstein projection onto the constraint manifold. Algorithmically, we introduce Terminal Optimal Control with Flow-based models (TOCFlow), a geometry-aware sampling-time guidance method for pre-trained flows. Solving the control problem in a terminal co-moving frame that tracks reference trajectories yields a closed-form scalar damping factor along the Riemannian gradient, capturing second-order curvature effects without matrix inversions. TOCFlow therefore matches the geometric consistency of Gauss-Newton updates at the computational cost of standard gradient guidance. We evaluate TOCFlow on three high-dimensional scientific tasks spanning equality, inequality, and global statistical constraints, namely Darcy flow, constrained trajectory planning, and turbulence snapshot generation with Kolmogorov spectral scaling. Across all settings, TOCFlow improves constraint satisfaction over Euclidean guidance and projection baselines while preserving the reference model's generative quality.

</details>


### [128] [Class Adaptive Conformal Training](https://arxiv.org/abs/2601.09522)
*Badr-Eddine Marani,Julio Silva-Rodriguez,Ismail Ben Ayed,Maria Vakalopoulou,Stergios Christodoulidis,Jose Dolz*

Main category: cs.LG

TL;DR: CaCT 将 conformal training 以增广拉格朗日优化形式实现类条件形状的预测集，在不依赖分布假设的前提下提升预测集的紧凑性与信息量，同时保持覆盖性。


<details>
  <summary>Details</summary>
Motivation: 现有 CP 主要优化全局预测集大小，难以在不同类别下自适应形状集合，往往依赖数据分布先验。需要在保持覆盖性前提下实现类条件的更小、信息量更高的预测集。

Method: 将 conformal training 转化为增广拉格朗日问题，自适应学习以按类别形状预测集；不依赖分布假设；适用于标准与长尾图像识别及文本分类，评估覆盖率与集合大小之间的权衡。

Result: 在多个基准数据集上，CaCT 相较于以往方法显著缩小预测集合，同时维持理论覆盖保证，且在标准与长尾数据、以及文本分类任务上表现一致优于先前方法。

Conclusion: CaCT 展示了无需分布假设即可实现类条件的 conformal training，提供鲁棒、信息量更丰富的预测不确定性量化，适用范围广且具有潜在扩展空间。

Abstract: Deep neural networks have achieved remarkable success across a variety of tasks, yet they often suffer from unreliable probability estimates. As a result, they can be overconfident in their predictions. Conformal Prediction (CP) offers a principled framework for uncertainty quantification, yielding prediction sets with rigorous coverage guarantees. Existing conformal training methods optimize for overall set size, but shaping the prediction sets in a class-conditional manner is not straightforward and typically requires prior knowledge of the data distribution. In this work, we introduce Class Adaptive Conformal Training (CaCT), which formulates conformal training as an augmented Lagrangian optimization problem that adaptively learns to shape prediction sets class-conditionally without making any distributional assumptions. Experiments on multiple benchmark datasets, including standard and long-tailed image recognition as well as text classification, demonstrate that CaCT consistently outperforms prior conformal training methods, producing significantly smaller and more informative prediction sets while maintaining the desired coverage guarantees.

</details>


### [129] [Constraint- and Score-Based Nonlinear Granger Causality Discovery with Kernels](https://arxiv.org/abs/2601.09579)
*Fiona Murphy,Alessio Benavoli*

Main category: cs.LG

TL;DR: 提出将两种基于核的GC方法统一到KPCR框架，并据此提出KPCR相关的因果识别策略；同时引入基于高斯过程的分数型模型，对边际似然施加平滑信息准则惩罚（GP_SIC），以提升非线性时序因果发现性能，并提出一个完全基于GC的同时因果识别算法GP_SIC及与前沿方法的比较。


<details>
  <summary>Details</summary>
Motivation: 解决时序数据中非线性因果发现的挑战；通过理论统一将现有核GC方法整合到KPCR框架，提升因果识别的准确性与稳定性，并引入GP_SIC以改进边际似然优化过程，扩展GC在同时因果识别中的应用。

Method: （1）将两类状态前沿的核GC方法在Kernel PCA Regression (KPCR) 框架下实现理论统一；（2）提出基于高斯过程的分数型模型，并对边际似然施加平滑信息准则惩罚，形成GP_SIC方法；（3）基于GP_SIC提出完全基于GC的同时因果识别算法；（4）与现有最先进行的时序非线性因果发现方法进行比较。

Result: 给出两类核GC方法的理论统一为KPCR框架，证明在该框架下两者等价或可互补；GP_SIC在非线性因果发现任务中表现出改进的识别性能；提出的GC‑SIC同时识别算法在与诸多同类方法比较时显示优越或竞争力的性能。

Conclusion: 通过KPCR的统一框架和GP_SIC量化自适应边际似然的惩罚，实现对非线性时序因果关系的更稳定、准确识别，并扩展了GC在同时因果识别中的应用，展示了核方法与高斯过程结合的潜力。

Abstract: Kernel-based methods are used in the context of Granger Causality to enable the identification of nonlinear causal relationships between time series variables. In this paper, we show that two state of the art kernel-based Granger Causality (GC) approaches can be theoretically unified under the framework of Kernel Principal Component Regression (KPCR), and introduce a method based on this unification, demonstrating that this approach can improve causal identification. Additionally, we introduce a Gaussian Process score-based model with Smooth Information Criterion penalisation on the marginal likelihood, and demonstrate improved performance over existing state of the art time-series nonlinear causal discovery methods. Furthermore, we propose a contemporaneous causal identification algorithm, fully based on GC, using the proposed score-based $GP_{SIC}$ method, and compare its performance to a state of the art contemporaneous time series causal discovery algorithm.

</details>


### [130] [Energy-Entropy Regularization: The True Power of Minimal Looped Transformers](https://arxiv.org/abs/2601.09588)
*Wai-Lun Lam*

Main category: cs.LG

TL;DR: 通过引入 Tsallis 熵与哈密顿动力学的训练框架，重塑参数更新的几何结构，从而成功训练出维度为8的单头循环 Transformer，解决长度为1000的 induction head 任务，揭示其推理能力的内部机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明循环 Transformer 具更强的推理能力，但单头循环结构在基准任务上的训练常因非凸、离散且不规则的损失景观而陷入局部极小值/鞍点，难以从零开始有效训练，因此需要更深入理解模型内部机制并提供更稳健的训练方法。

Method: 将 Tsallis 熵与哈密顿动力学结合，把参数更新视为物理流动，通过改变损失景观几何结构来实现优化过程的动力学转化，具体包括以 Tsallis 熵为正则化/驱动项，和采用基于哈密顿力学的更新规则来引导参数在高维能量表面上穿越鞍点和局部极小。

Result: 在模型维度 d=8 的单头循环 Transformer 上，成功训练完成 induction head 任务，输入序列长度为1000 tokens。

Conclusion: 结果揭示了造成其优越推理能力的内部机制，同时为单头循环 Transformer 的训练提供了可行路径，表明通过物理流动的优化框架可在非凸损失景观中获得更稳定的优化结果。

Abstract: Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The internal mechanisms of these single-head looped transformer models remain poorly understood, and training them from scratch remains a significant challenge. In this paper, we propose a novel training framework that leverages Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape. By treating the parameter updates as a physical flow, we successfully trained a single-head looped Transformer with model dimension $d = 8$ to solve induction head task with input sequence length of 1000 tokens. This success reveals the internal mechanism behind the superior reasoning capability.

</details>


### [131] [Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric](https://arxiv.org/abs/2601.09624)
*Jiali Cheng,Ziheng Chen,Chirag Agarwal,Hadi Amiri*

Main category: cs.LG

TL;DR: 提出 Circuit-guided Unlearning Difficulty (CUD) 指标，通过模型电路信号对样本进行预评估的无痕难度，能区分易删与难删样本并揭示深层计算路径的机制性差异。


<details>
  <summary>Details</summary>
Motivation: 无痕学习的效果在样本之间差异显著，且不仅由数据决定，亦由模型内部记忆机制所驱动。本研究从模型回路出发，寻求解释性机制与可预测的无痕难度。

Method: 提出 CUD 指标，基于电路级信号对样本进行连续的无痕难度评分；通过对原始模型中信息流通路的长度、深度、以及在早中段与晚期计算中的分布进行分析，确定易删样本与难删样本的机制性特征；在多种无痕方法上测试稳定性。

Result: CUD 能稳定区分易删与难删样本，且对不同无痕方法具有鲁棒性；识别出易删样本倾向于短、浅、早段路径，难删样本依赖更长、深且靠近后期计算的路径，形成可解释的机械签名。

Conclusion: 为无痕难度提供了第一批 principled、细粒度且可解释的分析，推动基于模型机制的无痕方法开发。

Abstract: Machine unlearning is becoming essential for building trustworthy and compliant language models. Yet unlearning success varies considerably across individual samples: some are reliably erased, while others persist despite the same procedure. We argue that this disparity is not only a data-side phenomenon, but also reflects model-internal mechanisms that encode and protect memorized information. We study this problem from a mechanistic perspective based on model circuits--structured interaction pathways that govern how predictions are formed. We propose Circuit-guided Unlearning Difficulty (CUD), a {\em pre-unlearning} metric that assigns each sample a continuous difficulty score using circuit-level signals. Extensive experiments demonstrate that CUD reliably separates intrinsically easy and hard samples, and remains stable across unlearning methods. We identify key circuit-level patterns that reveal a mechanistic signature of difficulty: easy-to-unlearn samples are associated with shorter, shallower interactions concentrated in earlier-to-intermediate parts of the original model, whereas hard samples rely on longer and deeper pathways closer to late-stage computation. Compared to existing qualitative studies, CUD takes a first step toward a principled, fine-grained, and interpretable analysis of unlearning difficulty; and motivates the development of unlearning methods grounded in model mechanisms.

</details>


### [132] [Exploring Fine-Tuning for Tabular Foundation Models](https://arxiv.org/abs/2601.09654)
*Aditya Tanna,Pratinav Seth,Mohamed Bouadi,Vinay Kumar Sankarapu*

Main category: cs.LG

TL;DR: 对包括 TALENT、OpenML-CC18、TabZilla 在内的多基准上，系统性比较 Zero-Shot、Meta-Learning、Supervised Fine-Tuning (SFT) 与 PEFT 在 Tabular Foundation Models (TFMs) 上的微调策略。结论：零-shot 表现已很强，微调收益高度依赖模型与数据；SFT 常导致准确性或校准下降；Meta-Learning 与 PEFT 在特定条件下有中等增益；数据特征如不均衡、规模、维度显著影响结果，给出实用指南及局限性。


<details>
  <summary>Details</summary>
Motivation: 理解结构化数据场景中，TFMs 的不同微调策略的有效性及其对性能、校准和公平性的影响，填补大规模对比研究的空白。

Method: 跨基准评估：TALENT、OpenML-CC18、TabZilla；比较 Zero-Shot、Meta-Learning、SFT、PEFT 等；分析数据集特征（不均衡、样本量、维度）对性能、校准、公平性的影响。

Result: Zero-shot TFMs 已具强烈竞争力；微调收益受模型与数据依赖，SFT 常降低准确性或校准；Meta-Learning 与 PEFT 在特定条件下可实现中等增益；数据特征（不均衡、规模、维度）显著影响结果。

Conclusion: 微调在 TFMs 上并非普适良药，应结合数据特征选择策略，给出何时微调有益的实践指南，同时关注校准与公平性，且需警惕 SFT 的潜在负效应。

Abstract: Tabular Foundation Models (TFMs) have recently shown strong in-context learning capabilities on structured data, achieving zero-shot performance comparable to traditional machine learning methods. We find that zero-shot TFMs already achieve strong performance, while the benefits of fine-tuning are highly model and data-dependent. Meta-learning and PEFT provide moderate gains under specific conditions, whereas full supervised fine-tuning (SFT) often reduces accuracy or calibration quality. This work presents the first comprehensive study of fine-tuning in TFMs across benchmarks including TALENT, OpenML-CC18, and TabZilla. We compare Zero-Shot, Meta-Learning, Supervised (SFT), and parameter-efficient (PEFT) approaches, analyzing how dataset factors such as imbalance, size, and dimensionality affect outcomes. Our findings cover performance, calibration, and fairness, offering practical guidelines on when fine-tuning is most beneficial and its limitations.

</details>


### [133] [Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection](https://arxiv.org/abs/2601.09684)
*Ziyu Yang,Guibin Chen,Yuxin Yang,Aoxiong Zeng,Xiangquan Yang*

Main category: cs.LG

TL;DR: Ortho-LoRA uses gradient projection to align multi-task LoRA adapters, reducing negative transfer and recovering most of the multi-task vs single-task gap with minimal overhead.


<details>
  <summary>Details</summary>
Motivation: MTL with LoRA suffers from task interference due to a shared, low-rank adapter; a method is needed to disentangle conflicting gradients within the LoRA subspace.

Method: A gradient projection approach tailored to LoRA's bipartite structure that projects conflicting task gradients onto the orthogonal complement within the intrinsic LoRA subspace, preserving task-specific updates while reducing interference.

Result: Experiments on GLUE show effective mitigation of task interference, outperforming standard joint training and recovering ~95% of the performance gap between multi-task and single-task baselines with negligible computational overhead.

Conclusion: Ortho-LoRA effectively reduces task interference in LoRA-based MTL, enabling efficient, near-parity multi-task performance with minimal extra cost.

Abstract: Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.

</details>


### [134] [Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design](https://arxiv.org/abs/2601.09693)
*Lisa Schneckenreiter,Sohvi Luukkonen,Lukas Friedrich,Daniel Kuhn,Günter Klambauer*

Main category: cs.LG

TL;DR: 提出ConGLUDe，一体化的结构-配体对比学习框架，在缺少口袋信息的情况下实现零-shot虚拟筛选、目标捕获与口袋预测的联合能力；展示统一结构-配体训练的潜力，成为药物发现通用基础模型的有力候选。


<details>
  <summary>Details</summary>
Motivation: 长期以来，结构基和配体基药物设计各自依赖分离的数据源与假设，难以在规模上联合利用。需要一个能够统一结构与配体信息、端到端学习的模型，以提升虚拟筛选、目标发现与口袋预测的综合性能并促进迁移学习。

Method: 提出一个单一的对比几何模型ConGLUDe，结合全蛋白表示与预测结合位点的隐式嵌入的几何蛋白编码器，以及一个高效的配体编码器。通过对比学习将配体在全局蛋白表征和多个候选位点之间建立对齐关系，且无需预定义口袋信息。训练数据包括蛋白-配体复合物和大规模生物活性数据，使模型能够进行配体条件的口袋预测、虚拟筛选和目标捕获等任务。

Result: 在多种基准上实现零-shot虚拟筛选的SOTA，且在无输入口袋信息的情形下显著优于现有方法的目标捕获任务；对配体条件的口袋选择具有竞争力；结果体现了统一结构-配体训练的优势，推动其成为药物发现的通用基础模型的一步。

Conclusion: ConGLUDe展示了统一结构-配体对比学习的潜力，证明在不同药物发现任务中对齐全局蛋白表征与局部结合信息的有效性，支持向更通用的基础模型发展。

Abstract: Structure-based and ligand-based computational drug design have traditionally relied on disjoint data sources and modeling assumptions, limiting their joint use at scale. In this work, we introduce Contrastive Geometric Learning for Unified Computational Drug Design (ConGLUDe), a single contrastive geometric model that unifies structure- and ligand-based training. ConGLUDe couples a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding sites with a fast ligand encoder, removing the need for pre-defined pockets. By aligning ligands with both global protein representations and multiple candidate binding sites through contrastive learning, ConGLUDe supports ligand-conditioned pocket prediction in addition to virtual screening and target fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data. Across diverse benchmarks, ConGLUDe achieves state-of-the-art zero-shot virtual screening performance in settings where no binding pocket information is provided as input, substantially outperforms existing methods on a challenging target fishing task, and demonstrates competitive ligand-conditioned pocket selection. These results highlight the advantages of unified structure-ligand training and position ConGLUDe as a step toward general-purpose foundation models for drug discovery.

</details>
