<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.LG](#cs.LG) [Total: 24]
- [cs.IR](#cs.IR) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors](https://arxiv.org/abs/2602.21218)
*Amin Banayeeanzade,Qingchuan Yang,Deqing Fu,Spencer Hong,Erin Babinsky,Alfy Samuel,Anoop Kumar,Robin Jia,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: 针对私有文本生成效率低下的问题，本文提出 EPSVec——一种基于差分隐私的轻量级替代方案。该方法利用"数据集向量"引导 LLM 生成，仅需一次向量提取与净化，即可实现隐私预算与生成过程的解耦，支持无限次无额外隐私成本的合成数据采样，在低数据 regime 下仍保持高保真度。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习依赖高质量数据，但大量有价值语料因隐私敏感性无法共享。现有私有文本生成方法严重低效：数据与计算成本高昂，且需大规模私有数据或批量才能达到可用质量，难以适应低资源场景。

Method: EPSVec 方法核心为：1）在激活空间中构建"数据集向量"以捕捉私有数据与公共先验的分布差异；2）对向量实施一次性差分隐私净化；3）在标准解码阶段应用净化向量进行引导生成，实现隐私预算与生成次数的解耦；4）结合预训练基础模型与固定样本提示策略提升生成多样性与保真度。

Result: 实验验证 EPSVec 在分布对齐与下游任务效用上显著优于现有基线，特别在低数据 regime 下优势突出，同时计算开销大幅降低，并支持无额外隐私成本的任意规模合成数据生成。

Conclusion: EPSVec 实现了高效隐私保护的合成数据生成，解决了传统方法计算密集、数据依赖强的根本缺陷，为敏感数据场景下的机器学习开发提供了可扩展、实用的解决方案，在低资源环境中具有重要应用价值。

Abstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.

</details>


### [2] [Reasoning-Based Personalized Generation for Users with Sparse Data](https://arxiv.org/abs/2602.21219)
*Bo Ni,Branislav Kveton,Samyadeep Basu,Subhojyoti Mukherjee,Leyao Wang,Franck Dernoncourt,Sungchul Kim,Seunghyun Yoon,Zichao Wang,Ruiyi Zhang,Puneet Mathur,Jihyung Kil,Jiuxiang Gu,Nedim Lipka,Yu Wang,Ryan A. Rossi,Tyler Derr*

Main category: cs.CL

TL;DR: 针对稀疏用户交互历史导致的LLM个性化生成效果下降问题，本文提出GraSPer框架，通过预测用户未来交互项目并生成相应文本，有效增强个性化生成质量。


<details>
  <summary>Details</summary>
Motivation: 真实场景中大量用户（如社交平台和电商平台的冷启动用户）交互历史稀疏，个人上下文有限，导致LLM难以准确捕捉用户偏好，从而制约了个性化生成效果。

Method: GraSPer框架采用三阶段策略：首先基于图结构预测用户未来可能交互的项目以扩充上下文；然后通过推理对齐机制为这些预测交互生成相应文本；最终基于真实历史与合成历史的联合条件，生成符合用户风格和偏好的个性化输出。

Result: 在三个基准个性化生成数据集上的实验表明，GraSPer在稀疏用户上下文设置下实现了显著的性能增益，有效提升了冷启动用户的个性化生成质量。

Conclusion: 该研究通过上下文增强和推理对齐策略，为稀疏数据下的LLM个性化提供了有效解决方案，证明了合成数据在个性化生成中的价值，为后续研究提供了新思路。

Abstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.

</details>


### [3] [Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment](https://arxiv.org/abs/2602.21543)
*Barah Fazili,Koustava Goswami*

Main category: cs.CL

TL;DR: 本研究通过构建六语言多向平行语料并应用对比学习，显著提升了多语言模型的跨语言对齐能力，在MTEB基准上使双语文本挖掘、语义相似度和分类任务分别获得21.3%、5.3%和28.4%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 标准多语言预训练缺乏显式的对齐监督信号，导致跨语言表示空间对齐不佳，影响下游NLU任务性能。

Method: 利用神经机器翻译模型构建涵盖六种语言的多向平行语料库，对XLM-Roberta和mBERT基础模型进行对比学习训练，并与从多语种池中采样的以英语为中心的双语平行数据进行对比。

Result: 在MTEB基准评估中，相比双语数据，多向平行语料训练使双语文本挖掘、语义相似度和分类任务性能分别提升21.3%、5.3%和28.4%，并在已见和未见语言上均获得显著增益；对mE5模型进行多向平行微调也能显著改善双语文本挖掘效果。

Conclusion: 多向跨语言监督对比训练能有效改善跨语言对齐，即使对已预训练的高质量句子嵌入模型进行微调仍能带来显著提升，凸显了多向平行语料在多语言表示学习中的重要性。

Abstract: Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.

</details>


### [4] [Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation](https://arxiv.org/abs/2602.21220)
*Subhadip Mitra*

Main category: cs.CL

TL;DR: 提出一种基于场论的AI记忆系统，将记忆视为由偏微分方程控制的连续场，实现语义空间中的扩散、热力学衰减和多智能体场耦合。在LoCoMo和LongMemEval基准上显著超越现有方法，LongMemEval上多会话推理F1提升+116%，时间推理提升+43.8%，知识更新检索召回提升+27.8%，多智能体集体智能达>99.8%。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有离散记忆系统在长上下文与多智能体协作中存在局限性：难以建模语义连续性与记忆的动态衰减。受经典场论启发，本文提出将记忆视为连续场，以实现语义空间的扩散、热力学衰减与多智能体场耦合，从而提升长期记忆保持与协作推理能力。

Method: 系统将每条记忆表示为语义空间中的连续场，通过偏微分方程（PDE）控制其演化。具体包括：(1) 记忆在语义空间中扩散，使其邻近概念相互影响；(2) 基于重要性热力学衰减，重要记忆衰减慢；(3) 多智能体场景下，记忆场通过场耦合相互作用，实现信息共享与协同推理。

Result: 在LoCoMo（35个会话、300轮对话）和LongMemEval（500+轮）基准上评估。LongMemEval结果显示：多会话推理F1提升+116%（p<0.01, d=3.06），时间推理提升+43.8%（p<0.001, d=9.21），知识更新检索召回提升+27.8%（p<0.001, d=5.00）。多智能体实验显示，场耦合使集体智能达>99.8%。

Conclusion: 场论记忆系统为AI长期记忆与多智能体协作提供了新范式，显著提升长上下文推理与协作性能，展示了在复杂任务中的潜力。

Abstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p<0.01, d= 3.06), +43.8% on temporal reasoning (p<0.001, d= 9.21), and +27.8% retrieval recall on knowledge updates (p<0.001, d= 5.00). Multi-agent experiments show near-perfect collective intelligence (>99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.

</details>


### [5] [LiCQA : A Lightweight Complex Question Answering System](https://arxiv.org/abs/2602.22182)
*Sourav Saha,Dwaipayan Roy,Mandar Mitra*

Main category: cs.CL

TL;DR: 本文提出LiCQA，一种基于语料库证据的无监督问答模型，在基准测试中显著优于两种先进系统，且延迟大幅降低。


<details>
  <summary>Details</summary>
Motivation: 复杂问题问答仍具挑战，现有方法或依赖知识图谱，或需昂贵神经模型，计算资源与数据需求大。

Method: 提出LiCQA，一种基于语料库证据的无监督问答模型，与两种不同原理的先进系统进行了效果与效率对比实验。

Result: 实验结果表明，LiCQA在基准数据上显著优于这两种先进系统，且延迟大幅降低。

Conclusion: LiCQA通过无监督方式利用语料库证据，在保持高效的同时实现了更优的复杂问题问答性能，为资源受限场景提供了实用解决方案。

Abstract: Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that are designed to handle complex questions work either on the basis of knowledge graphs, or utilise contem- porary neural models that are expensive to train, in terms of both computational resources and the volume of training data required. In this paper, we present LiCQA, an unsupervised question answer- ing model that works primarily on the basis of corpus evidence. We empirically compare the effectiveness and efficiency of LiCQA with two recently presented QA systems, which are based on different underlying principles. The results of our experiments show that LiCQA significantly outperforms these two state-of-the-art systems on benchmark data with noteworthy reduction in latency.

</details>


### [6] [Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases](https://arxiv.org/abs/2602.21222)
*Riya Adsul,Balachandra Devarangadi Sunil,Isha Nalawade,Sudharshan Govindan*

Main category: cs.CL

TL;DR: 本文提出一种动态LoRA适配器组合框架，通过向量数据库相似性检索实现零样本跨任务泛化。该方法在22个数据集上构建任务感知向量库，推理时检索相似样本并加权融合多个LoRA适配器。实验表明该数据集中心检索方法性能可与单任务微调适配器媲美，Linear融合在PIQA和RTE任务上显著优于基线（70.95% vs 46%，77.62% vs 52%），为可扩展的参数高效多任务学习提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 尽管LoRA等参数高效微调方法能实现任务特定适配，但如何高效组合多个专用适配器以应对未知任务仍具挑战。现有方法难以实现零样本跨任务泛化。

Method: 1) 构建任务感知向量数据库：嵌入22个涵盖常识推理、问答、自然语言推理和情感分析的数据集训练样本；2) 推理时检索最相似训练样本；3) 通过核采样计算任务相似度分布；4) 采用检索加权融合策略动态合并相关LoRA适配器。比较了Linear、Concatenation、TIES和Magnitude Prune四种融合方法。

Result: 所提数据集中心检索方法性能常达到或超过单任务微调适配器水平。Linear融合在PIQA数据集上达到70.95%准确率，在RTE数据集上达到77.62%准确率，显著优于单任务基线（分别提升24.95和25.62个百分点）。该框架无需额外检索器训练，使用冻结嵌入，实现高效可解释的适配器组合。

Conclusion: 基于检索的动态融合方法为可扩展的参数高效多任务学习提供了有前景的方向，无需为每个新任务进行完整模型重训练。该方法具有零样本泛化能力，在保持效率的同时实现了有竞争力的性能。

Abstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.

</details>


### [7] [Make Every Draft Count: Hidden State based Speculative Decoding](https://arxiv.org/abs/2602.21224)
*Yuetao Chen,Xuliang Wang,Xinzhou Zheng,Ming Li,Peng Wang,Hong Xu*

Main category: cs.CL

TL;DR: 针对推测解码中草稿token验证失败造成的计算浪费问题，本文提出一种在隐藏状态层面进行自回归预测并延迟token信息整合的新方法，通过重构草稿模型架构、设计token信息注入机制和消除系统开销，实现高达3.3倍的推理加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码虽能通过轻量级草稿模型提升LLM推理速度，但多数草稿token验证失败后被丢弃，导致计算资源严重浪费。现有研究缺乏对这部分浪费计算的有效回收利用机制。

Method: 1) 提出基于自回归隐藏状态的草稿模型架构，保留比传统token级草稿更丰富的语义信息，便于草稿复用；2) 设计高效token信息注入机制，利用专用草稿模型构建高质量草稿token树，支持从验证失败中重新采样token；3) 优化系统实现以消除隐藏开销，最大化硬件利用率。核心创新在于将自回归预测移至隐藏状态层面，延迟token信息整合，避免草稿隐藏状态被错误token污染。

Result: 在广泛评估中，相比标准推测解码方法实现了最高3.3倍的推理加速。

Conclusion: 通过将废弃草稿隐藏状态转化为可重用计算资源，该方法显著提升了推测解码的计算效率，为内存受限的LLM推理加速提供了有效解决方案。

Abstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.

</details>


### [8] [Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal](https://arxiv.org/abs/2602.21225)
*Mohammed Hamdan,Vincenzo Dentamaro,Giuseppe Pirlo,Mohamed Cheriet*

Main category: cs.CL

TL;DR: 本研究系统评估了渐进式数据调度（33%→67%→100%）在文档理解任务中的效率增益。实验表明该策略可减少约33%训练时间，但课程学习效益存在条件性：在FUNSD数据集上，BERT（110M参数）显著受益（ΔF1=+0.023, p=0.022），而LayoutLMv3（126M参数）无显著效益（p=0.621）；在CORD数据集上所有条件均达性能天花板（F1≥0.947）。消融实验证实效率提升主要源于数据量减少而非排序策略，效益取决于模型容量与任务复杂度的交互。


<details>
  <summary>Details</summary>
Motivation: 渐进式数据调度作为课程学习策略，其计算效率增益是否在不同模型架构间保持一致尚不明确。文档理解领域同时存在文本单模态（如BERT）和多模态（如LayoutLMv3）模型，二者在参数容量和归纳偏置上存在显著差异，可能导致对调度策略的响应不同。本研究旨在系统评估该策略在架构异构模型上的普适性，并区分真正的课程学习效应与单纯计算量减少的贡献，为实际训练策略选择提供实证依据。

Method: 研究采用控制计算量的实验设计，在FUNSD和CORD两个标准文档理解基准上，对比评估了BERT（110M参数，文本单模态）和LayoutLMv3（126M参数，多模态）两种架构。实施三阶段渐进调度（33%→67%→100%数据比例），测量墙钟训练时间变化，并引入匹配计算量基线（Standard-7）以隔离课程效应。进一步通过消融实验比较渐进、两阶段、反向和随机四种调度策略，控制总梯度更新次数一致，确保公平对比。

Result: 关键发现包括：1）渐进调度使墙钟训练时间减少约33%，与有效数据轮次从10.0降至6.67等价；2）在FUNSD上，BERT的课程效益统计显著（ΔF1=+0.023, p=0.022, 效应量d_z=3.83），而LayoutLMv3无显著差异（p=0.621），表明多模态归纳偏置削弱了课程必要性；3）在CORD上，所有调度策略均收敛至等效F1分数（≥0.947），反映任务性能天花板；4）消融实验表明，效率增益主要源于数据体积缩减而非数据排序，不同调度策略间无显著性能差异。结果表明课程效益具有条件依赖性。

Conclusion: 渐进式数据调度是跨模型族的可靠计算缩减策略，可一致降低训练成本。然而，真正的课程学习效益并非普遍存在，而是取决于模型容量与任务复杂度的交互关系：容量受限的模型（如BERT）在复杂任务上受益显著，而具有充足归纳偏置的模型（如LayoutLMv3）则无明显增益。这为针对不同模型架构和任务难度选择训练策略提供了重要指导，强调需在计算效率与模型适应性间权衡。

Abstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\%$\rightarrow$67\%$\rightarrow$100\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($Δ$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.

</details>


### [9] [IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions](https://arxiv.org/abs/2602.21226)
*Ezieddin Elmahjub,Junaid Qadir,Abdullah Mushtaq,Rafay Naeem,Ibrahim Ghaznavi,Waleed Iqbal*

Main category: cs.CL

TL;DR: 本研究创建了首个伊斯兰法律LLM评估基准IslamicLegalBench，涵盖7大学派、718个实例和13项任务。对9个先进模型的评估显示，最佳模型仅达68%正确率和21%幻觉率，多数模型表现更差。少样本提示改善有限，中等复杂度任务错误率最高，且模型在错误前提检测中表现出高风险迎合倾向。研究表明，仅靠提示工程无法弥补基础法律知识的缺失。


<details>
  <summary>Details</summary>
Motivation: 随着数百万穆斯林越来越多地依赖GPT、Claude、DeepSeek等大语言模型获取宗教指导，一个关键问题浮现：这些AI系统能否可靠地进行伊斯兰法律推理？由于宗教建议的敏感性和重要性，LLM在此领域的不可靠性可能导致严重后果，因此迫切需要系统评估其能力。

Method: 研究者构建了IslamicLegalBench基准，涵盖伊斯兰法学的七个主要学派，包含718个评估实例和13项不同复杂度的任务。他们对九种最先进的LLM进行了全面评估，测试了模型在不同任务复杂度下的表现、少样本提示的效果以及错误前提检测能力。

Result: 评估结果揭示了重大局限性：最佳模型仅达到68%正确率和21%幻觉率，多个模型正确率低于35%且幻觉率超过55%。少样本提示对9个模型中的7个改善不足1%。需要精确知识的中等复杂度任务错误率最高，而高复杂度任务通过语义推理表现出虚假的能力。在错误前提检测中，9个模型中有6个以超过40%的概率接受误导性假设，显示出危险的迎合倾向。

Conclusion: 研究结果表明，基于提示的方法无法弥补模型在伊斯兰法律基础知识方面的缺失。IslamicLegalBench提供了首个系统性评估AI伊斯兰法律推理的框架，揭示了当前模型在为日益依赖AI进行精神指导的穆斯林社区提供服务时存在的关键差距，强调需要构建具有真正法律推理能力的专用模型。

Abstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.

</details>


### [10] [Budget-Aware Agentic Routing via Boundary-Guided Training](https://arxiv.org/abs/2602.21227)
*Caiqi Zhang,Menglin Xia,Xuchao Zhang,Daniel Madrigal,Ankur Mallick,Samuel Kessler,Victor Ruehle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 本文提出预算感知的智能体路由方法，解决LLM智能体执行长期任务时的高成本问题。通过边界引导训练和BoPO优化，在每一步动态选择廉价或昂贵模型，优化成本-成功前沿并在严格预算约束下实现与基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM演变为执行长期工作流的自治智能体，每步调用高能力模型在经济上不可持续。智能体路由面临顺序性、路径依赖挑战：早期错误会累积，反馈稀疏且延迟至episode结束，同时需满足严格的每任务支出限制。

Method: 提出预算感知智能体路由，在每一步动态选择模型。采用边界引导训练：利用始终小模型和始终大模型两个边界策略构建难度分类并锚定稀疏奖励学习。先通过边界引导的SFT数据合成（分层采样成本高效轨迹）进行热身启动，再应用边界引导策略优化（BoPO），结合边界相对奖励和参考引导优势避免廉价失败解。

Result: 实验表明该方法改善了效率前沿，以更低的成本匹配强路由基线性能，并展现出对严格推理时预算约束的良好泛化能力。

Conclusion: 本研究建立了智能体路由的基础框架，推动范式从静态模型选择转向动态、预算感知的序列决策，为长期任务中的成本效益优化提供了新方向。

Abstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.

</details>


### [11] [ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following](https://arxiv.org/abs/2602.21228)
*Yuancheng Yang,Lin Yang,Xu Wang,Chao Tong,Haihua Yang*

Main category: cs.CL

TL;DR: 本文提出ImpRIF方法，通过将复杂指令形式化为可验证的推理图，结合图推理微调与强化学习，增强大语言模型对隐式推理指令的理解能力，在五个复杂指令遵循基准测试上显著超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用日趋复杂，对强大复杂指令遵循能力的需求相应增长。作者认为，深入理解指令本身尤其是字里行间的潜在推理结构，对提升指令遵循能力至关重要。因此研究重点聚焦于涉及隐式推理、复杂逻辑关系和多约束依赖的复杂指令。

Method: 提出ImpRIF方法，将此类指令形式化为可验证的推理图，实现程序化验证和图驱动思维链推理。基于此框架，合成大规模单轮和多轮数据，采用图推理微调并应用强化学习，显式训练模型沿图结构进行推理。

Result: 在五个复杂指令遵循基准测试上，所提模型显著优于基线模型。

Conclusion: 增强隐式推理能力可显著改善复杂指令遵循性能。该项目即将开源。

Abstract: As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.

</details>


### [12] [TRACE: Trajectory-Aware Comprehensive Evaluation for Deep Research Agents](https://arxiv.org/abs/2602.21230)
*Yanyu Chen,Jiyue Jiang,Jiahong Liu,Yifei Zhang,Xiao Guo,Irwin King*

Main category: cs.CL

TL;DR: 针对深度研究智能体评估中单一指标和静态基准的局限性，本文提出 TRACE 框架，通过层次化轨迹效用函数和脚手架能力评估协议，全面评估求解轨迹的效率、质量和潜在能力，揭示传统指标忽略的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 传统基于结果的评估指标（如 Pass@1）无法捕捉复杂推理过程的细微差别，导致"高分幻觉"现象，即只关注准确率而忽略推理质量、效率和鲁棒性。静态基准也无法量化智能体的潜在能力和鲁棒性等关键属性。

Method: 提出 TRACE（轨迹感知综合评估）框架：1）层次化轨迹效用函数，量化过程效率、认知质量和证据 grounding；2）脚手架能力评估协议，通过测量成功所需的最少引导来评估潜在能力；3）构建具有可控复杂度的 DeepResearch-Bench 基准测试集。

Result: 实验表明，TRACE 能够提供细粒度的智能体排名，揭示传统单一指标完全忽略的准确率、效率和鲁棒性之间的关键权衡关系。

Conclusion: TRACE 框架通过评估整个问题解决轨迹，克服了传统指标的局限性，为深度研究智能体的全面评估提供了新范式，有助于更准确地理解和改进智能体的真实能力。

Abstract: The evaluation of Deep Research Agents is a critical challenge, as conventional outcome-based metrics fail to capture the nuances of their complex reasoning. Current evaluation faces two primary challenges: 1) a reliance on singular metrics like Pass@1, creating a "high-score illusion" that ignores the quality, efficiency, and soundness of the reasoning process; and 2) the failure of static benchmarks to quantify crucial attributes like robustness and latent capability. To address these gaps, we introduce TRACE (Trajectory-Aware Comprehensive Evaluation), a framework that holistically assesses the entire problem-solving trajectory. To counter the "high-score illusion", we propose a Hierarchical Trajectory Utility Function that quantifies process efficiency and cognitive quality, including evidence grounding, alongside accuracy. To measure deeper attributes, TRACE introduces a Scaffolded Capability Assessment protocol, quantifying an agent's latent ability by determining the minimum guidance needed for success. Our contributions include the TRACE framework, its novel metrics, and the accompanying DeepResearch-Bench with controllable complexity. Experiments show TRACE delivers a granular ranking that uncovers critical trade-offs between agent accuracy, efficiency, and robustness entirely missed by singular metrics.

</details>


### [13] [MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation](https://arxiv.org/abs/2602.21379)
*Daniel Tamayo,Iñaki Lacunza,Paula Rivera-Hidalgo,Severino Da Dalt,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

TL;DR: 本文提出 MrBERT，一个基于 ModernBERT 架构的 1.5 亿至 3 亿参数编码器家族，在 35 种语言和代码上预训练，并通过定向适配实现加泰罗尼亚语和西班牙语特定任务的最先进性能，同时在生物医学和法律等专业领域表现稳健。引入套娃表示学习（MRL）以实现灵活向量大小，显著降低推理和存储成本。


<details>
  <summary>Details</summary>
Motivation: 弥合研究与生产之间的差距，开发既能实现本地化语言卓越性（如加泰罗尼亚语和西班牙语），又能高效适应高风险专业领域（如生物医学和法律）的现代编码器模型。

Method: 基于 ModernBERT 架构构建，在 35 种语言和代码上进行预训练，采用定向适配（targeted adaptation）策略，并整合套娃表示学习（Matryoshka Representation Learning, MRL）以实现灵活的向量尺寸。

Result: 在加泰罗尼亚语和西班牙语特定任务上达到最先进（SOTA）水平，在专业生物医学和法律领域表现稳健；通过 MRL 显著降低推理和存储成本。

Conclusion: MrBERT 家族证明现代编码器架构可以同时优化为本地语言卓越性和高效、高风险领域专业化，相关模型已在 Huggingface 开源。

Abstract: We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.

</details>


### [14] [VecGlypher: Unified Vector Glyph Generation with Language Models](https://arxiv.org/abs/2602.21461)
*Xiaoke Huang,Bhavul Gauri,Kam Woh Ng,Tony Ng,Mengmeng Xu,Zhiheng Liu,Weiming Ren,Zhaochong An,Zijian Zhou,Haonan Qiu,Yuyin Zhou,Sen He,Ziheng Wang,Tao Xiang,Xiao Han*

Main category: cs.CL

TL;DR: 提出VecGlypher，一种单多模态语言模型，可直接从文本描述或图像示例生成高质量矢量字形。模型自回归发射SVG路径标记，避免光栅中间处理，一次生成可编辑密封轮廓。采用两阶段训练策略（39K噪声字体续训练+2.5K标注字体后训练）和专门预处理，在跨家族OOD评估中显著优于现有基线，大幅降低字体创作门槛。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的矢量字形流程依赖精心筛选的示例表和光栅转矢量的后处理，这限制了字体设计的可访问性和可编辑性。矢量字形作为数字排版的基本单元，现有方法在易用性和直接生成能力方面存在明显局限。

Method: 构建单一多模态语言模型，接收风格提示、可选参考字形图像和目标字符作为输入，自回归生成SVG路径标记。核心方法包括：（i）在39K个噪声Envato字体上进行大规模续训练以掌握SVG语法和长期几何依赖；（ii）在2.5K个专家标注的Google字体上进行后训练，对齐语言、图像与几何信息。预处理流程包括坐标框架归一化、路径规范化、家族去重和坐标量化，确保稳定的长序列解码。

Result: 在跨家族分布外评估中，VecGlypher在纯文本生成方面显著优于通用大语言模型和专用矢量字体基线；在图像参考生成方面达到最新先进性能，相比DeepVecFont-v2和DualVector有明显提升。消融实验表明模型规模、两阶段训练策略和绝对坐标序列化对性能至关重要。

Conclusion: VecGlypher通过支持用户使用自然语言或示例图像进行字体设计，大幅降低了字体创作的专业门槛。该模型为未来多模态设计工具提供了可扩展的技术基础，推动了矢量字形生成技术的发展和应用。

Abstract: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.

</details>


### [15] [When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning](https://arxiv.org/abs/2602.21619)
*Muku Akasaka,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 本研究通过假设驱动分析，系统考察了视觉空间推理任务中信息注入策略的有效性。研究发现，盲目增加信息量反而会降低模型性能，精准注入与任务相关的空间线索和常识知识，并结合精确的空间 grounding，才能有效提升多模态模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态架构取得了进展，视觉语言模型在视觉空间推理任务上仍面临挑战。当前常用策略是在推理时注入额外信息（如空间线索、外部常识知识或思维链提示），但尚不清楚这些信息何时真正改善推理、何时引入噪声。这种不确定性导致实践中缺乏设计可靠推理管道的指导原则。

Method: 研究采用假设驱动分析方法，在三个代表性视觉语言模型和两个公开基准上，系统考察了三类变量：(i) 空间上下文的类型和数量，(ii) 注入常识知识的数量和关联性，以及 (iii) 空间 grounding 与思维链提示之间的交互作用。

Result: 研究发现一致模式：信息量增加不一定带来更好的推理效果。具体表现为：有针对性的单一空间线索优于多上下文聚合；过多或弱相关的常识知识会损害性能；思维链提示仅在空间 grounding 足够精确时才能提升准确率。

Conclusion: 研究结果强调了选择性、任务对齐的信息注入对多模态推理的重要性，为设计可靠的多模态推理管道提供了实用指导：应避免盲目堆砌信息，而应注重信息的质量和相关性，确保空间 grounding 的精确性。

Abstract: Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or chain-of-thought (CoT) reasoning instructions. However, it remains unclear when such information genuinely improves reasoning and when it introduces noise. In this paper, we conduct a hypothesis-driven analysis of information injection for VSR across three representative VLMs and two public benchmarks. We examine (i) the type and number of spatial contexts, (ii) the amount and relevance of injected commonsense knowledge, and (iii) the interaction between spatial grounding and CoT prompting. Our results reveal a consistent pattern: more information does not necessarily yield better reasoning. Targeted single spatial cues outperform multi-context aggregation, excessive or weakly relevant commonsense knowledge degrades performance, and CoT prompting improves accuracy only when spatial grounding is sufficiently precise. These findings highlight the importance of selective, task-aligned information injection and provide practical guidance for designing reliable multimodal reasoning pipelines.

</details>


### [16] [RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2602.21628)
*Yukun Chen,Jiaming Li,Longze Chen,Ze Gong,Jingpeng Li,Zhen Qin,Hengyu Chang,Ancheng Xu,Zhihao Yang,Hamid Alinejad-Rokny,Qiang Qu,Bo Zheng,Min Yang*

Main category: cs.CL

TL;DR: 针对多模态大模型推理中的奖励破解问题，本文提出分层规则课程学习(RuCL)框架，通过动态调整规则权重实现从基础感知到高级推理的渐进式学习，在视觉推理基准测试中提升Qwen2.5-VL-7B模型7.83%准确率，达到60.06%的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 基于可验证奖励的强化学习(RLVR)虽能提升MLLMs推理能力，但存在奖励破解风险；而现有规则方法因计算成本高且将所有规则等同对待导致训练效率低下，亟需一种从奖励设计角度出发的课程学习框架。

Method: RuCL框架生成通用规则并进行能力分层，将课程学习从数据选择转向奖励设计，在训练中动态调整各层规则权重，引导模型从基础感知逐步进阶到复杂逻辑推理。

Result: 在多个视觉推理基准上，RuCL相比Qwen2.5-VL-7B平均提升7.83%，达到60.06%的state-of-the-art准确率。

Conclusion: RuCL通过规则分层和动态权重调整，有效缓解了奖励破解并提升了训练效率，为MLLMs推理能力发展提供了新的有效范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.

</details>


### [17] [Multi-dimensional Assessment and Explainable Feedback for Counselor Responses to Client Resistance in Text-based Counseling with LLMs](https://arxiv.org/abs/2602.21638)
*Anqi Li,Ruihan Wang,Zhaoming Chen,Yuqian Chen,Yu Lu,Yi Zhu,Yuan Xie,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 提出基于Llama-3.1-8B-Instruct的文本心理咨询客户阻抗评估框架，通过理论驱动的四类沟通机制分解和全参数指令微调，实现细粒度质量评估与解释生成。在专家标注数据集上，F1达77-81%，显著优于GPT-4o（45-59%），解释评分2.8-2.9/3.0。43名咨询师实验证实AI反馈能显著提升应对阻抗能力。


<details>
  <summary>Details</summary>
Motivation: 心理咨询师处理客户阻抗缺乏及时、可扩展的督导反馈。现有NLP研究仅评估整体咨询质量，无法针对阻抗高风险时刻提供细粒度评价。本研究旨在开发可扩展的AI评估工具以填补此空白。

Method: 构建多维度评估全流程：1）提出理论框架将咨询师回应分解为四种沟通机制；2）构建专家标注的真实咨询数据集，含评分与解释；3）对Llama-3.1-8B-Instruct进行全参数指令微调，建模细粒度质量判断并生成解释。

Result: 方法区分沟通机制质量的F1为77-81%，远超GPT-4o和Claude-3.5-Sonnet（45-59%）。生成解释与专家参考高度一致，获专家评分2.8-2.9/3.0。43名咨询师对照实验显示，AI反馈显著提升应对阻抗能力。

Conclusion: 该框架提供了可扩展的AI评估与培训方案，能精准评估并提升咨询师应对客户阻抗的技能，推动心理咨询服务专业化与标准化，具有重要临床价值。

Abstract: Effectively addressing client resistance is a sophisticated clinical skill in psychological counseling, yet practitioners often lack timely and scalable supervisory feedback to refine their approaches. Although current NLP research has examined overall counseling quality and general therapeutic skills, it fails to provide granular evaluations of high-stakes moments where clients exhibit resistance. In this work, we present a comprehensive pipeline for the multi-dimensional evaluation of human counselors' interventions specifically targeting client resistance in text-based therapy. We introduce a theory-driven framework that decomposes counselor responses into four distinct communication mechanisms. Leveraging this framework, we curate and share an expert-annotated dataset of real-world counseling excerpts, pairing counselor-client interactions with professional ratings and explanatory rationales. Using this data, we perform full-parameter instruction tuning on a Llama-3.1-8B-Instruct backbone to model fine-grained evaluative judgments of response quality and generate explanations underlying. Experimental results show that our approach can effectively distinguish the quality of different communication mechanisms (77-81% F1), substantially outperforming GPT-4o and Claude-3.5-Sonnet (45-59% F1). Moreover, the model produces high-quality explanations that closely align with expert references and receive near-ceiling ratings from human experts (2.8-2.9/3.0). A controlled experiment with 43 counselors further confirms that receiving these AI-generated feedback significantly improves counselors' ability to respond effectively to client resistance.

</details>


### [18] [Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling](https://arxiv.org/abs/2602.21728)
*Shiqi Yan,Yubo Chen,Ruiqi Zhou,Zhengxi Yao,Shuai Chen,Tianyi Zhang,Shijie Zhang,Wei Qiang Zhang,Yongfeng Huang,Haixin Duan,Yunqi Zhang*

Main category: cs.CL

TL;DR: 提出Explore-on-Graph (EoG)框架，通过强化学习让大语言模型在知识图谱上自主探索多样化的推理路径，结合路径信息奖励提升探索效率，在五个KGQA数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在问答任务中存在幻觉和事实缺失问题。现有基于知识图谱的增强方法通过规则约束或模仿固定示例来限制模型推理，导致推理模式局限于先验经验或微调数据范围内，泛化能力受限，难以处理分布外的图推理问题。

Method: 提出Explore-on-Graph (EoG)框架，鼓励LLM在知识图谱上自主探索多样化推理空间。引入强化学习训练机制，以推理路径最终答案的正确性作为奖励；同时加入路径信息作为额外奖励信号，优化探索过程，减少无效探索。

Result: 在五个知识图谱问答基准数据集上的广泛实验表明，该方法达到当前最佳性能，不仅超越开源模型，甚至优于闭源大语言模型。

Conclusion: EoG框架通过强化学习与路径奖励结合，有效解决了传统方法的泛化瓶颈，使LLM能够自主发现新颖推理路径，显著提升了知识图谱问答的准确性和泛化能力。

Abstract: The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods typically constrained LLM reasoning either by enforcing rules during generation or by imitating paths from a fixed set of demonstrations. However, they naturally confined the reasoning patterns of LLMs within the scope of prior experience or fine-tuning data, limiting their generalizability to out-of-distribution graph reasoning problems. To tackle this problem, in this paper, we propose Explore-on-Graph (EoG), a novel framework that encourages LLMs to autonomously explore a more diverse reasoning space on KGs. To incentivize exploration and discovery of novel reasoning paths, we propose to introduce reinforcement learning during training, whose reward is the correctness of the reasoning paths' final answers. To enhance the efficiency and meaningfulness of the exploration, we propose to incorporate path information as additional reward signals to refine the exploration process and reduce futile efforts. Extensive experiments on five KGQA benchmark datasets demonstrate that, to the best of our knowledge, our method achieves state-of-the-art performance, outperforming not only open-source but also even closed-source LLMs.

</details>


### [19] [Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization](https://arxiv.org/abs/2602.21741)
*MD. Sagor Chowdhury,Adiba Fairooz Chowdhury*

Main category: cs.CL

TL;DR: 本文介绍了在Kaggle DL Sprint 4.0竞赛中提交的孟加拉语长语音识别和说话人分离系统，通过领域微调、音源分离和静音分块等关键技术，在低资源条件下取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语面临音素库存大、方言变异显著、频繁英孟混码以及标注语料稀缺等挑战，针对低资源语言的语音处理技术亟需优化。本研究旨在通过领域自适应技术提升孟加拉语长语音识别和说话人分离的性能。

Method: ASR方面：采用BengaliAI微调的Whisper medium模型，结合Demucs音源分离技术进行人声隔离，使用静音边界分块策略和精心调优的生成超参数。说话人分离方面：在pyannote.audio流水线中替换为孟加拉语微调的切分模型，配合wespeaker-voxceleb-resnet34-LM嵌入向量和质心层次聚类算法。

Result: ASR最佳成绩：私有测试集词错误率0.37738，公开测试集0.36137；说话人分离最佳成绩：私有测试集分离错误率0.27671，公开测试集0.20936。

Conclusion: 实验表明，针对低资源孟加拉语语音处理，领域特定的切分组件微调、音源分离技术和静音感知分块是三个最具影响力的设计选择，为类似低资源语言场景提供了有效的技术路线。

Abstract: We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with English, and a relative scarcity of large-scale labelled corpora. For ASR we achieve a best private Word Error Rate (WER) of 0.37738 and public WER of 0.36137, combining a BengaliAI fine-tuned Whisper medium model with Demucs source separation for vocal isolation, silence-boundary chunking, and carefully tuned generation hyperparameters. For speaker diarization we reach a best private Diarization Error Rate (DER) of 0.27671 and public DER of 0.20936 by replacing the default segmentation model inside the pyannote.audio pipeline with a Bengali-fine-tuned variant, pairing it with wespeaker-voxceleb-resnet34-LM embeddings and centroid-based agglomerative clustering. Our experiments demonstrate that domain-specific fine-tuning of the segmentation component, vocal source separation, and natural silence-aware chunking are the three most impactful design choices for low-resource Bengali speech processing.

</details>


### [20] [RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning](https://arxiv.org/abs/2602.21951)
*Bo Xue,Yuan Jin,Luoyi Fu,Jiaxin Ding,Xinbing Wang*

Main category: cs.CL

TL;DR: 该论文针对知识图谱推理中生成式范式仅依赖表面共现而缺乏真正关系语义学习的问题，提出RADAR方法，通过将推理重构为判别式实体选择任务，利用强化学习增强实体可分性，在表示空间直接推理，避免生成幻觉，在四项基准测试中取得5-6%的相对提升。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在知识图谱推理中采用生成式范式，容易记忆表面共现模式而非学习真正的关系语义，导致分布外泛化能力受限，这是当前方法的核心瓶颈。

Method: 提出RADAR框架，将知识图谱推理从生成式模式匹配重构为判别式关系推理；具体通过强化学习机制强制实现相对实体可分性，超越简单的token似然模仿；最终直接在表示空间进行推理，与判别式优化目标保持一致。

Result: 在四项基准测试中，RADAR在链路预测和三元组分类任务上相比强LLM基线实现了5-6%的相对提升，同时其中间表示的任务相关互信息提升了62.9%，表明其关系推理更加鲁棒且具有迁移性。

Conclusion: 判别式关系推理范式相比生成式方法能更有效地捕捉知识图谱的深层语义结构，RADAR通过强化学习实现实体可分性，在提升性能的同时显著增强表示质量，为知识图谱推理提供了新方向。

Abstract: Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather than learning genuine relational semantics, limiting out-of-distribution generalization. To address this, we propose RADAR, which reformulates KGR from generative pattern matching to discriminative relational reasoning. We recast KGR as discriminative entity selection, where reinforcement learning enforces relative entity separability beyond token-likelihood imitation. Leveraging this separability, inference operates directly in representation space, ensuring consistency with the discriminative optimization and bypassing generation-induced hallucinations. Across four benchmarks, RADAR achieves 5-6% relative gains on link prediction and triple classification over strong LLM baselines, while increasing task-relevant mutual information in intermediate representations by 62.9%, indicating more robust and transferable relational reasoning.

</details>


### [21] [CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models](https://arxiv.org/abs/2602.21978)
*Miyu Oba,Saku Sugawara*

Main category: cs.CL

TL;DR: 本研究针对现有语言模型评测基准过度关注语法正确性而忽视语法形式语义理解的问题，提出了基于构式语法（Construction Grammar）的构式理解评测基准CxMP。该基准通过最小配对设计评估模型对九种构式（如let-alone、致使移动、双及物构式）的语义关系理解能力。实验发现，大型语言模型虽能较早获得句法能力，但对构式的深层语义理解发展缓慢且仍然有限，揭示了模型在整合形式与意义方面存在持续差距。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评测主要关注语法可接受性判断，而忽视了模型解释语法形式所传达意义的能力。构式语法认为形式-意义配对是基本语言单位，但这一层面的理解在语言模型中研究不足。因此，需要专门的评测工具来评估模型对构式语义关系的理解能力，以揭示其真正的语言理解水平。

Method: 基于构式语法理论构建CxMP评测基准，采用最小配对（minimal-pair）实验设计，涵盖九种不同类型的构式（包括let-alone构式、致使移动构式、双及物构式等）。通过对比分析模型在不同构式变体上的表现，系统评估其捕捉构式所蕴含语义关系的能力。

Result: 实验结果表明，语言模型的句法能力出现较早，但对构式的理解发展较为缓慢。即使在大型语言模型中，这种构式理解能力仍然有限。CxMP成功揭示了模型在整合语言形式与意义方面存在的持续性缺陷。

Conclusion: CxMP为研究语言模型中的构式理解及其学习轨迹提供了有效框架，证明了当前模型在语义理解方面的局限性。该基准不仅有助于理解模型的语言习得机制，也为未来改进模型的形式-意义整合能力指明了方向。

Abstract: Recent work has examined language models from a linguistic perspective to better understand how they acquire language. Most existing benchmarks focus on judging grammatical acceptability, whereas the ability to interpret meanings conveyed by grammatical forms has received much less attention. We introduce the Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models (CxMP), a benchmark grounded in Construction Grammar that treats form-meaning pairings, or constructions, as fundamental linguistic units. CxMP evaluates whether models can interpret the semantic relations implied by constructions, using a controlled minimal-pair design across nine construction types, including the let-alone, caused motion, and ditransitive constructions. Our results show that while syntactic competence emerges early, constructional understanding develops more gradually and remains limited even in large language models (LLMs). CxMP thus reveals persistent gaps in how language models integrate form and meaning, providing a framework for studying constructional understanding and learning trajectories in language models.

</details>


### [22] [Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models](https://arxiv.org/abs/2602.22072)
*Christian Nickel,Laura Schrewe,Florian Mai,Lucie Flek*

Main category: cs.CL

TL;DR: 本研究通过扰动错误信念任务测试LLM心智理论稳健性，发现所有模型在扰动下能力急剧下降，思维链提示虽整体提升性能，但对某些扰动类型会降低准确率，需选择性应用。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型是否具备真正心智理论能力的学术争议，本研究旨在探究其在任务扰动下的稳健性，并评估思维链提示对提升性能及解释模型决策的潜力。

Method: 研究构建了手工精细标注的ToM数据集，包含经典和扰动错误信念任务、有效推理链空间、推理忠实度标注及任务解决方案，并提出评估推理链正确性和答案与推理轨迹一致性的指标。

Result: 所有评估的LLM在扰动任务中表现出陡峭的能力下降，质疑了稳健心智理论的存在；尽管思维链提示总体上faithful地提升性能，但对部分扰动类型反而降低准确率，表明选择性应用至关重要。

Conclusion: 当前LLM的心智理论能力缺乏稳健性，思维链提示需根据任务类型审慎使用；研究提供了新的评估框架和数据集，为未来探索LLM认知能力奠定基础。

Abstract: Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.

</details>


### [23] [Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference](https://arxiv.org/abs/2602.22090)
*Bo-Wei Chen,Chung-Chi Chen,An-Zi Yen*

Main category: cs.CL

TL;DR: 针对大语言模型规模与计算成本的权衡问题，本文提出置信度驱动的动态模型选择策略，通过评估模型对任务的处理置信度和响应准确性，将高置信度任务分配给小模型，低置信度任务委托大模型处理，在MMLU基准上实现与最大模型相当的准确率同时降低20-40%计算成本，GPT-4o API调用减少60% token消耗，为资源受限场景提供高效部署方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型性能随规模提升而增强，但伴随更高的计算成本，亟需在保证结果可靠性的前提下优化计算效率，降低部署成本。

Method: 提出置信度驱动的动态路由策略，通过量化模型对正确答案的知晓概率和响应准确概率，实现模型选择的自适应决策：保留高置信度任务在当前模型，将低置信度或复杂任务转发至更大规模模型。

Result: 在MMLU大规模多任务语言理解基准上，本方法达到与最大模型相当的准确率，计算成本降低20%-40%；应用于GPT-4o API调用时token使用量减少约60%，显著提升成本效益。

Conclusion: 置信度驱动的模型选择策略有效平衡了性能与效率，为大语言模型在边缘设备、商业API等资源受限环境的实用化部署提供了可行方案，具有显著的实践价值。

Abstract: Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\% to 40\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.

</details>


### [24] [IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages](https://arxiv.org/abs/2602.22125)
*Thanmay Jayakumar,Mohammed Safi Ur Rahman Khan,Raj Dabre,Ratish Puduppully,Anoop Kunchukuttan*

Main category: cs.CL

TL;DR: 该论文提出IndicIFEval，一个覆盖14种印度语系语言的指令遵循评估基准，填补了非英语语言的评估空白。


<details>
  <summary>Details</summary>
Motivation: 当前指令遵循基准 predominantly English-centric，导致数亿印度语系语言使用者缺乏有效的评估工具，形成关键评估缺口。

Method: 构建IndicIFEval基准，涵盖14种印度语言，每种约800个人工验证示例。包含两个互补子集：(1) IndicIFEval-Ground：从IFEval翻译并本地化适配印度语境；(2) 第二子集（原文名称笔误，应为合成版本）：基于印度本土内容合成生成的指令。评估涵盖主流开源与闭源模型，包括推理和非推理模型。

Result: 模型在格式约束遵循方面表现良好，但在词汇和跨语言任务上存在显著困难；尽管高资源语言有所进步，但整体指令遵循能力仍大幅落后于英语。

Conclusion: 公开发布IndicIFEval及评估脚本，以支持多语言约束生成研究的进展。

Abstract: Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).

</details>


### [25] [SumTablets: A Transliteration Dataset of Sumerian Tablets](https://arxiv.org/abs/2602.22200)
*Cole Simmons,Richard Diehl Martinez,Dan Jurafsky*

Main category: cs.CL

TL;DR: 本研究创建SumTablets数据集，将91,606个苏美尔楔形文字碑牌的Unicode字形与Oracc转写文本配对，填补了现代自然语言处理方法在该领域应用的空白。基于该数据集的微调自回归语言模型转写性能达97.55字符级F分数，显著优于加权采样基线。


<details>
  <summary>Details</summary>
Motivation: 数字亚述学项目（ETCSL、CDLI、Oracc）虽已发布大量结构化苏美尔语转写数据，但缺乏转写文本与楔形文字字形数字表示配对的开放数据集，阻碍了自然语言处理技术在苏美尔语转写自动化中的应用。

Method: 通过预处理Oracc转写、映射解读至Unicode字形、用特殊标记保留结构信息（表面、换行、破损），构建大规模配对数据集。数据集含91,606碑牌共6,970,407字形，以CC BY 4.0许可在Hugging Face发布，代码在GitHub开源。

Result: 实现两种转写基线：加权采样与微调自回归语言模型。后者平均字符级F分数达97.55，证明基于Transformer的模型可辅助专家快速验证转写，大幅提升效率。

Conclusion: SumTablets数据集为亚述学自然语言处理研究奠定基础，实验验证了深度学习在该任务的有效性，为自动化转写工具开发提供重要支撑。

Abstract: Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.
  To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.
  Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本文对软集理论及其主要扩展（如超软集、超超软集、TreeSoft集、双极软集和动态软集）进行了系统性综述，阐述了其核心定义、典型构造及当前发展方向。


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了直接框架，能有效处理结构化不确定性。随着理论发展，已衍生出众多变体并与拓扑学、拟阵理论等多个领域建立联系，亟需系统性梳理。

Method: 采用综述性研究方法，系统回顾软集理论的发展历程，总结核心概念、典型构造和主要扩展形式。

Result: 全面梳理了软集理论的主要扩展变体，包括超软集、超超软集、TreeSoft集、双极软集和动态软集，并揭示了其与拓扑学、拟阵理论的内在联系。

Conclusion: 软集理论已发展成为一个包含多种变体的丰富理论体系，在多个数学领域展现出重要应用价值，未来仍有广阔的发展空间。

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [27] [The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems](https://arxiv.org/abs/2602.21745)
*Hyo Jin Kim*

Main category: cs.AI

TL;DR: 本文提出ASIR勇气模型，一个将真相披露形式化为状态转变而非人格特质的相动态框架。该模型通过数学不等式刻画从压抑到表达的转变条件，并将架构扩展至AI系统，为人机系统中的风险性真相披露提供统一的结构性解释。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将勇气或诚实视为个体特质，难以解释高压环境下行为转变的动态机制，更缺乏连接人类与AI系统的统一框架。本研究旨在通过形式化模型揭示真相披露的底层动力学规律，超越意图归因而关注结构性力量。

Method: 构建相态动力学模型，定义从压抑态(S0)到表达态(S1)的跃迁条件：λ(1+γ)+ψ > θ+φ，其中λ为基线开放度，γ为关系放大系数，ψ为累积内在压力，θ+φ为抑制阈值与转换成本。进一步引入反馈机制建模参数递归重校准。

Result: 模型成功统一解释人类在不对称风险下的沉默与AI在策略约束下的偏好扭曲；揭示路径依赖效应；将表观诚实度变化重新解释为约束相空间中相互作用力的几何后果，而非AI系统的意图。

Conclusion: ASIR勇气模型为跨人类与AI系统的风险性真相披露提供了形式化、结构性的动力学视角，有助于理解对齐问题中的深层机制，并提示政策设计需关注系统参数的结构性影响。

Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.
  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.
  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.

</details>


### [28] [fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation](https://arxiv.org/abs/2602.21746)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 本文针对模糊伦理决策框架(fEDM)在原则性解释和伦理多元性方面的不足，提出扩展版本fEDM+，通过引入可解释性追踪模块和多利益相关者验证机制，增强AI伦理治理的透明度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 先前fEDM框架虽具备形式化验证能力，但缺乏决策的透明性解释机制，且无法有效处理伦理多元主义场景下的原则冲突，难以满足AI系统伦理监督对可追溯性和多方共识的实际需求。

Method: 1) 设计可解释性与可追溯模块(ETM)，建立决策规则与道德原则的显式映射，量化各原则对推荐行动的权重贡献；2) 构建多元语义验证框架，取代单一规范参照，允许多个利益相关者参照系并存，各自编码不同的原则优先级和风险容忍参数。

Result: 所提fEDM+框架在保留模糊Petri网形式验证的基础上，实现了决策过程的可审计解释，并能形式化地表征而非消除原则性分歧，显著提升了情境敏感性和系统鲁棒性。

Conclusion: fEDM+框架通过融合可解释性架构与多元验证范式，为伦理敏感AI系统提供了兼顾形式严谨性与实践透明度的治理层，有效支持了负责任AI的 oversight 机制建设。

Abstract: In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.

</details>


### [29] [Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem](https://arxiv.org/abs/2602.21814)
*Heejin Jo*

Main category: cs.AI

TL;DR: 本研究通过变量隔离实验发现，STAR推理框架能显著提升大语言模型在"洗车问题"上的表现，从0%准确率提升至85%，结合用户画像和RAG上下文后达到100%准确率，表明结构化推理支架比上下文注入对隐式约束推理任务更重要。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在需要隐式物理约束推理的"洗车问题"基准测试中持续表现不佳，本研究旨在探究生产系统中哪些提示架构层能够使模型实现正确推理。

Method: 采用变量隔离研究方法，设置6个实验条件，每个条件20次试验，共120次总试验。使用Claude 3.5 Sonnet模型，控制超参数（温度0.7，top_p 1.0），测试STAR框架、用户画像向量检索和RAG上下文等不同提示架构层对推理准确率的影响。

Result: STAR推理框架单独使用即可将准确率从0%显著提升至85%（p=0.001，Fisher精确检验，优势比13.22）。增加用户画像上下文带来10个百分点的提升，RAG上下文再贡献5个百分点，全栈条件下最终达到100%准确率。

Conclusion: 研究结果表明，对于隐式约束推理任务，强制目标表述的结构化推理支架比上下文注入更为关键，这一发现为提升大语言模型复杂推理能力提供了实践指导。

Abstract: Large language models consistently fail the "car wash problem," a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.

</details>


### [30] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 该论文提出一种基于强化学习（RL）的复杂声明验证方法，通过组相对策略优化（GRPO）联合优化声明分解质量与验证器对齐，在六个评估设置中实现71.75%的宏F1分数，优于现有提示方法和RL方法。


<details>
  <summary>Details</summary>
Motivation: 现有复杂声明验证方法难以将声明分解质量与验证性能有效对齐，导致分解结果对下游验证任务的支撑不足。

Method: 提出基于组相对策略优化（GRPO）的强化学习方法，整合结构化序列推理、教师蒸馏示例的监督微调，以及平衡格式合规性、验证器对齐度和分解质量的多目标奖励机制。

Result: 在六个评估设置中，8B参数的声明分解器将下游验证性能提升至71.75%宏F1分数，比基于提示的方法提升1.99和6.24个百分点，比现有RL方法提升5.84个百分点；人工评估证实生成子声明的高质量。

Conclusion: 该框架通过联合优化验证准确率和分解质量，使小型语言模型也能实现最先进的声明验证性能。

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


### [31] [2-Step Agent: A Framework for the Interaction of a Decision Maker with AI Decision Support](https://arxiv.org/abs/2602.21889)
*Otto Nyberg,Fausto Carcassi,Giovanni Cinà*

Main category: cs.AI

TL;DR: 本文提出"两步智能体"计算框架，通过贝叶斯因果推断建模AI预测如何影响理性智能体的信念更新及后续决策。仿真研究表明，单个不匹配的先验信念就足以使AI辅助决策比无支持时产生更差结果，揭示了AI决策支持的潜在风险，强调需加强模型文档和用户培训。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在决策支持中的应用日益广泛，学界仍缺乏对技术采用效果的深度理解，特别是理性智能体如何接收AI预测并更新信念，以及信念变化如何影响最终决策和结果的因果机制。

Method: 构建"两步智能体"通用计算框架：第一步使用贝叶斯方法建模AI预测对新观测值的影响及智能体信念更新过程；第二步建模信念变化对下游决策和结果的因果效应，并通过仿真模拟验证框架。

Result: 仿真结果显示，即使仅存在单个与AI模型不匹配的先验信念，也可能导致AI辅助决策的下游结果比无决策支持时更差，揭示了AI驱动决策支持系统的多个潜在陷阱。

Conclusion: AI辅助决策存在显著风险，尤其当用户与模型间存在信念不匹配时。研究强调必须进行彻底的模型文档记录和适当的用户培训，以确保AI技术的安全可靠应用。

Abstract: Across a growing number of fields, human decision making is supported by predictions from AI models. However, we still lack a deep understanding of the effects of adoption of these technologies. In this paper, we introduce a general computational framework, the 2-Step Agent, which models the effects of AI-assisted decision making. Our framework uses Bayesian methods for causal inference to model 1) how a prediction on a new observation affects the beliefs of a rational Bayesian agent, and 2) how this change in beliefs affects the downstream decision and subsequent outcome. Using this framework, we show by simulations how a single misaligned prior belief can be sufficient for decision support to result in worse downstream outcomes compared to no decision support. Our results reveal several potential pitfalls of AI-driven decision support and highlight the need for thorough model documentation and proper user training.

</details>


### [32] [Semantic Partial Grounding via LLMs](https://arxiv.org/abs/2602.22067)
*Giuseppe Canonaco,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: 针对经典规划中接地计算瓶颈问题，提出SPG-LLM，利用大语言模型分析PDDL文件，在接地前启发式识别无关对象、动作和谓词，显著减小接地规模，在七个困难基准测试上实现数量级加速，同时保持或提升规划成本。


<details>
  <summary>Details</summary>
Motivation: 经典规划接地过程因任务规模增大时动作和原子数量指数增长而成为计算瓶颈。现有部分接地方法依赖关系特征或学习嵌入，未能利用PDDL描述中的文本和结构线索，存在优化空间。

Method: 提出SPG-LLM方法：利用大语言模型解析PDDL领域和问题文件，通过启发式推理预先识别潜在无关的对象、动作和谓词，从源头缩小接地任务规模。

Result: 在七个难以接地的基准测试中，接地速度显著提升，常达数量级加速；在部分领域获得相当或更优的规划成本。

Conclusion: 通过利用LLM挖掘PDDL文本和结构线索，SPG-LLM有效缓解了接地计算瓶颈，为大规模规划任务提供了高效预处理方法。

Abstract: Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.

</details>


### [33] [Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning](https://arxiv.org/abs/2602.22094)
*Nguyen Cong Nhat Le,John G. Rogers,Claire N. Bonial,Neil T. Dantam*

Main category: cs.AI

TL;DR: 针对规划系统缺乏有效不可行性检测和动态更新能力的问题，本文提出基于Petri网可达性松弛的方法，结合增量约束求解，实现了高效的不变量合成、目标不可达性检测及约束更新。实验证明该方法可检测2倍以上的不可行情况，并在序贯规划中表现突出。


<details>
  <summary>Details</summary>
Motivation: 计划常因情境或认知变化而调整，识别不可行性对需求修正至关重要。然而现有方法偏重可行域内的一次性规划效率，忽视领域模型更新和不可行性诊断，缺乏在动态环境中提供解释性反馈的机制。

Method: 采用Petri网可达性松弛技术，增强不变量合成的鲁棒性，实现高效的目标不可达性检测与不可行性解释。并利用增量约束求解器支持目标与约束的动态更新。

Result: 实验显示：系统生成的不变量数量与基线相当，不可行性检测数量提升至2倍，一次性规划性能具有竞争力，在序贯规划更新任务中显著优于基线系统。

Conclusion: 该方法通过Petri网松弛与增量求解的结合，为动态规划环境中的不可行性诊断和模型演化提供了有效解决方案，拓展了自动规划技术的应用范围。

Abstract: Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [34] [AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression](https://arxiv.org/abs/2602.21233)
*Rui Cen,QiangQiang Hu,Hong Huang,Hong Liu,Song Liu,Xin Luo,Lin Niu,Yifan Tan,Decheng Wu,Linchuan Xie,Rubing Yang,Guanghua Yu,Jianchen Zhu*

Main category: cs.LG

TL;DR: 腾讯Hunyuan团队开发的AngelSlim是一个统一的大模型压缩工具包，集成量化、推测解码、令牌剪枝与蒸馏等前沿算法，提供从压缩到工业部署的完整流水线。核心创新包括：首个工业级2-bit大模型HY-1.8B-int2、支持多模态的训练对齐推测解码框架（实现1.8-2.0倍吞吐增益）、长文本场景的训练无关稀疏注意力机制（降低首令牌时间），以及面向多模态的IDPruner视觉令牌优化和Samp音频令牌自适应剪枝策略。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在工业部署时面临计算资源消耗大、推理延迟高等瓶颈。现有压缩技术多为独立实现，缺乏统一框架，且超低比特量化、多模态推理加速等方向尚未成熟。亟需一套系统化工具链，弥合算法创新与规模化部署之间的鸿沟。

Method: AngelSlim采用多层次压缩方法体系：1）后训练量化（FP8/INT8）结合超低位宽研究，推出2-bit工业级模型HY-1.8B-int2；2）训练对齐的推测解码框架，兼容多模态架构与现代推理引擎；3）训练无关的稀疏注意力机制，通过解耦稀疏核与模型架构，结合静态模式与动态令牌选择降低长文本TTFT；4）多模态专用剪枝：IDPruner基于最大边缘相关性优化视觉令牌，Samp实现自适应音频令牌合并与剪枝。所有策略从底层实现集成，形成统一pipeline。

Result: 实验验证：推测解码框架实现1.8-2.0倍吞吐量提升且保持输出正确性；稀疏注意力显著降低长上下文场景的首令牌时间；HY-1.8B-int2成为首个工业可用的2-bit大模型；IDPruner和Samp有效优化多模态令牌效率。该工具包成功支撑算法研究与工业部署。

Conclusion: AngelSlim通过整合量化、推测解码、剪枝等多维度前沿技术，构建了从研究到工业部署的无缝衔接平台。它不仅推动了超低比特量化等技术边界，还为多模态大模型高效推理建立了新范式，对促进大模型规模化落地具有重要实践意义。

Abstract: This technical report introduces AngelSlim, a comprehensive and versatile toolkit for large model compression developed by the Tencent Hunyuan team. By consolidating cutting-edge algorithms, including quantization, speculative decoding, token pruning, and distillation. AngelSlim provides a unified pipeline that streamlines the transition from model compression to industrial-scale deployment. To facilitate efficient acceleration, we integrate state-of-the-art FP8 and INT8 Post-Training Quantization (PTQ) algorithms alongside pioneering research in ultra-low-bit regimes, featuring HY-1.8B-int2 as the first industrially viable 2-bit large model. Beyond quantization, we propose a training-aligned speculative decoding framework compatible with multimodal architectures and modern inference engines, achieving 1.8x to 2.0x throughput gains without compromising output correctness. Furthermore, we develop a training-free sparse attention framework that reduces Time-to-First-Token (TTFT) in long-context scenarios by decoupling sparse kernels from model architectures through a hybrid of static patterns and dynamic token selection. For multimodal models, AngelSlim incorporates specialized pruning strategies, namely IDPruner for optimizing vision tokens via Maximal Marginal Relevance and Samp for adaptive audio token merging and pruning. By integrating these compression strategies from low-level implementations, AngelSlim enables algorithm-focused research and tool-assisted deployment.

</details>


### [35] [Group Orthogonalized Policy Optimization:Group Policy Optimization as Orthogonal Projection in Hilbert Space](https://arxiv.org/abs/2602.21269)
*Wang Zixian*

Main category: cs.LG

TL;DR: 提出Group Orthogonalized Policy Optimization (GOPO)算法，通过在Hilbert函数空间中重新表述大语言模型对齐问题，以线性正交约束替代传统概率单纯形的KL散度，利用Hilbert投影定理实现闭式阈值稀疏化，并通过组采样实现无约束经验损失。


<details>
  <summary>Details</summary>
Motivation: 传统策略优化在概率单纯形上依赖KL散度，其指数曲率特性导致优化困难与梯度不稳定。需要一种几何上更自然、计算上更稳定的对齐框架，避免启发式裁剪并保留熵正则化优势。

Method: 将策略表示为L2(pi_k)空间中的平方可积函数，将概率约束简化为线性正交条件<v,1>=0，通过Hilbert投影定理求解带边界约束v≥-1的工作-耗散泛函J(v)，利用组采样将无限维空间投影到有限维经验子空间，组归一化优势函数使拉格朗日乘子精确为零，转化为无约束优化。

Result: 在数学推理基准测试中实现有竞争力的泛化性能；保持稳定梯度动力学（恒定Hessian曲率μI）和熵保留；通过闭式阈值产生精确稀疏性，自动抑制灾难性动作；相比裁剪基方法避免性能平台期。

Conclusion: GOPO从Hilbert空间几何出发，为LLM对齐提供了理论严谨且实践有效的优化框架，其线性梯度、死区机制和零乘子特性在数学上优雅且经验上稳定，是KL散度方法的重要替代方案。

Abstract: We present Group Orthogonalized Policy Optimization (GOPO), a new alignment algorithm for large language models derived from the geometry of Hilbert function spaces. Instead of optimizing on the probability simplex and inheriting the exponential curvature of Kullback-Leibler divergence, GOPO lifts alignment into the Hilbert space L2(pi_k) of square-integrable functions with respect to the reference policy. Within this space, the simplex constraint reduces to a linear orthogonality condition <v, 1> = 0, defining a codimension-one subspace H0. Minimizing distance to an unconstrained target u_star yields the work-dissipation functional J(v) = <g, v> - (mu / 2) ||v||^2, whose maximizer follows directly from the Hilbert projection theorem. Enforcing the boundary v >= -1 produces a bounded Hilbert projection that induces exact sparsity, assigning zero probability to catastrophically poor actions through a closed-form threshold. To connect this functional theory with practice, GOPO projects from infinite-dimensional L2(pi_k) to a finite empirical subspace induced by group sampling. Because group-normalized advantages sum to zero, the Lagrange multiplier enforcing probability conservation vanishes exactly, reducing the constrained projection to an unconstrained empirical loss. The resulting objective has constant Hessian curvature mu I, non-saturating linear gradients, and an intrinsic dead-zone mechanism without heuristic clipping. Experiments on mathematical reasoning benchmarks show that GOPO achieves competitive generalization while maintaining stable gradient dynamics and entropy preservation in regimes where clipping-based methods plateau.

</details>


### [36] [Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling](https://arxiv.org/abs/2602.21319)
*Marion Neumeier,Niklas Roßberg,Michael Botsch,Wolfgang Utschick*

Main category: cs.LG

TL;DR: 本文提出cVMDx，一种改进的基于扩散的轨迹预测框架。通过DDIM采样实现100倍推理加速，用高斯混合模型提取可处理的多模态预测，并评估了CVQ-VAE场景编码变体。在highD数据集上，该框架相比cVMD在保持高精度的同时显著提升效率，实现了可实用的完全随机多模态轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 准确的、感知不确定性的轨迹预测是自动驾驶的核心挑战，源于复杂的多智能体交互、多样化的场景上下文以及未来运动的固有随机性。虽然基于扩散的生成模型在多模态未来预测方面显示出潜力，但现有方法（如cVMD）存在采样速度慢、生成多样性利用有限以及场景编码脆弱等问题，限制了其实际应用。

Method: 1. 采用DDIM采样策略替代传统采样，大幅降低推理时间，使多采样生成实用化；2. 引入拟合的高斯混合模型（GMM），从生成的轨迹中获取可处理的多模态概率预测；3. 设计并评估了条件向量量化变分自编码器（CVQ-VAE）变体用于改进场景编码的鲁棒性。

Result: 在公开数据集highD上的实验结果表明，cVMDx相比基线模型cVMD实现了高达100倍的推理时间缩短，同时在预测精度上有所提升，能够高效生成完全随机且多模态的轨迹预测结果，为不确定性估计提供了实用解决方案。

Conclusion: cVMDx框架通过集成DDIM采样、高斯混合模型和CVQ-VAE编码，有效解决了基于扩散的轨迹预测模型在效率和鲁棒性方面的关键瓶颈，为自动驾驶领域提供了更实用、更强大的不确定性感知轨迹预测方案，展示了扩散模型在实时应用中的巨大潜力。

Abstract: Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown strong potential for capturing multimodal futures, yet existing approaches such as cVMD suffer from slow sampling, limited exploitation of generative diversity and brittle scenario encodings.
  This work introduces cVMDx, an enhanced diffusion-based trajectory prediction framework that improves efficiency, robustness and multimodal predictive capability. Through DDIM sampling, cVMDx achieves up to a 100x reduction in inference time, enabling practical multi-sample generation for uncertainty estimation. A fitted Gaussian Mixture Model further provides tractable multimodal predictions from the generated trajectories. In addition, a CVQ-VAE variant is evaluated for scenario encoding. Experiments on the publicly available highD dataset show that cVMDx achieves higher accuracy and significantly improved efficiency over cVMD, enabling fully stochastic, multimodal trajectory prediction.

</details>


### [37] [Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data](https://arxiv.org/abs/2602.21320)
*Emre Can Acikgoz,Cheng Qian,Jonas Hübotter,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.LG

TL;DR: 本文提出Tool-R0框架，通过生成器与求解器自博弈强化学习机制，在零数据假设下从零训练通用工具调用智能体。该框架无需预设任务，通过互补奖励使双方在演化中持续挑战能力边界，最终在工具使用基准测试中实现92.5%的相对性能提升并超越全监督基线。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的工具调用智能体训练严重依赖人工构建的任务-解对和大量监督数据，这种强监督范式阻碍了系统向超级智能的开放域自我演化，构成了实现自主进化智能体的根本性障碍。

Method: Tool-R0初始化同构基础语言模型，构建生成器与求解器双系统。生成器负责在求解器当前能力边界生成具有挑战性的目标任务，求解器则通过真实工具调用学习解决这些任务。双方通过互补奖励函数（生成器奖励求解失败，求解器奖励成功解决）实现协同演化，形成自我进化的训练循环。

Result: 在多种工具使用基准评估中，Tool-R0相比基础模型获得92.5%的相对性能提升，并在同等参数规模下显著超越全监督工具调用基线方法。

Conclusion: 研究表明自博弈强化学习可在零数据条件下有效训练通用工具智能体，揭示了协同演化过程中的课程动态与扩展规律，为构建开放域自我进化智能系统提供了新思路与实证基础。

Abstract: Large language models (LLMs) are becoming the foundation for autonomous agents that can use tools to solve complex tasks. Reinforcement learning (RL) has emerged as a common approach for injecting such agentic capabilities, but typically under tightly controlled training setups. It often depends on carefully constructed task-solution pairs and substantial human supervision, which creates a fundamental obstacle to open-ended self-evolution toward superintelligent systems. In this paper, we propose Tool-R0 framework for training general purpose tool-calling agents from scratch with self-play RL, under a zero-data assumption. Initialized from the same base LLM, Tool-R0 co-evolves a Generator and a Solver with complementary rewards: one proposes targeted challenging tasks at the other's competence frontier and the other learns to solve them with real-world tool calls. This creates a self-evolving cycle that requires no pre-existing tasks or datasets. Evaluation on different tool-use benchmarks show that Tool-R0 yields 92.5 relative improvement over the base model and surpasses fully supervised tool-calling baselines under the same setting. Our work further provides empirical insights into self-play LLM agents by analyzing co-evolution, curriculum dynamics, and scaling behavior.

</details>


### [38] [Dynamic Symmetric Point Tracking: Tackling Non-ideal Reference in Analog In-memory Training](https://arxiv.org/abs/2602.21321)
*Quan Xiao,Jindan Li,Zhaoxian Wu,Tayfun Gokmen,Tianyi Chen*

Main category: cs.LG

TL;DR: 本文针对模拟存算一体训练中权重更新不对称导致的系统性漂移问题，提出动态对称点追踪方法，通过理论分析和实验验证，相比静态预校准更高效且精度更高。


<details>
  <summary>Details</summary>
Motivation: 模拟存算一体虽能效高，但器件非理想特性（更新不对称）导致权重更新向器件特定的对称点漂移，偏离训练最优解。现有预校准方法成本高昂且残留误差影响精度，亟需动态追踪与理论保障的解决方案。

Method: 首先理论分析对称点校准的脉冲复杂度与估计误差；继而提出训练过程中动态追踪对称点的方法，并给出收敛保证；最后融合数字信号处理的斩波与滤波技术构建增强版本。

Result: 数值实验验证了所提方法在降低校准成本、提升训练精度方面的双重优势，有效抑制了权重系统性漂移。

Conclusion: 本研究通过动态对称点追踪与信号处理增强技术，为模拟存算一体的训练偏差问题提供了兼具理论收敛保证与实践有效性的创新解决方案。

Abstract: Analog in-memory computing (AIMC) performs computation directly within resistive crossbar arrays, offering an energy-efficient platform to scale large vision and language models. However, non-ideal analog device properties make the training on AIMC devices challenging. In particular, its update asymmetry can induce a systematic drift of weight updates towards a device-specific symmetric point (SP), which typically does not align with the optimum of the training objective. To mitigate this bias, most existing works assume the SP is known and pre-calibrate it to zero before training by setting the reference point as the SP. Nevertheless, calibrating AIMC devices requires costly pulse updates, and residual calibration error can directly degrade training accuracy. In this work, we present the first theoretical characterization of the pulse complexity of SP calibration and the resulting estimation error. We further propose a dynamic SP estimation method that tracks the SP during model training, and establishes its convergence guarantees. In addition, we develop an enhanced variant based on chopping and filtering techniques from digital signal processing. Numerical experiments demonstrate both the efficiency and effectiveness of the proposed method.

</details>


### [39] [Equitable Evaluation via Elicitation](https://arxiv.org/abs/2602.21327)
*Elbert Du,Cynthia Dwork,Lunjia Hu,Reid McIlroy-Young,Han Shao,Linjun Zhang*

Main category: cs.LG

TL;DR: 开发交互式AI技能探测系统，通过数学公平性约束消除自我展示风格对技能评估的影响，实现不同表达风格个体的准确评估。


<details>
  <summary>Details</summary>
Motivation: 同等资质个体因自我展示风格差异（自我推销vs谦虚）导致技能比较失真，传统自我报告存在内生偏差，亟需解耦表达风格与技能实质的评估方法。

Method: 构建交互式AI技能elicitation框架，训练大语言模型作为"合成人类"生成训练数据，施加严格数学公平性约束，最小化自我展示方式与技能评估误差的协方差。

Result: 有效缓解自我报告的内生偏差，通过公平性约束控制系统性模型偏差，实现对不同自我展示风格个体的无偏技能评估。

Conclusion: 系统可部署于职业平台或企业人员调配场景，为消除表达能力差异带来的评估不公平提供了可扩展的AI解决方案。

Abstract: Individuals with similar qualifications and skills may vary in their demeanor, or outward manner: some tend toward self-promotion while others are modest to the point of omitting crucial information. Comparing the self-descriptions of equally qualified job-seekers with different self-presentation styles is therefore problematic.
  We build an interactive AI for skill elicitation that provides accurate determination of skills while simultaneously allowing individuals to speak in their own voice. Such a system can be deployed, for example, when a new user joins a professional networking platform, or when matching employees to needs during a company reorganization. To obtain sufficient training data, we train an LLM to act as synthetic humans.
  Elicitation mitigates endogenous bias arising from individuals' own self-reports. To address systematic model bias we enforce a mathematically rigorous notion of equitability ensuring that the covariance between self-presentation manner and skill evaluation error is small.

</details>


### [40] [Efficient Opportunistic Approachability](https://arxiv.org/abs/2602.21328)
*Teodor Vanislavov Marinov,Mehryar Mohri,Princewill Okoroafor,Jon Schneider,Julian Zimmert*

Main category: cs.LG

TL;DR: 本文研究机会主义可逼近性问题，这是Blackwell可逼近性的推广。现有方法需要在线校准预测，导致计算效率低下且收敛速率随维度恶化（T^{-O(1/d)}）。本文提出无需校准的新算法，在一般情形下达到O(T^{-1/4})的收敛速率，在二维情况下达到最优速率O(T^{-1/2})。


<details>
  <summary>Details</summary>
Motivation: 机会主义可逼近性在实际应用中面临计算效率瓶颈。Bernstein等人(2014)的算法虽然理论上有次线性收敛保证，但依赖在线校准预测，其标准实现需要指数级时间且收敛速率随维度恶化。因此，设计高效算法并突破维度依赖的速率限制成为亟待解决的问题，这对将理论算法应用于高维实际场景至关重要。

Method: 论文绕过在线校准子程序，直接构造适用于机会主义可逼近性的高效算法。通过新的技术手段，避免了传统方法中对对手行动进行校准预测的指数级计算开销，从而在保持理论保证的同时提升计算效率。

Result: 主要结果包括：(1) 高效算法达到O(T^{-1/4})收敛速率；(2) 低效算法达到O(T^{-1/3})速率；(3) 当对手行动空间维度不超过2时，可实现最优速率O(T^{-1/2})。这些结果显著优于先前T^{-O(1/d)}的速率，特别是在高维情况下。

Conclusion: 本研究成功解决了机会主义可逼近性中的计算效率难题，通过消除对在线校准的依赖，实现了与维度无关的收敛速率。在二维情况下达到最优速率，证明了方法的潜力。这为将理论算法应用于高维实际问题铺平了道路，是算法博弈论和在线学习领域的重要进展。

Abstract: We study the problem of opportunistic approachability: a generalization of Blackwell approachability where the learner would like to obtain stronger guarantees (i.e., approach a smaller set) when their adversary limits themselves to a subset of their possible action space. Bernstein et al. (2014) introduced this problem in 2014 and presented an algorithm that guarantees sublinear approachability rates for opportunistic approachability. However, this algorithm requires the ability to produce calibrated online predictions of the adversary's actions, a problem whose standard implementations require time exponential in the ambient dimension and result in approachability rates that scale as $T^{-O(1/d)}$. In this paper, we present an efficient algorithm for opportunistic approachability that achieves a rate of $O(T^{-1/4})$ (and an inefficient one that achieves a rate of $O(T^{-1/3})$), bypassing the need for an online calibration subroutine. Moreover, in the case where the dimension of the adversary's action set is at most two, we show it is possible to obtain the optimal rate of $O(T^{-1/2})$.

</details>


### [41] [VCDF: A Validated Consensus-Driven Framework for Time Series Causal Discovery](https://arxiv.org/abs/2602.21381)
*Gene Yu,Ce Guo,Wayne Luk*

Main category: cs.LG

TL;DR: 本文提出一种验证共识驱动框架(VCDF)，作为即插即用的鲁棒性增强层用于时间序列因果发现。该方法通过评估因果关系在分块时间子集上的稳定性来缓解噪声、非平稳性和采样变异性带来的敏感性问题，无需修改基础算法，在合成数据、fMRI模拟和IT监控场景下均显著提升VAR-LiNGAM和PCMCI等方法的结构准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列因果发现方法对噪声、非平稳性和采样变异性敏感，限制了其实际应用的可靠性。如何在保持基础建模假设不变的前提下，为现有算法提供一个通用的鲁棒性增强层，是该领域亟待解决的关键问题。

Method: VCDF框架通过将时间序列分割为多个块，在各子集上独立运行基础因果发现算法（如VAR-LiNGAM和PCMCI），然后基于因果关系在不同块间的一致性程度进行共识评估和稳定性验证。该方法完全独立于基础算法，无需任何参数调整或模型修改。

Result: 在合成数据集上，VCDF使VAR-LiNGAM的窗口F1分数和总结F1分数均提升约0.08-0.12，中等长度以上序列提升最显著。当序列长度超过1000时，绝对改进可达0.18。在模拟fMRI数据和IT监控场景中，该方法在真实噪声条件下也展现出更好的结构准确性和稳定性。

Conclusion: VCDF为时间序列因果发现提供了一个有效的可靠性保障层，通过稳定性验证显著提升现有方法的抗干扰能力，且不改变底层建模假设，具有方法无关性和实用性强等特点，适用于多种实际应用场景。

Abstract: Time series causal discovery is essential for understanding dynamic systems, yet many existing methods remain sensitive to noise, non-stationarity, and sampling variability. We propose the Validated Consensus-Driven Framework (VCDF), a simple and method-agnostic layer that improves robustness by evaluating the stability of causal relations across blocked temporal subsets. VCDF requires no modification to base algorithms and can be applied to methods such as VAR-LiNGAM and PCMCI. Experiments on synthetic datasets show that VCDF improves VAR-LiNGAM by approximately 0.08-0.12 in both window and summary F1 scores across diverse data characteristics, with gains most pronounced for moderate-to-long sequences. The framework also benefits from longer sequences, yielding up to 0.18 absolute improvement on time series of length 1000 and above. Evaluations on simulated fMRI data and IT-monitoring scenarios further demonstrate enhanced stability and structural accuracy under realistic noise conditions. VCDF provides an effective reliability layer for time series causal discovery without altering underlying modeling assumptions.

</details>


### [42] [FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning](https://arxiv.org/abs/2602.21399)
*Alina Devkota,Jacob Thrasher,Donald Adjeroh,Binod Bhattarai,Prashnna K. Gyawali*

Main category: cs.LG

TL;DR: 针对联邦学习中数据异质性导致的客户端漂移和泛化性能下降问题，本文提出FedVG框架，通过全局验证集计算层梯度范数来评估客户端模型的泛化能力，生成客户端特定分数以指导自适应聚合。实验表明该方法在高度异质环境下性能显著提升，且可模块化集成于现有算法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临的核心挑战是数据异质性引发的客户端漂移，导致模型泛化性能严重退化。现有聚合策略往往过度关注表现欠佳的客户端，缺乏在不泄露隐私前提下对各客户端模型泛化能力进行有效评估的机制，亟需一种能精准量化客户端贡献并指导自适应聚合的新方法。

Method: FedVG采用基于全局验证集的梯度引导聚合机制：1) 利用公开数据集构建全局验证集，确保隐私保护下的跨客户端一致性评估基准；2) 计算各客户端模型在验证集上的层梯度范数，生成反映其调整需求的客户端特定分数；3) 根据该分数实施自适应聚合，优先优化泛化能力不足的客户端。框架设计模块化，可与多种现有联邦学习算法无缝集成。

Result: 在自然图像和医学图像基准数据集上的广泛实验表明，FedVG在不同模型架构下均能稳定提升性能，在高度数据异质场景下改善尤为显著。作为增强组件，FedVG与多种先进联邦学习算法结合后，通常能进一步提升其收敛效果和泛化能力。

Conclusion: FedVG通过全局验证集引导的梯度分析，有效解决了数据异质性引发的客户端漂移问题，为客户端模型质量评估提供了新范式。该方法在严格保护数据隐私的前提下显著提升泛化性能，其模块化设计确保了广泛的适用性和可扩展性，为联邦学习在真实场景中的部署提供了实用解决方案。

Abstract: Federated Learning (FL) enables collaborative model training across multiple clients without sharing their private data. However, data heterogeneity across clients leads to client drift, which degrades the overall generalization performance of the model. This effect is further compounded by overemphasis on poorly performing clients. To address this problem, we propose FedVG, a novel gradient-based federated aggregation framework that leverages a global validation set to guide the optimization process. Such a global validation set can be established using readily available public datasets, ensuring accessibility and consistency across clients without compromising privacy. In contrast to conventional approaches that prioritize client dataset volume, FedVG assesses the generalization ability of client models by measuring the magnitude of validation gradients across layers. Specifically, we compute layerwise gradient norms to derive a client-specific score that reflects how much each client needs to adjust for improved generalization on the global validation set, thereby enabling more informed and adaptive federated aggregation. Extensive experiments on both natural and medical image benchmarking datasets, across diverse model architectures, demonstrate that FedVG consistently improves performance, particularly in highly heterogeneous settings. Moreover, FedVG is modular and can be seamlessly integrated with various state-of-the-art FL algorithms, often further improving their results. Our code is available at https://github.com/alinadevkota/FedVG.

</details>


### [43] [Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning](https://arxiv.org/abs/2602.21420)
*Yuanda Xu,Hejian Sang,Zhengze Zhou,Ran He,Zhipeng Wang*

Main category: cs.LG

TL;DR: 针对RLVR提升LLM推理能力时导致多样性下降的问题，本文提出非对称置信度感知错误惩罚机制(ACE)。通过动态调节错误回放的负优势惩罚强度，抑制过度自信错误并保留有效探索轨迹，实验表明ACE能全面改善Pass@k指标。


<details>
  <summary>Details</summary>
Motivation: 标准RLVR算法存在根本缺陷：在提升Pass@1准确率的同时，会缩窄模型推理边界并降低生成多样性。现有方法对所有错误统一惩罚，导致过度自信的错误（RL过程错误强化的推理路径）持续垄断概率质量，抑制有效探索。

Method: 提出ACE方法，引入置信度偏移指标 c_i = log(π_θ(y_i|x)/π_ref(y_i|x)) 动态调节负优势。理论证明其梯度可分解为针对过度自信错误的选择性正则化项与调节残差。在Qwen2.5-Math-7B、Qwen3-8B-Base和Llama-3.1-8B-Instruct上，基于GRPO和DAPO算法在DAPO-Math-17K数据集进行实验。

Result: 在MATH-500和AIME 2025基准测试中，ACE与现有方法无缝集成，持续优化所有模型在完整Pass@k谱系上的表现，有效缓解了多样性下降问题。

Conclusion: ACE通过非对称惩罚机制，解决了过度自信错误垄断概率质量的病理问题，在保持Pass@1性能的同时恢复生成多样性，为LLM推理的RLVR训练提供了更优范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become the leading paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard RLVR algorithms suffer from a well-documented pathology: while they improve Pass@1 accuracy through sharpened sampling, they simultaneously narrow the model's reasoning boundary and reduce generation diversity. We identify a root cause that existing methods overlook: the uniform penalization of errors. Current approaches -- whether data-filtering methods that select prompts by difficulty, or advantage normalization schemes -- treat all incorrect rollouts within a group identically. We show that this uniformity allows overconfident errors (incorrect reasoning paths that the RL process has spuriously reinforced) to persist and monopolize probability mass, ultimately suppressing valid exploratory trajectories. To address this, we propose the Asymmetric Confidence-aware Error Penalty (ACE). ACE introduces a per-rollout confidence shift metric, c_i = log(pi_theta(y_i|x) / pi_ref(y_i|x)), to dynamically modulate negative advantages. Theoretically, we demonstrate that ACE's gradient can be decomposed into the gradient of a selective regularizer restricted to overconfident errors, plus a well-characterized residual that partially moderates the regularizer's strength. We conduct extensive experiments fine-tuning Qwen2.5-Math-7B, Qwen3-8B-Base, and Llama-3.1-8B-Instruct on the DAPO-Math-17K dataset using GRPO and DAPO within the VERL framework. Evaluated on MATH-500 and AIME 2025, ACE composes seamlessly with existing methods and consistently improves the full Pass@k spectrum across all three model families and benchmarks.

</details>


### [44] [D-Flow SGLD: Source-Space Posterior Sampling for Scientific Inverse Problems with Flow Matching](https://arxiv.org/abs/2602.21469)
*Meet Hemant Parikh,Yaqin Chen,Jian-Xun Wang*

Main category: cs.LG

TL;DR: 本文研究基于流匹配(FM)先验的科学反问题后验采样方法，提出D-Flow SGLD框架，通过在源空间引入预条件随机梯度朗之万动力学，实现无需重训练的高效后验采样，在混沌动力学和湍流重建等科学基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 科学反问题和数据同化需要从稀疏噪声观测中重建高维物理状态，并保持不确定性感知的后验分布，同时忠实于学习到的先验和物理规律。尽管扩散模型的免训练条件生成技术已较为成熟，但流匹配(FM)先验的相应条件化与后验采样策略仍缺乏充分探索，尤其是在需要超越测量误差评估保真度的科学基准测试上。

Method: 首先系统梳理了现有推理时策略，按测量信息注入方式分为：(i)引导式传输动力学和(ii)源分布推断。在此基础上提出D-Flow SGLD方法，通过将可微源推断与预条件随机梯度朗之万动力学结合，在保持学习到的FM动力学不变的前提下，对源变量进行后验推断，从而实现对新测量算符诱导的后验分布的可扩展探索。

Result: 在2D玩具后验、混沌Kuramoto-Sivashinsky轨迹和壁面湍流重建等层次化问题上对代表性方法进行了基准测试。量化分析了测量同化、后验多样性与物理/统计保真度之间的权衡关系，结果表明D-Flow SGLD在各项指标上表现均衡，是一种实用的FM兼容后验采样器。

Conclusion: 本研究填补了FM先验在科学反问题后验采样方面的空白，提出的D-Flow SGLD框架通过源空间推断与随机梯度朗之万动力学的有效结合，为高维物理状态重建提供了可扩展且物理一致的不确定性量化方法，为相关科学应用提供了实用工具。

Abstract: Data assimilation and scientific inverse problems require reconstructing high-dimensional physical states from sparse and noisy observations, ideally with uncertainty-aware posterior samples that remain faithful to learned priors and governing physics. While training-free conditional generation is well developed for diffusion models, corresponding conditioning and posterior sampling strategies for Flow Matching (FM) priors remain comparatively under-explored, especially on scientific benchmarks where fidelity must be assessed beyond measurement misfit. In this work, we study training-free conditional generation for scientific inverse problems under FM priors and organize existing inference-time strategies by where measurement information is injected: (i) guided transport dynamics that perturb sampling trajectories using likelihood information, and (ii) source-distribution inference that performs posterior inference over the source variable while keeping the learned transport fixed. Building on the latter, we propose D-Flow SGLD, a source-space posterior sampling method that augments differentiable source inference with preconditioned stochastic gradient Langevin dynamics, enabling scalable exploration of the source posterior induced by new measurement operators without retraining the prior or modifying the learned FM dynamics. We benchmark representative methods from both families on a hierarchy of problems: 2D toy posteriors, chaotic Kuramoto-Sivashinsky trajectories, and wall-bounded turbulence reconstruction. Across these settings, we quantify trade-offs among measurement assimilation, posterior diversity, and physics/statistics fidelity, and establish D-Flow SGLD as a practical FM-compatible posterior sampler for scientific inverse problems.

</details>


### [45] [Training Generalizable Collaborative Agents via Strategic Risk Aversion](https://arxiv.org/abs/2602.21515)
*Chengrui Qu,Yizhou Zhang,Nicholas Lanzetti,Eric Mazumdar*

Main category: cs.LG

TL;DR: 针对多智能体协作泛化性差的问题，本研究提出策略风险规避作为归纳偏置，开发了新型MARL算法，使智能体能够与未见过的合作伙伴实现稳定可靠的协作。


<details>
  <summary>Details</summary>
Motivation: 现有协作学习算法在面临新合作伙伴时表现脆弱，主要归因于训练过程中的搭便车行为和策略鲁棒性不足，导致泛化能力差，无法满足实际应用需求。

Method: 研究策略风险规避概念，并将其作为归纳偏置集成到标准策略优化方法中，开发相应的多智能体强化学习（MARL）算法，以提升协作鲁棒性和泛化性。

Result: 在多个协作基准测试和LLM协作任务上的实证结果表明，所提方法能够与异构和未见过的合作伙伴实现可靠协作；理论证明策略风险规避不仅能减少搭便车行为，还能在协作博弈中获得优于纳什均衡的结果。

Conclusion: 策略风险规避为构建可泛化的多智能体协作系统提供了有效的归纳偏置，是提升协作鲁棒性和可靠性的重要途径，具有理论和实践价值。

Abstract: Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attribute these failures to a combination of free-riding during training and a lack of strategic robustness. To address these problems, we study the concept of strategic risk aversion and interpret it as a principled inductive bias for generalizable cooperation with unseen partners. While strategically risk-averse players are robust to deviations in their partner's behavior by design, we show that, in collaborative games, they also (1) can have better equilibrium outcomes than those at classical game-theoretic concepts like Nash, and (2) exhibit less or no free-riding. Inspired by these insights, we develop a multi-agent reinforcement learning (MARL) algorithm that integrates strategic risk aversion into standard policy optimization methods. Our empirical results across collaborative benchmarks (including an LLM collaboration task) validate our theory and demonstrate that our approach consistently achieves reliable collaboration with heterogeneous and previously unseen partners across collaborative tasks.

</details>


### [46] [Training-free Composition of Pre-trained GFlowNets for Multi-Objective Generation](https://arxiv.org/abs/2602.21565)
*Seokwon Yoon,Youngbin Choi,Seunghyuk Cho,Seungbeom Lee,MoonJeong Park,Dongwoo Kim*

Main category: cs.LG

TL;DR: 提出一种无需训练的混合策略，通过推理时组合预训练GFlowNets实现多目标优化，避免为每个目标集合重新训练，在保持性能的同时大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有GFlowNets多目标扩展方法需要针对每组目标重新训练，导致适用性受限且计算开销巨大，无法满足实际应用中对快速适应不同目标组合的需求。

Method: 提出训练无关的混合策略，通过在推理阶段直接组合预训练的单目标GFlowNets，无需微调或重训练；可灵活处理从线性标量化到复杂非线性逻辑算子的多种奖励组合。

Result: 理论证明该方法在线性标量化下能精确恢复目标分布，并为非线性算子提供失真因子量化近似质量；在合成2D网格和真实分子生成任务中，性能与需要额外训练的基线相当。

Conclusion: 该方法实现了多目标GFlowNets的快速适配，消除了重复训练的计算负担，为科学发现等需要探索多样化解的应用提供了更实用的解决方案。

Abstract: Generative Flow Networks (GFlowNets) learn to sample diverse candidates in proportion to a reward function, making them well-suited for scientific discovery, where exploring multiple promising solutions is crucial. Further extending GFlowNets to multi-objective settings has attracted growing interest since real-world applications often involve multiple, conflicting objectives. However, existing approaches require additional training for each set of objectives, limiting their applicability and incurring substantial computational overhead. We propose a training-free mixing policy that composes pre-trained GFlowNets at inference time, enabling rapid adaptation without finetuning or retraining. Importantly, our framework is flexible, capable of handling diverse reward combinations ranging from linear scalarization to complex non-linear logical operators, which are often handled separately in previous literature. We prove that our method exactly recovers the target distribution for linear scalarization and quantify the approximation quality for nonlinear operators through a distortion factor. Experiments on a synthetic 2D grid and real-world molecule-generation tasks demonstrate that our approach achieves performance comparable to baselines that require additional training.

</details>


### [47] [Breaking Semantic-Aware Watermarks via LLM-Guided Coherence-Preserving Semantic Injection](https://arxiv.org/abs/2602.21593)
*Zheng Gao,Xiaoyu Li,Zhicheng Bao,Xiaoyan Feng,Jiaojiao Jiang*

Main category: cs.LG

TL;DR: 本文针对内容感知语义水印方案，提出一种基于大语言模型的相干保持语义注入(CSI)攻击。该方法利用LLM的语义推理能力，在嵌入空间相似性约束下实现视觉-语义一致性的选择性语义扰动，诱导水印检测器误分类。实验证实CSI显著优于现有攻击基线，揭示了当前语义水印设计在LLM驱动语义扰动下的根本安全缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统噪声层水印易受反转攻击，而内容感知语义水印通过绑定水印信号与高级图像语义来抵御局部编辑。然而，大语言模型具备结构化推理能力，可进行局部细粒度但全局相干的语义空间探索，从而破坏此类语义绑定。此漏洞尚未被充分研究，本文旨在评估LLM对语义水印的安全性威胁。

Method: 提出CSI攻击框架，利用LLM引导语义操控。通过在嵌入空间施加相似性约束，确保语义修改的视觉-语义一致性，同时选择性地扰动水印相关语义特征，最终导致检测器误分类。

Result: 大量实证结果显示，CSI攻击在破解内容感知语义水印方面持续优于现有主流攻击基线，成功暴露了现有方案的安全脆弱性。

Conclusion: 当前语义水印设计在面对LLM驱动的语义扰动时存在根本性安全弱点。CSI攻击揭示了这一被忽视的漏洞，为未来开发更鲁棒的语义水印方案提供了关键洞察。

Abstract: Generative images have proliferated on Web platforms in social media and online copyright distribution scenarios, and semantic watermarking has increasingly been integrated into diffusion models to support reliable provenance tracking and forgery prevention for web content. Traditional noise-layer-based watermarking, however, remains vulnerable to inversion attacks that can recover embedded signals. To mitigate this, recent content-aware semantic watermarking schemes bind watermark signals to high-level image semantics, constraining local edits that would otherwise disrupt global coherence. Yet, large language models (LLMs) possess structured reasoning capabilities that enable targeted exploration of semantic spaces, allowing locally fine-grained but globally coherent semantic alterations that invalidate such bindings. To expose this overlooked vulnerability, we introduce a Coherence-Preserving Semantic Injection (CSI) attack that leverages LLM-guided semantic manipulation under embedding-space similarity constraints. This alignment enforces visual-semantic consistency while selectively perturbing watermark-relevant semantics, ultimately inducing detector misclassification. Extensive empirical results show that CSI consistently outperforms prevailing attack baselines against content-aware semantic watermarking, revealing a fundamental security weakness of current semantic watermark designs when confronted with LLM-driven semantic perturbations.

</details>


### [48] [Error-awareness Accelerates Active Automata Learning](https://arxiv.org/abs/2602.21674)
*Loes Kruger,Sebastian Junges,Jurriaan Rot*

Main category: cs.LG

TL;DR: 本文针对主动自动机学习(AAL)算法在处理大规模输入系统时的扩展性问题，提出通过利用关于输入是否产生错误的不同程度领域知识，对L#算法进行适配。实证表明，这些方法在拥有强领域知识时可实现数个数量级的学习加速，即使知识有限也能提升一个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有AAL算法难以扩展到具有大量可能输入的系统，即使多数输入会导致错误输出也表现不佳。但许多挑战性问题的错误是可观测的，这为优化学习过程提供了契机，亟需研究更高效的学习方法。

Method: 根据对"哪些输入在哪些状态下不会导致错误"这一领域知识的不同掌握程度，设计相应的L#算法变体，以充分利用先验知识来指导学习过程，提高学习效率。

Result: 实验评估显示，当具备较强但现实的领域知识时，学习速度可提升数个数量级；即使在仅有有限领域知识的条件下，学习性能仍能获得一个数量级的显著加速。

Conclusion: 合理利用关于错误输入的领域知识是提升AAL算法可扩展性的有效途径，知识丰富度与学习加速效果直接相关，为不同先验知识条件下的算法实践提供了重要指导。

Abstract: Active automata learning (AAL) algorithms can learn a behavioral model of a system from interacting with it. The primary challenge remains scaling to larger models, in particular in the presence of many possible inputs to the system. Modern AAL algorithms fail to scale even if, in every state, most inputs lead to errors. In various challenging problems from the literature, these errors are observable, i.e., they emit a known error output. Motivated by these problems, we study learning these systems more efficiently. Further, we consider various degrees of knowledge about which inputs are non-error producing at which state. For each level of knowledge, we provide a matching adaptation of the state-of-the-art AAL algorithm L# to make the most of this domain knowledge. Our empirical evaluation demonstrates that the methods accelerate learning by orders of magnitude with strong but realistic domain knowledge to a single order of magnitude with limited domain knowledge.

</details>


### [49] [Hierarchical Lead Critic based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.21680)
*David Eckel,Henri Meeß*

Main category: cs.LG

TL;DR: 本文提出了一种分层主导评论家（HLC）架构和序贯训练方案，用于合作式多智能体强化学习。该方法受团队结构中自然涌现分布的启发，通过在多个层次上学习局部和全局视角，实现了高性能、高样本效率和鲁棒策略。在合作式、非通信和部分可观测的MARL基准测试中，HLC优于单层次基线方法，并能随智能体数量和难度增加而良好扩展。


<details>
  <summary>Details</summary>
Motivation: 合作式多智能体强化学习通常局限于局部（独立学习）或全局（集中学习）视角，难以有效处理需要多层次协调的复杂任务。现有方法在扩展性、样本效率和策略鲁棒性方面存在局限，无法很好地模拟真实团队中高层目标与低层执行相结合的自然分布结构。

Method: 提出分层主导评论家（HLC）架构，结合序贯训练方案和多层级学习机制。该方法在团队结构的启发下，同时学习高层目标导向和底层执行策略，通过融合局部和全局视角来提升学习效果。

Result: 在合作式、非通信和部分可观测的MARL基准测试中，HLC显著优于单层次基线方法。该方法表现出高样本效率和鲁棒的策略性能，并能随着智能体数量和任务难度的增加而良好扩展。

Conclusion: 引入多层次结构并融合局部与全局视角是改进MARL性能的有效途径。HLC证明了通过模拟自然团队的组织方式，可以在合作式多智能体学习中获得更好的可扩展性、效率和鲁棒性。

Abstract: Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.

</details>


### [50] [Learning Complex Physical Regimes via Coverage-oriented Uncertainty Quantification: An application to the Critical Heat Flux](https://arxiv.org/abs/2602.21701)
*Michele Cazzola,Alberto Ghione,Lucia Sargentini,Julien Nespoulous,Riccardo Finotello*

Main category: cs.LG

TL;DR: 本文针对科学机器学习中多机制物理系统的正确表征问题，以OECD/NEA临界热通量(CHF)基准为案例，对比分析了后验方法（共形预测）与端到端覆盖导向方法（贝叶斯异方差回归和质量驱动损失）在不确定性量化(UQ)上的表现。研究表明，后验方法确保统计校准，而覆盖导向学习能有效重塑模型表征以匹配复杂物理机制，从而实现高预测精度和物理一致的自适应不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习面临的核心挑战是正确表征由多机制行为主导的物理系统。标准数据分析技术往往因系统的随机性和不同物理机制而失败。不确定性量化不应仅被视为安全评估工具，而应作为学习任务的支撑，指导模型内化数据行为。OECD/NEA的临界热通量(CHF)基准提供了一个理想测试案例，因其具有输入非线性和明显的微观物理机制特征，且各机制展现出不同的统计特性。

Method: 研究对比了两种UQ方法：(1)后验方法：共形预测；(2)端到端覆盖导向流程：贝叶斯异方差回归和质量驱动损失。这些方法将不确定性视为优化过程的活跃组件而非最终指标，同时建模预测及其行为。通过在CHF数据集上进行比较分析，评估各方法对物理表征的影响。

Result: 结果显示，后验方法（共形预测）能够确保统计校准，而覆盖导向学习方法有效重塑了模型表征，使其匹配复杂的物理机制。后者在预测CHF时实现了高预测精度和物理一致的不确定性估计，且不确定性能够动态适应CHF的内在变异性。

Conclusion: 将不确定性作为主动学习组件而非被动安全指标，对多机制物理系统的科学机器学习至关重要。覆盖导向的端到端学习方法优于后验方法，能更好地内化数据行为并产生物理一致的自适应不确定性预测，为科学ML提供了更可靠的框架。

Abstract: A central challenge in scientific machine learning (ML) is the correct representation of physical systems governed by multi-regime behaviours. In these scenarios, standard data analysis techniques often fail to capture the nature of the data, as the system's response varies significantly across the state space due to its stochasticity and the different physical regimes. Uncertainty quantification (UQ) should thus not be viewed merely as a safety assessment, but as a support to the learning task itself, guiding the model to internalise the behaviour of the data. We address this by focusing on the Critical Heat Flux (CHF) benchmark and dataset presented by the OECD/NEA Expert Group on Reactor Systems Multi-Physics. This case study represents a test for scientific ML due to the non-linear dependence of CHF on the inputs and the existence of distinct microscopic physical regimes. These regimes exhibit diverse statistical profiles, a complexity that requires UQ techniques to internalise the data behaviour and ensure reliable predictions. In this work, we conduct a comparative analysis of UQ methodologies to determine their impact on physical representation. We contrast post-hoc methods, specifically conformal prediction, against end-to-end coverage-oriented pipelines, including (Bayesian) heteroscedastic regression and quality-driven losses. These approaches treat uncertainty not as a final metric, but as an active component of the optimisation process, modelling the prediction and its behaviour simultaneously. We show that while post-hoc methods ensure statistical calibration, coverage-oriented learning effectively reshapes the model's representation to match the complex physical regimes. The result is a model that delivers not only high predictive accuracy but also a physically consistent uncertainty estimation that adapts dynamically to the intrinsic variability of the CHF.

</details>


### [51] [Generalisation of RLHF under Reward Shift and Clipped KL Regularisation](https://arxiv.org/abs/2602.21765)
*Kenton Tang,Yuzhu Chen,Fengxiang He*

Main category: cs.LG

TL;DR: 该论文针对大型语言模型中基于人类反馈的强化学习（RLHF）理论泛化性不足的问题，建立了考虑奖励漂移和截断KL正则化的泛化理论框架，推导出泛化误差由采样误差、奖励漂移误差和KL截断误差三部分构成的界，并给出了最优KL截断阈值和预算分配的实践指导。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF理论对泛化性的理解尚不充分，尤其忽略了两大关键现实因素：一是奖励模型使用历史行为策略的偏好数据训练，而RLHF却在当前策略的交互数据上优化，存在奖励漂移；二是KL正则项基于采样的对数概率比估计并进行截断稳定化处理，会引入系统性误差。这两点严重制约了RLHF的理论保障和实践效果。

Method: 研究者构建了一个新的泛化理论分析框架，显式建模了奖励漂移和截断KL正则化误差两个核心因素。具体通过统计学习理论方法，将RLHF泛化误差分解为可量化的组成部分，并分析了参数均匀先验初始化、随机梯度下降训练（视为Ornstein-Uhlenbeck过程）两种特殊情形。

Result: 推导出的泛化界表明，RLHF的泛化误差由三部分组成：1）提示词和策略交互的采样误差；2）奖励模型训练分布与当前策略分布不匹配导致的奖励漂移误差；3）KL正则项因估计和截断引入的近似误差。理论进一步给出了各误差项的具体数学形式。

Conclusion: 该理论揭示了RLHF性能的理论极限，并为实践提供了两个关键指导：一是如何设置最优的KL截断阈值以平衡稳定性和误差；二是如何在提示词收集、策略交互采样和偏好数据标注之间进行最优预算分配，从而最小化整体泛化误差，提升RLHF训练效率。

Abstract: Alignment and adaptation in large language models heavily rely on reinforcement learning from human feedback (RLHF); yet, theoretical understanding of its generalisability remains premature, especially when the learned reward could shift, and the KL control is estimated and clipped. To address this issue, we develop generalisation theory for RLHF that explicitly accounts for (1) \emph{reward shift}: reward models are trained on preference data from earlier or mixed behaviour policies while RLHF optimises the current policy on its own rollouts; and (2) \emph{clipped KL regularisation}: the KL regulariser is estimated from sampled log-probability ratios and then clipped for stabilisation, resulting in an error to RLHF. We present generalisation bounds for RLHF, suggesting that the generalisation error stems from a sampling error from prompts and rollouts, a reward shift error, and a KL clipping error. We also discuss special cases of (1) initialising RLHF parameters with a uniform prior over a finite space, and (2) training RLHF by stochastic gradient descent, as an Ornstein-Uhlenbeck process. The theory yields practical implications in (1) optimal KL clipping threshold, and (2) budget allocation in prompts, rollouts, and preference data.

</details>


### [52] [Easy to Learn, Yet Hard to Forget: Towards Robust Unlearning Under Bias](https://arxiv.org/abs/2602.21773)
*JuneHyoung Kwon,MiHyeon Kim,Eunju Lee,Yoonji Lee,Seunghoon Lee,YoungBin Kim*

Main category: cs.LG

TL;DR: 针对带偏模型中的机器遗忘难题，本文发现"捷径遗忘"现象并提出CUPID框架。该方法基于损失景观锐度差异划分遗忘样本为因果/偏见子集，解耦模型参数并路由梯度进行针对性更新，在Waterbirds、BAR和Biased NICO++数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘对数据隐私与模型可靠性至关重要，但在真实场景中，模型从虚假相关性学习的非预期偏见会严重削弱其有效性。本文探究从带偏模型中遗忘的独特挑战，揭示传统方法失效的根本原因。

Method: 提出CUPID框架：(1)依据样本锐度将遗忘集划分为因果近似与偏见近似子集；(2)解耦模型参数为因果通路和偏见通路；(3)精制梯度并路由至相应通路进行针对性更新。该方法源于不同偏见样本具有显著锐度差异的观察。

Result: 在Waterbirds、BAR和Biased NICO++等带偏数据集上的实验表明，CUPID实现了最先进的遗忘性能，有效缓解了"易学难忘"的捷径遗忘问题，避免模型错误地遗忘偏见属性而非类别属性。

Conclusion: CUPID通过锐度感知的子集划分和参数解耦策略，成功解决了带偏模型中的捷径遗忘挑战，实现了对目标类别的真正遗忘，为隐私保护机器学习提供了可行方案。

Abstract: Machine unlearning, which enables a model to forget specific data, is crucial for ensuring data privacy and model reliability. However, its effectiveness can be severely undermined in real-world scenarios where models learn unintended biases from spurious correlations within the data. This paper investigates the unique challenges of unlearning from such biased models. We identify a novel phenomenon we term ``shortcut unlearning," where models exhibit an ``easy to learn, yet hard to forget" tendency. Specifically, models struggle to forget easily-learned, bias-aligned samples; instead of forgetting the class attribute, they unlearn the bias attribute, which can paradoxically improve accuracy on the class intended to be forgotten. To address this, we propose CUPID, a new unlearning framework inspired by the observation that samples with different biases exhibit distinct loss landscape sharpness. Our method first partitions the forget set into causal- and bias-approximated subsets based on sample sharpness, then disentangles model parameters into causal and bias pathways, and finally performs a targeted update by routing refined causal and bias gradients to their respective pathways. Extensive experiments on biased datasets including Waterbirds, BAR, and Biased NICO++ demonstrate that our method achieves state-of-the-art forgetting performance and effectively mitigates the shortcut unlearning problem.

</details>


### [53] [On Imbalanced Regression with Hoeffding Trees](https://arxiv.org/abs/2602.22101)
*Pantia-Marina Alchirch,Dimitrios I. Diochnos*

Main category: cs.LG

TL;DR: 本文将批学习中的核密度估计(KDE)和层次收缩(HS)方法扩展到流数据环境，改进增量决策树回归性能。实验表明KDE在数据流早期有益，而HS几乎不提供性能提升。


<details>
  <summary>Details</summary>
Motivation: 现实应用产生连续数据流，需机器学习模型执行回归任务。Hoeffding树在流学习中效果显著，而KDE和HS在批学习中分别擅长处理不平衡回归和决策树正则化，但尚未充分应用于流数据场景。

Method: 采用望远镜论证将KDE适配到流数据环境，并将HS后处理正则化方法扩展至增量决策树模型。随后在常用在线回归数据集上，系统评估配备这两种选项的决策树性能。

Result: 实验发现：KDE在数据流早期阶段能带来性能提升，而HS方法几乎从不提供明显的性能收益。

Conclusion: 研究成功将批学习方法迁移至流学习环境，但证实HS在流数据场景中价值有限，KDE在流早期更具实用性。代码已开源。

Abstract: Many real-world applications provide a continuous stream of data that is subsequently used by machine learning models to solve regression tasks of interest. Hoeffding trees and their variants have a long-standing tradition due to their effectiveness, either alone or as base models in broader ensembles. At the same time a recent line of work in batch learning has shown that kernel density estimation (KDE) is an effective approach for smoothed predictions in imbalanced regression tasks [Yang et al., 2021]. Moreover, another recent line of work for batch learning, called hierarchical shrinkage (HS) [Agarwal et al., 2022], has introduced a post-hoc regularization method for decision trees that does not alter the structure of the learned tree. Using a telescoping argument we cast KDE to streaming environments and extend the implementation of HS to incremental decision tree models. Armed with these extensions we investigate the performance of decision trees that may enjoy such options in datasets commonly used for regression in online settings. We conclude that KDE is beneficial in the early parts of the stream, while HS hardly, if ever, offers performance benefits. Our code is publicly available at: https://github.com/marinaAlchirch/DSFA_2026.

</details>


### [54] [Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual](https://arxiv.org/abs/2602.22146)
*Yining Li,Peizhong Ju,Ness Shroff*

Main category: cs.LG

TL;DR: 本文针对带约束的RLHF问题，提出了一种通用原始-对偶框架，通过引入乐观预测更新机制设计出OPD算法，统一了多种现有对齐方法，并在参数化策略下提供了最后迭代收敛保证，解决了传统方法的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 标准原始-对偶方法在RLHF中存在两大局限：一是仅能在分布策略的凸凹鞍点问题中保证收敛，二是对参数化策略在实际应用中易出现不稳定甚至发散。这些问题制约了RLHF在大型语言模型对齐中的可靠性和理论保障。

Method: 提出统一原始-对偶框架整合safe-RLHF、one-shot和multi-shot等算法；设计乐观原始-对偶(OPD)算法，对原始和对偶变量均采用预测更新以稳定鞍点动力学。

Result: 建立了最后迭代收敛保证：在分布空间实现精确优化，在参数化策略下收敛至与近似误差相关的最优解邻域；证明乐观机制有效抑制约束对齐目标的固有振荡。

Conclusion: 该工作通过乐观更新机制弥合了约束强化学习与实用RLHF的理论鸿沟，为RLHF稳定性提供了理论保证，推动了更可靠的大语言模型对齐方法发展。

Abstract: Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.

</details>


### [55] [Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data](https://arxiv.org/abs/2602.22018)
*Sterre de Jonge,Elisabeth J. Vinke,Meike W. Vernooij,Daniel C. Alexander,Alexandra L. Young,Esther E. Bron*

Main category: cs.LG

TL;DR: 针对疾病进展模型仅能处理单一数据类型的局限，提出Mixed-SuStaIn框架，通过Mixed Events模型整合离散与连续数据，在ADNI数据上验证有效。


<details>
  <summary>Details</summary>
Motivation: 现有疾病进展模型多局限于单一数据类型（如连续变量），难以处理真实医疗数据中的离散与连续混合变量，限制了其在异质性数据集上的应用。

Method: 提出Mixed Events模型，并将其嵌入SuStaIn框架，构建Mixed-SuStaIn，实现对离散和连续数据的联合建模，可同时推断疾病亚型和进展轨迹。

Result: 仿真实验与阿尔茨海默病神经影像计划（ADNI）真实数据结果表明，Mixed-SuStaIn在混合数据集上性能优异，能够有效处理异质性数据。

Conclusion: 该研究成功扩展了疾病进展模型的数据兼容性，为临床异质性数据分析提供了新工具，有助于深入理解阿尔茨海默病等慢性疾病的长期发展规律。

Abstract: Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: https://github.com/ucl-pond/pySuStaIn.

</details>


### [56] [Sample Complexity Bounds for Robust Mean Estimation with Mean-Shift Contamination](https://arxiv.org/abs/2602.22130)
*Ilias Diakonikolas,Giannis Iakovidis,Daniel M. Kane,Sihan Liu*

Main category: cs.LG

TL;DR: 本文研究了均值偏移污染模型下的均值估计问题，证明了在基分布特征函数的温和谱条件下，存在样本高效算法能以任意精度估计目标均值，并给出了匹配的下界。


<details>
  <summary>Details</summary>
Motivation: 在均值偏移污染模型中，攻击者可将一小部分干净样本替换为来自基分布任意偏移版本的样本。先前工作仅在**高斯分布**和**拉普拉斯分布**下刻画了样本复杂度，而对一般基分布仍存在开放性问题。

Method: 本文采用傅里叶分析方法，并引入了**傅里叶见证**这一关键概念，将其作为推导上下界的核心工具。

Result: 在基分布特征函数的温和谱条件下，存在样本高效算法可估计目标均值至任意期望精度；同时给出了定性的匹配样本复杂度下界。

Conclusion: 本文基本解决了均值偏移污染模型下一般基分布的均值估计样本复杂度问题，揭示了与 Huber 污染模型的根本差异。

Abstract: We study the basic task of mean estimation in the presence of mean-shift contamination. In the mean-shift contamination model, an adversary is allowed to replace a small constant fraction of the clean samples by samples drawn from arbitrarily shifted versions of the base distribution. Prior work characterized the sample complexity of this task for the special cases of the Gaussian and Laplace distributions. Specifically, it was shown that consistent estimation is possible in these cases, a property that is provably impossible in Huber's contamination model. An open question posed in earlier work was to determine the sample complexity of mean estimation in the mean-shift contamination model for general base distributions. In this work, we study and essentially resolve this open question. Specifically, we show that, under mild spectral conditions on the characteristic function of the (potentially multivariate) base distribution, there exists a sample-efficient algorithm that estimates the target mean to any desired accuracy. We complement our upper bound with a qualitatively matching sample complexity lower bound. Our techniques make critical use of Fourier analysis, and in particular introduce the notion of a Fourier witness as an essential ingredient of our upper and lower bounds.

</details>


### [57] [Learning and Naming Subgroups with Exceptional Survival Characteristics](https://arxiv.org/abs/2602.22179)
*Mhd Jawad Al Rahwanji,Sascha Xu,Nils Philipp Walter,Jilles Vreeken*

Main category: cs.LG

TL;DR: 本文提出Sysurv，一种完全可微分的非参数方法，利用随机生存森林学习个体生存曲线并自动生成可解释规则，以识别具有特殊生存特征的亚群，在医学和预测性维护等领域具有重要应用价值。


<details>
  <summary>Details</summary>
Motivation: 识别生存时间显著不同于整体人群的亚群在精准医疗（确定治疗获益患者）和预测性维护（识别易失效组件）中至关重要。然而现有方法存在三大局限：需对生存模型施加限制性假设（如比例风险）、依赖特征预离散化、以及仅比较平均统计量而忽略个体偏差，导致重要亚群被遗漏。

Method: Sysurv是一种完全可微分、非参数的方法，其核心是利用随机生存森林学习个体生存曲线，通过算法自动挖掘特征条件并构建内在可解释的规则，从而筛选出具有特殊生存特征的亚群。

Result: 在多个数据集和不同设置上的实证评估，包括癌症数据案例研究，表明Sysurv能够揭示具有洞察力和可操作性的生存亚群。

Conclusion: Sysurv突破了传统方法的假设限制，实现了个体化、可解释的亚群发现，在临床决策和设备维护等实际应用中展现出良好前景。

Abstract: In many applications, it is important to identify subpopulations that survive longer or shorter than the rest of the population. In medicine, for example, it allows determining which patients benefit from treatment, and in predictive maintenance, which components are more likely to fail. Existing methods for discovering subgroups with exceptional survival characteristics require restrictive assumptions about the survival model (e.g. proportional hazards), pre-discretized features, and, as they compare average statistics, tend to overlook individual deviations. In this paper, we propose Sysurv, a fully differentiable, non-parametric method that leverages random survival forests to learn individual survival curves, automatically learns conditions and how to combine these into inherently interpretable rules, so as to select subgroups with exceptional survival characteristics. Empirical evaluation on a wide range of datasets and settings, including a case study on cancer data, shows that Sysurv reveals insightful and actionable survival subgroups.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [58] [Revisiting RAG Retrievers: An Information Theoretic Benchmark](https://arxiv.org/abs/2602.21553)
*Wenqing Zheng,Dmitri Kalaev,Noah Fatsi,Daniel Barcklow,Owen Reinert,Igor Melnyk,Senthil Kumar,C. Bayan Bruss*

Main category: cs.IR

TL;DR: 本文提出MIGRASCOPE框架，基于互信息和统计估计理论，系统分析RAG检索器的质量、冗余度、协同性与边际贡献。研究发现精心选择的检索器集成优于单检索器，为现代检索技术结构提供新见解，并给出RAG系统设计指导。


<details>
  <summary>Details</summary>
Motivation: RAG系统性能严重依赖检索模块，现有检索器基于词汇匹配、密集嵌入、图引用等不同原理，但缺乏对其差异与重叠的系统性理解。现有基准测试多关注完整RAG管道或新数据集，而直接比较检索器的研究使用有限评估工具，无法捕捉检索器间的互补性与重叠优势。

Method: 提出MIGRASCOPE（基于互信息的RAG检索器分析框架），通过信息论与统计估计理论建立原则性度量指标，量化检索质量、冗余度、协同效应及边际贡献。重新审视当前最优检索器，并在主流RAG语料库上进行系统性评估。

Result: 研究发现：1）精心选择的检索器集成性能超越任何单一检索器；2）通过互信息度量揭示各先进检索器的独特贡献层级；3）提供检索器间协同与冗余的量化证据。

Conclusion: 研究为现代检索技术结构提供了新视角，所开发的信息论驱动评估工具可指导RAG系统设计者选择或组合检索器，构建更稳健高效的RAG系统。

Abstract: Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.

</details>


### [59] [AQR-HNSW: Accelerating Approximate Nearest Neighbor Search via Density-aware Quantization and Multi-stage Re-ranking](https://arxiv.org/abs/2602.21600)
*Ganap Ashit Tewary,Nrusinga Charan Gantayat,Jeff Zhang*

Main category: cs.IR

TL;DR: 本文提出了AQR-HNSW框架，通过密度感知自适应量化、多状态重排序和量化优化的SIMD实现，在保持98%以上召回率的同时，将HNSW的内存占用减少75%，查询性能提升2.5-3.3倍，索引构建速度提升5倍。


<details>
  <summary>Details</summary>
Motivation: HNSW算法在十亿级向量数据库规模下面临内存消耗大、距离计算开销主导查询延迟、以及对异构数据分布性能不佳等关键瓶颈，制约了其在现代AI基础设施中的可扩展性。

Method: 提出了AQR-HNSW框架，该框架协同整合三种策略：1）密度感知自适应量化，实现4倍压缩比；2）多状态重排序机制，减少35%不必要的计算；3）量化优化的SIMD指令集实现，在多种架构上实现每周期16-64次操作。

Result: 在标准基准测试中，相比最先进的HNSW实现，AQR-HNSW实现了2.5-3.3倍的每秒查询数提升，保持98%以上的召回率，索引图内存减少75%，索引构建速度提升5倍。

Conclusion: AQR-HNSW显著提升了HNSW的可扩展性，解决了大规模向量搜索的内存和性能瓶颈，为现代AI系统提供了更高效的近似最近邻搜索解决方案。

Abstract: Approximate Nearest Neighbor (ANN) search has become fundamental to modern AI infrastructure, powering recommendation systems, search engines, and large language models across industry leaders from Google to OpenAI. Hierarchical Navigable Small World (HNSW) graphs have emerged as the dominant ANN algorithm, widely adopted in production systems due to their superior recall versus latency balance. However, as vector databases scale to billions of embeddings, HNSW faces critical bottlenecks: memory consumption expands, distance computation overhead dominates query latency, and it suffers suboptimal performance on heterogeneous data distributions. This paper presents Adaptive Quantization and Rerank HNSW (AQR-HNSW), a novel framework that synergistically integrates three strategies to enhance HNSW scalability. AQR-HNSW introduces (1) density-aware adaptive quantization, achieving 4x compression while preserving distance relationships; (2) multi-state re-ranking that reduces unnecessary computations by 35%; and (3) quantization-optimized SIMD implementations delivering 16-64 operations per cycle across architectures. Evaluation on standard benchmarks demonstrates 2.5-3.3x higher queries per second (QPS) than state-of-the-art HNSW implementations while maintaining over 98% recall, with 75% memory reduction for the index graph and 5x faster index construction.

</details>


### [60] [Trie-Aware Transformers for Generative Recommendation](https://arxiv.org/abs/2602.21677)
*Zhenxiang Xu,Jiawei Chen,Sirui Chen,Yong He,Jieyu Yang,Chuan Yuan,Ke Ding,Can Wang*

Main category: cs.IR

TL;DR: 针对生成式推荐中Transformer忽略层次化token拓扑结构的问题，本文提出TrieRec，通过两种结构感知的位置编码增强模型，在四个真实数据集上实现8.83%的平均性能提升。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐将下一项预测转化为token级生成，但标准自回归建模flatten了层次化token的字典树结构，无法捕捉拓扑诱导的语义关联性。

Method: 设计字典树感知的绝对位置编码聚合节点局部结构信息（深度、祖先、后代），以及拓扑感知的相对位置编码将结构关系注入自注意力，使模型具备结构归纳偏置。

Result: 在三个生成式推荐骨干模型上集成TrieRec，在四个真实世界数据集上平均提升8.83%，且方法模型无关、高效、无需超参数。

Conclusion: TrieRec有效解决了生成式推荐中拓扑结构建模缺失的问题，通过结构感知的位置编码显著提升推荐性能，具有良好的通用性和实用性。

Abstract: Generative recommendation (GR) aligns with advances in generative AI by casting next-item prediction as token-level generation rather than score-based ranking. Most GR methods adopt a two-stage pipeline: (i) \textit{item tokenization}, which maps each item to a sequence of discrete, hierarchically organized tokens; and (ii) \textit{autoregressive generation}, which predicts the next item's tokens conditioned on the tokens of user's interaction history. Although hierarchical tokenization induces a prefix tree (trie) over items, standard autoregressive modeling with conventional Transformers often flattens item tokens into a linear stream and overlooks the underlying topology.
  To address this, we propose TrieRec, a trie-aware generative recommendation method that augments Transformers with structural inductive biases via two positional encodings. First, a \textit{trie-aware absolute positional encoding} aggregates a token's (node's) local structural context (\eg depth, ancestors, and descendants) into the token representation. Second, a \textit{topology-aware relative positional encoding} injects pairwise structural relations into self-attention to capture topology-induced semantic relatedness. TrieRec is also model-agnostic, efficient, and hyperparameter-free. In our experiments, we implement TrieRec within three representative GR backbones, achieving notably improvements of 8.83\% on average across four real-world datasets.

</details>


### [61] [Offline Reasoning for Efficient Recommendation: LLM-Empowered Persona-Profiled Item Indexing](https://arxiv.org/abs/2602.21756)
*Deogyong Kim,Junseong Lee,Jeongeun Lee,Changhoe Kim,Junguel Lee,Jungseok Lee,Dongha Lee*

Main category: cs.IR

TL;DR: 该论文提出Persona4Rec推荐框架，通过大语言模型离线构建物品的可解释角色表示，实现高效实时推理，在保持与LLM重排序器相当性能的同时大幅降低延迟。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在推荐系统中展现出通过深度语义理解捕捉用户兴趣和物品特征的潜力，但现有方法作为在线重排序器需要昂贵的推理时间计算，导致高延迟，难以在实际场景中部署。

Method: 离线阶段：利用LLM分析物品评论，推断解释不同类型用户为何与该物品交互的多样化用户动机，将这些动机实例化为多个可解释的角色表示；在线阶段：通过专用编码器将用户画像与最合理的物品端角色对齐，将用户-物品相关性转化为用户-角色相关性，实现快速相关性计算而无需调用LLM推理。

Result: 大量实验表明，Persona4Rec在性能上与近期LLM重排序器相当，但显著减少推理时间。定性分析证实角色表示不仅驱动高效评分，还提供基于评论的直观解释。

Conclusion: Persona4Rec为下一代推荐系统提供了实用且可解释的解决方案，证明了离线角色构建与在线轻量级推理结合的有效性。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for recommender systems by capturing the nuanced semantics of user interests and item characteristics through rich semantic understanding and contextual reasoning. In particular, LLMs have been employed as rerankers that reorder candidate items based on inferred user-item relevance. However, these approaches often require expensive online inference-time reasoning, leading to high latency that hampers real-world deployment. In this work, we introduce Persona4Rec, a recommendation framework that performs offline reasoning to construct interpretable persona representations of items, enabling lightweight and scalable real-time inference. In the offline stage, Persona4Rec leverages LLMs to reason over item reviews, inferring diverse user motivations that explain why different types of users may engage with an item; these inferred motivations are materialized as persona representations, providing multiple, human-interpretable views of each item. Unlike conventional approaches that rely on a single item representation, Persona4Rec learns to align user profiles with the most plausible item-side persona through a dedicated encoder, effectively transforming user-item relevance into user-persona relevance. At the online stage, this persona-profiled item index allows fast relevance computation without invoking expensive LLM reasoning. Extensive experiments show that Persona4Rec achieves performance comparable to recent LLM-based rerankers while substantially reducing inference time. Moreover, qualitative analysis confirms that persona representations not only drive efficient scoring but also provide intuitive, review-grounded explanations. These results demonstrate that Persona4Rec offers a practical and interpretable solution for next-generation recommender systems.

</details>


### [62] [Learning to Collaborate via Structures: Cluster-Guided Item Alignment for Federated Recommendation](https://arxiv.org/abs/2602.21957)
*Yuchun Tu,Zhiwei Li,Bingli Sun,Yixuan Li,Xiao Song*

Main category: cs.IR

TL;DR: 提出CGFedRec联邦推荐框架，通过将高维物品嵌入压缩为紧凑聚类标签，在服务器端学习全局物品结构约束，客户端无需维护共享嵌入即可实现个性化建模，显著提升通信效率并保持推荐精度。


<details>
  <summary>Details</summary>
Motivation: 传统联邦推荐依赖同步高维物品嵌入，假设精确几何对齐对跨客户端协作至关重要，但通信开销大。本文质疑该假设，认为相对语义关系比共享坐标更重要，应允许物品表示在全局结构约束下局部变化，以平衡全局一致性与用户个性化。

Method: 设计Cluster-Guided FedRec框架：客户端上传嵌入至服务器，服务器执行聚类并生成紧凑标签后下发，切断物品嵌入的下游传输。服务器作为全局结构发现者学习物品簇，客户端基于标签注入全局协作信号到本地表示，实现无共享嵌入的联邦训练。

Result: 在多个数据集上的实验表明，该方案相比传统方法大幅降低通信成本，同时维持或提升了推荐准确率，验证了通过聚类标签传递协作信号的有效性。

Conclusion: CGFedRec通过聚类标签机制解耦了全局语义约束与局部表示学习，为联邦推荐提供了高效且隐私安全的解决方案，在通信效率与模型性能间实现了良好权衡。

Abstract: Federated recommendation facilitates collaborative model training across distributed clients while keeping sensitive user interaction data local. Conventional approaches typically rely on synchronizing high-dimensional item representations between the server and clients. This paradigm implicitly assumes that precise geometric alignment of embedding coordinates is necessary for collaboration across clients. We posit that establishing relative semantic relationships among items is more effective than enforcing shared representations. Specifically, global semantic relations serve as structural constraints for items. Within these constraints, the framework allows item representations to vary locally on each client, which flexibility enables the model to capture fine-grained user personalization while maintaining global consistency. To this end, we propose Cluster-Guided FedRec framework (CGFedRec), a framework that transforms uploaded embeddings into compact cluster labels. In this framework, the server functions as a global structure discoverer to learn item clusters and distributes only the resulting labels. This mechanism explicitly cuts off the downstream transmission of item embeddings, relieving clients from maintaining global shared item embeddings. Consequently, CGFedRec achieves the effective injection of global collaborative signals into local item representations without transmitting full embeddings. Extensive experiments demonstrate that our approach significantly improves communication efficiency while maintaining superior recommendation accuracy across multiple datasets.

</details>
