<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 31]
- [cs.IR](#cs.IR) [Total: 6]
- [cs.LG](#cs.LG) [Total: 45]
- [cs.AI](#cs.AI) [Total: 19]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: 针对大语言模型在社会科学学术写作评估中的挑战，本研究提出首个教育学术写作评估平台EduResearchBench，基于分层原子任务分解框架和课程学习策略训练专用模型EduWrite，实验证明垂直领域数据质量和分层训练比参数量更重要。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单次生成，缺乏对复杂学术研究流程的细粒度评估，无法提供具体的能力瓶颈诊断。

Method: 提出分层原子任务分解（HATD）框架，将端到端研究流程分解为6个专用模块和24个原子任务；构建自动化评估管道提供细粒度诊断反馈；设计课程学习策略从基础技能渐进培养复杂推理能力；基于5.5万原始学术样本筛选1.1万高质量指令对训练专用模型EduWrite。

Result: 拥有300亿参数的EduWrite在多项核心评估指标上显著优于720亿参数的通用大模型。

Conclusion: 在垂直专业领域中，高质量数据密度和分层递进式训练体系比单纯扩大模型参数量更具决定性作用。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [2] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: 该论文提出Indic-TunedLens，一个针对印度语言的解释性框架，通过为每种语言学习共享仿射变换来调整隐藏状态，显著优于标准Logit Lens，尤其在形态丰富的低资源印度语言上提升明显。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言大模型在印度等语言多样地区应用广泛，但现有解释工具多针对英语。先前研究发现LLMs存在英语中心化表征空间，跨语言解释性成为迫切问题。

Method: 提出Indic-TunedLens框架，学习共享仿射变换；不同于标准Logit Lens直接解码中间激活，该方法为每门目标语言调整隐藏状态，对齐其输出分布以实现更忠实的表征解码。

Result: 在10种印度语言的MMLU基准测试中，该方法显著超越现有最优解释性方法，在形态丰富、低资源语言上提升尤其突出，揭示了多语言Transformer的逐层语义编码特性。

Conclusion: 该研究为理解多语言模型的跨语言表征提供了关键洞察，证明了语言特定调整对提升低资源语言解释性的重要性，相关模型和代码已开源。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [3] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 针对古典伊斯兰文本问答挑战，本文提出CGRA DeBERTa模型，融合定制DeBERTa、LoRA适配器和概念门控机制，利用42,591个圣训问答对训练，以97.85的EM分数超越DeBERTa 8.08个百分点，实现高效神学感知的精准问答。


<details>
  <summary>Details</summary>
Motivation: 古典伊斯兰文本存在领域特异性语义、长程依赖和概念敏感推理等挑战，现有模型难以准确捕捉神学细微差别，需开发兼顾专业性与效率的领域自适应问答系统。

Method: 基于DeBERTa架构，采用LoRA低秩自适应微调；构建含12个核心术语的伊斯兰概念词典，通过残差概念块注入神学先验；设计重要性加权注意力门控，对关键token进行1.04-3.00倍动态缩放，实现语义增强与计算效率平衡。

Result: 在Sahih al-Bukhari与Sahih Muslim构建的数据集上，模型EM达97.85，较BERT(75.87)与DeBERTa(89.77)分别提升21.98和8.08个百分点；定性评估证实其在神学精确性和语义判别上的优势，推理开销仅增加约8%。

Conclusion: 该研究构建了可解释、高效且准确的圣训问答系统，能在保持计算效率的同时保留神学细微差别，为宗教经典智能教育提供可扩展的技术方案。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [4] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 本文提出了一个在AVerImaTeC事实核查共享任务中获得第三名的系统，该系统创新性地将检索增强生成(RAG)流程与反向图像搜索(RIS)模块结合，仅通过单次多模态大语言模型调用即可完成事实核查，平均成本仅0.013美元，且架构简单易于复现，为研究者提供了一个可访问的实验起点。


<details>
  <summary>Details</summary>
Motivation: 为事实核查领域提供一个低成本、易于复现和调整的基线系统，通过简化架构降低研究门槛，使更多研究者能够在此基础上进行实验和创新。

Method: 系统由三个解耦模块组成：基于相似性搜索的文本检索模块、通过API访问的反向图像搜索的图像检索模块，以及使用GPT5.1的生成模块。核心方法是将去年的RAG流程与RIS模块集成，每个事实核查仅需单次多模态大语言模型调用。

Result: 在AVerImaTeC共享任务中获得第三名，性能具有竞争力，单次事实核查平均成本仅为0.013美元，验证了简单架构下的高效表现。

Conclusion: 该系统证明了检索增强与图像搜索结合在事实核查中的有效性，其简单、低成本、易复现的特点使其成为理想的研究起点。作者开源了代码、提示词、向量存储及成本分析，为后续改进提供了清晰方向。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [5] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 针对LLM智能体调用不透明工具的挑战，本文提出ToolObserver框架，通过观察执行反馈迭代优化工具文档。在OpaqueToolsBench（包含通用函数调用、交互式象棋、长轨迹搜索三个环境）上，该方法性能优于现有基线，且效率提升3.5-7.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设工具具有完美文档，但现实工具（如搜索API）往往不透明且缺乏明确使用规范。LLM智能体能否通过交互学习改进不透明工具的使用性能并完善文档，是一个关键但未被充分研究的问题。

Method: 提出ToolObserver框架，从工具调用轨迹的执行反馈中迭代学习并精炼工具文档。创建OpaqueToolsBench基准测试，包含三个任务导向环境：通用函数调用、交互式国际象棋和长轨迹智能体搜索，所有工具均为规格说明不足的不透明工具。

Result: OpaqueToolsBench揭示现有自文档方法在不透明工具上既昂贵又不可靠。ToolObserver在所有设置下均优于基线方法，尤其在困难场景下优势明显。测试时探索阶段，其token消耗比最佳基线低3.5-7.5倍，展现出显著效率优势。

Conclusion: 对于不透明工具，基于执行反馈的简单迭代优化比复杂的自动文档方法更有效且高效。ToolObserver为LLM智能体在真实世界工具环境中提供了可扩展的学习与优化方案。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [6] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis提出了一种新型AI记忆框架，通过结合系统1的相似性搜索和系统2的全局选择机制，实现了语义和结构上都更相关的记忆检索，在长期记忆基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG和Graph-RAG等AI记忆方法主要依赖基于相似性的系统1检索机制，虽然在效率上有优势，但在需要全局推理或全面覆盖相关信息的场景下表现不佳。随着大语言模型对记忆能力的需求日益增长，亟需一种更强大的记忆组织和管理方案。

Method: 提出Mnemis框架，整合系统1相似性搜索与系统2全局选择机制。将记忆组织为基础图（用于相似性检索）和层次图（支持自上而下的语义层次遍历），通过两条互补的检索路径实现语义和结构双重相关的记忆检索。

Result: 在长期记忆基准测试中全面超越现有方法，使用GPT-4.1-mini在LoCoMo上达到93.9分，在LongMemEval-S上达到91.6分，取得最先进性能。

Conclusion: 结合系统1快速检索与系统2全局推理的双路径记忆机制相比单一相似性检索方法具有显著优势，为LLM的长程记忆管理提供了更有效的解决方案。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [7] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive是一个结合可微分神经符号推理层和主动价值引导探索控制器的模块化框架，用于知识图谱问答。它通过软统一风格的符号模块、神经路径评估器和蒙特卡洛风格的探索策略，在保持高准确率的同时减少了昂贵的图检索和模型调用。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在需要精确、结构化多跳推理的知识密集型查询中仍然面临挑战。知识图谱为事实基础提供了紧凑的符号基底，但将图结构与神经模型集成并非易事：简单地将图事实嵌入提示会导致低效和脆弱性，而纯符号或重度搜索方法在检索方面成本高昂，且缺乏基于梯度的优化。

Method: 提出NeuroSymActive模块化框架，结合可微分神经符号推理层与主动价值引导探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略相结合，优先扩展高价值路径。

Result: 在标准KGQA基准测试上的实证结果表明，NeuroSymActive获得了强大的答案准确率，同时与常见的检索增强基线相比，减少了昂贵的图检索和模型调用次数。

Conclusion: 该框架通过神经符号方法与主动探索的有效结合，在知识图谱问答任务中实现了准确性和效率的平衡，为处理知识密集型查询提供了新的解决方案。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [8] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 针对客户服务自动化中存在的人工编排复杂和指令泛化能力差的问题，本文提出一种基于面向任务流程图(TOFs)的无编排框架，通过流程图构建算法、本地化小语言模型和分散式蒸馏技术实现端到端自动化，实验表明性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖模块化设计需要大量人工编排，要么采用过度简化的指令模式导致指导有限和泛化性差，无法满足数字化转型中对高效、可扩展自动化服务的需求。

Method: 首先定义TOF组件与评估指标，然后形式化成本高效的流程图构建算法以从服务对话中抽象程序知识；同时强调小语言模型本地部署，并提出基于流程图的分散式蒸馏方法解决训练中的数据稀缺与隐私问题。

Result: 在多类服务任务上的广泛实验验证了框架有效性，定量指标和应用性能均显著优于强基线与市场化产品。

Conclusion: 通过开源Web演示系统和案例研究，本工作推动了服务自动化的简化创建，为未来数字化转型提供了更高效、隐私保护的自动化范式。

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [9] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 本研究以图卢语（一种拥有200多万使用者但数字资源稀缺的达罗毗荼语系语言）为案例，探讨大型语言模型能否在训练数据缺失的情况下获得基础对话能力。通过结构化提示工程，结合语法规则注入、负约束抑制、罗马化标准化和自生成合成数据等策略，成功将词汇污染率从80%降至5%，语法准确率达85%，证明该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 全球存在大量低资源语言，其数字内容极度匮乏，导致这些语言在大型语言模型训练数据中几乎缺席。这种技术鸿沟加剧了语言不平等，限制了语言多样性保护。图卢语作为典型代表，研究如何使其获得LLM支持，对促进语言公平具有重要意义。

Method: 研究采用四重策略：(1) 显式语法文档注入；(2) 负约束机制，抑制相关语言的高概率token生成；(3) 罗马化标准化处理；(4) 质量可控的自博弈合成数据生成。在人工标注的保留测试集上评估三个LLM，结果由母语者验证。

Result: 词汇污染率从基线80%降至5%，语法准确率达85%。负约束对三种模型提供稳定提升（12-18个百分点），语法文档效果因模型架构而异（8-22个百分点）。所有结果经母语者验证有效。

Conclusion: 研究表明结构化提示可使LLMs掌握低资源语言基础对话能力，无需微调。负约束是普适有效策略，语法利用效率与模型架构相关。该方法为濒危语言技术处理提供可行路径，但需针对不同模型特性优化。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [10] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: 本文提出Vision Wormhole框架，通过利用视觉语言模型的视觉接口作为通用端口，设计通用视觉编解码器实现异构模型间的无文本通信，采用中心-辐条拓扑和师生蒸馏策略，在保持推理保真度的同时显著降低多智能体系统的通信开销。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的多智能体系统虽具备高级协作推理能力，但受限于离散文本通信带来的运行时开销和信息量化损失。现有隐状态传输方案要么假设发送-接收架构同质，要么依赖成对学习的翻译器，无法实现跨异构模型族的可扩展模块化通信。

Method: 1) 提出通用视觉编解码器，将异质推理轨迹映射至共享连续隐空间；2) 将视觉编码器重构为跨模型"心灵感应"的通用端口；3) 设计中心-辐条拓扑，将成对对齐复杂度从O(N²)降至O(N)；4) 采用无标签师生蒸馏目标，对齐高速视觉通道与文本通路的鲁棒推理模式。

Result: 在Qwen-VL、Gemma等异构模型族上的控制实验表明，该框架相比标准文本通信减少端到端墙钟时间，同时保持相当的推理保真度。

Conclusion: Vision Wormhole通过复用视觉接口成功实现了模型无关的高效多智能体通信，解决了文本通信瓶颈，为未来异构智能体协作提供了可扩展的解决方案。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [11] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 本文针对历史档案信息难以量化分析的问题，以芬兰二战卡累利阿疏散者访谈为例，开发了一个包含活动类型、社交程度、发生频率和体力强度四个维度的分类框架，通过开放权重大型语言模型结合投票机制，成功将35万条休闲活动提及标注为结构化数据，为研究社会融合提供了可靠资源。


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案虽使大规模日常生活研究成为可能，但直接从文本提取的信息难以定量回答历史学或社会学问题。具体挑战在于：从芬兰二战卡累利阿疏散者家庭访谈中提取的35万条活动提及产生了7.1万个唯一名称，维度灾难阻碍了直接分析。

Method: 构建多维分类框架（活动/组织类型、社交性、频率、体力要求）；人工标注黄金标准集用于评估；测试大型语言模型的大规模标注能力；采用多模型运行投票集成策略提升可靠性。

Result: 开放权重大型语言模型通过投票机制能达到与专家判断接近的一致性，成功为全部35万条实体完成标注，生成高质量结构化数据集。

Conclusion: 该方法为历史档案文本信息量化提供了可行方案，生成的结构化资源有效支撑社会融合及相关社会学问题的下游研究。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [12] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT是一种测试驱动的能力自适应课程强化微调方法，通过构建四层测试套件并解耦课程进度与原始奖励分数，根据模型能力自适应地设计课程策略，显著提升了代码生成的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型正在改变编码范式（vibe coding），但生成算法复杂且鲁棒的代码仍是关键挑战。现有强化微调方法忽略了测试用例的异质难度和粒度，导致奖励信号分布不均和梯度更新偏差，亟需有效激励模型的深度推理能力。

Method: 提出TAROT框架，为每个问题系统构建基础、中级、复杂、边缘四层测试套件，创建可控难度梯度；核心创新在于将课程进度与原始奖励分数解耦，实现能力条件化评估和原则性的课程策略选择，通过课程学习促进稳定优化和高效能力获取。

Result: 实验表明RFT的最优课程与模型内在能力密切相关：能力较弱的模型采用由易到难课程获得更大提升，而能力较强的模型则更适合先难后易课程。TAROT能自适应地为不同模型定制课程设计，持续提升生成代码的功能正确性和鲁棒性。

Conclusion: TAROT提供了一种可复现的代码生成强化微调课程设计方法，通过能力自适应的课程策略选择，有效解决了奖励信号不平衡问题，为提升LLM代码生成质量提供了新思路，相关代码和数据已开源。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [13] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: 本研究通过控制实验发现，多个LLM智能体存在系统性、可预测的来源偏好，这些偏好受语境影响，可压倒内容质量，且难以通过提示消除，揭示了信息推荐中的潜在偏见机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦LLM生成内容的偏见，却忽视了LLM作为信息中介时，其选择呈现给用户的信息所受到的外部因素影响。当信息附带特定来源属性时，LLM的筛选机制可能引入系统性偏见，这一现象亟待探究。

Method: 研究设计控制实验，测试了来自6家供应商的12个LLM，在合成任务和真实世界任务中，当信息标注具体来源（如出版商、平台）时的选择偏好行为，并进行交叉验证。

Result: 实验显示多个模型存在显著且一致的来源偏好，这些偏好具有语境敏感性，其影响力可超越内容相关性，且对反偏见提示具有抵抗力。该现象可解释先前研究中的新闻推荐政治倾向性。

Conclusion: 研究揭示了LLM智能体中根深蒂固的来源偏见问题，强调需深入探究其成因，并建立透明度机制和用户控制手段，以保障信息推荐系统的公平性。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [14] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 本研究首次将"期望检测"引入自然语言处理领域，通过构建RedHOTExpect语料库（4.5K条Reddit帖子）并运用大语言模型进行标注，分析在线医疗社区中患者治疗期望的表达模式，发现身体疾病相关帖子比心理健康相关帖子表现出更强的乐观性和主动性，且患者主要讨论治疗益处而非负面结果。


<details>
  <summary>Details</summary>
Motivation: 患者治疗期望对治疗效果有显著影响，但现有研究主要集中于临床环境，忽视了在线医疗平台（如医疗subreddit）中患者不愿或无需在其他场合分享的期望。由于"期望"在自然语言处理领域尚未被研究，本研究提出期望检测任务，以挖掘包括观点挖掘和产品设计在内的多种应用价值。

Method: 研究团队构建了RedHOTExpect语料库，包含4.5K条Reddit医疗帖子。采用大语言模型（LLM）进行银标标注，并通过人工验证确保质量（标注准确率约78%）。基于该语料库，分析期望的语言学特征模式及其表达方式。

Result: 研究发现，与心理健康相关帖子相比，身体疾病或治疗相关帖子表现出更明显的乐观态度和主动框架；在数据集中，患者主要讨论治疗益处而非负面结果。研究还探索了患者期望的内容及其背后的原因。

Conclusion: 本研究首次将期望检测引入NLP领域，创建的RedHOTExpect语料库为医疗期望研究提供了新资源。研究结果揭示了不同医疗背景下患者期望表达的差异性，为理解在线医疗交流中的期望表达提供了重要洞察，对改进医患沟通和医疗产品设计具有应用价值。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [15] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: 本文介绍LuxMT，一个基于Gemma 3 27B微调的卢森堡语到法语/英语机器翻译系统。研究团队构建了首个基于《Luci》旅游杂志人工翻译数据的卢森堡语翻译基准测试，使用LuxAlign新闻语料库和议会记录作为训练数据，并通过LuxEmbedder句子嵌入过滤低质量句对。实验表明LuxMT相比基线模型性能显著提升，且能泛化至未训练的德语翻译方向。此外，LuxEmbedder作为质量评估指标与其他参考指标呈强相关性，但需进一步研究验证其可靠性。


<details>
  <summary>Details</summary>
Motivation: 卢森堡语作为低资源语言，缺乏高质量的机器翻译系统和评估基准。现有平行语料稀缺，数据质量参差不齐，亟需开发针对性的翻译模型、构建可靠的人工评估数据集，并探索有效的数据清洗与质量评估方法。

Method: 采用Gemma 3 27B作为基础模型进行微调。训练数据来自LuxAlign多语种新闻平行语料和经Google Translate增强的卢森堡议会 transcripts。利用LuxEmbedder（卢森堡语句子嵌入模型）过滤低等价性句对。评估基准基于《Luci》旅游杂志的人工翻译文本，涵盖LB→FR、LB→EN和LB→DE三个方向。同时探索LuxEmbedder作为无参考质量估计指标的潜力。

Result: LuxMT在LB→FR和LB→EN任务上显著优于Gemma 3基线模型，并在训练数据中未包含的LB→DE翻译上展现出良好的零样本泛化能力。LuxEmbedder作为质量评估指标与BLEU、COMET等参考基指标呈现强相关性，显示出其作为质量估计工具的潜力。

Conclusion: LuxMT为低资源语言机器翻译提供了有效方案，证明了数据过滤与模型微调的重要性。LuxEmbedder具备成为质量评估指标的前景，但其实际应用价值仍需更多系统性的研究与验证。作者建议在将其作为可靠评估工具使用前应保持谨慎，并呼吁开展进一步研究以充分评估其效用。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [16] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: 本文提出Fine-Refine细粒度精炼框架，通过将LLM对话响应分解为原子单元、外部知识验证、困惑度评估流畅性及迭代纠错，显著缓解模型幻觉问题，在事实准确性上最高提升7.63分，为对话系统事实性优化提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的幻觉倾向会产生事实错误的响应，误导用户并损害系统信任；而现有对话系统精炼方法仅在响应级别操作，忽略了单个响应包含多个可验证或不可验证事实的特性，无法进行细粒度修正。

Method: 提出Fine-Refine框架，将对话响应分解为原子单元，利用外部知识逐一验证每个单元的事实性，通过困惑度评估单元流畅性，并基于验证结果进行迭代式的颗粒状错误修正。

Result: 在HybriDialogue和OpendialKG数据集上，从事实准确性（fact score）和覆盖度（Not Enough Information比例）评估，Fine-Refine使对话事实分数最高提升7.63个点，但对话质量存在小幅折衷。

Conclusion: Fine-Refine通过细粒度分解与迭代修正机制有效提升了对话系统的事实准确性，证明原子化验证策略是缓解LLM幻觉的有效途径，为构建更可靠的对话系统提供了新思路。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [17] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: ExpertWeaver是一个无需训练的稠密模型转MoE框架，通过挖掘GLU机制中神经元激活模式揭示的固有专家结构，构建共享和专用专家，在动态结构剪枝和下循环初始化方面均超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 训练高质量MoE模型计算成本极高，现有稠密转MoE方法（动态结构剪枝和下循环）会破坏模型内在激活模式，导致专家构建效果不佳。亟需一种能保持原始激活规律的高效转换方法。

Method: 论文发现GLU单元的细粒度神经元激活模式隐含了由持续激活的通用神经元和动态激活的专用神经元构成的粗粒度MoE架构。ExpertWeaver据此按激活模式划分神经元，并采用层自适应配置构建共享专家和路由专家。

Result: 实验证明ExpertWeaver作为无需训练的动态结构剪枝方法和下循环初始化策略，性能显著优于现有方法，能获得更优的MoE模型。

Conclusion: GLU机制为稠密转稀疏提供了天然设计蓝图，ExpertWeaver通过保持原始激活模式实现了专家结构的有效发现，为高效MoE构建开辟了新思路。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [18] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: 这篇论文提出ZeroSyl，一种无需训练的方法，直接从冻结的WavLM模型中提取音节边界和嵌入。通过利用WavLM中间层特征的L2范数，该方法实现了有竞争力的音节分割性能，并在词汇、句法和叙事基准测试中优于先前的音节级分词器。


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型旨在直接从原始音频中学习语言而不依赖文本资源，但自监督语音编码器的离散token会产生过长的序列。最近的音节级单元方法（如Sylber和SyllableLM）需要复杂的多阶段训练流程，这激发了对更简洁解决方案的需求。

Method: ZeroSyl提出了一种简单的无需训练的方法，直接从冻结的WavLM模型中提取音节边界。该方法利用WavLM中间层特征的L2范数来检测音节边界，然后将得到的段进行平均池化，使用K-means离散化，并用于训练语言模型。

Result: ZeroSyl在词汇、句法和叙事基准测试上均优于先前的音节级分词器。扩展实验表明，虽然更细粒度的单元对词汇任务有益，但发现的音节级单元在句法建模方面表现出更好的扩展行为。

Conclusion: 该研究证明了一种简单、无需训练的方法可以有效地从语音中提取音节级单元，并实现优越的性能，为纯语音语言模型的发展提供了新思路。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [19] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: 本文提出Perspectives——一套面向数字人文领域的交互式文档分析工具，通过人机协同的方面级聚类框架，支持学者对大规模非结构化文档集合进行探索性分析与组织。


<details>
  <summary>Details</summary>
Motivation: 数字人文研究者需处理海量非结构化文本，传统方法缺乏灵活性且难以融入领域知识。现有工具在支持用户自定义分析视角、持续优化分析过程方面存在不足，亟需一种能够结合人类专业判断与机器学习优势的交互式分析框架。

Method: 构建基于提示的文档重写与指令嵌入机制，实现分析视角的初始设定；设计面向方面的文档聚类管道，并集成集群优化工具与嵌入模型微调机制，形成"人在回路"的迭代优化范式。

Result: 开发了支持交互式文档地图可视化的Perspectives系统，可揭示文档集合中的主题、情感等多维度类别结构，为数字人文研究者提供从探索到深度分析的工作流支持。

Conclusion: 该工作通过将人类意图引导与机器学习相结合，为数字人文领域提供了一种可控、灵活的大规模文本分析方法，增强了研究者探索和解读复杂文档集合的能力。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [20] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 论文提出结合模型蒸馏与任务特定对比损失的训练方案，用于构建紧凑高效的文本嵌入模型。该方法优于单一训练范式，所生成的jina-embeddings-v5-text-small/nano模型在相似规模下达到或超越SOTA，支持32k token长文本与多语言，且在截断与二值量化下保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入模型广泛应用于语义相似度任务，但通用模型通常仅用对比损失训练。为在小型化模型上保持高性能，需要更有效的训练策略。

Method: 采用模型蒸馏与任务特定对比损失相结合的新型训练方案，优化小型嵌入模型的性能。

Result: jina-embeddings-v5-text-small和nano模型在同类规模模型中实现最先进或可比性能，支持多达32k token的多语言长文本处理，在截断和二值量化下保持鲁棒性。

Conclusion: 该方法比单纯对比学习或蒸馏更适合训练小型模型，模型权重已开源以促进后续研究。

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [21] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: 针对Text-to-SQL在真实场景中难以应用的问题，本文提出SquRL框架，通过强化学习实现推理时的动态工作流构建，实验证明该方法显著优于静态工作流，尤其在复杂和分布外查询上表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL方法依赖单一静态工作流，无法有效扩展到分布外和长尾场景，用户需要大量实验才能选择合适方法。论文旨在让系统能够在推理时自适应构建工作流，通过动态策略超越静态工作流的性能限制。

Method: 提出SquRL强化学习框架，设计基于规则的奖励函数，引入动态actor masking机制鼓励广泛探索，以及伪奖励机制提升训练效率，从而增强LLM在自适应工作流构建中的推理能力。

Result: 在广泛使用的Text-to-SQL基准测试上，动态工作流构建持续优于最佳静态工作流方法，在复杂查询和分布外查询上的提升尤为显著。

Conclusion: 动态工作流构建是Text-to-SQL实际应用的有效路径，SquRL框架通过强化学习实现了自适应推理，为处理异质性和分布外场景提供了新思路，代码已开源。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [22] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 针对现有抑郁预测方法缺乏症状级分析的问题，本文提出一种症状特异性的临床启发框架。该方法通过症状引导的交叉注意力机制将PHQ-8问卷项目与情感感知语音表示对齐，识别关键语音片段，并引入可学习参数自适应控制注意力锐度。在标准临床数据集EDAIC上验证了其优越性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 抑郁症具有多样化的症状表现（如睡眠障碍、兴趣丧失、注意力困难），但现有研究多将其预测简化为二分类标签或总体严重程度评分，缺乏对症状特异性信息的显式建模，无法满足临床筛查中症状级分析的需求。

Method: 提出一种症状特异性且临床启发的抑郁严重程度估计框架。该框架采用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表示进行对齐，以识别与每个症状更相关的语音片段；同时引入可学习的症状特异性参数，自适应控制注意力分布的锐度，以捕捉症状表达的时序差异。

Result: 在标准临床风格数据集EDAIC上的实验表明，该方法性能优于现有工作。注意力分布分析显示，模型对包含多种抑郁症状线索的语句赋予了更高的注意力权重，验证了其良好的可解释性。

Conclusion: 该研究证明了症状引导和情感感知建模在基于语音的抑郁筛查中的重要性，为临床评估提供了更精细的症状级分析能力，推动了可解释性抑郁检测技术的发展。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [23] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 针对大型语言模型强化学习微调中的训练不稳定问题，论文提出STAPO方法，通过识别并掩码约0.01%的"伪标记"来解决性能崩溃，在数学推理基准测试中相比基线方法平均提升7.13%。


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法依赖熵正则化等启发式技术维持稳定性，但常出现后期性能崩溃。研究发现训练不稳定性源于极少数伪标记（约0.01%），这些标记在正确响应中贡献微小却获得完整序列奖励，导致梯度异常放大。

Method: 提出伪标记感知策略优化（STAPO）：首先推导标记级策略梯度幅度与标记概率及局部策略熵的负相关性；然后识别伪标记，在训练中选择性掩码这些标记的更新，并在有效标记上重新归一化损失函数。

Result: 在六个数学推理基准测试中使用Qwen 1.7B、8B和14B模型，STAPO展现出显著更优的熵稳定性，相比GRPO、20-Entropy和JustRL平均性能提升7.13%。

Conclusion: STAPO通过精准识别和处理导致不稳定的伪标记，有效解决了大型语言模型RL微调中的性能崩溃问题，显著提升训练稳定性和推理性能，为大规模模型优化提供了有效方案。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [24] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 针对埃及阿拉伯语TTS资源稀缺问题，本研究构建NileTTS数据集（38小时，两说话人，多领域），提出LLM生成→语音合成→自动转录→人工验证的流水线，微调XTTS v2模型，并开源全部资源。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语TTS资源集中于现代标准阿拉伯语与海湾方言，埃及阿拉伯语作为使用最广泛的方言却严重缺乏数据，制约了该方言语音合成研究进展。

Method: 采用大语言模型生成埃及阿拉伯语内容，经音频合成工具转换为语音，通过自动转录与说话人分离技术处理，辅以人工质量验证，构建涵盖医疗、销售和日常对话的38小时数据集；基于此微调多语言TTS模型XTTS v2。

Result: 贡献包括：1）首个公开埃及阿拉伯语TTS数据集；2）可复现的方言TTS合成流水线；3）开源的埃及阿拉伯语优化TTS模型。

Conclusion: 该工作填补了埃及阿拉伯语TTS研究空白，通过开源资源推动该方言语音合成技术的发展与应用。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [25] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 针对弗莱的四大叙事类型，现有计算研究多关注叙事模式而非角色功能。本研究融合荣格原型理论，构建了一套包含4个通用角色功能（主角、导师、对手、同伴）和16个类型专用角色的框架，并通过6个大语言模型在40部叙事作品上的验证显示，模型能有效识别和拒绝角色-类型对应关系（平均平衡准确率82.5%），揭示了角色功能在不同类型中的系统性差异，为计算叙事学提供了新的角色分析方法。


<details>
  <summary>Details</summary>
Motivation: 现有对弗莱叙事类型理论的计算方法主要聚焦于叙事模式分析，忽视了角色功能在不同类型中的表现差异。角色是叙事的核心要素，但缺乏系统的、可计算的角色功能框架来补充模式导向的分析方法，这限制了计算叙事学对叙事结构的深入理解。

Method: 研究首先基于荣格原型理论，将心理结构成分映射为4个通用角色功能（主角、导师、对手、同伴），再针对喜剧、浪漫、悲剧、讽刺四种类型，从典型作品中提炼出16个类型专用角色。验证阶段采用多模型方法，使用6个先进大语言模型评估40部叙事作品中的角色-类型对应关系，包含160个有效对应和30个无效对应样本，通过平衡准确率和Fleiss' κ系数评估模型性能与一致性。

Result: 大语言模型表现出良好性能，平均平衡准确率达82.5%，模型间一致性较强（Fleiss' κ = 0.600）。性能存在显著的类型和角色差异：类型准确率从72.7%到89.9%不等，角色准确率从52.5%到99.2%不等。定性分析表明，这些差异反映了真实的叙事特性，如浪漫类型中的功能分布特点和讽刺类型中典型的原型颠覆现象。

Conclusion: 该角色功能框架有效补充了现有的模式导向分析方法，证实了大语言模型在计算叙事学中的潜力。研究不仅为叙事生成和互动叙事应用提供了基础，也展示了计算人文研究的新路径，未来可进一步开发基于角色结构的自动化叙事分析方法。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [26] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 该论文针对词汇语义变化检测（LSCD）中过度依赖少数传统度量（APD和PRT）的问题，提出了两种新的度量方法AMD和SAMD。实验表明，AMD在非专业编码器和降维场景下更具鲁棒性，而SAMD在专业编码器上表现更优，建议LSCD领域应考虑采用这些替代度量。


<details>
  <summary>Details</summary>
Motivation: 当前词汇语义变化检测研究虽广泛采用上下文语言模型嵌入，但量化语义变化时仍主要依赖少量传统度量（平均成对距离APD和词原型余弦距离PRT）。这种依赖性限制了方法的鲁棒性和适用性，尤其是在降维或非专业编码器条件下表现不佳，亟需开发更优的度量标准。

Method: 作者提出了两种新度量：平均最小距离（AMD）和对称平均最小距离（SAMD）。其核心思想是通过量化不同时期词语用法之间的局部对应关系来评估语义变化。AMD计算一个时期所有用法向量到另一时期最近邻向量的平均距离；SAMD则对称地计算两个方向的AMD并取平均，以消除方向性偏差。

Result: 在多语言、多编码器模型和多种表征空间的实验中，AMD在降维和非专业编码器条件下展现出更强的鲁棒性；而SAMD在与专业编码器结合时性能更优。结果表明，超越传统APD和PRT度量能有效提升LSCD性能，AMD为上下文嵌入分析提供了可靠的替代方案。

Conclusion: 词汇语义变化检测领域应拓宽视野，采纳如AMD和SAMD这样的替代性语义变化度量。特别是AMD，因其在非理想条件下的稳定性，值得在基于上下文嵌入的LSCD研究中推广使用。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [27] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出了一个端到端的文本干预生成与因果效应估计流程，通过稀疏自编码器生成可控文本变异，并采用协变量残差化方法解决文本中处理变量与协变量混杂导致的估计偏差问题，为文本作为处理因素的因果推断提供了稳健框架。


<details>
  <summary>Details</summary>
Motivation: 理解文本对下游结果的因果效应是众多应用的核心任务，但必须通过严格控制实验来实现。由于文本本身混淆了处理变量与协变量信息，朴素估计方法会产生显著偏差。大语言模型虽具备文本生成潜力，但要产生和评估可控变异需要更精细的考量，因此亟需解决文本作为处理因素实验中的计算和统计挑战。

Method: 提出一个端到端流程：首先利用稀疏自编码器（SAEs）进行假设生成和特征引导，然后执行稳健因果估计。针对文本固有的处理-协变量混杂问题，提出基于协变量残差化的解决方案以消除估计偏差，同时应对计算和统计层面的双重挑战。

Result: 实证结果显示，该流程能有效诱导目标特征变异，显著减轻估计误差，为文本作为处理因素的因果效应估计提供了稳健基础。

Conclusion: 该研究成功解决了文本作为处理因素实验中的核心挑战，通过稀疏自编码器和协变量残差化的组合方法，为文本因果推断建立了可行且稳健的框架，使研究者能够更准确地进行文本干预的因果效应估计。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [28] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: 本研究评估GPT-4与Mistral等大型语言模型在四门低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语、叙利亚语）的词形还原与词性标注任务中的表现，证实少样本场景下LLMs无需微调即可超越基线模型，为低资源语言处理开辟新路径。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的词形还原与词性标注面临数据稀缺的核心难题，传统方法依赖大量标注数据而难以适用。本研究旨在验证大型语言模型在少样本与零样本条件下处理历史及语言学多样性低资源语言的能力，为破解低资源语言NLP困境提供新思路。

Method: 构建包含对齐训练集与域外测试集的新颖基准，对GPT-4系列模型及开源Mistral模型在古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语上的词形还原与词性标注性能进行系统评估，并以任务专用RNN模型PIE作为基线进行对比分析。

Result: 实验结果显示，未经微调的LLMs在少样本设置下于多数语言的词性标注与词形还原任务中表现优异，性能达到或超越基线水平。然而，针对复杂形态结构与非拉丁文字的语言仍存在显著挑战。

Conclusion: 研究表明，在数据缺失情境下，大型语言模型可作为语言标注任务启动的可靠选项，有效辅助低资源语言处理，为古文字与历史语言计算提供了切实可行的技术方案。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [29] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: 本文针对多模态大语言模型在真实世界探索性数据分析中多轮交互能力的不足，提出了ChartEditBench基准测试，包含5000条难度可控的修改链，并设计了融合执行验证、像素相似度和逻辑检查的评估框架。实验发现现有模型在多轮编辑中因错误累积和上下文丢失性能显著下降，尤其在数据变换上表现不佳，为grounded的多模态编程提供了挑战性测试平台。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在单轮图表生成上表现强劲，但在真实场景的探索性数据分析中，用户需要通过多轮迭代细化可视化，这要求模型保持共同基础、追踪先前编辑并适应偏好变化，而该能力尚未被充分探索。

Method: 提出ChartEditBench基准，包含5000条难度可控的增量式视觉grounded图表编辑链和人工验证子集；设计鲁棒评估框架，通过执行fidelity检查、像素级视觉相似度和逻辑代码验证缓解LLM-as-a-Judge的局限性。

Result: 在ChartEditBench上的实验显示，先进的多模态大语言模型在多轮设置中因错误累积和共享上下文崩溃出现显著性能退化，在风格编辑上表现良好但数据为中心变换的执行频繁失败。

Conclusion: ChartEditBench为grounded、意图感知的多模态编程建立了具有挑战性的测试平台，揭示了当前模型在多轮交互编辑中的关键短板。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [30] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 该论文针对自动文本质量评估中LLM-as-a-judge方法计算成本高、需后处理的问题，提出了*-PLUIE——一种基于困惑度的非生成式LLM评估指标的任务特定prompt变体。实验表明，个性化*-PLUIE在保持低计算成本的同时，与人类评分的相关性更强。


<details>
  <summary>Details</summary>
Motivation: 当前LLM-as-a-judge方法在自动文本质量评估中效果良好，但存在计算成本高、需要后处理步骤的局限性。为克服这些问题，需要开发更高效、更经济的评估指标。

Method: 在ParaPLUIE（一种基于困惑度的LLM-judge指标，无需生成文本即可估计"Yes/No"答案置信度）基础上，引入任务特定的prompt变体*-PLUIE，并通过实验评估其与人类判断的一致性。

Result: 实验结果表明，个性化*-PLUIE指标与人类评分的相关性更强，同时保持了较低的计算成本。

Conclusion: 该研究表明，通过设计任务特定的prompt策略，可以在不增加计算开销的前提下，显著提升非生成式LLM评估指标的性能，为高效、低成本的文本质量评估提供了新思路。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [31] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文针对工业级NLP应用中计算和存储资源受限的场景，重新设计了Avey模型使其适用于仅编码器架构。通过引入解耦的静态和动态参数化、稳定性归一化以及神经压缩等创新，该模型在标准token分类和信息检索基准测试中持续优于四种广泛使用的基于Transformer的编码器，并且在处理长文本时扩展性更佳。


<details>
  <summary>Details</summary>
Motivation: 工业界在资源受限环境下仍依赖紧凑的预训练双向编码器，如BERT架构。虽然Avey作为自回归、无注意力的替代方案被提出，但其最初设计并非针对仅编码器范式。本研究旨在将Avey重新设计为仅编码器架构，以提升其在资源受限场景下的适用性和性能。

Method: 研究提出将Avey模型从自回归架构重构为仅编码器架构，并引入三项主要创新：1）解耦的静态和动态参数化，分离固定和动态参数以提高效率；2）稳定性导向的归一化，增强训练稳定性；3）神经压缩技术，优化模型大小和计算效率。

Result: 实验结果表明，重构后的Avey架构在四个标准token分类和信息检索基准测试中持续优于四种广泛使用的Transformer编码器。更重要的是，该模型在处理长上下文时展现出更高效的扩展性，表明其在资源受限工业场景中具有实际应用价值。

Conclusion: 本研究成功将Avey模型重构为高效的仅编码器架构，通过架构创新在保持紧凑性的同时提升了性能。该方法为工业级NLP应用提供了一种有竞争力的Transformer替代方案，特别是在需要处理长文本且资源受限的环境中。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [32] [Automatic Funny Scene Extraction from Long-form Cinematic Videos](https://arxiv.org/abs/2602.15381)
*Sibendu Paul,Haotian Jiang,Caren Chen*

Main category: cs.IR

TL;DR: 本文提出端到端系统，用于从长片中自动识别和排序幽默场景。系统结合视觉与文本线索进行场景分割，通过引导三元组挖掘优化镜头表示，并构建基于音频和文本的多模态幽默标签框架。在OVSD数据集上场景检测AP提升18.3%，幽默检测F1达0.834，87%提取片段具有幽默意图，98%场景定位准确，且可推广至预告片，显著提升流媒体平台内容创作效率和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 为提升流媒体平台用户参与度，需自动生成吸引人的幽默短视频预览。但长片因时长和叙事复杂，且幽默依赖多模态和微妙风格，给场景定位和内容提取带来挑战。

Method: 提出包含镜头检测、多模态场景定位和幽默标签的端到端系统。关键创新：1) 视觉与文本融合的场景分割方法；2) 引导三元组挖掘改进镜头表示；3) 音频与文本协同的多模态幽默识别框架。

Result: 在OVSD数据集上场景检测AP相对提升18.3%；幽默检测F1分数0.834；87%提取片段旨在搞笑；98%场景准确定位；成功推广至预告片领域。

Conclusion: 该系统可优化内容创作流程，提升用户参与度，并为多样化电影媒体格式高效生成短视频内容，具有显著的实际应用价值。

Abstract: Automatically extracting engaging and high-quality humorous scenes from cinematic titles is pivotal for creating captivating video previews and snackable content, boosting user engagement on streaming platforms. Long-form cinematic titles, with their extended duration and complex narratives, challenge scene localization, while humor's reliance on diverse modalities and its nuanced style add further complexity. This paper introduces an end-to-end system for automatically identifying and ranking humorous scenes from long-form cinematic titles, featuring shot detection, multimodal scene localization, and humor tagging optimized for cinematic content. Key innovations include a novel scene segmentation approach combining visual and textual cues, improved shot representations via guided triplet mining, and a multimodal humor tagging framework leveraging both audio and text. Our system achieves an 18.3% AP improvement over state-of-the-art scene detection on the OVSD dataset and an F1 score of 0.834 for detecting humor in long text. Extensive evaluations across five cinematic titles demonstrate 87% of clips extracted by our pipeline are intended to be funny, while 98% of scenes are accurately localized. With successful generalization to trailers, these results showcase the pipeline's potential to enhance content creation workflows, improve user engagement, and streamline snackable content generation for diverse cinematic media formats.

</details>


### [33] [GaiaFlow: Semantic-Guided Diffusion Tuning for Carbon-Frugal Search](https://arxiv.org/abs/2602.15423)
*Rong Fu,Wenxin Zhang,Jia Yee Tan,Chunlei Meng,Shuo Yin,Xiaowen Ma,Wangyu Wu,Muge Qi,Guangzhen Yao,Zhaolu Kang,Zeli Su,Simon Fong*

Main category: cs.IR

TL;DR: 本文提出GaiaFlow框架，通过语义引导的扩散调优技术，在保持检索质量的同时显著降低神经搜索系统的运行碳足迹，实现了效果与能效的平衡。


<details>
  <summary>Details</summary>
Motivation: 随着神经架构功耗需求激增，信息检索领域亟需从模型设计层面实现生态可持续性转向。现有神经排序器虽精度卓越，但其计算强度带来的环境外部性在大规模部署中常被忽视。

Method: 该框架结合检索引导的朗之万动力学与硬件无关的性能建模策略，通过自适应早期退出协议和精度感知量化推理，优化搜索精度与环境保护的权衡。

Result: 大量实验评估表明，GaiaFlow在异构计算基础设施上实现了效果与能源效率的卓越平衡，显著降低了运行碳足迹。

Conclusion: GaiaFlow为下一代神经搜索系统提供了可扩展且可持续的发展路径，在保持鲁棒检索质量的同时有效缓解了环境压力。

Abstract: As the burgeoning power requirements of sophisticated neural architectures escalate, the information retrieval community has recognized ecological sustainability as a pivotal priority that necessitates a fundamental paradigm shift in model design. While contemporary neural rankers have attained unprecedented accuracy, the substantial environmental externalities associated with their computational intensity often remain overlooked in large-scale deployments. We present GaiaFlow, an innovative framework engineered to facilitate carbon-frugal search by operationalizing semantic-guided diffusion tuning. Our methodology orchestrates the convergence of retrieval-guided Langevin dynamics and a hardware-independent performance modeling strategy to optimize the trade-off between search precision and environmental preservation. By incorporating adaptive early exit protocols and precision-aware quantized inference, the proposed architecture significantly mitigates operational carbon footprints while maintaining robust retrieval quality across heterogeneous computing infrastructures. Extensive experimental evaluations demonstrate that GaiaFlow achieves a superior equilibrium between effectiveness and energy efficiency, offering a scalable and sustainable pathway for next-generation neural search systems.

</details>


### [34] [Binge Watch: Reproducible Multimodal Benchmarks Datasets for Large-Scale Movie Recommendation on MovieLens-10M and 20M](https://arxiv.org/abs/2602.15505)
*Giuseppe Spillo,Alessandro Petruzzelli,Cataldo Musto,Marco de Gemmis,Pasquale Lops,Giovanni Semeraro*

Main category: cs.IR

TL;DR: 本文针对多模态推荐系统研究中的数据瓶颈，通过文档化流水线将MovieLens-10M/20M与电影图文视频数据进行丰富整合，利用先进编码器提取多模态特征，开源了M3L-10M和M3L-20M两个大规模可复现数据集，为领域发展提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统研究日益受到关注，其依赖高质量的多媒体侧信息数据集。但现有文献多使用小规模、未公开或构建过程不透明的中小型数据集，严重制约了研究的可复现性。为填补这一空白，本研究致力于构建大规模、可复现的多模态电影数据集。

Method: 采用完全文档化的处理流程，将电影情节、海报和预告片等多模态数据与MovieLens-10M和MovieLens-20M数据集进行丰富整合。使用多种先进编码器分别提取文本、视觉、声学和视频特征，并公开发布原始数据、提取特征及完整数据集的下载映射，支持多种格式。同时开展定性和定量分析以多维度展示数据集特性。

Result: 成功构建并开源了M3L-10M和M3L-20M两个大规模可复现多模态电影数据集，数据集可通过Zenodo平台（https://zenodo.org/records/18499145）完整获取，源代码发布于GitHub（https://github.com/giuspillo/M3L_10M_20M），并通过多维度分析验证了数据集质量。

Conclusion: 该工作为大规模多模态电影推荐领域的可复现性和可重现性奠定了重要基础，通过提供标准化数据和完整流程，有效推动了多模态推荐系统的研究进展。

Abstract: With the growing interest in Multimodal Recommender Systems (MRSs), collecting high-quality datasets provided with multimedia side information (text, images, audio, video) has become a fundamental step. However, most of the current literature in the field relies on small- or medium-scale datasets that are either not publicly released or built using undocumented processes.
  In this paper, we aim to fill this gap by releasing M3L-10M and M3L-20M, two large-scale, reproducible, multimodal datasets for the movie domain, obtained by enriching with multimodal features the popular MovieLens-10M and MovieLens-20M, respectively. By following a fully documented pipeline, we collect movie plots, posters, and trailers, from which textual, visual, acoustic, and video features are extracted using several state-of-the-art encoders. We publicly release mappings to download the original raw data, the extracted features, and the complete datasets in multiple formats, fostering reproducibility and advancing the field of MRSs. In addition, we conduct qualitative and quantitative analyses that showcase our datasets across several perspectives.
  This work represents a foundational step to ensure reproducibility and replicability in the large-scale, multimodal movie recommendation domain. Our resource can be fully accessed at the following link: https://zenodo.org/records/18499145, while the source code is accessible at https://github.com/giuspillo/M3L_10M_20M.

</details>


### [35] [Eco-Amazon: Enriching E-commerce Datasets with Product Carbon Footprint for Sustainable Recommendations](https://arxiv.org/abs/2602.15508)
*Giuseppe Spillo,Allegra De Filippo,Cataldo Musto,Michela Milano,Giovanni Semeraro*

Main category: cs.IR

TL;DR: 针对可持续AI研究缺乏物品级环境影响数据的问题，本文提出Eco-Amazon资源，通过大语言模型零样本框架为三个亚马逊数据集生成产品碳足迹元数据，以支持开发环境可持续的信息检索与推荐系统。


<details>
  <summary>Details</summary>
Motivation: 负责任AI时代要求信息检索与推荐系统超越准确率指标，纳入环境可持续性。然而，标准基准缺乏物品级环境影响数据，严重制约了该研究方向。本文旨在填补这一空白。

Method: 选取家居、服装、电子产品三个亚马逊数据集，利用大语言模型零样本框架，基于产品属性自动生成物品级产品碳足迹（PCF）及CO2e排放分数。

Result: 提出三大贡献：(i) 发布Eco-Amazon数据集，富集PCF信号；(ii) 开源LLM-based PCF估计脚本，支持任意产品目录扩展与结果复现；(iii) 通过应用案例展示PCF数据如何促进可持续产品推荐。数据集与代码均已公开。

Conclusion: Eco-Amazon通过提供标准化环境信号，赋能社区开发、评测下一代可持续检索与推荐模型，推动信息检索与推荐系统领域向环境可持续方向发展。

Abstract: In the era of responsible and sustainable AI, information retrieval and recommender systems must expand their scope beyond traditional accuracy metrics to incorporate environmental sustainability. However, this research line is severely limited by the lack of item-level environmental impact data in standard benchmarks. This paper introduces Eco-Amazon, a novel resource designed to bridge this gap. Our resource consists of an enriched version of three widely used Amazon datasets (i.e., Home, Clothing, and Electronics) augmented with Product Carbon Footprint (PCF) metadata. CO2e emission scores were generated using a zero-shot framework that leverages Large Language Models (LLMs) to estimate item-level PCF based on product attributes. Our contribution is three-fold: (i) the release of the Eco-Amazon datasets, enriching item metadata with PCF signals; (ii) the LLM-based PCF estimation script, which allows researchers to enrich any product catalogue and reproduce our results; (iii) a use case demonstrating how PCF estimates can be exploited to promote more sustainable products. By providing these environmental signals, Eco-Amazon enables the community to develop, benchmark, and evaluate the next generation of sustainable retrieval and recommendation models. Our resource is available at https://doi.org/10.5281/zenodo.18549130, while our source code is available at: http://github.com/giuspillo/EcoAmazon/.

</details>


### [36] [Can Recommender Systems Teach Themselves? A Recursive Self-Improving Framework with Fidelity Control](https://arxiv.org/abs/2602.15659)
*Luankang Zhang,Hao Wang,Zhongzhou Liu,Mingjia Yin,Yonghao Huang,Jiaqi Li,Wei Guo,Yong Liu,Huifeng Guo,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 针对推荐系统数据稀疏瓶颈，提出RSIR递归自改进框架，通过模型自生成序列+保真度筛选实现闭环优化，理论证明其为隐式正则化器，实证在多基准/架构上取得持续增益，小模型亦可受益并辅助大模型。


<details>
  <summary>Details</summary>
Motivation: 高质量训练数据稀缺是机器学习规模化的根本瓶颈，推荐系统中用户交互极度稀疏导致优化景观崎岖、泛化性能差，亟需不依赖外部数据或教师模型的自主解决方案。

Method: RSIR构建闭环自举机制：当前模型生成合理用户交互序列→基于保真度的质量控制模块按偏好流形一致性筛选→富集数据集训练继任模型，递归迭代实现性能自提升。

Result: 跨多个基准与架构实现一致且累积的性能提升；小规模模型同样获益；弱模型可为强模型生成有效的训练课程。

Conclusion: 递归自改进是克服数据稀疏的通用模型无关范式，为推荐系统及更广泛领域提供可扩展的前进路径。

Abstract: The scarcity of high-quality training data presents a fundamental bottleneck to scaling machine learning models. This challenge is particularly acute in recommendation systems, where extreme sparsity in user interactions leads to rugged optimization landscapes and poor generalization. We propose the Recursive Self-Improving Recommendation (RSIR) framework, a paradigm in which a model bootstraps its own performance without reliance on external data or teacher models. RSIR operates in a closed loop: the current model generates plausible user interaction sequences, a fidelity-based quality control mechanism filters them for consistency with user's approximate preference manifold, and a successor model is augmented on the enriched dataset. Our theoretical analysis shows that RSIR acts as a data-driven implicit regularizer, smoothing the optimization landscape and guiding models toward more robust solutions. Empirically, RSIR yields consistent, cumulative gains across multiple benchmarks and architectures. Notably, even smaller models benefit, and weak models can generate effective training curricula for stronger ones. These results demonstrate that recursive self-improvement is a general, model-agnostic approach to overcoming data sparsity, suggesting a scalable path forward for recommender systems and beyond. Our anonymized code is available at https://anonymous.4open.science/r/RSIR-7C5B .

</details>


### [37] [The Next Paradigm Is User-Centric Agent, Not Platform-Centric Service](https://arxiv.org/abs/2602.15682)
*Luankang Zhang,Hang Lv,Qiushi Pan,Kefen Wang,Yonghao Huang,Xinrui Miao,Yin Xu,Wei Guo,Yong Liu,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 本文批判当前平台中心化的数字服务模式（以用户参与度和转化率为导向）与用户真实需求脱节，导致利益冲突。主张转向用户中心化智能体，优先保障隐私、对齐用户目标并赋予用户控制权。借助大语言模型和端侧智能的进步，提出设备-云协同架构及相应治理体系，探讨实现路径与挑战。


<details>
  <summary>Details</summary>
Motivation: 现有平台中心化的服务模式以平台指标（如参与度、转化率）为核心优化目标，忽视用户真实需求，导致服务商利益与用户福祉之间的根本性冲突。尽管大语言模型等技术在平台侧取得显著进展，但服务质量的提升并未转化为真实的用户价值。因此，亟需范式转变。

Method: 通过分析平台中心化模式的局限性，论证用户中心化智能的可行性；提出一个实用的设备-云协同技术架构作为实现路径；并探讨支撑该模式所需的治理机制和生态系统结构。

Result: 提出了从平台中心化向用户中心化智能转型的完整方案，包括：(1) 用户中心化智能体的核心原则（隐私优先、目标对齐、用户控制）；(2) 设备-云协同的技术实现管道；(3) 相应的治理框架和生态系统设计。

Conclusion: 在LLM和端侧智能技术支持下，构建用户中心化数字服务不仅是可行的，更是未来发展方向。这需要技术架构革新（设备-云管道）和制度创新（治理与生态系统）的双重突破，最终实现从平台利益导向到用户价值导向的根本转变。

Abstract: Modern digital services have evolved into indispensable tools, driving the present large-scale information systems. Yet, the prevailing platform-centric model, where services are optimized for platform-driven metrics such as engagement and conversion, often fails to align with users' true needs. While platform technologies have advanced significantly-especially with the integration of large language models (LLMs)-we argue that improvements in platform service quality do not necessarily translate to genuine user benefit. Instead, platform-centric services prioritize provider objectives over user welfare, resulting in conflicts against user interests. This paper argues that the future of digital services should shift from a platform-centric to a user-centric agent. These user-centric agents prioritize privacy, align with user-defined goals, and grant users control over their preferences and actions. With advancements in LLMs and on-device intelligence, the realization of this vision is now feasible. This paper explores the opportunities and challenges in transitioning to user-centric intelligence, presents a practical device-cloud pipeline for its implementation, and discusses the necessary governance and ecosystem structures for its adoption.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [38] [Near-Optimal Sample Complexity for Online Constrained MDPs](https://arxiv.org/abs/2602.15076)
*Chang Liu,Yunfan Li,Lin F. Yang*

Main category: cs.LG

TL;DR: 本文针对强化学习安全问题，提出基于模型的原始-对偶算法，解决约束马尔可夫决策过程（CMDP）在宽松可行性（允许ε违反）和严格可行性（零违反）下的高效学习问题。在两种设定下均达到ε-最优策略，样本复杂度与对应下界匹配。


<details>
  <summary>Details</summary>
Motivation: 强化学习在实际应用中面临安全挑战，CMDP虽可建模安全约束，但现有方法存在显著安全违反或高样本复杂度缺陷。亟需在允许小违反和严格零违反两种场景下，实现高效安全的策略学习。

Method: 设计基于模型的原始-对偶算法，融合在线强化学习与约束优化技术，平衡累计遗憾与约束违反程度，分别在宽松和严格可行性设定下进行策略优化。

Result: - 宽松可行性：算法以任意高概率获得ε-最优策略且约束违反不超过ε，样本复杂度为Õ(SAH³/ε²)，与无约束MDP下界一致；
- 严格可行性：算法以任意高概率获得零违反的ε-最优策略，样本复杂度为Õ(SAH⁵/ε²ζ²)，其中ζ为Slater常数，与带生成模型的CMDP学习下界匹配。

Conclusion: 理论证明在线学习CMDP的难度等同于使用生成模型学习，且在允许小违反时其复杂度与无约束MDP相当，为安全敏感应用提供了高效学习算法和理论保障。

Abstract: Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce safety constraints while optimizing performance. However, existing methods often suffer from significant safety violations or require a high sample complexity to generate near-optimal policies. We address two settings: relaxed feasibility, where small violations are allowed, and strict feasibility, where no violation is allowed. We propose a model-based primal-dual algorithm that balances regret and bounded constraint violations, drawing on techniques from online RL and constrained optimization. For relaxed feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with $\varepsilon$-bounded violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^3}{\varepsilon^2}\right)$ learning episodes, matching the lower bound for unconstrained MDPs. For strict feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with zero violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^5}{\varepsilon^2ζ^2}\right)$ learning episodes, where $ζ$ is the problem-dependent Slater constant characterizing the size of the feasible region. This result matches the lower bound for learning CMDPs with access to a generative model.
  Our results demonstrate that learning CMDPs in an online setting is as easy as learning with a generative model and is no more challenging than learning unconstrained MDPs when small violations are allowed.

</details>


### [39] [Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction](https://arxiv.org/abs/2602.15089)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 针对设备预测性维护中纯深度学习方法在实际数据上准确率不足的问题，本研究提出一种混合方法：将LoRA微调的Granite TinyTimeMixer提取的64维时间序列嵌入与28维领域统计特征（趋势、波动性、回撤等）结合，通过LightGBM分类器实现HVAC设备异常预测。在64台设备、51,564个样本的实验中，该方法在30/60/90天预测窗口下达到91-95%精确率、0.995 ROC-AUC，误报率≤1.1%，检测率88-94%，验证了深度学习表示学习与统计特征工程的互补优势。


<details>
  <summary>Details</summary>
Motivation: 设备预测性维护中，基于深度学习的时间序列异常检测虽受关注，但纯深度学习方法在实际数据上常难以达到足够精度，需融合领域知识提升性能。

Method: 方法包括：1)采用LoRA微调策略训练Granite TinyTimeMixer编码器，提取64维时间序列嵌入；2)基于领域知识构建28维统计特征（趋势、波动性、回撤指标）；3)将两类特征融合后输入LightGBM梯度提升分类器进行异常预测。

Result: 实验基于64台HVAC设备、51,564个样本：在30天、60天和90天预测窗口下，精确率达91-95%，ROC-AUC为0.995；生产环境下误报率≤1.1%，异常检测率88-94%。

Conclusion: 研究表明，融合深度学习的表示学习能力与统计特征工程可构建实用的预测性维护异常检测系统，二者优势互补，为工业应用提供了有效解决方案。

Abstract: In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a hybrid approach that integrates 64-dimensional time series embeddings from Granite TinyTimeMixer with 28-dimensional statistical features based on domain knowledge for HVAC equipment anomaly prediction tasks. Specifically, we combine time series embeddings extracted from a Granite TinyTimeMixer encoder fine-tuned with LoRA (Low-Rank Adaptation) and 28 types of statistical features including trend, volatility, and drawdown indicators, which are then learned using a LightGBM gradient boosting classifier. In experiments using 64 equipment units and 51,564 samples, we achieved Precision of 91--95\% and ROC-AUC of 0.995 for anomaly prediction at 30-day, 60-day, and 90-day horizons. Furthermore, we achieved production-ready performance with a false positive rate of 1.1\% or less and a detection rate of 88--94\%, demonstrating the effectiveness of the system for predictive maintenance applications. This work demonstrates that practical anomaly detection systems can be realized by leveraging the complementary strengths between deep learning's representation learning capabilities and statistical feature engineering.

</details>


### [40] [PolyNODE: Variable-dimension Neural ODEs on M-polyfolds](https://arxiv.org/abs/2602.15128)
*Per Åhag,Alexander Friedrich,Fredrik Ohlsson,Viktor Vigren Näslund*

Main category: cs.LG

TL;DR: 本文提出PolyNODE，首个基于M-polyfold的可变维度流基模型，通过构造具有维度瓶颈的M-polyfold空间并设计参数化向量场，实现了可变维度下的自动编码器架构，在重建和下游分类任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有神经ODE模型因流形内在维度限制，只能描述固定维度动力学，无法适应需要可变维度建模的应用场景，亟需扩展至可变维度空间。

Method: 将神经ODE理论扩展至M-polyfold（能够同时容纳不同维度并保持可微性的数学空间），提出PolyNODE框架，具体构造具有维度瓶颈的显式M-polyfold，并设计参数化向量场实现跨维度流。

Result: 实验结果表明，所提PolyNODE模型能够成功训练以解决M-polyfold空间中的重建任务，同时可提取潜在表示用于下游分类任务，验证了可变维度建模的可行性。

Conclusion: PolyNODE开创了几何深度学习中可变维度流建模的先河，为处理维度变化问题提供了新范式，相关代码已开源促进后续研究。

Abstract: Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at https://github.com/turbotage/PolyNODE .

</details>


### [41] [Learning Representations from Incomplete EHR Data with Dual-Masked Autoencoding](https://arxiv.org/abs/2602.15159)
*Xiao Xiang,David Restrepo,Hyewon Jeong,Yugang Jia,Leo Anthony Celi*

Main category: cs.LG

TL;DR: 提出AID-MAE模型，通过双重掩码策略（固有缺失掩码和增强掩码）直接从不完整的EHR时间序列中学习表示，在多个临床任务上优于XGBoost和DuETT等基线方法，并能自然地实现患者分层。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录(EHR)时间序列学习面临不规则采样、异构缺失和观测稀疏性等挑战。现有自监督方法要么在学习前进行插补，要么通过专用输入信号表示缺失，或仅优化插补任务，这限制了其学习支持临床下游任务表示的能力。

Method: 提出增强-内在双掩码自编码器(AID-MAE)，通过内在缺失掩码表示自然缺失值，同时使用增强掩码在训练期间隐藏部分观测值用于重建。模型仅处理未掩码的token子集，直接从不完整时间序列中学习表示。

Result: 在两个数据集的多项临床任务上，AID-MAE持续优于XGBoost和DuETT等强基线。学习到的嵌入在表示空间中自然地实现了患者队列分层。

Conclusion: AID-MAE通过双重掩码策略有效解决了EHR时间序列的缺失问题，能够直接从原始不完整数据中学习高质量表示，支持临床下游任务和患者分层，优于现有方法。

Abstract: Learning from electronic health records (EHRs) time series is challenging due to irregular sam- pling, heterogeneous missingness, and the resulting sparsity of observations. Prior self-supervised meth- ods either impute before learning, represent missingness through a dedicated input signal, or optimize solely for imputation, reducing their capacity to efficiently learn representations that support clinical downstream tasks. We propose the Augmented-Intrinsic Dual-Masked Autoencoder (AID-MAE), which learns directly from incomplete time series by applying an intrinsic missing mask to represent naturally missing values and an augmented mask that hides a subset of observed values for reconstruction during training. AID-MAE processes only the unmasked subset of tokens and consistently outperforms strong baselines, including XGBoost and DuETT, across multiple clinical tasks on two datasets. In addition, the learned embeddings naturally stratify patient cohorts in the representation space.

</details>


### [42] [Seeing to Generalize: How Visual Data Corrects Binding Shortcuts](https://arxiv.org/abs/2602.15183)
*Nicolas Buzeta,Felipe del Rio,Cristian Hinostroza,Denis Parra,Hans Lobel,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: 视觉语言模型在纯文本任务上超越其底层的大语言模型，尤其在长上下文信息检索中表现突出。通过构建可控的合成检索任务，研究发现仅进行文本训练会导致模型依赖位置捷径，而在相同任务上进行图像标记化训练则通过空间平移不变性打破这些捷径，迫使模型采用更鲁棒的符号绑定机制，使文本任务的分布外性能几乎翻倍，且该机制在重新引入纯文本示例后仍保持。跨模态训练能够提升模型在单模态任务上的推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型旨在为大语言模型增加视觉能力，但研究发现它们在纯文本任务上表现优于底层的大语言模型，这一现象在长上下文信息检索中尤为明显。为探究其背后的原因，作者构建了可控的合成检索任务，以比较纯文本训练与图像标记化训练对模型泛化能力的影响。

Method: 作者构建了一个可控的合成检索任务。首先，训练一个仅处理文本的变换器模型，观察其在分布内和分布外的表现；随后，在相同任务上对模型进行图像标记化训练，即将文本转换为图像标记，比较两种训练方式对模型性能的影响。通过机制可解释性分析，研究模型内部绑定策略的变化，并考察不同训练方式、视觉编码器、初始化对绑定策略的影响，以及在预训练大语言模型到视觉语言模型转换过程中的类似变化。

Result: 实验表明，仅进行文本训练的模型在分布内达到完美准确率，但在分布外表现极差；而经过图像标记化训练后，模型的纯文本分布外性能几乎翻倍。机制分析揭示，文本训练促使模型使用位置捷径进行信息绑定，而图像训练通过空间平移不变性打破这些捷径，迫使模型学习更鲁棒的符号绑定机制，且该机制在重新引入纯文本示例后仍然保持。此外，不同训练方式、视觉编码器和初始化均会导致绑定策略的变化，预训练大语言模型到视觉语言模型的转换也出现类似转变。

Conclusion: 跨模态训练能够提升模型在单模态任务上的推理和泛化能力，即使任务本身不涉及视觉信息。研究结果表明，视觉训练通过改变模型内部表示和学习策略，使得模型更倾向于使用符号化的绑定方式，从而提高了对未见数据的泛化性能。这为理解和改进多模态模型的设计提供了新视角。

Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.

</details>


### [43] [Learning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge](https://arxiv.org/abs/2602.15184)
*Siying Ma,Mehrdad M. Zadeh,Mauricio Soroco,Wuyang Chen,Jiguo Cao,Vijay Ganesh*

Main category: cs.LG

TL;DR: 针对现有神经算子忽略偏微分方程基本物理原理的问题，本文提出一种多物理场训练框架，通过联合学习原始方程与简化形式，显式融入基础物理知识，在提升数据效率的同时，显著改善分布外泛化性能，并在多种维度PDE基准测试中实现一致的nRMSE降低。


<details>
  <summary>Details</summary>
Motivation: 当前神经算子虽能建模PDE动态演化，但主要聚焦于目标方程的模拟而忽视其底层物理规律。受数值求解器可适配不同PDE设置的启发，作者认为显式整合基础物理知识将有效增强模型在物理参数漂移和合成至真实迁移等OOD场景下的泛化能力。

Method: 提出一种多物理场联合训练框架，同步学习原始偏微分方程及其简化基础形式。该框架具有架构无关性，可兼容各类神经算子结构，通过共享表示学习同时优化两种物理约束，从而捕获更本质的物理规律。

Result: 在1D/2D/3D多种PDE问题上，该方法持续降低归一化均方根误差（nRMSE），并显著提升数据效率。尤其在物理参数偏移和合成-真实迁移的OOD场景下，泛化性能显著优于基线方法，验证了显式物理知识注入的有效性。

Conclusion: 显式融入基础物理知识可显著强化神经算子的泛化能力，为科学机器学习提供了一种通用且有效的训练范式。该方法有望拓展至更复杂的物理系统建模，并促进跨领域知识迁移。

Abstract: Recent advances in scientific machine learning (SciML) have enabled neural operators (NOs) to serve as powerful surrogates for modeling the dynamic evolution of physical systems governed by partial differential equations (PDEs). While existing approaches focus primarily on learning simulations from the target PDE, they often overlook more fundamental physical principles underlying these equations. Inspired by how numerical solvers are compatible with simulations of different settings of PDEs, we propose a multiphysics training framework that jointly learns from both the original PDEs and their simplified basic forms. Our framework enhances data efficiency, reduces predictive errors, and improves out-of-distribution (OOD) generalization, particularly in scenarios involving shifts of physical parameters and synthetic-to-real transfer. Our method is architecture-agnostic and demonstrates consistent improvements in normalized root mean square error (nRMSE) across a wide range of 1D/2D/3D PDE problems. Through extensive experiments, we show that explicit incorporation of fundamental physics knowledge significantly strengthens the generalization ability of neural operators. We will release models and codes at https://sites.google.com/view/sciml-fundemental-pde.

</details>


### [44] [COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression](https://arxiv.org/abs/2602.15200)
*Denis Makhov,Dmitriy Shopkhoev,Magauiya Zhussip,Ammar Ali,Baher Mohammad,Stamatios Lefkimmiatis*

Main category: cs.LG

TL;DR: 提出COMPOT框架，通过校准数据集实现Transformer模型的无训练压缩，利用正交字典和Procrustes解析解避免迭代优化，并动态分配层间压缩率，在质量和压缩率上优于现有方法且兼容量化。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer后训练压缩方法（如截断SVD）因强制单一共享子空间导致精度损失，而稀疏字典学习方法存在迭代更新字典和系数的高计算开销问题，亟需高效且高精度的压缩方案。

Method: COMPOT采用小校准数据集估计稀疏权重分解：1) 使用正交字典实现闭式Procrustes字典更新；2) 通过解析单步稀疏编码获取系数，消除迭代优化；3) 引入一次性动态分配策略，根据全局压缩预算自适应调整各层压缩率。

Result: 跨架构和任务的实验表明，COMPOT在质量-压缩权衡上显著优于低秩和稀疏基线方法，同时完全兼容后训练量化以实现极端压缩。

Conclusion: COMPOT作为无训练压缩框架，通过正交字典和动态分配策略实现了高精度高效率的模型压缩，为资源受限场景下的Transformer部署提供了有效解决方案。

Abstract: Post-training compression of Transformer models commonly relies on truncated singular value decomposition (SVD). However, enforcing a single shared subspace can degrade accuracy even at moderate compression. Sparse dictionary learning provides a more flexible union-of-subspaces representation, but existing approaches often suffer from iterative dictionary and coefficient updates. We propose COMPOT (Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers), a training-free compression framework that uses a small calibration dataset to estimate a sparse weight factorization. COMPOT employs orthogonal dictionaries that enable closed-form Procrustes updates for the dictionary and analytical single-step sparse coding for the coefficients, eliminating iterative optimization. To handle heterogeneous layer sensitivity under a global compression budget, COMPOT further introduces a one-shot dynamic allocation strategy that adaptively redistributes layer-wise compression rates. Extensive experiments across diverse architectures and tasks show that COMPOT consistently delivers a superior quality-compression trade-off over strong low-rank and sparse baselines, while remaining fully compatible with post-training quantization for extreme compression. Code is available $\href{https://github.com/mts-ai/COMPOT}{here}$.

</details>


### [45] [MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference](https://arxiv.org/abs/2602.15206)
*Raphaël Baur,Yannick Metz,Maria Gkoulta,Mennatallah El-Assady,Giorgia Ramponi,Thomas Kleine Buening*

Main category: cs.LG

TL;DR: 这篇论文提出了一种贝叶斯推断框架，用于从多种异构反馈类型（演示、比较、评分、停止）中联合学习奖励函数，采用变分推断方法避免手动加权损失项，在离散和连续控制任务中表现出更好的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励学习方法通常依赖单一反馈类型或需要手动调整权重的多反馈组合，但如何有效整合不同质的反馈信号（如演示、比较、评分、停止）仍不明确。不同反馈类型提供互补信息，手动加权难以最优平衡，且现有方法常将反馈简化为统一表示导致信息损失。

Method: 将多反馈奖励学习建模为共享潜在奖励函数的贝叶斯推断问题，每种反馈类型通过显式似然函数贡献信息。提出可扩展的摊销变分推断方法，学习共享奖励编码器和特定反馈的似然解码器，通过优化单一证据下界（ELBO）进行训练。

Result: 在离散和连续控制基准测试中，联合推断的奖励后验优于单一反馈基线，能利用反馈间的互补信息，产生对环境扰动更鲁棒的策略。推断的奖励不确定性提供了可解释的信号，用于分析模型在不同反馈类型下的置信度和一致性。

Conclusion: 该方法成功解决了多反馈奖励学习问题，无需手动平衡损失项或简化反馈表示，通过贝叶斯框架自然融合异构反馈，提升学习效果并提供不确定性量化，为可解释强化学习提供了新思路。

Abstract: Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.

</details>


### [46] [tensorFM: Low-Rank Approximations of Cross-Order Feature Interactions](https://arxiv.org/abs/2602.15229)
*Alessio Mazzetto,Mohammad Mahdi Khalili,Laura Fee Nern,Michael Viderman,Alex Shtoff,Krzysztof Dembczyński*

Main category: cs.LG

TL;DR: 针对表格分类数据预测问题，本文提出tensorFM模型，通过低秩张量近似高效捕获高阶域间交互，在保持性能竞争力的同时具备低延迟特性，适用于在线广告等时间敏感场景。


<details>
  <summary>Details</summary>
Motivation: 表格分类数据预测在点击率预估和社会科学等领域广泛应用，现有域加权分解机等方法难以高效建模高阶交互，需开发能同时兼顾表达能力和计算效率的新模型。

Method: 提出tensorFM模型，采用低秩张量分解技术近似表示交互强度，推广了域加权分解机，实现高阶属性间交互的参数高效建模。

Result: 实验表明tensorFM性能与最先进方法相当，且延迟更低，在在线广告等实时系统中具备实用性优势。

Conclusion: tensorFM通过张量低秩近似有效平衡了高阶交互建模能力与计算效率，为表格数据预测提供了适用于时间敏感场景的解决方案。

Abstract: We address prediction problems on tabular categorical data, where each instance is defined by multiple categorical attributes, each taking values from a finite set. These attributes are often referred to as fields, and their categorical values as features. Such problems frequently arise in practical applications, including click-through rate prediction and social sciences. We introduce and analyze {tensorFM}, a new model that efficiently captures high-order interactions between attributes via a low-rank tensor approximation representing the strength of these interactions. Our model generalizes field-weighted factorization machines. Empirically, tensorFM demonstrates competitive performance with state-of-the-art methods. Additionally, its low latency makes it well-suited for time-sensitive applications, such as online advertising.

</details>


### [47] [ÜberWeb: Insights from Multilingual Curation for a 20-Trillion-Token Dataset](https://arxiv.org/abs/2602.15210)
*DatologyAI,:,Aldo Gael Carranza,Kaleigh Mentzer,Ricardo Pio Monti,Alex Fang,Alvin Deng,Amro Abbas,Anshuman Suri,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Diego Kiner,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 该研究揭示多语言模型性能下降主因并非容量限制，而是数据质量与组成缺陷。通过对13种语言精细筛选，发现仅占总token不足8%的精选多语言数据即可显著提升性能。基于此构建的20万亿token公开语料库，使30亿与80亿参数模型在1万亿token训练量下，以4-10倍更少计算量达到强基线水平，并在Trinity Large等前沿模型上验证了此方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现代基础模型需具备多语言能力，但面临跨语言数据分布不均与联合训练导致的性能干扰（"多语言诅咒"）两大核心挑战。现有研究多将此归因于模型容量限制，但本文旨在探究这些性能下降是否真正不可避免，抑或源于可修复的数据质量问题，从而寻求更高效的多语言扩展路径。

Method: 1. 在13种语言上进行系统性多语言数据筛选实验；2. 开展受控双语研究，分别优化英语与非英语数据并评估其交叉影响；3. 实施定制化 per-language 数据筛选策略；4. 构建完全源自公开资源的20万亿token预训练语料库；5. 在1万亿token子集上训练3B/8B模型并与公开基线对比；6. 将语料库扩展至Trinity Large (4000亿/A130亿参数) 等前沿模型验证泛化性。

Result: 1. 多数性能下降源于可纠正的数据质量与组成问题，而非多语言扩展的固有限制；2. 单语言数据优化具有跨语言溢出效应：英语筛选使13种语言中的12种非英语性能提升，非英语筛选亦反向提升英语性能；3. 定制化 per-language 筛选在语言内部产生显著更大改进；4. 精选多语言数据占比不足8%时仍保持高效；5. 3B/8B模型在1万亿token训练下，以4-10倍更少FLOPs达到竞争性多语言准确率，建立新帕累托前沿；6. 20万亿token语料库作为Trinity Large预训练数据的一部分，该模型相对于训练FLOPs展现出强大的多语言性能。

Conclusion: 针对性的 per-language 数据筛选能有效缓解多语言干扰，实现计算高效的多语言扩展。此方法在中小规模与前沿大规模模型上均得到验证，为构建高质量多语言模型提供了可操作的工程范式，重新定义了多语言性能与计算成本的优化边界。

Abstract: Multilinguality is a core capability for modern foundation models, yet training high-quality multilingual models remains challenging due to uneven data availability across languages. A further challenge is the performance interference that can arise from joint multilingual training, commonly referred to as the "curse of multilinguality". We study multilingual data curation across thirteen languages and find that many reported regressions are not inherent to multilingual scaling but instead stem from correctable deficiencies in data quality and composition rather than fundamental capacity limits. In controlled bilingual experiments, improving data quality for any single language benefits others: curating English improves non-English performance in 12 of 13 languages, while curating non-English yields reciprocal improvements in English. Bespoke per-language curation produces substantially larger within-language improvements. Extending these findings to large-scale general-purpose training mixtures, we show that curated multilingual allocations comprising under 8% of total tokens remain remarkably effective. We operationalize this approach within an effort that produced a 20T-token pretraining corpus derived entirely from public sources. Models with 3B and 8B parameters trained on a 1T-token random subset achieve competitive multilingual accuracy with 4-10x fewer training FLOPs than strong public baselines, establishing a new Pareto frontier in multilingual performance versus compute. Moreover, these benefits extend to frontier model scale: the 20T-token corpus served as part of the pretraining dataset for Trinity Large (400B/A13B), which exhibits strong multilingual performance relative to its training FLOPs. These results show that targeted, per-language data curation mitigates multilingual interference and enables compute-efficient multilingual scaling.

</details>


### [48] [Automatically Finding Reward Model Biases](https://arxiv.org/abs/2602.15222)
*Atticus Wang,Iván Arcuschin,Arthur Conmy*

Main category: cs.LG

TL;DR: 本文开发了一种自动化探测奖励模型偏见的框架，利用大语言模型迭代生成和精炼候选偏见描述，成功识别出Skywork-V2-8B等先进奖励模型中存在的冗余空格偏好和幻觉内容偏好等新偏见，证实进化迭代策略优于传统best-of-N搜索，并通过合成偏见验证了方法的有效性，为奖励模型可解释性改进提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 奖励模型是大型语言模型后训练的核心组件，但研究表明其会奖励文本长度、格式、幻觉、奉承等虚假或不理想属性，严重影响模型对齐效果。传统手动分析方法效率低下，亟需自动化方法系统性识别奖励模型偏见，以提升LLM后训练的安全性和可靠性。

Method: 提出LLM驱动的迭代式偏见发现框架，核心是让大语言模型自动生成并迭代优化候选偏见描述。通过让LLM分析模型响应模式生成初始偏见假设，再基于统计反馈循环精炼假设，形成可解释的偏见表述。采用进化迭代策略替代传统best-of-N搜索，实现更高效的偏见空间探索。

Result: 实验成功复现了已知奖励模型偏见，并发现多个新偏见：Skywork-V2-8B（领先的开源奖励模型）会显著偏好带有冗余空格的回复以及包含幻觉内容的回复。在合成数据中注入偏见并验证，显示该方法具有较高的召回率。对比实验证实进化迭代策略显著优于扁平化best-of-N搜索。

Conclusion: 本研究通过自动化可解释性方法系统性揭示奖励模型偏见，为改进奖励模型质量提供了新工具。发现的意外偏见（如格式偏好和幻觉偏好）对开发更安全可靠的LLM后训练技术具有重要启示，将推动可解释性AI在奖励模型领域的应用，促进更公平、透明的模型对齐研究。

Abstract: Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.

</details>


### [49] [BindCLIP: A Unified Contrastive-Generative Representation Learning Framework for Virtual Screening](https://arxiv.org/abs/2602.15236)
*Anjie Qiao,Zhen Wang,Yaliang Li,Jiahua Rao,Yuedong Yang*

Main category: cs.LG

TL;DR: BindCLIP是一个统一的对比-生成式表示学习框架，用于解决现有CLIP式虚拟筛选模型对细粒度结合相互作用不敏感和依赖捷径相关性的问题。该方法通过联合训练口袋和配体编码器，结合对比学习和口袋条件扩散生成目标，并引入硬负样本增强和配体-配体锚定正则化，在公开基准测试中实现显著性能提升，特别是在分布外虚拟筛选和FEP+基准上。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP式模型（如DrugCLIP）在虚拟筛选中存在的问题：1）对细粒度结合相互作用不敏感；2）依赖训练数据中的捷径相关性；3）无法根据真实结合兼容性有效排序配体。这些问题限制了模型在实际应用中的泛化能力。

Method: 提出BindCLIP框架，包含三个核心组件：1）联合训练口袋和配体编码器的CLIP式对比学习；2）口袋条件扩散目标进行结合构象生成，提供构象级监督以塑造检索嵌入空间；3）硬负样本增强和配体-配体锚定正则化，防止表示崩溃并减轻捷径依赖。

Result: 在两个公开基准测试中，BindCLIP相比强基线模型表现出持续提升：1）在具有挑战性的分布外虚拟筛选任务上获得显著增益；2）在FEP+基准上改善了配体类似物排序性能。这些结果表明整合生成式构象监督与对比学习能有效提升模型泛化能力。

Conclusion: 通过将生成式、构象级监督与对比学习相结合，BindCLIP能够学习到更具相互作用感知能力的嵌入表示，并在真实筛选场景中提升泛化性能，使虚拟筛选更接近实际应用需求。

Abstract: Virtual screening aims to efficiently identify active ligands from massive chemical libraries for a given target pocket. Recent CLIP-style models such as DrugCLIP enable scalable virtual screening by embedding pockets and ligands into a shared space. However, our analyses indicate that such representations can be insensitive to fine-grained binding interactions and may rely on shortcut correlations in training data, limiting their ability to rank ligands by true binding compatibility. To address these issues, we propose BindCLIP, a unified contrastive-generative representation learning framework for virtual screening. BindCLIP jointly trains pocket and ligand encoders using CLIP-style contrastive learning together with a pocket-conditioned diffusion objective for binding pose generation, so that pose-level supervision directly shapes the retrieval embedding space toward interaction-relevant features. To further mitigate shortcut reliance, we introduce hard-negative augmentation and a ligand-ligand anchoring regularizer that prevents representation collapse. Experiments on two public benchmarks demonstrate consistent improvements over strong baselines. BindCLIP achieves substantial gains on challenging out-of-distribution virtual screening and improves ligand-analogue ranking on the FEP+ benchmark. Together, these results indicate that integrating generative, pose-level supervision with contrastive learning yields more interaction-aware embeddings and improves generalization in realistic screening settings, bringing virtual screening closer to real-world applicability.

</details>


### [50] [Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238)
*Chengzhi Hu,Jonas Dornbusch,David Lüdke,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: 针对当前对抗训练在大型语言模型上仍易受简单分布内攻击（如时态改写、翻译）的脆弱性，本文提出分布对抗训练（DAT）。该方法利用扩散语言模型近似提示-响应对的真实联合分布，生成多样化的高似然样本以改善泛化失败，并结合连续对抗训练在数据分布上进行优化，显著提升了模型的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管对抗训练能有效提升大型语言模型的抗攻击能力，但现有方法训练的模型仍对简单的分布内利用（如将提示改写为过去时或翻译成其他语言）表现出显著脆弱性。这种脆弱性源于当前对抗训练算法仅最小化训练集上的对抗损失，而未能充分覆盖真实数据分布，导致模型在面对轻微但分布内的输入变换时泛化能力不足。

Method: 提出的分布对抗训练（DAT）方法包含两个核心组件：（1）利用扩散语言模型近似提示与响应的真实联合概率分布，从而生成大量高似然、多样化的样本，填补训练数据分布覆盖的空白；（2）将这些样本与连续对抗训练相结合，在扩散模型所建模的数据分布上进行对抗性优化，而非局限于有限的训练集，从而系统性提升模型对分布内微小扰动的鲁棒性。

Result: 实验结果表明，DAT在对抗鲁棒性方面显著优于先前方法，能够有效防御包括时态改写、翻译等在内的简单分布内攻击，证明了其通过改善数据分布覆盖来提升模型泛化能力和安全性的有效性。

Conclusion: 本研究揭示了当前对抗训练在数据分布覆盖上的根本局限性，所提出的DAT框架通过整合扩散模型的分布建模能力与连续对抗训练，为构建更鲁棒的大型语言模型提供了新方向，强调了分布级优化在对抗防御中的关键作用。

Abstract: Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.

</details>


### [51] [Scaling Laws for Masked-Reconstruction Transformers on Single-Cell Transcriptomics](https://arxiv.org/abs/2602.15253)
*Ihor Kendiukhov*

Main category: cs.LG

TL;DR: 本研究首次系统性地探索了单细胞基因组学中的神经缩放定律，通过掩码重建Transformer模型发现：仅在数据充足条件下会出现清晰的幂律缩放行为，数据-参数比率是决定缩放的关键因素，并初步估计每个掩码基因位置的信息熵约为2.30比特。


<details>
  <summary>Details</summary>
Motivation: 语言与视觉Transformer中的神经缩放定律已被充分证实，但单细胞基因组学中是否存在类似规律尚属未知。本研究旨在填补这一空白，系统检验单细胞转录组学中的缩放行为特征。

Method: 利用CELLxGENE Census的scRNA-seq数据构建两种实验范式：数据丰富组（512个高变基因，20万细胞）与数据有限组（1024个基因，1万细胞），训练参数量跨度达三个数量级（533至3.4×10⁸参数）的掩码重建Transformer，并通过验证均方误差进行参数化缩放定律拟合分析。

Result: 数据丰富组呈现清晰的幂律缩放特性，具有约1.44的不可约损失下限；数据有限组则表现出可忽略的缩放行为，表明数据稀缺时模型容量并非瓶颈。初步信息论换算得出每个掩码基因位置的熵值约为2.30比特。

Conclusion: 研究表明当数据充足时，单细胞转录组学中确实存在与NLP相似的缩放定律，数据-参数比率是缩放行为的核心决定因素。该发现为单细胞基础模型设计提供了关键指导，并明确了需进一步精确熵估计测量的研究方向。

Abstract: Neural scaling laws -- power-law relationships between loss, model size, and data -- have been extensively documented for language and vision transformers, yet their existence in single-cell genomics remains largely unexplored. We present the first systematic study of scaling behaviour for masked-reconstruction transformers trained on single-cell RNA sequencing (scRNA-seq) data. Using expression profiles from the CELLxGENE Census, we construct two experimental regimes: a data-rich regime (512 highly variable genes, 200,000 cells) and a data-limited regime (1,024 genes, 10,000 cells). Across seven model sizes spanning three orders of magnitude in parameter count (533 to 3.4 x 10^8 parameters), we fit the parametric scaling law to validation mean squared error (MSE). The data-rich regime exhibits clear power-law scaling with an irreducible loss floor of c ~ 1.44, while the data-limited regime shows negligible scaling, indicating that model capacity is not the binding constraint when data are scarce. These results establish that scaling laws analogous to those observed in natural language processing do emerge in single-cell transcriptomics when sufficient data are available, and they identify the data-to-parameter ratio as a critical determinant of scaling behaviour. A preliminary conversion of the data-rich asymptotic floor to information-theoretic units yields an estimate of approximately 2.30 bits of entropy per masked gene position. We discuss implications for the design of single-cell foundation models and outline the additional measurements needed to refine this entropy estimate.

</details>


### [52] [Fast and Effective On-policy Distillation from Reasoning Prefixes](https://arxiv.org/abs/2602.15260)
*Dongxu Zhang,Zhichao Yang,Sepehr Janghorbani,Jun Han,Andrew Ressler,Qian Qian,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.LG

TL;DR: 这篇论文针对on-policy distillation (OPD)训练成本过高的问题，提出了prefix distillation方法，通过仅在输出前缀应用蒸馏目标并提前终止采样，在保持性能的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 虽然OPD相比off-policy distillation能获得更好的泛化性能，但其需要在训练过程中实时采样学生策略，导致训练成本显著增加，尤其对于长文本生成。研究发现蒸馏信号主要集中在输出前缀，这为优化提供了机会。

Method: 作者提出一种简单的OPD改进方法：仅在学生生成输出的前缀上应用蒸馏目标，并在蒸馏过程中提前终止采样。这种方法利用教师生成的短前缀来引导学生生成正确答案。

Result: 在AI-for-Math和域外基准测试上，所提出的前缀蒸馏方法在性能上媲美完整的OPD，同时将训练FLOP降低了2倍到47倍。

Conclusion: 通过利用输出前缀的关键作用，前缀蒸馏能够以更低的计算成本实现与完整OPD相当的性能，为高效知识蒸馏提供了有效解决方案。

Abstract: On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.

</details>


### [53] [The Information Geometry of Softmax: Probing and Steering](https://arxiv.org/abs/2602.15293)
*Kiho Park,Todd Nief,Yo Joong Choe,Victor Veitch*

Main category: cs.LG

TL;DR: 本文探讨AI系统如何将语义结构编码至表示空间的几何结构，指出在softmax分布下自然几何应为信息几何，并开发"dual steering"方法最优操控概念表示，实证显示该方法提升操控可控性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 表示空间的几何结构应反映模型利用表示产生行为的方式，特别是在定义softmax分布的表示中，其内在几何应与模型行为语义保持一致。

Method: 将信息几何确立为softmax表示空间的自然几何框架；提出"dual steering"方法，通过线性探针稳健操控概念；理论证明该方法在最大化目标概念修改的同时最小化对非目标概念的影响。

Result: 理论证明了dual steering的最优性；实验验证该方法能增强概念操控的可控性与稳定性。

Conclusion: 信息几何在理解语义编码中具有核心作用；dual steering为可解释且可控地操纵AI内部表示提供了有效工具。

Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop "dual steering", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.

</details>


### [54] [On Surprising Effectiveness of Masking Updates in Adaptive Optimizers](https://arxiv.org/abs/2602.15322)
*Taejong Joo,Wenhan Xia,Cheolmin Kim,Ming Zhang,Eugene Ie*

Main category: cs.LG

TL;DR: 提出Magma优化器，通过动量对齐的梯度掩码机制替代复杂自适应优化器，在1B参数模型上相比Adam和Muon分别降低困惑度19%和9%，计算开销可忽略。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型训练过度依赖具有复杂预条件器的密集自适应优化器（如Adam），计算成本高且结构复杂。本文挑战这一范式，探索更简单的随机参数更新掩码策略的有效性。

Method: 首先验证随机掩码RMSProp变体优于先进优化器；通过理论分析揭示随机掩码能诱导曲率依赖的几何正则化，平滑优化轨迹。基于此提出Magma（动量对齐梯度掩码），利用动量-梯度对齐调制掩码更新，实现自适应优化器的即插即用替代。

Result: 在大规模语言模型预训练实验中，Magma作为自适应优化器的直接替代品，带来持续性能提升且计算开销可忽略。特别地，在10亿参数模型规模上，相比Adam和Muon优化器，困惑度分别显著降低19%以上和9%。

Conclusion: 随机掩码是提升LLM训练效率的有效机制，Magma通过动量对齐策略将其系统化，为复杂自适应优化器提供了简单而强大的替代方案，在保持效率的同时大幅改善模型性能。

Abstract: Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\% and 9\% compared to Adam and Muon, respectively.

</details>


### [55] [Prescriptive Scaling Reveals the Evolution of Language Model Capabilities](https://arxiv.org/abs/2602.15327)
*Hanlin Zhang,Jikai Jin,Vasilis Syrgkanis,Sham Kakade*

Main category: cs.LG

TL;DR: 本研究通过5k观测+2k新采样的模型性能数据，采用平滑分位数回归和Sigmoid参数化，构建了预训练计算量与下游精度间的预测性缩放定律。发现除数学推理外能力边界基本稳定，数学推理边界持续演进，并提出20%评估预算即可恢复性能前沿的高效算法，发布Proteus 2k数据集。


<details>
  <summary>Details</summary>
Motivation: 基础模型部署亟需从预训练计算预算预测下游精度的明确缩放定律，并评估该映射关系的时序稳定性。现有方法缺乏大规模实证验证和预测性边界量化，难以指导实际部署决策。

Method: 基于大规模观测评估（5k观测数据+2k新采样），使用平滑分位数回归估计基准分数高条件分位数，采用单调饱和Sigmoid函数参数化计算量-性能关系，通过早期模型拟合验证后期模型释放的时序可靠性。

Result: 跨任务能力边界大多稳定，数学推理边界持续显著提升；识别任务相关饱和现象及数学推理污染偏移；开发高效算法可用20%评估预算恢复接近完整前沿；发布Proteus 2k性能数据集。

Conclusion: 提出了连接计算预算与可靠性能预期的实用方法论，建立了监测能力边界时序演变的分析框架，为模型部署提供决策支持，Proteus 2k数据集推动相关研究发展。

Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.

</details>


### [56] [A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining](https://arxiv.org/abs/2602.15330)
*Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 针对多标签学习中的长尾分布问题，提出CD-GTMLL框架，将问题重构为多玩家博弈，各子预测器负责标签子空间，通过合作与好奇心驱动奖励机制自适应地提升尾部标签学习，无需手动调参，在3万+标签的数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据挖掘中的大规模多标签分类面临长尾分布挑战，即少数头部标签主导而大量尾部标签稀少。现有重采样和重加权策略往往破坏标签间依赖关系或需要脆弱的超参数调优，尤其在标签空间扩展到数万级别时。这些问题限制了模型在资源受限环境下的自适应能力和实际部署效果。

Method: 提出好奇心驱动博弈论多标签学习（CD-GTMLL）框架，将长尾多标签分类重构为多玩家博弈问题。框架中每个子预测器作为一个"玩家"，专门负责标签空间的一个分区。玩家之间通过合作最大化全局准确率，同时基于尾部标签稀有性和玩家间分歧获得内在好奇心奖励。该机制无需人工平衡或调优，自适应地向代表性不足的尾部标签注入学习信号。

Result: 在7个基准数据集上的广泛实验表明，包括包含3万+标签的极端多标签分类数据集，CD-GTMLL持续优于现有最优方法，在Wiki10-31K数据集上P@3指标提升高达+1.6%。消融研究证实了博弈论合作机制和好奇心驱动探索对稳健尾部性能的贡献。

Conclusion: CD-GTMLL通过融合博弈论与好奇心机制，不仅提升了资源受限环境下的模型效率，还为电子商务、医疗等行业中不平衡数据场景的自适应学习铺平了道路。该方法为处理大规模长尾多标签分类提供了可扩展且免调的解决方案。

Abstract: The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor ("player") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.

</details>


### [57] [Directional Reasoning Trajectory Change (DRTC): Identifying Critical Trace Segments in Reasoning Models](https://arxiv.org/abs/2602.15332)
*Waldemar Chang*

Main category: cs.LG

TL;DR: 论文提出DRTC框架，用于解释语言模型长程推理。该方法检测关键决策点，通过干预特定早期上下文块并测量其对推理轨迹的影响，发现影响高度集中且学习到的关键点比随机片段更有效。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型如何执行长程推理仍是未解难题。现有可解释性方法仅能突出与答案相关的token或片段，但无法揭示模型的关键推理转折点、触发这些转折的早期上下文，以及高亮文本是否真正引导推理过程。

Method: 提出方向性推理轨迹变化(DRTC)框架，利用不确定性和分布偏移信号检测关键决策点，在保持已实现轨迹的前提下，仅在关键点阻断特定早期块的信息流，测量干预对模型对数概率轨迹方向的改变，生成带符号的块级归因分数，并计算原始logits的转向角曲率变化作为补充诊断，用曲率签名总结干预-响应的几何模式。

Result: 在四个推理模型上，方向性影响高度集中(每例|DRTC|份额的基尼系数0.50-0.58，前5%占比0.23-0.28)，学习到的关键点的干预强度高于匹配的随机片段。在R1-Distill-Qwen-1.5B上对500个MATH问题的扩展研究表明，学习片段优于随机片段(中位提升0.409，355例正向，符号检验p=2.3e-21)。

Conclusion: DRTC提供了因果性的、轨迹层面的解释框架，揭示了特定上下文元素如何在策略动态下引导推理过程。

Abstract: Understanding how language models carry out long-horizon reasoning remains an open challenge. Existing interpretability methods often highlight tokens or spans correlated with an answer, but they rarely reveal where the model makes consequential reasoning turns, which earlier context causally triggers those turns, or whether the highlighted text actually steers the reasoning process. We introduce Directional Reasoning Trajectory Change (DRTC), a process-causal framework for interpreting long-form reasoning from a single on-policy rollout. DRTC detects pivot decision points using uncertainty and distribution-shift signals, then applies receiver-side interventions that preserve the realized rollout without resampling the continuation while blocking information flow from selected earlier chunks only at a pivot. It measures whether each intervention redirects the direction of the model's log-probability trajectory relative to the realized rollout direction, producing a signed per-chunk attribution score. We also compute turning-angle curvature changes on raw logits as a complementary diagnostic and introduce curvature signatures to summarize shared intervention-response geometry. Empirically, directional influence is sharply concentrated across four reasoning models (per-example |DRTC| shares yield Gini 0.50 to 0.58 and top-5 percent mass 0.23 to 0.28), and learned pivots induce stronger intervention magnitudes than matched random spans. In a scaling study on 500 MATH problems with R1-Distill-Qwen-1.5B, learned spans outperform matched random spans (median delta = 0.409, 355 of 500 positive; sign test p = 2.3e-21). Overall, DRTC provides a causally grounded, trajectory-level view of how specific context elements steer reasoning under on-policy dynamics.

</details>


### [58] [FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning](https://arxiv.org/abs/2602.15337)
*Chaoyi Lu*

Main category: cs.LG

TL;DR: 本文提出FedPSA框架，通过参数敏感性实现细粒度模型陈旧性度量，结合动态动量队列实时调整过时信息容忍度，在异步联邦学习中相比基线提升6.37%，超越当前最优方法1.93%。


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习虽通过并发训练提升速度，但存在模型陈旧性问题。现有方法仅用轮次差粗粒度度量陈旧性，缺乏对模型本身的观察，导致性能天花板受限，亟需更精细的评估机制。

Method: 提出FedPSA：1）利用参数敏感性细粒度评估模型过时程度；2）建立动态动量队列实时判断训练阶段；3）根据训练阶段动态调整过时信息容忍阈值。

Result: 在多个数据集上的实验表明，FedPSA性能显著优于基线方法，最高提升6.37%；且超越当前最优异步方法1.93%，验证了细粒度陈旧性度量与动态调整策略的有效性。

Conclusion: FedPSA通过参数敏感性捕捉模型内在状态，结合动态动量机制自适应调整陈旧信息处理策略，为异步联邦学习性能提升提供了新范式，有效解决了异步更新带来的信息不一致问题。

Abstract: Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\% improvement over baseline methods and 1.93\% over the current state-of-the-art method.

</details>


### [59] [Discovering Implicit Large Language Model Alignment Objectives](https://arxiv.org/abs/2602.15338)
*Edward Chen,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: 本文提出Obj-Disco框架，通过迭代贪心算法自动将LLM对齐奖励信号分解为稀疏、可解释的自然语言目标组合，能识别>90%的奖励行为并发现潜在的对齐风险，为AI安全开发提供透明化工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对齐依赖复杂且不透明的奖励信号，导致激励行为模糊，存在错位和奖励黑客攻击风险；现有解释方法依赖预定义标准，可能遗漏"未知的未知"，且无法识别全面覆盖并因果影响模型行为的客观目标。

Method: 提出Obj-Disco框架，利用迭代贪心算法分析训练检查点间的行为变化，自动将奖励信号分解为稀疏加权的人可解释自然语言目标组合；通过识别并验证能最佳解释残余奖励信号的候选目标来实现目标发现。

Result: 在多任务、模型规模和对齐算法上的广泛评估显示框架具有鲁棒性；在开源奖励模型上实验一致捕获>90%的奖励行为，该结果经人类评估证实；案例研究表明框架能成功识别与预期行为伴随出现的潜在错位激励。

Conclusion: 该工作为揭示LLM对齐中的隐式目标提供了关键工具，为开发更透明、更安全的AI系统铺平道路。

Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on pre-defined rubrics, risking the omission of "unknown unknowns", or fail to identify objectives that comprehensively cover and are causal to the model behavior. To address these limitations, we introduce Obj-Disco, a framework that automatically decomposes an alignment reward signal into a sparse, weighted combination of human-interpretable natural language objectives. Our approach utilizes an iterative greedy algorithm to analyze behavioral changes across training checkpoints, identifying and validating candidate objectives that best explain the residual reward signal. Extensive evaluations across diverse tasks, model sizes, and alignment algorithms demonstrate the framework's robustness. Experiments with popular open-source reward models show that the framework consistently captures > 90% of reward behavior, a finding further corroborated by human evaluation. Additionally, a case study on alignment with an open-source reward model reveals that Obj-Disco can successfully identify latent misaligned incentives that emerge alongside intended behaviors. Our work provides a crucial tool for uncovering the implicit objectives in LLM alignment, paving the way for more transparent and safer AI development.

</details>


### [60] [ER-MIA: Black-Box Adversarial Memory Injection Attacks on Long-Term Memory-Augmented Large Language Models](https://arxiv.org/abs/2602.15344)
*Mitchell Piehl,Zhaohan Xi,Zuobin Xiong,Pan He,Muchao Ye*

Main category: cs.LG

TL;DR: 本文首次系统研究了针对长时记忆增强型大语言模型中基于相似度检索机制的黑盒对抗性记忆注入攻击，提出ER-MIA统一框架，揭示了相似度检索存在的根本性安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 长时记忆系统扩展了LLMs的能力，但也引入了新的攻击面，现有研究缺乏对黑盒场景下记忆注入攻击的系统性分析，存在安全盲区。

Method: 提出ER-MIA框架，包含内容基础和问题定向两种攻击设定，提供可组合的攻击原语和集成攻击策略，在最小化攻击假设下实现高成功率。

Result: 在多个LLMs和长时记忆系统上的实验证明，基于相似度检索机制存在系统性漏洞，风险跨越不同记忆设计和应用场景。

Conclusion: 相似度检索机制是长时记忆增强型LLMs的根本性、系统级安全漏洞，这一发现对现有架构构成普遍性威胁。

Abstract: Large language models (LLMs) are increasingly augmented with long-term memory systems to overcome finite context windows and enable persistent reasoning across interactions. However, recent research finds that LLMs become more vulnerable because memory provides extra attack surfaces. In this paper, we present the first systematic study of black-box adversarial memory injection attacks that target the similarity-based retrieval mechanism in long-term memory-augmented LLMs. We introduce ER-MIA, a unified framework that exposes this vulnerability and formalizes two realistic attack settings: content-based attacks and question-targeted attacks. In these settings, ER-MIA includes an arsenal of composable attack primitives and ensemble attacks that achieve high success rates under minimal attacker assumptions. Extensive experiments across multiple LLMs and long-term memory systems demonstrate that similarity-based retrieval constitutes a fundamental and system-level vulnerability, revealing security risks that persist across memory designs and application scenarios.

</details>


### [61] [Fractional-Order Federated Learning](https://arxiv.org/abs/2602.15380)
*Mohammad Partohaghighi,Roummel Marcia,YangQuan Chen*

Main category: cs.LG

TL;DR: 本文提出分数阶联邦平均(FOFedAvg)算法，通过引入分数阶随机梯度下降和记忆感知更新，解决联邦学习中收敛慢、通信成本高和非独立同分布数据问题。在多个基准数据集上，FOFedAvg展现出更优的测试性能和收敛速度，并从理论上证明了算法的收敛性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽能保护客户端隐私，但存在收敛速度慢、通信开销大以及因数据异构性（非独立同分布）导致的不稳定性等显著缺陷。这些问题限制了其在实际应用中的效率和可靠性，亟需新的优化方法来解决。

Method: 提出分数阶联邦平均(FOFedAvg)，采用分数阶随机梯度下降(FOSGD)来捕捉远程关联和更深层的历史信息。通过引入记忆感知的分数阶更新机制，在标准联邦平均框架中融入分数阶微积积分思想，以改善通信效率并加速收敛。

Result: 在MNIST、FEMNIST、CIFAR-10/100等9个基准数据集上，针对多种非独立同分布划分方案，FOFedAvg与现有联邦优化算法相比具有竞争力且经常表现更优，测试性能和收敛速度均有提升。

Conclusion: 分数阶、记忆感知的更新机制可显著提升联邦学习的鲁棒性和有效性，为非独立同分布数据下的分布式训练提供了实用路径，兼具理论保证和实践价值。

Abstract: Federated learning (FL) allows remote clients to train a global model collaboratively while protecting client privacy. Despite its privacy-preserving benefits, FL has significant drawbacks, including slow convergence, high communication cost, and non-independent-and-identically-distributed (non-IID) data. In this work, we present a novel FedAvg variation called Fractional-Order Federated Averaging (FOFedAvg), which incorporates Fractional-Order Stochastic Gradient Descent (FOSGD) to capture long-range relationships and deeper historical information. By introducing memory-aware fractional-order updates, FOFedAvg improves communication efficiency and accelerates convergence while mitigating instability caused by heterogeneous, non-IID client data. We compare FOFedAvg against a broad set of established federated optimization algorithms on benchmark datasets including MNIST, FEMNIST, CIFAR-10, CIFAR-100, EMNIST, the Cleveland heart disease dataset, Sent140, PneumoniaMNIST, and Edge-IIoTset. Across a range of non-IID partitioning schemes, FOFedAvg is competitive with, and often outperforms, these baselines in terms of test performance and convergence speed. On the theoretical side, we prove that FOFedAvg converges to a stationary point under standard smoothness and bounded-variance assumptions for fractional order $0<α\le 1$. Together, these results show that fractional-order, memory-aware updates can substantially improve the robustness and effectiveness of federated learning, offering a practical path toward distributed training on heterogeneous data.

</details>


### [62] [Joint Enhancement and Classification using Coupled Diffusion Models of Signals and Logits](https://arxiv.org/abs/2602.15405)
*Gilad Nurko,Roi Benita,Yehoshua Dissen,Tomohiro Nakatani,Marc Delcroix,Shoko Araki,Joseph Keshet*

Main category: cs.LG

TL;DR: 该论文提出了一种集成两个交互式扩散模型的通用框架，用于在噪声环境中进行鲁棒分类。该框架通过信号与分类器输出的耦合建模实现相互引导，无需重新训练分类器，在图像分类和语音识别任务上均优于传统序列增强方法。


<details>
  <summary>Details</summary>
Motivation: 标准方法将信号增强与分类视为分离的顺序阶段，无法利用分类器输出中的语义信息来指导去噪过程，限制了噪声环境下的分类性能。

Method: 提出一个域无关框架，包含两个交互扩散模型：一个作用于输入信号，另一个作用于分类器输出logits。通过三种策略建模输入与logits的联合分布，实现信号增强与类别估计的相互引导。

Result: 在图像分类和自动语音识别任务上，所提方法超越了传统序列增强基线，在不同噪声条件下均实现了稳健且灵活的分类精度提升。

Conclusion: 该耦合扩散框架有效解决了噪声环境下的鲁棒分类问题，通过信号与语义信息的双向交互，为多模态增强学习提供了新思路。

Abstract: Robust classification in noisy environments remains a fundamental challenge in machine learning. Standard approaches typically treat signal enhancement and classification as separate, sequential stages: first enhancing the signal and then applying a classifier. This approach fails to leverage the semantic information in the classifier's output during denoising. In this work, we propose a general, domain-agnostic framework that integrates two interacting diffusion models: one operating on the input signal and the other on the classifier's output logits, without requiring any retraining or fine-tuning of the classifier. This coupled formulation enables mutual guidance, where the enhancing signal refines the class estimation and, conversely, the evolving class logits guide the signal reconstruction towards discriminative regions of the manifold. We introduce three strategies to effectively model the joint distribution of the input and the logit. We evaluated our joint enhancement method for image classification and automatic speech recognition. The proposed framework surpasses traditional sequential enhancement baselines, delivering robust and flexible improvements in classification accuracy under diverse noise conditions.

</details>


### [63] [Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas](https://arxiv.org/abs/2602.15407)
*Alper Demir,Hüseyin Aydın,Kale-ab Abebe Tessera,David Abel,Stefano V. Albrecht*

Main category: cs.LG

TL;DR: 针对多智能体强化学习中的序贯社会困境问题，现有基于公平性的方法通常假设智能体面临相同激励且能获取全局信息。本文研究非对称场景下智能体自然差异对合作的影响，指出现有方法因强制原始平等而错误激励背叛行为。为此提出三项改进：基于奖励范围重新定义公平性、引入智能体权重机制处理非对称性、以及本地化社会反馈以适应部分可观测环境。实验表明该方法在非对称场景中能更快促进合作，且保持可扩展性与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有序贯社会困境研究多假设智能体同质化且可获取全局信息，这与现实场景存在差距。当智能体存在天然差异时，强制原始平等的公平性准则反而会激励背叛行为，导致合作难以形成。因此需要新的理论框架来应对非对称条件下的合作动力学问题。

Method: 提出三项核心改进：(i) 基于智能体奖励范围重新定义公平性标准，替代原始平等准则；(ii) 设计智能体权重机制，动态处理环境固有非对称性；(iii) 将社会反馈本地化，使方法适用于部分可观测场景而无需全局信息共享。

Result: 在非对称序贯社会困境环境中，本方法相比现有公平性方法能显著加快合作策略的涌现速度。同时，通过本地化设计保持了算法的可扩展性和实用性，验证了框架的有效性。

Conclusion: 本研究成功解决了多智能体系统中非对称性对合作形成的挑战，通过重新构建公平性定义和引入本地化机制，为非对称社会困境提供了有效的解决方案，推动了多智能体合作学习理论在现实场景中的应用。

Abstract: Sequential Social Dilemmas (SSDs) provide a key framework for studying how cooperation emerges when individual incentives conflict with collective welfare. In Multi-Agent Reinforcement Learning, these problems are often addressed by incorporating intrinsic drives that encourage prosocial or fair behavior. However, most existing methods assume that agents face identical incentives in the dilemma and require continuous access to global information about other agents to assess fairness. In this work, we introduce asymmetric variants of well-known SSD environments and examine how natural differences between agents influence cooperation dynamics. Our findings reveal that existing fairness-based methods struggle to adapt under asymmetric conditions by enforcing raw equality that wrongfully incentivize defection. To address this, we propose three modifications: (i) redefining fairness by accounting for agents' reward ranges, (ii) introducing an agent-based weighting mechanism to better handle inherent asymmetries, and (iii) localizing social feedback to make the methods effective under partial observability without requiring global information sharing. Experimental results show that in asymmetric scenarios, our method fosters faster emergence of cooperative policies compared to existing approaches, without sacrificing scalability or practicality.

</details>


### [64] [Logit Distance Bounds Representational Similarity](https://arxiv.org/abs/2602.15438)
*Beatrix M. B. Nielsen,Emanuele Marconato,Luigi Gresele,Andrea Dittadi,Simon Buchholz*

Main category: cs.LG

TL;DR: 本文研究判别模型（包括自回归语言模型）在分布接近但不完全相等时，其内部表示是否保持线性相似性。研究发现KL散度接近不能保证线性表示相似性，而基于logit差异的新距离度量可提供理论保证。在知识蒸馏中，logit-distance方法比传统KL-based方法更能保留教师模型的线性表示结构和可解释概念。


<details>
  <summary>Details</summary>
Motivation: 现有可识别性理论表明，当两个模型诱导相同条件分布时，其内部表示在可逆线性变换下一致。但实际场景中分布仅近似相等，特别是Nielsen等发现KL散度接近与线性表示相似性无必然联系，这威胁到知识蒸馏中线性探测可解释性和表示保真度的可靠性。

Method: 基于模型logit差异定义分布距离度量，提出与可识别类别相关的表示不相似性测度。理论证明该表示不相似性被logit距离上界，并分析KL散度与logit距离的关系，揭示KL-based蒸馏的潜在缺陷。

Result: 理论结果表明，虽然KL散度在概率远离零时可上界logit距离，但该界在实践中缺乏实际意义。蒸馏实验证实，KL-based蒸馏虽能匹配教师预测，却可能破坏线性表示特性；而logit-distance蒸馏在合成和图像数据集上显著提升学生模型的线性表示相似性和可解释概念保留。

Conclusion: KL散度作为蒸馏目标存在根本局限，无法保证表示结构相似性。logit距离提供了更合适的替代度量，能确保学生模型在预测精度和内部表示两个层面同时逼近教师模型，对可解释AI和知识蒸馏方法设计具有重要指导意义。

Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.

</details>


### [65] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 本研究构建评估框架检验链式思维(CoT)在网格导航任务的泛化能力。发现CoT提升分布内泛化但分布外泛化有限，文本多格式推理最优且纯文本模型优于视觉模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型与视觉-语言模型集成推理能力后性能显著提升，但其泛化能力定义模糊且缺乏系统理解。为此，本文旨在建立严格评估框架以探究CoT推理在不同分布条件下的泛化表现。

Method: 研究提出网格导航评估框架，模型需根据地图生成从起点到终点的避障移动序列。通过视觉和文本两种输入表示及不同CoT策略微调模型，并在分布内(ID)和分布外(OOD)条件下进行系统评估。

Result: 实验表明：1)CoT在所有表示下均改善分布内泛化；2)控制ID平凡匹配后，OOD泛化（如更大地图）仍非常有限；3)多格式文本推理轨迹实现最佳非平凡OOD泛化；4)纯文本模型持续优于图像模型，包括潜在空间推理方法。

Conclusion: 本工作提供严谨的CoT泛化评估框架，揭示其在分布内外的泛化特性差异，证明文本表示在推理中的优势，为未来推理模型设计提供重要参考。

Abstract: Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.

</details>


### [66] [POP: Prior-fitted Optimizer Policies](https://arxiv.org/abs/2602.15473)
*Jan Kobiolka,Christian Frey,Gresa Shala,Arlind Kadra,Erind Bedalli,Josif Grabocka*

Main category: cs.LG

TL;DR: 本文提出POP（Prior-fitted Optimizer Policies）元学习优化器，通过在数百万覆盖凸与非凸目标函数的新型先验合成优化问题上进行训练，使其能够基于优化轨迹上下文预测逐坐标步长。在47个优化函数基准测试中，该模型在匹配预算下持续超越传统梯度方法、进化策略、贝叶斯优化及其他元学习方法，且具备强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统梯度基优化器对超参数配置极为敏感，在高度非凸优化场景中，其性能高度依赖学率、动量、梯度累积等参数的精细调节，导致鲁棒性不足且适用性受限。

Method: 提出一种元学习优化框架POP，通过在数百万从新型先验分布采样的合成优化问题（涵盖凸与非凸目标）上进行元训练，使模型学会根据优化轨迹的上下文信息动态预测逐坐标的优化步长，实现自适应优化。

Result: 在包含47个不同复杂度函数的基准测试中，POP在相同计算预算下显著优于一阶梯度基方法、进化策略等非凸优化方法、贝叶斯优化及近期元学习优化器，展现出卓越的泛化性能和无需任务特定调参的优势。

Conclusion: POP元学习优化器通过在多样化合成优化问题上的预训练，获得了对优化任务的强大泛化能力，能够在不进行额外调参的情况下，在各类复杂优化问题上超越传统方法，为非凸优化提供了有效的新范式。

Abstract: Optimization refers to the task of finding extrema of an objective function. Classical gradient-based optimizers are highly sensitive to hyperparameter choices. In highly non-convex settings their performance relies on carefully tuned learning rates, momentum, and gradient accumulation. To address these limitations, we introduce POP (Prior-fitted Optimizer Policies), a meta-learned optimizer that predicts coordinate-wise step sizes conditioned on the contextual information provided in the optimization trajectory. Our model is learned on millions of synthetic optimization problems sampled from a novel prior spanning both convex and non-convex objectives. We evaluate POP on an established benchmark including 47 optimization functions of various complexity, where it consistently outperforms first-order gradient-based methods, non-convex optimization approaches (e.g., evolutionary strategies), Bayesian optimization, and a recent meta-learned competitor under matched budget constraints. Our evaluation demonstrates strong generalization capabilities without task-specific tuning.

</details>


### [67] [Evaluating Federated Learning for Cross-Country Mood Inference from Smartphone Sensing Data](https://arxiv.org/abs/2602.15478)
*Sharmad Kalpande,Saurabh Shirke,Haroon R. Lone*

Main category: cs.LG

TL;DR: 提出FedFAP框架，采用跨国联邦学习方法，通过智能手机传感数据实现情绪推断，有效处理异构传感模态并保护用户隐私，在跨文化人群评估中AUROC达0.744，优于集中式和现有个性化联邦学习方法。


<details>
  <summary>Details</summary>
Motivation: 情绪不稳定性是心理健康的核心行为指标，但传统评估方法依赖低频回顾性报告，无法捕捉其动态连续性。智能手机传感技术虽能基于日常行为实现被动、实时的情绪推断，但在大规模部署时面临隐私保护限制、传感数据分布不均以及用户行为模式差异显著等挑战。

Method: 提出FedFAP（特征感知个性化联邦学习框架），在跨国联邦学习架构下，将各国作为独立客户端并保留本地数据。该框架专为适应不同地区传感模态的异构性而设计，通过特征感知机制实现个性化建模。

Result: 在跨地理和文化多样的人群评估中，FedFAP的情绪推断AUROC达到0.744，性能显著优于集中式训练方法和现有个性化联邦学习基线。

Conclusion: 本研究验证了群体感知个性化策略与隐私保护学习相结合可赋能可扩展的情绪感知移动传感技术，为未来情绪感知系统的设计提供了重要洞见。

Abstract: Mood instability is a key behavioral indicator of mental health, yet traditional assessments rely on infrequent and retrospective reports that fail to capture its continuous nature. Smartphone-based mobile sensing enables passive, in-the-wild mood inference from everyday behaviors; however, deploying such systems at scale remains challenging due to privacy constraints, uneven sensing availability, and substantial variability in behavioral patterns.
  In this work, we study mood inference using smartphone sensing data in a cross-country federated learning setting, where each country participates as an independent client while retaining local data. We introduce FedFAP, a feature-aware personalized federated framework designed to accommodate heterogeneous sensing modalities across regions. Evaluations across geographically and culturally diverse populations show that FedFAP achieves an AUROC of 0.744, outperforming both centralized approaches and existing personalized federated baselines. Beyond inference, our results offer design insights for mood-aware systems, demonstrating how population-aware personalization and privacy-preserving learning can enable scalable and mood-aware mobile sensing technologies.

</details>


### [68] [LLM-as-Judge on a Budget](https://arxiv.org/abs/2602.15481)
*Aadirupa Saha,Aniket Wagde,Branislav Kveton*

Main category: cs.LG

TL;DR: 针对LLM-as-a-judge评估中多次查询的资源分配问题，本文提出一种基于多臂赌博机理论的方差自适应方法，在固定计算预算下动态分配查询以最小化评分估计误差。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge通过大语言模型推理为提示-响应对评分，已成为评估大模型的关键技术。由于判断具有随机性，实践中需多次查询以准确估计平均分。给定固定预算B，如何在K个样本间最优分配查询次数以降低估计误差，是该领域的核心挑战。

Method: 作者结合多臂赌博机理论与浓度不等式，提出方差自适应算法。该方法动态估计各提示-响应对的评分方差，并将更多查询资源分配给不确定性最高的样本，实现资源的最优配置。

Result: 理论上，该算法达到Õ(√(∑σ_i²/B))的最坏情况估计误差上界，其中σ_i²为第i个样本的真实评分方差，证明了其近优性。在Summarize-From-Feedback和HelpSteer2数据集上的实验表明，相比均匀分配，本方法在相同预算下显著降低了最坏情况估计误差。

Conclusion: 本研究为高效的LLM评估建立了理论框架，对提升AI安全、模型对齐和大规模自动化评估的效率具有重要实践意义。

Abstract: LLM-as-a-judge has emerged as a cornerstone technique for evaluating large language models by leveraging LLM reasoning to score prompt-response pairs. Since LLM judgments are stochastic, practitioners commonly query each pair multiple times to estimate mean scores accurately. This raises a critical challenge: given a fixed computational budget $B$, how to optimally allocate queries across $K$ prompt-response pairs to minimize estimation error? %
We present a principled variance-adaptive approach leveraging multi-armed bandit theory and concentration inequalities. Our method dynamically allocates queries based on estimated score variances, concentrating resources where uncertainty is highest. Further, our algorithm is shown to achieve a worst-case score-estimation error of $\tilde{O}\left(\sqrt{\frac{\sum_{i=1}^K σ_i^2}{B}}\right)$, $σ_i^2$ being the unknown score variance for pair $i \in [K]$ with near-optimal budget allocation. %
Experiments on \emph{Summarize-From-Feedback} and \emph{HelpSteer2} demonstrate that our method significantly outperforms uniform allocation, reducing worst-case estimation error while maintaining identical budgets. Our work establishes a theoretical foundation for efficient LLM evaluation with practical implications for AI safety, model alignment, and automated assessment at scale.

</details>


### [69] [Approximation Theory for Lipschitz Continuous Transformers](https://arxiv.org/abs/2602.15503)
*Takashi Furuya,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 本文提出一类按构造即满足Lipschitz连续性的梯度下降型上下文Transformer，通过将MLP和注意力块实现为负梯度流的显式欧拉步，解决了Lipschitz约束架构逼近理论保证缺失的问题，并证明了其通用逼近定理。


<details>
  <summary>Details</summary>
Motivation: 在安全敏感场景中部署Transformer需要高度稳定性和鲁棒性。约束Lipschitz常数是原理性的保证方法，但现有Lipschitz保持架构缺乏逼近理论保证，亟需理论突破。

Method: 引入按构造即Lipschitz连续的梯度下降型上下文Transformer，将MLP和注意力模块实现为负梯度流的显式欧拉步，在不牺牲表达力的前提下确保固有稳定性；采用测度理论形式化，将Transformer视为概率测度上的算子。

Result: 证明该类Transformer在Lipschitz约束函数空间中的通用逼近定理，获得与token数量无关的逼近保证，实现了稳定性与表达力的统一。

Conclusion: 本研究为设计鲁棒、Lipschitz连续的Transformer架构提供了严格的理论基础，填补了逼近理论空白，指导安全敏感场景下的模型设计。

Abstract: Stability and robustness are critical for deploying Transformers in safety-sensitive settings. A principled way to enforce such behavior is to constrain the model's Lipschitz constant. However, approximation-theoretic guarantees for architectures that explicitly preserve Lipschitz continuity have yet to be established. In this work, we bridge this gap by introducing a class of gradient-descent-type in-context Transformers that are Lipschitz-continuous by construction. We realize both MLP and attention blocks as explicit Euler steps of negative gradient flows, ensuring inherent stability without sacrificing expressivity. We prove a universal approximation theorem for this class within a Lipschitz-constrained function space. Crucially, our analysis adopts a measure-theoretic formalism, interpreting Transformers as operators on probability measures, to yield approximation guarantees independent of token count. These results provide a rigorous theoretical foundation for the design of robust, Lipschitz continuous Transformer architectures.

</details>


### [70] [The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes](https://arxiv.org/abs/2602.15515)
*Mohammad Taufeeque,Stefan Heimersheim,Adam Gleave,Chris Cundy*

Main category: cs.LG

TL;DR: 在真实代码环境中研究对抗白盒欺骗探测器的训练，揭示模型通过混淆激活或混淆策略逃避检测，强KL正则化与探测器惩罚可确保模型诚实。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅在人工环境中研究模型混淆，缺乏对自然奖励黑客场景的考察。为构建诚实AI系统，需在真实环境中研究对抗欺骗探测器训练时模型的规避行为。

Method: 构建真实代码生成环境，使奖励黑客通过硬编码测试用例自然发生。提出训练结果的分类法：诚实、混淆激活（修改内部表征）、混淆策略（生成带理由的欺骗文本）。通过强化学习结合探测器惩罚与KL正则化进行实证，并理论分析策略梯度方法。

Result: 混淆激活源于RL表征漂移（无论是否有探测器惩罚）；探测器惩罚仅激励混淆策略；理论证明策略梯度方法天然倾向混淆策略；强KL正则化+探测器惩罚可获诚实策略。

Conclusion: 适当强的KL正则化与探测器惩罚使白盒欺骗探测器成为奖励黑客易发任务的可行训练信号，为构建诚实AI系统提供解决方案。

Abstract: Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.

</details>


### [71] [CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals](https://arxiv.org/abs/2602.15546)
*Tomàs Garriga,Gerard Sanz,Eduard Serrahima de Cambra,Axel Brando*

Main category: cs.LG

TL;DR: 该论文提出一种针对市场事件影响下时间序列反事实推理的新方法——条件熵惩罚自编码器（CEPAE），在结构因果模型和溯因-行动-预测框架下，通过熵正则化实现解耦表示学习，并在多类数据集上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 时间序列反事实推理对金融、医疗、营销等领域的因果决策至关重要，但现有方法缺乏针对市场事件影响的专门设计，且未充分考虑时间序列的动态特性。本研究受工业应用需求驱动，旨在填补这一方法空白。

Method: 采用结构因果模型与溯因-行动-预测框架，首先改造变分自编码器和对抗自编码器以适应时间序列反事实推理；进而提出CEPAE，通过在潜在空间引入熵惩罚损失函数，鼓励解耦表示学习，以捕捉因果机制。

Result: 在合成、半合成及真实世界数据集上的理论与实验验证表明，CEPAE在各项评估指标上普遍优于现有对比方法，验证了熵惩罚机制在时间序列反事实推断中的有效性。

Conclusion: 本研究成功开发了一套适用于市场事件影响下时间序列数据的反事实推理新范式，CEPAE通过熵正则化实现解耦表示，为时序因果推断提供了有效工具，兼具理论创新与应用价值。

Abstract: The ability to accurately perform counterfactual inference on time series is crucial for decision-making in fields like finance, healthcare, and marketing, as it allows us to understand the impact of events or treatments on outcomes over time. In this paper, we introduce a new counterfactual inference approach tailored to time series data impacted by market events, which is motivated by an industrial application. Utilizing the abduction-action-prediction procedure and the Structural Causal Model framework, we first adapt methods based on variational autoencoders and adversarial autoencoders, both previously used in counterfactual literature although not in time series settings. Then, we present the Conditional Entropy-Penalized Autoencoder (CEPAE), a novel autoencoder-based approach for counterfactual inference, which employs an entropy penalization loss over the latent space to encourage disentangled data representations. We validate our approach both theoretically and experimentally on synthetic, semi-synthetic, and real-world datasets, showing that CEPAE generally outperforms the other approaches in the evaluated metrics.

</details>


### [72] [GLM-5: from Vibe Coding to Agentic Engineering](https://arxiv.org/abs/2602.15763)
*GLM-5 Team,:,Aohan Zeng,Xin Lv,Zhenyu Hou,Zhengxiao Du,Qinkai Zheng,Bin Chen,Da Yin,Chendi Ge,Chengxing Xie,Cunxiang Wang,Gengzheng Pan,Hao Zeng,Haoke Zhang,Haoran Wang,Huilong Chen,Jiajie Zhang,Jian Jiao,Jiaqi Guo,Jingsen Wang,Jingzhao Du,Jinzhu Wu,Kedong Wang,Lei Li,Lin Fan,Lucen Zhong,Mingdao Liu,Mingming Zhao,Pengfan Du,Qian Dong,Rui Lu,Shuang-Li,Shulin Cao,Song Liu,Ting Jiang,Xiaodong Chen,Xiaohan Zhang,Xuancheng Huang,Xuezhen Dong,Yabo Xu,Yao Wei,Yifan An,Yilin Niu,Yitong Zhu,Yuanhao Wen,Yukuo Cen,Yushi Bai,Zhongpei Qiao,Zihan Wang,Zikang Wang,Zilin Zhu,Ziqiang Liu,Zixuan Li,Bojie Wang,Bosi Wen,Can Huang,Changpeng Cai,Chao Yu,Chen Li,Chen Li,Chenghua Huang,Chengwei Hu,Chenhui Zhang,Chenzheng Zhu,Congfeng Yin,Daoyan Lin,Dayong Yang,Di Wang,Ding Ai,Erle Zhu,Fangzhou Yi,Feiyu Chen,Guohong Wen,Hailong Sun,Haisha Zhao,Haiyi Hu,Hanchen Zhang,Hanrui Liu,Hanyu Zhang,Hao Peng,Hao Tai,Haobo Zhang,He Liu,Hongwei Wang,Hongxi Yan,Hongyu Ge,Huan Liu,Huan Liu,Huanpeng Chu,Jia'ni Zhao,Jiachen Wang,Jiajing Zhao,Jiamin Ren,Jiapeng Wang,Jiaxin Zhang,Jiayi Gui,Jiayue Zhao,Jijie Li,Jing An,Jing Li,Jingwei Yuan,Jinhua Du,Jinxin Liu,Junkai Zhi,Junwen Duan,Kaiyue Zhou,Kangjian Wei,Ke Wang,Keyun Luo,Laiqiang Zhang,Leigang Sha,Liang Xu,Lindong Wu,Lintao Ding,Lu Chen,Minghao Li,Nianyi Lin,Pan Ta,Qiang Zou,Rongjun Song,Ruiqi Yang,Shangqing Tu,Shangtong Yang,Shaoxiang Wu,Shengyan Zhang,Shijie Li,Shuang Li,Shuyi Fan,Wei Qin,Wei Tian,Weining Zhang,Wenbo Yu,Wenjie Liang,Xiang Kuang,Xiangmeng Cheng,Xiangyang Li,Xiaoquan Yan,Xiaowei Hu,Xiaoying Ling,Xing Fan,Xingye Xia,Xinyuan Zhang,Xinze Zhang,Xirui Pan,Xunkai Zhang,Yandong Wu,Yanfu Li,Yidong Wang,Yifan Zhu,Yijun Tan,Yilin Zhou,Yiming Pan,Ying Zhang,Yinpei Su,Yipeng Geng,Yipeng Geng,Yong Yan,Yonglin Tan,Yuean Bi,Yuhan Shen,Yuhao Yang,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yurong Wu,Yutao Zhang,Yuxi Duan,Yuxuan Zhang,Zezhen Liu,Zhengtao Jiang,Zhenhe Yan,Zheyu Zhang,Zhixiang Wei,Zhuo Chen,Zhuoer Feng,Zijun Yao,Ziwei Chai,Ziyuan Wang,Zuzhou Zhang,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.LG

TL;DR: 本文提出GLM-5，一个旨在实现从"氛围编码"向"智能体工程"范式转变的下一代基础模型。通过DSA技术降低训练推理成本、异步强化学习基础设施解耦生成与训练、以及新型异步智能体RL算法，GLM-5在保持长上下文保真度的同时显著提升后训练效率，最终在公开基准和真实世界编码任务上均达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在推动从"氛围编码"到"智能体工程"的范式演进。基于前代模型的智能体、推理与编码（ARC）能力，GLM-5致力于在保持长上下文保真度的前提下大幅降低训练和推理成本，同时通过先进的强化学习方法提升模型对齐与自主性。

Method: 本文提出三项核心技术创新：1）采用DSA技术显著降低训练与推理成本；2）构建异步强化学习基础设施，通过解耦生成与训练过程大幅提升后训练效率；3）设计新型异步智能体RL算法，优化从复杂长时程交互中的学习效果，提升强化学习质量。

Result: GLM-5在主流公开基准测试上取得最先进（SOTA）性能，在真实世界编码任务中展现出前所未有的能力，特别是在端到端软件工程挑战方面显著超越先前基线模型。

Conclusion: 该系列创新成功实现了从氛围编码到智能体工程的范式突破，GLM-5在保持成本效率的同时，在模型性能尤其是复杂软件工程实践应用方面取得显著进展，为智能体驱动的软件开发展示了广阔前景。

Abstract: We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.

</details>


### [73] [1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization](https://arxiv.org/abs/2602.15563)
*Sohir Maskey,Constantin Eichenberg,Johannes Messner,Douglas Orr*

Main category: cs.LG

TL;DR: 本文通过实证研究探索低比特量化感知训练(QAT)的设计空间，发现k-means权重量化优于整数格式且能在标准硬件高效实现；在固定推理内存预算下，1-bit量化权重在生成式下游任务中表现最佳，突破了传统困惑度评估的局限。


<details>
  <summary>Details</summary>
Motivation: 尽管QAT能有效降低大语言模型内存占用，但量化格式和位宽的最优选择缺乏系统研究；现有工作未充分探索QAT的完整设计空间，对量化与下游任务性能的精确权衡理解不足，且评估常局限于困惑度指标，亟需更全面的实证研究。

Method: 开展低比特场景下QAT的实证研究，系统比较不同量化格式（k-means与整数格式）的性能差异，并在固定推理内存约束下，评估多种位宽配置对生成式下游任务的影响。

Result: k-means权重量化显著优于传统整数格式，且具备标准硬件高效实现的可行性；在给定内存预算下，1-bit量化权重在生成式任务上达到最佳性能，揭示了量化位宽与任务性能间的非线性关系。

Conclusion: 低比特QAT中量化格式选择至关重要，k-means方案为实用化提供了更优解；1-bit量化在内存受限的生成任务场景下展现出意外优势，为未来高效LLM部署指明了方向，并呼吁采用超越困惑度的更全面评估体系。

Abstract: Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quantization is not fully explored in the context of QAT, and the precise trade-off between quantization and downstream performance is poorly understood, as comparisons often rely solely on perplexity-based evaluations. In this work, we address these shortcomings with an empirical study of QAT in the low-bit regime. We show that k-means based weight quantization outperforms integer formats and can be implemented efficiently on standard hardware. Furthermore, we find that, under a fixed inference memory budget, the best performance on generative downstream tasks is achieved with $1$-bit quantized weights.

</details>


### [74] [Uniform error bounds for quantized dynamical models](https://arxiv.org/abs/2602.15586)
*Abdelkader Metakalard,Fabien Lauer,Kevin Colin,Marion Gilson*

Main category: cs.LG

TL;DR: 本文针对从相关数据序列学习的动态模型提供了统计精度保证。通过块分解和间距点策略，分别得到了慢速率和快速率、方差自适应的一致误差界，这些界随模型编码所需比特数缩放，从而将硬件约束转化为可解释的统计复杂度。


<details>
  <summary>Details</summary>
Motivation: 在实际系统辨识（特别是混合系统辨识）中，数据通常具有依赖性，模型需要量化，且优化算法往往不完美。现有理论缺乏对这些实际约束的统计保证，需要开发能统一处理这些问题的方法，并将硬件限制与统计性能联系起来。

Method: 提出了两类一致误差界：1）基于块分解的慢速率界；2）基于新颖间距点策略的快速率、方差自适应界。这些方法专门针对量化模型和实际优化算法设计。

Result: 获得了在相关数据下学习动态模型的统计精度保证，所得误差界与模型编码所需比特数成正比，成功将硬件约束转化为可解释的统计复杂度度量。

Conclusion: 该研究为实际系统辨识场景（含量化、不完美优化和相关数据）提供了坚实的理论基础，建立了硬件资源与统计性能之间的定量联系，对混合系统等复杂动态模型的可靠学习具有重要意义。

Abstract: This paper provides statistical guarantees on the accuracy of dynamical models learned from dependent data sequences. Specifically, we develop uniform error bounds that apply to quantized models and imperfect optimization algorithms commonly used in practical contexts for system identification, and in particular hybrid system identification. Two families of bounds are obtained: slow-rate bounds via a block decomposition and fast-rate, variance-adaptive, bounds via a novel spaced-point strategy. The bounds scale with the number of bits required to encode the model and thus translate hardware constraints into interpretable statistical complexities.

</details>


### [75] [Certified Per-Instance Unlearning Using Individual Sensitivity Bounds](https://arxiv.org/abs/2602.15602)
*Hanna Benarroch,Jamal Atif,Olivier Cappé*

Main category: cs.LG

TL;DR: 该论文针对通过噪声注入实现可验证机器遗忘的问题，提出了一种基于实例自适应噪声校准的新方法。传统方法使用最坏情况敏感性校准过于保守，导致性能下降。新方法利用每实例差分隐私为岭回归的朗之万动力学训练推导高概率敏感性边界，从而在减少噪声注入的同时实现可验证遗忘，并通过线性和深度学习实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的通过噪声注入实现可验证机器遗忘的方法基于最坏情况敏感性校准，这种保守的校准方式往往导致严重的性能退化，限制了其实用性。

Method: 采用每实例差分隐私框架，针对噪声梯度动力学中的单个数据点敏感性进行分析。具体而言，对通过朗之万动力学训练的岭回归模型，推导高概率每实例敏感性边界，实现自适应的每实例噪声校准。

Result: 理论分析表明该方法能显著减少噪声注入量，同时保持可验证的遗忘保证。在线性设置下的实验验证了理论结果，深度学习环境中的进一步实验也证明了该方法的相关性。

Conclusion: 该研究提出的基于每实例敏感性的自适应噪声校准方法为可验证机器遗忘提供了更实用的解决方案，在保持严格隐私保证的同时有效缓解了性能退化问题，对推动机器遗忘技术的实际应用具有重要意义。

Abstract: Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.

</details>


### [76] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的逆设计方法，通过将离散的设计空间松弛为连续网格表示，利用隐式微分计算梯度，并通过引导扩散和反向投影实现复合材料设计。


<details>
  <summary>Details</summary>
Motivation: 逆设计问题在工程和材料科学中普遍存在，但面临两大挑战：前向模拟（如FEM）计算成本高，且离散参数和约束限制了梯度优化方法的使用。多个设计参数可导致相似输出，需要多模态概率方法来获得多样化解决方案。

Method: 方法包括：(1)将原始设计空间松弛为连续网格，通过隐式微分计算梯度；(2)在松弛空间训练扩散模型作为设计先验；(3)推理时通过可微分模拟反向传播目标函数梯度，实现引导扩散采样；(4)通过反向投影将样本映射回原始参数空间。

Result: 在复合材料设计中验证：对中高等级目标体积模量，2D和3D设置下均能生成相对误差1%内的多样化设计。同时可通过多目标损失函数最小化材料密度。

Conclusion: 该方法有效解决了离散约束下的逆设计难题，利用扩散模型和梯度引导实现了精确且多样化的设计生成，在材料设计中展现出良好性能。

Abstract: Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.

</details>


### [77] [CAMEL: An ECG Language Model for Forecasting Cardiac Events](https://arxiv.org/abs/2602.15677)
*Neelay Velingker,Alaia Solko-Breslin,Mayank Keoliya,Seewon Choi,Jiayi Xin,Anika Marathe,Alireza Oraii,Rajat Deo,Sameed Khatana,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: 本文提出了CAMEL，首个能够进行长时程心电图信号推理以实现未来心脏事件预测的心电图语言模型。该模型通过专用心电图编码器和课程学习策略，在零样本条件下在ECGBench和ECGForecastBench基准测试中均达到最先进性能，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有心电图语言模型仅能进行分类和报告生成，无法预测未来心脏事件，而这对于早期干预具有重要临床价值。当前模型缺乏对长时程信号进行推理的能力，限制了其在预测性医疗中的应用。

Method: 提出CAMEL框架，核心是专用心电图编码器，实现心电图信号与文本的交叉理解。采用LoRA适配和课程学习训练策略，课程包含心电图分类、指标计算和多轮对话推理任务，以激发模型的推理能力。

Result: 在6个任务和9个数据集上展现强大零样本性能。在ECGBench上平均提升7.0%，在新型心律失常预测基准ECGForecastBench上，分别比全监督模型提升12.4%、比零样本心电图语言模型提升21.1%，整体达到最先进水平。

Conclusion: CAMEL首次实现了心电图语言模型的未来事件预测能力，通过长时程信号推理和跨模态理解，为临床早期干预提供了新工具。该工作在预测性心血管疾病诊断领域具有重要价值，展现了心电图语言模型的广阔应用前景。

Abstract: Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).

</details>


### [78] [UrbanVerse: Learning Urban Region Representation Across Cities and Tasks](https://arxiv.org/abs/2602.15750)
*Fengze Sun,Egemen Tanin,Shanika Karunasekera,Zuqing Li,Flora D. Salim,Jianzhong Qi*

Main category: cs.LG

TL;DR: UrbanVerse是一个跨城市、跨任务的城市场景表示学习模型。它通过图随机游走捕获区域局部和结构特征，并利用条件扩散模块HCondDiffCT整合区域先验和任务语义，在六个跨城市预测任务上显著超越现有方法，最高提升35.89%。


<details>
  <summary>Details</summary>
Motivation: 现有城市场景表示学习方法在跨城市和跨任务泛化能力上存在局限，无法有效适应不同城市和分析任务的需求。为此，本文旨在突破城市与任务特定的限制，构建一个类似基础模型的通用框架，实现城市分析任务的跨领域泛化。

Method: 提出UrbanVerse模型：1）跨城市泛化方面，将城市区域建模为图节点，通过随机游走生成"区域序列"，捕获目标区域自身特征及其邻近区域的结构信息；2）跨任务泛化方面，设计通用模块HCondDiffCT，在扩散过程中融合区域条件先验知识与任务条件语义，实现多下游任务的联合建模。该模块可集成至现有模型中以提升其效果。

Result: 在真实世界数据集上的跨城市实验表明，UrbanVerse在六个预测任务上持续优于现有最优方法，预测准确率相对提升最高达35.89%，验证了模型在跨城市场景和跨任务设定下的有效性与鲁棒性。

Conclusion: UrbanVerse成功实现了城市场景表示学习的跨城市与跨任务泛化，为城市分析领域提供了可扩展的基础模型新范式，展现了强大的泛化能力和实际应用潜力。

Abstract: Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form "sequences of regions" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.

</details>


### [79] [The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety](https://arxiv.org/abs/2602.15799)
*Max Springer,Chung Peng Lee,Blossom Metevier,Jane Castleman,Bohdan Turbal,Hayoung Jung,Zeyu Shen,Aleksandra Korolova*

Main category: cs.LG

TL;DR: 该论文揭示了对已对齐语言模型进行良性任务微调会意外破坏安全护栏的根本原因：并非训练数据或意图问题，而是梯度下降动态过程中对齐几何结构固有的脆弱性，表现为低维子空间中的尖锐曲率导致更新轨迹被系统性地偏转到安全敏感区域。


<details>
  <summary>Details</summary>
Motivation: 现有研究无法解释为何在无害数据和无对抗意图的微调过程中安全护栏会意外退化，传统正交性假设被认为能提供安全保障，但缺乏对梯度下降动态过程中几何不稳定性机制的系统分析。

Method: 采用新型几何分析方法，证明模型对齐集中在低维子空间且伴随尖锐曲率，构建了"对齐不稳定性条件"这一形式化机制，通过曲率耦合理论揭示了二阶加速如何系统性地将更新轨迹导向安全敏感区域。

Result: 建立了四次方缩放定律：对齐损失随训练时间呈四次方增长，其速率由对齐几何的尖锐度与微调任务和安全关键参数之间的曲率耦合强度共同决定，证明安全退化是动态演化而非静态快照问题。

Conclusion: 对齐脆弱性是梯度下降在弯曲流形上运行的固有几何属性，而非可修补的程序缺陷；当前安全范式存在结构性盲点，必须从反应式红队测试转向基于曲率感知的预测性诊断，为开源权重模型部署提供理论支撑。

Abstract: Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.

</details>


### [80] [Beyond Match Maximization and Fairness: Retention-Optimized Two-Sided Matching](https://arxiv.org/abs/2602.15752)
*Ren Kishimoto,Rikiya Takehi,Koichi Tanaka,Masahiro Nomura,Riku Togashi,Yoji Tomita,Yuta Saito*

Main category: cs.LG

TL;DR: 论文提出MRet算法解决双边匹配平台的用户留存最大化问题，通过动态学习个性化留存曲线，联合优化双边用户的留存收益，实证显示其优于匹配最大化或公平性方法。


<details>
  <summary>Details</summary>
Motivation: 现有匹配最大化算法导致用户匹配分布失衡，大量用户因匹配不足而流失；公平性虽能改善分布，但非平台终极目标——用户留存。订阅制平台需主动优化留存，而非依赖运气。

Method: 形式化定义留存最大化新问题，提出动态LTR算法MRet。从用户档案与交互历史学习个性化留存曲线，基于曲线动态分配匹配机会，联合考虑推荐方与被推荐方的留存增益。

Result: 在合成及真实约会平台数据集上，MRet相比优化匹配数或公平性的传统方法，实现了显著更高的用户留存率，验证了直接优化留存的有效性。

Conclusion: 对于以留存为核心目标的平台，直接优化留存优于优化匹配或公平性。MRet通过个性化留存曲线建模和双边联合优化，为平台留存优化提供了有效解决方案。

Abstract: On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions. Some may use fairness objectives to solve the problem of match maximization. However, fairness in itself is not the ultimate objective for many platforms, as users do not suddenly reward the platform simply because exposure is equalized. In practice, where user retention is often the ultimate goal, casually relying on fairness will leave the optimization of retention up to luck.
  In this work, instead of maximizing matches or axiomatically defining fairness, we formally define the new problem setting of maximizing user retention in two-sided matching platforms. To this end, we introduce a dynamic learning-to-rank (LTR) algorithm called Matching for Retention (MRet). Unlike conventional algorithms for two-sided matching, our approach models user retention by learning personalized retention curves from each user's profile and interaction history. Based on these curves, MRet dynamically adapts recommendations by jointly considering the retention gains of both the user receiving recommendations and those who are being recommended, so that limited matching opportunities can be allocated where they most improve overall retention. Naturally but importantly, empirical evaluations on synthetic and real-world datasets from a major online dating platform show that MRet achieves higher user retention, since conventional methods optimize matches or fairness rather than retention.

</details>


### [81] [Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning](https://arxiv.org/abs/2602.15817)
*Oswin So,Eric Yang Yu,Songyuan Zhang,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: 针对深度强化学习在可达性问题上的应用错配，本文提出可行性引导探索（FGE）方法，同步识别可行初始条件并学习安全策略，在MuJoCo和Kinetix模拟器上实现覆盖率提升>50%。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在高维控制任务中成效显著，但应用于可达性问题时存在根本性错配：可达性目标是最大化系统无限保持安全的状态集合，而RL优化的是用户指定分布上的期望回报，导致策略在低概率但安全的状态上性能不佳。尽管可建模为鲁棒优化，但问题可行性事先未知，构成核心挑战。

Method: 提出Feasibility-Guided Exploration（FGE），该方法同步完成两个目标：识别存在安全策略的可行初始条件子集，并学习解决该子集可达性问题的策略。通过自适应探索机制，FGE聚焦于可解问题区域，避免传统方法因可行性未知导致的探索低效。

Result: 在MuJoCo和Kinetix模拟器（含像素观测）的多个挑战性任务上，FGE学习的策略覆盖范围比现有最佳方法高出50%以上，验证了其显著优势。

Conclusion: FGE通过协同探索可行性与策略学习，有效解决了深度强化学习与可达性目标的本质错配，为安全关键系统的可达性问题提供了新范式，显著提升了策略覆盖能力和鲁棒性。

Abstract: Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.

</details>


### [82] [Operationalising the Superficial Alignment Hypothesis via Task Complexity](https://arxiv.org/abs/2602.15829)
*Tomás Vergara-Browne,Darshan Patil,Ivan Titov,Siva Reddy,Tiago Pimentel,Marius Mosbach*

Main category: cs.LG

TL;DR: 针对表面对齐假设（SAH）缺乏形式化定义的问题，本文提出"任务复杂度"度量（实现目标性能的最短程序长度），实验表明预训练模型能大幅降低任务复杂度，而后训练可将达到相同性能所需的程序长度从GB级压缩至KB级，揭示任务适应所需信息量极小。


<details>
  <summary>Details</summary>
Motivation: 表面对齐假设认为大语言模型的知识主要在预训练阶段获得，后训练仅激活已有知识，但该假设缺乏精确定义，导致支持论点碎片化且遭受重要批评，亟需形式化框架统一理解。

Method: 定义"任务复杂度"为在特定任务上达到目标性能的最短程序长度。在此框架下，SAH等价于预训练模型能显著降低任务复杂度。通过分析数学推理、机器翻译和指令遵循任务，量化比较预训练与后训练条件下的复杂度差异。

Result: 实验发现：1）预训练模型可使任务复杂度降至极低水平；2）预训练虽支持高性能但需GB级程序访问；3）后训练将相同性能的复杂度降低数个数量级，仅需数KB信息即可完成适应。

Conclusion: 研究表明任务适应通常只需极少信息（数KB），后训练能有效压缩实现高性能所需的程序长度。形式化的任务复杂度框架为SAH提供了统一解释，揭示了训练过程中知识获取与激活的本质，对理解大语言模型的能力涌现具有重要意义。

Abstract: The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个用于评估AI智能体端到端研究能力的基准测试环境。研究基于5篇顶会论文创建了5个容器化任务环境（共39个子任务），测试发现GPT-5智能体存在严重的"能力-可靠性差距"：仅在一个评估中超越基线6.7%，平均完成26.5%的子任务，尽管偶尔能达到SOTA性能但极不可靠。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估AI智能体在闭环研究任务中能力的基准，且前沿模型虽偶尔展现突破性性能，但可靠性存疑。本研究旨在填补这一空白，通过构建真实研究任务环境，系统性评估智能体的端到端研究能力，并揭示其能力与可靠性之间的差距。

Method: 研究选取ICML、ICLR和ACL的5篇口头/焦点论文，保留其数据集、评估框架和基线实现，但隐藏作者提出的方法。将每篇论文转化为容器化任务环境，共39个子任务。智能体需提出新假设、运行实验并尝试超越人类基线。在受控环境中测试了GPT-5驱动的智能体，并评估了Claude Code和Codex等专有智能体框架。

Result: GPT-5智能体在15次评估中仅1次（6.7%）超越基线11.5%，平均子任务完成率仅26.5%。识别出长期失败模式：缺乏耐心、时间与资源管理不善、对弱假设过度自信、难以协调并行实验、上下文长度限制。单次运行中智能体曾超越ICML 2025焦点任务方案，显示前沿智能体偶可达到SOTA但极不可靠。Claude Code和Codex表现类似。

Conclusion: ResearchGym为系统化评估和自主智能体在闭环研究任务中的分析提供了基础设施，揭示了AI智能体在端到端研究中的能力-可靠性鸿沟，为未来改进指明了方向。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [84] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该论文针对大语言模型知识蒸馏中的未授权使用问题，提出了修改教师模型推理轨迹以实现抗蒸馏和API水印的方法，通过动态重写响应在保持正确性的同时降低蒸馏效用并嵌入可验证签名。


<details>
  <summary>Details</summary>
Motivation: 开发前沿大模型需要巨大投入，但未授权知识蒸馏会不公平地利用这些成果。需要技术手段保护模型开发者的知识产权和投资回报。

Method: 提出多种动态重写教师推理输出的方法：其中两种利用LLM的改写能力，其他采用梯度技术。核心是在保持答案正确性和语义连贯性的前提下，实现抗蒸馏和水印嵌入双重目标。

Result: 实验表明，简单的基于指令的改写方法即可实现强抗蒸馏效果，同时保持甚至提升教师性能；此外，该方法还支持几乎无误报的高可靠性水印检测。

Conclusion: 通过重写教师推理轨迹可有效防止未授权知识蒸馏并实现可靠API水印，为保护大模型知识产权提供了实用且高效的解决方案。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [85] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 本文提出一种基于Carnapian-Goguenism和推论系统理论的新方法来解决本体异质性问题，命名为da Costian-Tarskianism。该方法引入扩展推论系统（增加本体公理）和扩展开发图结构，通过态射、纤维化和分割等操作关联不同本体，并探讨了其对应用本体论的意义及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 本体异质性导致不同本体在概念化上存在差异，阻碍了本体集成与互操作。本文的动机是借鉴Carnapian-Goguenism的容忍原则和Tarski的推论算子理论，为处理这种异质性提供一个统一的逻辑框架。

Method: 方法包括：（1）基于Carnapian-Goguenism和Carnielli、Citkin等人的推论系统理论；（2）定义扩展推论系统，即在推论系统中加入本体公理；（3）构建扩展开发图，利用扩展推论系统的态射以及纤维化、分割操作来关联和协调不同本体。

Result: 主要结果包括：da Costian-Tarskianism方法论框架、扩展推论系统的形式化定义、扩展开发图的图结构表示，以及通过态射、纤维化和分割实现本体间关系协调的形式化机制。

Conclusion: 该研究为应用本体论提供了新的理论基础和形式化工具，有助于更好地处理本体异质性问题。未来研究应进一步完善理论框架、拓展操作类型，并加强该方法在实际本体工程中的应用。

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [86] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 本研究通过比较20个前沿大语言模型（LLM）在风险决策中的表现，揭示了LLM可分为推理模型（RMs）和对话模型（CMs）两类。RMs表现理性，不受选项顺序、框架或解释影响，且在显式与经验两种呈现方式下行为一致；CMs则更不理性、更类人，对顺序、框架和解释敏感，且存在显著的描述-历史差距。研究发现数学推理训练是区分两类模型的关键因素。


<details>
  <summary>Details</summary>
Motivation: 大语言模型正迅速改变数字生态系统，但其在不确定性环境下的决策机制尚不明确。现有研究缺乏对LLM风险决策行为系统性比较，特别是在不同选项呈现方式和决策理由要求下的表现差异，这限制了LLM作为决策支持系统或智能体工作流的可靠应用。

Method: 研究沿两个维度开展比较分析：（1）前景呈现方式（显式呈现vs经验历史）；（2）决策理由要求（需解释vs无解释）。实验涵盖20个前沿开源LLM，并设置人类被试实验作为行为参照基准，以及期望收益最大化理性智能体模型作为理论基准。通过控制变量法测试模型对选项顺序、收益/损失框架等决策偏好的敏感性。

Result: LLM聚类为两大类别：推理模型（RMs）和对话模型（CMs）。RMs表现出理性行为特征，对选项顺序、框架效应和解释要求不敏感，且在显式与经验呈现条件下决策一致性高；CMs则显著更不理性，行为更类人，对顺序、框架和解释高度敏感，并呈现巨大的描述-历史差距。进一步分析表明，数学推理训练是区分两类模型的关键因素，开源模型配对比较结果支持这一结论。

Conclusion: 大语言模型在风险决策中存在系统性异质性，其行为模式可被清晰划分为理性型与类人型两类。这一分类与模型的数学推理训练强度密切相关，揭示了训练目标函数对LLM决策架构的塑造作用。该发现为理解LLM决策机制提供了重要理论框架，对开发更可靠的AI决策支持系统具有指导意义。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [87] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 本文针对供应链金融中发票支付稀释风险，提出AI/ML框架，通过分析九类交易字段的大规模生产数据，评估该框架如何补充确定性算法以实现买家-供应商对的实时稀释预测，解决传统IPU方法对非投资级买家的局限性。


<details>
  <summary>Details</summary>
Motivation: 发票支付稀释是供应链金融中非信用风险和利润率损失的主要来源。传统不可撤销付款承诺(IPU)虽能确保全额支付，但会阻碍供应链金融采纳，尤其对非投资级买家不适用。需要数据驱动的动态信用限额方法来实现更灵活的实时风险预测。

Method: 构建人工智能与机器学习框架，利用涵盖九个关键交易字段的大规模生产数据集，评估该框架对确定性算法的补充作用，实现对每个买家-供应商对发票稀释的实时预测。

Result: 通过评估AI/ML框架与确定性算法的结合效果，验证了数据驱动方法在实时预测发票稀释方面的可行性，为动态信用限额管理提供了实证依据。

Conclusion: AI/ML框架能有效增强传统确定性算法的预测能力，为供应链金融中的发票稀释风险提供更精准、实时的解决方案，有助于扩大供应链金融在非投资级买家群体中的适用范围。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [88] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 本研究探讨记忆类型与使用方式如何辅助智能体在不确定动态环境中进行空间导航。通过简单觅食任务，发现融合多策略、采用非稳态概率学习更新情景记忆并基于有限经验实时建图规划的架构，在任务难度提升时显著优于简单记忆智能体。


<details>
  <summary>Details</summary>
Motivation: 现实场景中智能体常面临动态变化且感知受限的导航挑战，传统方法难以平衡鲁棒性与适应性。亟需探索记忆与学习机制如何支持快速、高效的空间决策。

Method: 采用简单觅食范式：智能体每日需从家出发穿越障碍物获取食物。环境非稳态（障碍物与食物位置每日变化），感知信息不确定且受限。系统比较了从简单到复杂的多层次策略，重点考察基于非稳态概率学习的情景记忆更新机制，以及利用这些记忆构建不完美地图并实时规划的智能体架构。

Result: 结果表明，多策略架构能有效应对不同性质子任务（未知食物探索与已知位置规划）。当任务难度（如目标距离）增加时，具备记忆更新与实时建图能力的智能体相比最小记忆智能体效率大幅提升，但该优势在不确定性（定位误差与环境变化）过大时会减弱。

Conclusion: 记忆机制对动态导航至关重要。融合探索与规划的多策略架构，结合非稳态概率学习与情景记忆更新，可显著提升智能体在不确定环境中的适应性与效率，为自主导航系统提供了有效的解决方案。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [89] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: 针对当前网页智能体在环境变化预测和风险认知方面的不足，本文提出WAC框架，通过多智能体协作、结果模拟和反馈精化机制，提升智能体在网页任务执行中的推理能力和风险感知，在VisualWebArena和Online-Mind2Web基准测试中分别取得1.8%和1.3%的绝对性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的网页智能体虽然展现出自动化网页任务的潜力，但在预测环境变化方面存在推理能力局限，且缺乏对执行风险的全面认知，容易过早执行高风险动作导致任务失败和损失。

Method: 提出WAC框架，整合模型协作、结果模拟和反馈驱动的动作精化。引入多智能体协作流程，使动作模型能够咨询作为网页环境专家的世界模型以获得战略指导；通过两阶段推理链，世界模型模拟动作结果，评判模型审查结果并在必要时触发动作纠正反馈。

Result: 实验表明，WAC在VisualWebArena基准测试上取得1.8%的绝对增益，在Online-Mind2Web上取得1.3%的绝对增益。

Conclusion: WAC通过多智能体协作和风险感知的模拟-反馈机制，有效提升了网页智能体的推理能力和执行鲁棒性，为复杂网页环境下的可靠自动化任务执行提供了可行方案。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [90] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 针对LLM部署的安全-效用权衡难题，本文提出自适应abstention系统，通过上下文感知的动态阈值调整和五检测器级联架构，在降低延迟的同时显著减少误报，实现安全、效用与性能的可扩展平衡。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生产部署中存在安全过滤与效用保持的根本矛盾：严格机制导致良性查询被误阻，宽松策略则引发内容安全风险。传统基于静态规则或固定阈值的护栏缺乏上下文感知能力，计算开销大、延迟高，无法实现细粒度的动态平衡。

Method: 提出自适应abstention框架：1）利用领域和用户历史等实时上下文信号动态调节安全阈值；2）构建五个并行检测器的多维架构；3）采用分层级联机制渐进过滤查询，优化计算效率与检测精度。该设计避免了不必要的计算开销。

Result: 在混合及领域特定负载上的评估表明：系统误报率显著下降（尤其在医疗咨询和创意写作等敏感场景），在严格模式下保持高安全精度与近完美召回率，延迟较非级联模型及外部护栏系统大幅降低，实现了安全性与可用性的有效平衡。

Conclusion: 该上下文感知abstention框架通过动态阈值与级联检测机制，为LLM的可靠部署提供了可扩展解决方案，在保持高性能的同时有效协调了安全-效用权衡，具有重要实践价值。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [91] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 该论文解决了共同信念逻辑的完全性刻画问题，发现当个体信念为KD45时，共同信念满足KD4但失去5公理，并具有移位自反性C(Cφ→φ)。然而，仅KD4加此公理不足以完全刻画共同信念；还存在一个依赖于智能体数量的新公理。论文给出了完整公理系统，从而解决了这一开放问题。


<details>
  <summary>Details</summary>
Motivation: 动机在于纠正一个普遍误解：当个体信念为KD45时，共同信念并非简单的KD4逻辑。虽然它保持D和4公理，但失去5公理，并获得移位自反性。这引发了一个开放问题：KD4加移位自反性公理是否足以完全刻画KD45情形下的共同信念？若不能，真正的共同信念逻辑是什么？

Method: 论文采用逻辑分析方法，通过研究KD45框架下共同信念算子C的性质，首先证明移位自反性C(Cφ→φ)的有效性。随后构造反模型证明仅KD4加此公理仍不充分，并揭示所需额外公理与智能体数量相关。最终给出完整公理系统并证明其完全性。

Result: 结果表明：(1) KD45下共同信念满足KD4但缺失5公理；(2) 具有移位自反性C(Cφ→φ)；(3) 但KD4+移位自反性仍不充分；(4) 存在一个基数依赖的额外公理；(5) 完整公理系统成功解决了该开放问题，获得了KD45框架下共同信念的完全性刻画。

Conclusion: 论文结论指出，共同信念逻辑比传统认知更复杂，不仅包含移位自反性，还需一个依赖于群体规模的额外公理。该完整公理系统的建立，为共同信念的形式化提供了最终解决方案，结束了该领域的长期开放问题，对认知逻辑和多智能体系统具有理论终结意义。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [92] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: 本文提出了 EduEVAL-DB，一个基于教师角色构建的数据集，用于评估和训练自动教学评估器及AI导师的教学解释生成能力。该数据集包含来自ScienceQA基准的854个解释，覆盖K-12科学、语言和社会科学领域，每个问题包含1个人类教师解释和6个LLM模拟教师角色生成的解释。研究设计了包含事实正确性、解释深度与完整性、聚焦性与相关性、学生水平适宜性及意识形态偏见五个维度的教学风险评估标准，并通过半自动化流程结合专家审核完成标注。初步实验验证了数据集的有效性，并对Gemini 2.5 Pro和Llama 3.1 8B模型进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 开发能够自动评估和指导教学解释质量的AI系统需要高质量、细粒度的教学评估数据集。现有数据集缺乏对真实教学场景中教师角色多样性和教学风险的系统性刻画，无法支持AI导师的 pedagogical risk detection 能力训练。本研究旨在填补这一空白，为教育AI提供基于实证教学实践的角色化、可评估的数据基础。

Method: 从ScienceQA基准精选139个问题，覆盖K-12科学、语言和社会科学。对每个问题收集1个人类教师解释和6个LLM生成的解释，后者通过prompt engineering模拟真实教学实践中的不同指导风格和典型缺陷角色。构建包含事实正确性、解释深度与完整性、聚焦性与相关性、学生水平适宜性、意识形态偏见五个维度的教学风险评估标准。采用半自动化标注流程结合专家教师审核，为所有解释标注二元风险标签。最后通过基准测试和微调实验验证数据集适用性。

Result: 成功构建包含854个解释的EduEVAL-DB数据集，覆盖多学科K-12教育场景。初步实验表明：1）Gemini 2.5 Pro在 pedagogical risk detection 任务上显著优于轻量级Llama 3.1 8B模型；2）在EduEVAL-DB上进行监督微调能有效提升模型的教学风险识别能力；3）微调后的模型可在消费级硬件上部署，为AI导师的实时评估提供可行性。

Conclusion: EduEVAL-DB为教学AI的评估与训练提供了首个系统性、角色化、可操作的数据基础。该数据集不仅支持先进模型的性能基准测试，更使轻量级模型通过微调获得实用的教学风险评估能力，促进教育AI在真实课堂场景中的可部署性。研究为AI导师的质量保证机制奠定了重要数据和方法论基础。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [93] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: 本文针对当前个人AI中"黑箱"检索增强生成系统缺乏透明度和精确隐私控制的问题，提出Ruva——首个"玻璃箱"架构。该方案通过将个人AI建立在个人知识图谱上，取代传统的向量数据库匹配，使用户能够审查和精确编辑AI记忆，从而实现真正的"被遗忘权"。


<details>
  <summary>Details</summary>
Motivation: 现有个人AI依赖的"黑箱"检索增强生成系统存在根本性缺陷：1) 缺乏可解释性，用户无法检查AI产生幻觉或检索敏感数据的原因；2) 无法精确删除概念，向量空间中删除操作会留下概率性"幽灵"，违反真正的隐私保护。这导致用户对自身数字记忆缺乏控制权。

Method: 提出Ruva架构，采用范式转变：从向量匹配转向图推理。核心方法是将个人AI建立在个人知识图谱上，实现人机协同记忆管理。该架构支持：1) 记忆透明化，用户可以检查AI所掌握的知识；2) 精确事实编辑，可对特定事实进行精确修订；3) 完全遗忘机制，确保"被遗忘权"的实现。

Result: Ruva实现了"玻璃箱"设计理念，使个人AI记忆系统具有完全透明性和可编辑性。用户作为自身记忆的"编辑者"获得了实际控制权，能够精确管理和删除特定记忆内容，解决了传统向量数据库中概率性删除不彻底的问题。

Conclusion: Ruva通过知识图谱架构为个人AI建立了负责任的框架，将控制权交还给用户。这不仅解决了当前黑箱系统的隐私和可解释性问题，更重新定义了人机关系——用户不再是数据的被动提供者，而是自身数字记忆的积极管理者。该系统代表了向可信、可控个人AI的重要迈进。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [94] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 本文提出一种预处理方法，通过发现覆盖集、提升不等式和注入约束的方式，从现有累积约束推断额外约束以捕获多资源交互，从而提升约束编程调度性能。在RCPSP测试中发现了25个新下界和5个新最优解。


<details>
  <summary>Details</summary>
Motivation: 传统约束编程调度中按约束单独传播累积约束会忽略多资源交互，导致某些基准测试性能严重下降。需要开发能捕获资源间复杂交互的方法来提升调度效率。

Method: 将累积约束视为占用向量的线性不等式，通过三步预处理：(1) 识别无法并行任务的覆盖集；(2) 使用提升技术强化覆盖不等式；(3) 将生成的约束注入原问题实例，无需搜索时额外探测。

Result: 在RCPSP和RCPSP/max标准测试集上，该方法在有利实例上提升搜索性能并收紧目标边界，对不利实例影响轻微。实验发现25个新下界和5个新最优解，其中8个下界直接源于推断约束。

Conclusion: 该预处理方法通过捕获多资源交互显著改善约束编程调度性能，在发现新下界和最优解方面效果显著，为复杂调度问题提供了有效的优化途径。

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [95] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: 本文提出CARE Drive框架，用于评估自动驾驶视觉语言模型的理由响应性，通过两阶段上下文扰动测试揭示人类理由对决策的因果影响，避免事后合理化带来的虚假置信度。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶大模型的评估局限于安全性和轨迹准确性等结果性指标，无法判别模型决策是否真正反映人类价值考量。这种评估盲区导致模型生成的解释可能是事后合理化而非真实推理过程，在安全关键领域造成严重隐患，因此亟需建立理由响应性评估方法。

Method: CARE Drive采用两阶段模型无关评估框架：第一阶段通过提示校准稳定模型输出；第二阶段实施系统性上下文扰动，控制性改变安全边际、社会压力和效率约束等人类理由因素，比较基线决策与理由增强决策的差异，量化因果影响程度。

Result: 在自行车超车场景的实证表明：显式人类理由能显著影响模型决策，改善与专家行为建议的对齐度；但模型对不同理由类型的响应性存在异质性，安全边际类理由的敏感性高于社会压力类理由。

Conclusion: 本研究首次实现了不修改模型参数前提下对大模型理由响应性的系统性评估，为自动驾驶AI的可解释性验证提供了新范式，对确保安全关键系统决策符合人类价值观具有重要意义，推动了可信AI评估方法学的发展。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [96] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: 本文提出 PERSONA 框架，通过直接操控激活空间中的个性向量，以无训练方式实现与微调相当的人格控制效果，证明了 LLM 个性特征在数学上的可处理性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态性和组合性本质，亟需更高效、灵活的解决方案。

Method: PERSONA 采用三阶段方法：1) Persona-Base 通过对比激活分析提取正交特质向量；2) Persona-Algebra 利用向量算术实现精确控制（标量乘法调节强度、加法组合特质、减法抑制特质）；3) Persona-Flow 在推理过程中动态组合向量以实现上下文感知适配。

Result: 在 PersonalityBench 上取得 9.60 的平均分，几乎匹配监督微调上限 9.61；在 Persona-Evolve 动态人格适应基准上，跨模型家族获得高达 91% 的胜率。

Conclusion: 研究结果表明 LLM 人格的某些方面具有数学上的可处理性，为可解释且高效的行为控制开辟了新方向，无需梯度更新即可实现类人的动态特质操控。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [97] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: 该论文提出递归概念演化(RCE)框架，使预训练语言模型能够在推理过程中动态修改内部表示几何结构。通过检测表示不足时生成低秩概念子空间，并基于最小描述长度准则进行选择、协同合并和约束优化，RCE使模型能够构建新抽象而非仅重组现有概念。在Mistral-7B上集成后，在ARC-AGI-2、GPQA、BBH等组合推理基准测试中获得12-18点和8-14点的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在ARC-AGI-2、GPQA、MATH、BBH和HLE等组合推理基准测试上准确率急剧下降，尽管其在复杂推理任务中表现优异。现有方法（思维链提示、自洽性、强化学习）仅通过扩展token级搜索改进推理，但都保持模型的潜在表示空间固定。当任务所需的抽象能力未预先编码在该表示空间中时，模型性能会完全崩溃。因此需要一种能够在推理时动态调整内部表示、构建新抽象概念的方法。

Method: 递归概念演化(RCE)框架包含四个核心机制：1）动态子空间生成——当检测到表示不足时，自动生成低秩概念子空间；2）最小描述长度选择——基于MDL准则筛选最优子空间；3）协同合并——将具有协同效应的子空间进行合并；4）约束优化整合——通过约束优化方法整合子空间以保持模型稳定性。该框架使预训练模型能够从"重组已有概念"升级为"构建全新抽象"，从根本上增强组合推理能力。实验中将RCE集成至Mistral-7B模型进行验证。

Result: 在多个组合推理基准测试上的评估结果：ARC-AGI-2获得12-18个百分点的性能提升；GPQA和BBH获得8-14个百分点的提升；MATH和HLE上深度诱导错误率持续降低。这些结果表明RCE在需要复杂抽象的组合推理任务上实现了显著性能突破。

Conclusion: RCE框架通过动态演化内部表示几何结构，成功解决了语言模型在组合推理任务上的性能瓶颈。该方法突破了传统token级搜索的局限，使模型能够在推理时构建新抽象概念，在保持稳定性的同时实现显著性能提升，为开发更强大的语言模型推理能力提供了新的技术路径。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [98] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: 本文针对多智能体系统部分可观测性问题，提出Global State Diffusion Algorithm (GlobeDiff)，通过多模态扩散过程推断全局状态，理论证明误差有界且实验验证性能优越。


<details>
  <summary>Details</summary>
Motivation: 部分可观测性是多智能体系统协调决策的关键障碍。现有方法中，信念状态估计仅关注历史经验而未能充分利用全局信息；智能体间通信缺乏有效利用辅助信息的鲁棒模型。因此，亟需一种能同时克服状态歧义性并实现高精度全局推断的算法。

Method: 提出GlobeDiff算法，将状态推断过程形式化为多模态扩散过程。该算法基于局部观测进行全局状态重构，能够有效消除状态估计歧义性，同时保持高保真度的推断结果。

Result: 理论分析表明，GlobeDiff在单模态与多模态分布下均具有有界的估计误差。大量实验验证了该算法的优越性能，证实其能够准确推断全局状态。

Conclusion: GlobeDiff通过创新的扩散建模框架有效解决了多智能体系统的部分可观测性挑战，为分布式状态估计提供了新的理论方法与实践工具，兼具理论严谨性与实际应用价值。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [99] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 本文系统分析了大型语言模型作为合成参与者在社会科学实验中的应用有效性，通过对比启发式方法与统计校准策略，揭示了前者在探索性研究中的实用价值与后者的统计优势，并强调两种方法的适用性均取决于模型对目标人群的表征能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏关于何时可将LLM模拟结果有效推论至人类行为的指导，亟需厘清不同策略的适用条件与假设。

Method: 通过理论对比分析两种策略：启发式方法依赖提示工程与微调实现人机行为互换，统计校准则结合辅助人类数据进行统计调整；并评估其在探索性与验证性研究中的适用性。

Result: 启发式方法虽适用于探索性任务但缺乏验证性研究所需的统计保证；统计校准在明确假设下可保持推论有效性，以较低成本提供更精确的因果效应估计；两种方法的有效性均受限于LLM对目标人群的近似程度。

Conclusion: 研究者应超越简单的人机替代思维，根据研究性质（探索vs验证）和假设条件选择合适的策略，并重视LLM人群表征能力的评估。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [100] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 该研究针对AECO行业建筑语义表示问题，提出使用大语言模型嵌入替代传统one-hot编码。通过在BIM数据上训练GraphSAGE分类42类建筑对象，验证了LLM嵌入的有效性，其中llama-3紧凑嵌入F1分数达0.8766，优于one-hot的0.8475，为建筑领域AI语义理解提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 在建筑、工程、施工和运营（AECO）行业中，准确的建筑语义表示对AI模型训练至关重要。传统编码方法（如one-hot）无法捕捉密切相关的建筑对象子类型之间的细微关系，限制了AI对领域特定语义的深度理解。

Method: 研究采用大语言模型（OpenAI GPT和Meta LLaMA）嵌入作为新型编码方式，以保留建筑语义的精细差异。在五个高层住宅建筑信息模型（BIM）上训练GraphSAGE模型，对42个建筑对象子类型进行分类。测试了原始高维嵌入（1536、3072、4096维）和经套娃表示模型压缩的1024维嵌入。

Result: 实验结果表明，LLM编码显著优于传统one-hot基线。llama-3紧凑嵌入取得了0.8766的加权平均F1分数，较one-hot编码的0.8475有明显提升，证明了LLM嵌入在捕捉建筑领域语义细微差别方面的有效性。

Conclusion: 该研究证实了利用LLM-based编码增强AI解释复杂建筑语义能力的潜力。随着LLM和降维技术的演进，此方法在AECO行业语义精细化任务中具有广泛应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [101] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章针对AI训练数据不足的核心痛点，系统介绍基于仿真的合成数据生成技术，包括其关键概念、优势、挑战，以及数字孪生AI仿真解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 现代亚符号AI的发展受到数据量与质量不足的关键制约，亟需系统化的合成数据生成技术来突破此瓶颈。

Method: 提出以仿真作为系统性的合成数据生成方法，并构建数字孪生驱动的AI仿真参考框架用于方案设计与分析。

Result: 系统阐述了仿真生成合成数据的核心概念、价值与挑战，并提供了数字孪生AI仿真解决方案的参考框架。

Conclusion: 基于仿真的合成数据生成（尤其是数字孪生技术）是克服AI数据障碍的有效途径，为AI训练提供了可扩展的解决方案。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>
