<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.LG](#cs.LG) [Total: 39]
- [cs.AI](#cs.AI) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ChiEngMixBench: Evaluating Large Language Models on Spontaneous and Natural Chinese-English Code-Mixed Generation](https://arxiv.org/abs/2601.16217)
*Qingyan Yang,Tongxi Wang,Yunsheng Luo*

Main category: cs.CL

TL;DR: First benchmark ChiEngMixBench for code-mixing evaluation in authentic contexts; introduces two signals, Spontaneity and Naturalness, to assess cognitive alignment, revealing an emergent Terminology Layering Strategy aligned with Matrix Language Frame theory.


<details>
  <summary>Details</summary>
Motivation: Code-mixing in human-LLM interactions is not adequately captured by translation-based metrics. There is a need for scalable, context-sensitive evaluation that reflects human conventions and cognitive alignment across domains and bilingual pairs.

Method: Proposes a general construction pipeline to develop scalable code-mixing datasets. Formulates code-mixing as a cognitive alignment problem, using two complementary signals (Spontaneity and Naturalness). Empirically evaluates various models and analyzes the emergence of a Terminology Layering Strategy consistent with MLF.

Result: The metrics systematically differentiate code-mixing performance across models. An implicit Terminology Layering Strategy emerges, aligning with Matrix Language Frame theory, indicating cognitive alignment between multilingual LLMs and human communication.

Conclusion: ChiEngMixBench provides a scalable, cognitively grounded benchmark for code-mixing evaluation in authentic contexts; findings suggest models exhibit structured alignment with human linguistic conventions and reveal emergent strategies compatible with MLF.

Abstract: Code-mixing is increasingly prevalent in interactions between humans and large language models, yet existing work often reduces it to a translation or convertibility problem, making it difficult to assess whether a model's switching behavior is context-appropriate and aligned with human conventions. We introduce ChiEngMixBench, the first benchmark designed to evaluate code-mixing ability in authentic community contexts, built upon a general construction pipeline that enables scalable dataset development across domains and bilingual pairs. ChiEngMixBench formulates code-mixing as a cognitive alignment problem, characterized by two complementary signals: Spontaneity and Naturalness. Empirical evaluation shows that our metrics can systematically distinguish code-mixing performance across models. Beyond benchmarking, we further uncover an implicitly emergent Terminology Layering Strategy, a phenomenon consistent with the Matrix Language Frame (MLF) theory, indicating structured cognitive alignment between multilingual large language models and human communication.

</details>


### [2] [M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.16218)
*Aleix Torres-Camps,Nathaniel Mitrani Hadida,Víctor Conchello Vendrell,Àlex Batlle Casellas,Arnau Padrés Masdemont,Jordi Ros-Giralt*

Main category: cs.CL

TL;DR: 提出 M3Kang：一个 massively multilingual、multimodal 的数学推理数据集，基于 Kangaroo 数学竞赛，覆盖 108 种语言和涉及图表的题目，用于评估 VLM 的跨语言与跨模态推理能力，并开源 English-only 子集 M2Kang 与构建框架。


<details>
  <summary>Details</summary>
Motivation: 弥合多语言与多模态数学推理研究中的空白，比较 VLMs 与人类在数学推理上的差异，并提供一个可扩展的评估基准以促进模型改进。

Method: 从 Kangaroo Math Competition 提取 1,747 道独特的多项选择题，按年级难度组织；将题目翻译成 108 种语言（包含必要的图表信息），构建多语言多模态数据集。对闭源与开源的最新 SOTA 模型进行系统基线评测；结合 68,000 名学生的表现数据进行直接的人类对比，并开源数据集及 English-only 子集 M2Kang 以及数据构建框架与代码。

Result: 模型在基础数学与图表推理方面仍显不足，性能随语言覆盖和模型规模提高而提升，但与年级难度无显著相关性。多语言技术可有效迁移至多模态设定，显著优于基线。将模型评估与大量真实学生数据进行对比，揭示人机差异与潜在改进方向。

Conclusion: M3Kang 为跨语言、跨模态数学推理的评估提供了一个大规模基准，并证实需要进一步提升跨语言与跨模态推理能力，同时公开数据与工具以促进研究的透明性与可重复性。

Abstract: Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first massively multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world's largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,747 unique multiple-choice problems organized by grade-level difficulty, with translations into 108 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.

</details>


### [3] [Domain Specific Specialization in Low-Resource Settings: The Efficacy of Offline Response-Based Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2601.16219)
*Erdem Aslan,Pakize Erdoğmuş*

Main category: cs.CL

TL;DR: 在有限资源下，数据质量和结构对领域适应比数据量更关键；用500行上下文感知合成数据实现高精度与鲁棒拒识。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在领域/机构知识上产生幻觉的问题，并在受限硬件下构建高精度领域助手。

Method: 采用离线基于响应的知识蒸馏；比较三种数据策略（通用领域适应15k行、非结构化知识注入2k行、由教师模型生成的500线上下文感知合成数据）；使用Unsloth优化Qwen-2.5-7B学生模型，将显存从40GB降至16GB。

Result: 较大规模的非结构化数据仍出现幻觉，500线上下文感知数据集达到96.7%准确性并具鲁棒拒识能力；实验结果支持LIMA假设，即数据质量和结构对低资源领域适应比数据量更关键。

Conclusion: 在资源受限条件下，优先考虑数据的相关性、结构对齐和高质量标注；离线响应式蒸馏与高效推理对高质量领域助手的实现具有实证价值。

Abstract: Large Language Models (LLMs) excel in general tasks but often struggle with hallucinations when handling domain-specific or institutional knowledge absent from their pre-training. We present an offline response-based knowledge distillation method that develops high-accuracy specialized assistants under constrained hardware resources. We evaluate three distinct data strategies: general domain adaptation (15,000 lines), unstructured knowledge injection (2,000 lines), and a context-aware synthetic dataset (500 lines) generated by a teacher model. To minimize computational costs, we utilize the Unsloth library to optimize the Qwen-2.5-7B student model, reducing NVIDIA A100 GPU memory requirements from 40 GB to 16 GB. Experimental results demonstrate that while larger unstructured datasets suffer from persistent hallucinations, the 500-line context-aware dataset achieves a 96.7% accuracy rate and robust rejection capability. These findings validate the LIMA hypothesis, showing that data quality and structural alignment are more critical than quantity for domain adaptation in low-resource settings.

</details>


### [4] [Towards Latent Diffusion Suitable For Text](https://arxiv.org/abs/2601.16220)
*Nesta Midavaine,Christian A. Naesseth,Grigory Bartosh*

Main category: cs.CL

TL;DR: 提出 Neural Flow Diffusion Models (NFDM)，将连续扩散扩展到离散语言符号空间，显著缩小与自回归模型的似然差距，并获得与先前潜在扩散模型相当的样本质量。


<details>
  <summary>Details</summary>
Motivation: 解决离散语言建模中将连续扩散应用于离散状态空间的挑战，提升生成速度与连贯性，同时缩小与自回归基线的性能差距。

Method: 从数据中学习多变量前向过程，扩展 NFDM 至离散状态空间，使前向过程与生成轨迹更契合语言建模需求。

Result: 在同等规模下显著减小似然差距，样本质量接近以往的潜在扩散模型。

Conclusion: NFDM 为离散语言生成提供一个高效且质量可比的扩展，证明将连续扩散应用于离散语言任务的可行性。

Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.

</details>


### [5] [Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition](https://arxiv.org/abs/2601.16711)
*Shanshan Liu,Noriki Nishida,Fei Cheng,Narumi Tokunaga,Rumana Ferdous Munne,Yuki Yamagata,Kouji Kozaki,Takehito Utsuro,Yuji Matsumoto*

Main category: cs.CL

TL;DR: 提出基于层级概念索引的评估框架与LLM自动标注数据管线，提升MA-BCR对未见概念的泛化能力，ALD虽不能完全替代人工标注，但能扩展覆盖范围与结构知识。


<details>
  <summary>Details</summary>
Motivation: MA-BCR在未见概念上的泛化受限，主要原因是人类注释稀缺，需可扩展的评估方法和数据资源来提升泛化能力。

Method: 1) 构建基于层级概念索引的泛化评估框架，并提出新的评估指标；2) 设计面向特定任务的LLM自动标注数据(ALD)生成管线，作为可扩展的数据资源。

Result: 实验表明，LLM生成的ALD对泛化有正向作用，但不能完全替代人工标注；ALD提高了覆盖范围和结构知识的获取。

Conclusion: ALD是提升MA-BCR泛化的有价值资源，可作为人工标注的补充；代码与数据集开放，便于复现和后续研究。

Abstract: Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.

</details>


### [6] [GameTalk: Training LLMs for Strategic Conversation](https://arxiv.org/abs/2601.16276)
*Victor Conchello Vendrell,Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: GameTalk: 通过多轮对话训练LLMs在整个对话中优化全局目标的框架，利用reward信号对话史进行微调，尤其在DPO+奖励塑形下效果最好，胜过未训练模型。


<details>
  <summary>Details</summary>
Motivation: 解决跨轮对话中的长期目标优化、协作与谈判问题，弥补以往将注意力放在单轮任务或静态动作预测的研究空缺。

Method: 在GRPO、DPO、STaR等微调方法基础上，加入依赖整轮对话结果的奖励信号，进行多轮对话的全局目标优化训练。

Result: 在一组逐步复杂的博弈上评估，GameTalk显著优于未训练模型；奖励塑形提升显著，DPO带来最强增益。

Conclusion: 对话式微调为让LLMs在互动环境中进行推理、协商和行动提供了有前景的方向。

Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.

</details>


### [7] [Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification](https://arxiv.org/abs/2601.16278)
*Branislav Pecher,Jan Cegin,Robert Belanec,Ivan Srba,Jakub Simko,Maria Bielikova*

Main category: cs.CL

TL;DR: 用大型多语言模型生成合成数据，以蒸馏出表现优于生成器本身的较小模型，特别是在低资源语言中。结论认为应将LLMs作为数据生成器/教师，而非分类器。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中的数据稀缺问题，探究是否可以通过LLM生成的合成数据对较小模型进行有效蒸馏，使其在多语言和多任务上达到甚至超过庞大生成模型的表现。

Method: 使用最先进的多语言LLM生成覆盖11种语言、4个分类任务的合成数据集；通过微调、指令微调或为紧凑LLMs提供合成上下文示例来训练较小模型；也可将合成数据用作紧凑LLMs的合成上下文示例。

Result: 即使只有少量合成数据，也能使较小模型的表现超过用于生成数据的“大模型本身”，特别是在低资源语言中更为显著。

Conclusion: 将LLMs更有效地用作数据生成器（教师）而非直接分类器，通过生成的数据提升较小、较高效的多语言模型的能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.

</details>


### [8] [Generating Literature-Driven Scientific Theories at Scale](https://arxiv.org/abs/2601.16282)
*Peter Jansen,Peter Clark,Doug Downey,Daniel S. Weld*

Main category: cs.CL

TL;DR: 文献支撑的理论生成在大规模文献上显著优于依赖参数知识的生成，在证据匹配和未来预测方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 当前自动化科学发现多聚焦于实验阶段，缺乏从大量文献中系统化生成可验证理论的方法。本研究提出从文献中合成包含定性和定量规律的理论，并在规模上测试其可扩展性。

Method: 使用13.7k篇源论文来合成2.9k理论，比较文献 grounding 与 parametric knowledge，以及以准确性优先与新颖性优先的不同生成目标对理论属性的影响。通过在4.6k篇后续论文上评估理论对现有证据的一致性和对未来结果的预测能力。

Result: 相比仅使用参数化LLM记忆，文献支持的方法在匹配现有证据和预测未来结果方面均显著提高。

Conclusion: 从大规模文献中进行文献支撑的理论生成能够更好地对证据一致性与预测能力进行对齐，推动自动化理论生成的可扩展性与可靠性。

Abstract: Contemporary automated scientific discovery has focused on agents for generating scientific experiments, while systems that perform higher-level scientific activities such as theory building remain underexplored. In this work, we formulate the problem of synthesizing theories consisting of qualitative and quantitative laws from large corpora of scientific literature. We study theory generation at scale, using 13.7k source papers to synthesize 2.9k theories, examining how generation using literature-grounding versus parametric knowledge, and accuracy-focused versus novelty-focused generation objectives change theory properties. Our experiments show that, compared to using parametric LLM memory for generation, our literature-supported method creates theories that are significantly better at both matching existing evidence and at predicting future results from 4.6k subsequently-written papers

</details>


### [9] [A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War](https://arxiv.org/abs/2601.16309)
*Dikshya Mohanty,Taisiia Sabadyn,Jelwin Rodrigues,Chenlu Wang,Abhishek Kalugade,Ritwik Banerjee*

Main category: cs.CL

TL;DR: A longitudinal, multilingual news corpus (DNIPRO) with 246K articles (Feb 2022–Aug 2024) from 11 outlets in 5 nations and 3 languages, with rich metadata and annotations, enabling cross-national analysis of wartime discourse; demonstrates utility through stance, sentiment, framing, and contradiction analyses.


<details>
  <summary>Details</summary>
Motivation: to enable systematic transnational study of media narratives and information warfare during the Russo-Ukrainian war.

Method: data collection across outlets and languages; consistent metadata; multiple annotation types with rigorous human evaluations; use-case experiments on stance detection, sentiment, topical framing, contradiction; analysis of narrative divergence.

Result: reveals polarized interpretations reflecting geopolitical interests; outlets construct competing realities; demonstrates utility for computational journalism and cross-national narrative analysis.

Conclusion: DNIPRO provides a foundational resource for understanding emergence and evolution of conflicting narratives across global information ecosystems; supports research on media framing, narrative divergence, and information warfare.

Abstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.

</details>


### [10] [Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks](https://arxiv.org/abs/2601.16312)
*Dikshya Mohanty,Mohammad Saqib Hasan,Syed Mostofa Monsur,Size Zheng,Benjamin Hsiao,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: PolyBench: a large-scale polymer design benchmark (125K tasks, 13M+ data points) with a knowledge-augmented reasoning distillation method; 7B–14B SLMs trained on PolyBench outperform similar-sized models and frontier LLMs on the benchmark and show gains on other polymer benchmarks.


<details>
  <summary>Details</summary>
Motivation: Address the lack of polymer-specific knowledge and coverage in existing LLMs to enable reliable polymer design reasoning.

Method: Construct PolyBench dataset from experimental and synthetic data; organize tasks by increasing analytical complexity; propose knowledge-augmented reasoning distillation that integrates structured Chain-of-Thought; train 7B–14B SLMs on the dataset; evaluate against baselines and other polymer benchmarks.

Result: SLMs trained on PolyBench outperform comparable models and even frontier LLMs on PolyBench; show gains on other polymer benchmarks.

Conclusion: PolyBench with knowledge-augmented distillation enhances LLMs' capability in polymer design and suggests efficient performance with smaller models via specialized benchmarks.

Abstract: Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to polymer design. Addressing this, we introduce PolyBench, a large scale training and test benchmark dataset of more than 125K polymer design related tasks, leveraging a knowledge base of 13M+ data points obtained from experimental and synthetic sources to ensure broad coverage of polymers and their properties. For effective alignment using PolyBench, we introduce a knowledge-augmented reasoning distillation method that augments this dataset with structured CoT. Furthermore, tasks in PolyBench are organized from simple to complex analytical reasoning problems, enabling generalization tests and diagnostic probes across the problem space. Experiments show that small language models (SLMs), of 7B to 14B parameters, trained on PolyBench data outperform similar sized models, and even closed source frontier LLMs on PolyBench test dataset while demonstrating gains on other polymer benchmarks as well.

</details>


### [11] [Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP](https://arxiv.org/abs/2601.16314)
*Andres Karjus,Kais Allkivi,Silvia Maine,Katarin Leppik,Krister Kruusmaa,Merilin Aruvee*

Main category: cs.CL

TL;DR: LLM辅助的自动评分在两份爱沙尼亚全国性试题作文数据集上，与人工评分相当，且可以通过基于评分量表的人机协同管线实现国家级规模的高风险写作评估，并提供细粒度子分数以便个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 解决大规模、需在有限时间内对开放性试题回答进行一致、高效评估的问题，尤其在全国性考试和数字化教育环境中。

Method: 将官方课程标准的评分量表进行操作化，将LLM与统计自然语言处理方法的评分与人类评审小组分数进行对比。使用爱沙尼亚两份全国性队列的试题作文数据集，评估偏差、提示注入风险与LLM作为作文作者的情形，输出细粒度子分数并探讨一个 rubric驱动的人机循环评分管线的可行性。

Result: 自动评分的表现可与人工评分员媲美，且往往落在人工评分范围内；对偏见、提示注入风险等进行了评估，系统可生成细粒度子分数和个性化反馈；在国家级规模下，尤其在小语言环境中，仍能保持人类监督与合规。

Conclusion: 提出一个以评分量表为驱动的人机协同评分管线，适用于高风险写作评估；在数字化程度较高的社会如爱沙尼亚可实现国家级应用、符合新兴教育与监管标准，并提供用于教学和考试准备的系统性反馈。

Abstract: Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a limited time frame, such as nation-wide graduation exams in various countries. Here, we examine the applicability of automated scoring on two large datasets of trial exam essays of two full national cohorts from Estonia. We operationalize the official curriculum-based rubric and compare LLM and statistical natural language processing (NLP) based assessments with human panel scores. The results show that automated scoring can achieve performance comparable to that of human raters and tends to fall within the human scoring range. We also evaluate bias, prompt injection risks, and LLMs as essay writers. These findings demonstrate that a principled, rubric-driven, human-in-the-loop scoring pipeline is viable for high-stakes writing assessment, particularly relevant for digitally advanced societies like Estonia, which is about to adapt a fully electronic examination system. Furthermore, the system produces fine-grained subscore profiles that can be used to generate systematic, personalized feedback for instruction and exam preparation. The study provides evidence that LLM-assisted assessment can be implemented at a national scale, even in a small-language context, while maintaining human oversight and compliance with emerging educational and regulatory standards.

</details>


### [12] [Regional Bias in Large Language Models](https://arxiv.org/abs/2601.16349)
*M P V S Gopinadh,Kappara Lakshmi Sindhu,Soma Sekhar Pandu Ranga Raju P,Yesaswini Swarna*

Main category: cs.CL

TL;DR: 在10款主流大模型上通过FAZE框架利用100条强制区域选择的提示评估区域偏见，结果显示各模型偏见水平差异显著，GPT-3.5偏好度最高，Claude 3.5 Sonnet最低，强调建立包容性评估框架以缓解跨文化输出中的地理偏见。


<details>
  <summary>Details</summary>
Motivation: 揭示全球化语境下的区域偏见对AI公平性与全球代表性的影响，推动可重复、跨模型的偏见评估框架的发展。

Method: 提出FAZE框架；以100条中性场景的强制区域选择提示，评估10款模型（GPT-3.5、GPT-4o、Gemini 1.5 Flash、Gemini 1.0 Pro、Claude 3 Opus、Claude 3.5 Sonnet、Llama 3、Gemma 7B、Mistral 7B、Vicuna-13B）的区域偏好，使用10分制评分。

Result: 模型间偏见水平差异显著；GPT-3.5得分9.5，Claude 3.5 Sonnet得分2.5；区域偏见对LLM输出的可靠性、公平性与包容性具有实际影响。

Conclusion: 本研究强调需要包容性评估框架和系统性方法来识别和缓解地理偏见，从而提升跨区域应用中的AI公平性与可信度。

Abstract: This study investigates regional bias in large language models (LLMs), an emerging concern in AI fairness and global representation. We evaluate ten prominent LLMs: GPT-3.5, GPT-4o, Gemini 1.5 Flash, Gemini 1.0 Pro, Claude 3 Opus, Claude 3.5 Sonnet, Llama 3, Gemma 7B, Mistral 7B, and Vicuna-13B using a dataset of 100 carefully designed prompts that probe forced-choice decisions between regions under contextually neutral scenarios. We introduce FAZE, a prompt-based evaluation framework that measures regional bias on a 10-point scale, where higher scores indicate a stronger tendency to favor specific regions. Experimental results reveal substantial variation in bias levels across models, with GPT-3.5 exhibiting the highest bias score (9.5) and Claude 3.5 Sonnet scoring the lowest (2.5). These findings indicate that regional bias can meaningfully undermine the reliability, fairness, and inclusivity of LLM outputs in real-world, cross-cultural applications. This work contributes to AI fairness research by highlighting the importance of inclusive evaluation frameworks and systematic approaches for identifying and mitigating geographic biases in language models.

</details>


### [13] [Identity, Cooperation and Framing Effects within Groups of Real and Simulated Humans](https://arxiv.org/abs/2601.16355)
*Suhong Moon,Minwoo Kang,Joseph Suh,Mustafa Safdari,John Canny*

Main category: cs.CL

TL;DR: 对通过大语言模型（LLMs）在社会困境游戏中模拟人类行为的研究进行结构化摘要：通过对基础模型进行丰富的叙事身份绑定，可提升仿真忠实度，并能捕捉时间、问法和参与者群体等上下文因素，进而提高与人类研究的对比和可重复性。


<details>
  <summary>Details</summary>
Motivation: 探究深层绑定（而非仅仅 steering/弱绑定）是否能让LLMs更忠实地再现身份驱动的人类行为；并利用LLMs揭示在传统人类实验描述中常被省略的细节及其对结果的影响，以提升研究可重复性。

Method: 在社会困境游戏场景中，基模型通过丰富的叙事实体（叙事身份）进行前置条件设定；使用指令微调模型对一致性进行检查以确保身份一致性；考察时间（研究进行年份）、问题措辞、参与者池等上下文因素对仿真的影响与对比人类数据的一致性。

Result: 通过对基础模型的深度身份绑定，仿真忠实度相较于不绑定情形有所提升；模型能捕捉并再现时间、问题框架、参与者群体等上下文因素的影响；LLMs帮助揭示常被人类研究描述忽略的细节，从而有助于研究复现和对比分析。

Conclusion: LLMs提供一种可控且可回放的工具，用以模拟并解析影响人类实验结果的细节，有望提升跨研究的可重复性与解释性；同时需关注上下文依赖的解释性、潜在偏差和对实验伦理的评估。

Abstract: Humans act via a nuanced process that depends both on rational deliberation and also on identity and contextual factors. In this work, we study how large language models (LLMs) can simulate human action in the context of social dilemma games. While prior work has focused on "steering" (weak binding) of chat models to simulate personas, we analyze here how deep binding of base models with extended backstories leads to more faithful replication of identity-based behaviors. Our study has these findings: simulation fidelity vs human studies is improved by conditioning base LMs with rich context of narrative identities and checking consistency using instruction-tuned models. We show that LLMs can also model contextual factors such as time (year that a study was performed), question framing, and participant pool effects. LLMs, therefore, allow us to explore the details that affect human studies but which are often omitted from experiment descriptions, and which hamper accurate replication.

</details>


### [14] [Cross-Lingual Activation Steering for Multilingual Language Models](https://arxiv.org/abs/2601.16390)
*Rhitabrat Pokharel,Ameeta Agrawal,Tanay Nagar*

Main category: cs.CL

TL;DR: CLAS is a training-free, inference-time method that modulates neuron activations to improve cross-lingual transfer without altering weights; it yields consistent gains on classification and generation benchmarks, with improvements linked to functional divergence and greater language-cluster separation.


<details>
  <summary>Details</summary>
Motivation: To address persistent performance gaps between dominant and non-dominant languages in multilingual models by leveraging a training-free, inference-time intervention that avoids heavy retraining or architectural changes.

Method: Cross-Lingual Activation Steering (CLAS): an inference-time intervention that selectively modulates neuron activations to steer representations toward better cross-lingual transfer, with no model weight updates.

Result: On classification and generation benchmarks, CLAS achieves average improvements of 2.3% in accuracy and 3.4% in F1, while preserving high-resource language performance. Gains correlate with increased language cluster separation and are rooted in functional divergence rather than strict alignment.

Conclusion: Targeted activation steering can unlock latent multilingual capacity in existing models without modifying weights, offering a lightweight route to improve multilingual NLP performance through inference-time neuron modulation.

Abstract: Large language models exhibit strong multilingual capabilities, yet significant performance gaps persist between dominant and non-dominant languages. Prior work attributes this gap to imbalances between shared and language-specific neurons in multilingual representations. We propose Cross-Lingual Activation Steering (CLAS), a training-free inference-time intervention that selectively modulates neuron activations. We evaluate CLAS on classification and generation benchmarks, achieving average improvements of 2.3% (Acc.) and 3.4% (F1) respectively, while maintaining high-resource language performance. We discover that effective transfer operates through functional divergence rather than strict alignment; performance gains correlate with increased language cluster separation. Our results demonstrate that targeted activation steering can unlock latent multilingual capacity in existing models without modification to model weights.

</details>


### [15] [Cite-While-You-Generate: Training-Free Evidence Attribution for Multimodal Clinical Summarization](https://arxiv.org/abs/2601.16397)
*Qianqi Yan,Huy Nguyen,Sumana Srivatsa,Hari Bandi,Xin Eric Wang,Krishnaram Kenthapadi*

Main category: cs.CL

TL;DR: 提出一个训练-free 的生成时源属性框架，利用解码器注意力直接对齐并引用支撑文本片段或图像，提供两种多模态属性策略：原始图像模式与字幕-as-span模式，在 CliConSummation 与 MIMIC-CXR 两个领域显著优于嵌入基线与自属性基线，且字幕模式更轻量但性能接近原始图像模式。


<details>
  <summary>Details</summary>
Motivation: 临床摘要需要透明的来源证据以提升可解释性与可部署性；现有基于后处理或再训练的方法在生成时引导来源方面存在局限性。

Method: 提出一个训练无关的框架，在生成阶段通过解码器注意力来进行来源属性化；提出两种策略：1) 原始图像模式：直接使用图像 patch 的注意力来标注引用的图像区域；2) 字幕-as-span 模式：用生成的字幕替代图像，以实现纯文本的对齐与引用；对多模态数据进行跨模态的属性归属。

Result: 在两个数据集上，方法持续优于嵌入基线和自 attribution baselines，提升文本级与多模态 attribution 的准确性，约 +15% 的 F1 相对于嵌入基线；caption-based attribution 与 raw-image attention 性能相当，且更轻量、易于部署。

Conclusion: 注意力引导的属性化是可解释且易部署的临床摘要系统的有力方向，具备实际落地潜力。

Abstract: Trustworthy clinical summarization requires not only fluent generation but also transparency about where each statement comes from. We propose a training-free framework for generation-time source attribution that leverages decoder attentions to directly cite supporting text spans or images, overcoming the limitations of post-hoc or retraining-based methods. We introduce two strategies for multimodal attribution: a raw image mode, which directly uses image patch attentions, and a caption-as-span mode, which substitutes images with generated captions to enable purely text-based alignment. Evaluations on two representative domains: clinician-patient dialogues (CliConSummation) and radiology reports (MIMIC-CXR), show that our approach consistently outperforms embedding-based and self-attribution baselines, improving both text-level and multimodal attribution accuracy (e.g., +15% F1 over embedding baselines). Caption-based attribution achieves competitive performance with raw-image attention while being more lightweight and practical. These findings highlight attention-guided attribution as a promising step toward interpretable and deployable clinical summarization systems.

</details>


### [16] [Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification](https://arxiv.org/abs/2601.16400)
*Zongwan Cao,Bingbing Wen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: CoA (Clarify-or-Answer) efficiently handles under-specified VQA by deciding to ask a focused clarifying question or answer directly. It introduces CONTEXTCLARIFY and GRPO-CR (Clarification Reasoning) to optimize question generation via reinforcement learning. Demonstrates consistent gains across three VLLMs and three datasets, with +15.3 VQA accuracy points (83% relative) over prompting baselines.


<details>
  <summary>Details</summary>
Motivation: Real-world VQA often suffers from context-dependence and under-specified queries. Directly answering can yield confident but incorrect results. A minimal, targeted clarification can resolve ambiguity with limited user burden.

Method: - CoA: a two-branch decision process that first decides whether clarification is necessary; if yes, generates a single focused clarifying question and uses the answer to produce the final response.
- CONTEXTCLARIFY: a dataset consisting of ambiguous VQA questions and a non-ambiguous contrast set for evaluation.
- GRPO-CR (Clarification Reasoning): a reinforcement learning approach that optimizes clarifying-question generation using multiple rewards for well-formedness, focus, non-triviality, and effective ambiguity resolution.
- Evaluation: tested across three Vision-Language Large Language Models (VLLMs) and three datasets, comparing to prompting-based baselines.

Result: CoA achieves consistent improvements at both the module and system levels. End-to-end VQA accuracy improved by an average of +15.3 points, representing about an 83% relative increase over prompting-based baselines.

Conclusion: A clarifying-then-answering paradigm, reinforced by dedicated training signals and a purpose-built benchmark (CONTEXTCLARIFY), substantially improves real-world VQA where context is incomplete. The approach generalizes across models and datasets and highlights the value of targeted clarification in VQA systems.

Abstract: Real-world visual question answering (VQA) is often context-dependent: an image-question pair may be under-specified, such that the correct answer depends on external information that is not observable in the image. In such cases, directly answering can lead to confident but incorrect predictions. We propose CoA(Clarify-or-Answer), an ask-or-answer agent that separately models the decision to ask or answer, and what to ask if needed. CoA first determines whether clarification is necessary; if so, it asks a single focused question and then incorporates the response to produce the final answer. We introduce CONTEXTCLARIFY with a set of ambiguous VQA questions and the contrast set that is non-ambiguous. We further introduce GRPO-CR (Clarification Reasoning), a reinforcement learning approach that optimizes clarification question generation with multiple reward signals encouraging well-formed, focused, non-trivial questions that resolve ambiguity. Across three VLLMs and three datasets, CoA achieves consistent improvements at both the module and system levels, improving end-to-end VQA accuracy by an average of +15.3 points (83%) over prompting-based baselines

</details>


### [17] [Jacobian Scopes: token-level causal attributions in LLMs](https://arxiv.org/abs/2601.16407)
*Toni J. B. Liu,Baran Zadeoğlu,Nicolas Boullé,Raphaël Sarfati,Christopher J. Earls*

Main category: cs.CL

TL;DR: 提出 Jacobian Scopes，一组基于梯度的逐 token 级因果归因方法，用于解释大语言模型的预测。提供 Semantic、Fisher、Temperature 三个变体，通过分析最终隐藏态对输入的线性关系来量化输入 token 的影响，应用于指令理解、翻译和上下文学习，发现潜在偏见等现象，代码公开。


<details>
  <summary>Details</summary>
Motivation: 解释大语言模型中哪些前置 token 最强烈影响预测，然而多层和注意力头的复杂性使得难以解析。

Method: 对最终隐藏态相对于输入的雅可比矩阵进行线性化分析，度量各 token 对预测的影响。提出三种变体：Semantic Scopes（针对特定 logits 的敏感性）、Fisher Scopes（针对完整预测分布的敏感性）、Temperature Scopes（模型置信度的逆温度）。通过关于指令理解、翻译、ICL 的案例研究。

Result: 在指令理解、翻译和 ICL 的案例中，得到一些结论，如 Jacobian Scopes 能指向隐含的政治偏见；也帮助理解在上下文时间序列预测中的机制。代码和交互演示公开。

Conclusion: 为逐 token 级的因果归因提供了一种可解释的新工具，能够揭示模型内部如何将输入信息转化为预测，并为理解偏见与时间序列预测等现象提供线索，且具备可重复性和可扩展性。

Abstract: Large language models (LLMs) make next-token predictions based on clues present in their context, such as semantic descriptions and in-context examples. Yet, elucidating which prior tokens most strongly influence a given prediction remains challenging due to the proliferation of layers and attention heads in modern architectures. We propose Jacobian Scopes, a suite of gradient-based, token-level causal attribution methods for interpreting LLM predictions. By analyzing the linearized relations of final hidden state with respect to inputs, Jacobian Scopes quantify how input tokens influence a model's prediction. We introduce three variants - Semantic, Fisher, and Temperature Scopes - which respectively target sensitivity of specific logits, the full predictive distribution, and model confidence (inverse temperature). Through case studies spanning instruction understanding, translation and in-context learning (ICL), we uncover interesting findings, such as when Jacobian Scopes point to implicit political biases. We believe that our proposed methods also shed light on recently debated mechanisms underlying in-context time-series forecasting. Our code and interactive demonstrations are publicly available at https://github.com/AntonioLiu97/JacobianScopes.

</details>


### [18] [Learning Domain Knowledge in Multimodal Large Language Models through Reinforcement Fine-Tuning](https://arxiv.org/abs/2601.16419)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CL

TL;DR: 文本提示注入对MMLMs在专门领域的提升有限，需通过优化层面的域知识整合来实现显著改进。


<details>
  <summary>Details</summary>
Motivation: 在遥感、医学等专业领域，现有MLLMs对域先验的利用不足，单纯的文本指令/提示难以有效注入领域知识。

Method: 提出基于强化微调的框架，将域知识编码为领域信息约束和奖励信号，直接嵌入学习目标以影响输出空间行为。

Result: 在多个遥感与医学数据集上获得显著性能提升，达到或超越多模态领域任务的当前最佳水平。

Conclusion: 验证优化层面的域知识整合的必要性，揭示文本条件化在当前MLLM中的局限性。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities in multimodal perception and understanding tasks. However, their effectiveness in specialized domains, such as remote sensing and medical imaging, remains limited. A natural approach to domain adaptation is to inject domain knowledge through textual instructions, prompts, or auxiliary captions. Surprisingly, we find that such input-level domain knowledge injection yields little to no improvement on scientific multimodal tasks, even when the domain knowledge is explicitly provided. This observation suggests that current MLLMs fail to internalize domain-specific priors through language alone, and that domain knowledge must be integrated at the optimization level. Motivated by this insight, we propose a reinforcement fine-tuning framework that incorporates domain knowledge directly into the learning objective. Instead of treating domain knowledge as descriptive information, we encode it as domain-informed constraints and reward signals, shaping the model's behavior in the output space. Extensive experiments across multiple datasets in remote sensing and medical domains consistently demonstrate good performance gains, achieving state-of-the-art results on multimodal domain tasks. Our results highlight the necessity of optimization-level domain knowledge integration and reveal a fundamental limitation of textual domain conditioning in current MLLMs.

</details>


### [19] [Exploring the Effects of Alignment on Numerical Bias in Large Language Models](https://arxiv.org/abs/2601.16444)
*Ayako Sato,Hwichan Kim,Zhousi Chen,Masato Mita,Mamoru Komachi*

Main category: cs.CL

TL;DR: 对评估者LLM的数值偏差及其与对齐的因果关系进行实验分析，发现分数范围调整最能缓解偏差并提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估者LLM的数值评分往往存在偏差，可能由指令对齐与偏好对齐降低输出多样性造成，需阐明原因并提出缓解策略。

Method: 比较未对齐与对齐的LLM输出；在对齐后尝试温度缩放、分布校准、分数范围调整等方法，评估偏差与性能变化。

Result: 对齐提升了数值偏差；分数范围调整在减少偏差和提升性能方面最有效，但仍是启发式。

Conclusion: 需要更优的分数范围选择及更鲁棒的缓解策略，未来工作应聚焦于系统性校准与评估框架。

Abstract: "LLM-as-a-judge," which utilizes large language models (LLMs) as evaluators, has proven effective in many evaluation tasks. However, evaluator LLMs exhibit numerical bias, a phenomenon where certain evaluation scores are generated disproportionately often, leading reduced evaluation performance. This study investigates the cause of this bias. Given that most evaluator LLMs are aligned through instruction tuning and preference tuning, and that prior research suggests alignment reduces output diversity, we hypothesize that numerical bias arises from alignment. To test this, we compare outputs from pre- and post-alignment LLMs, and observe that alignment indeed increases numerical bias. We also explore mitigation strategies for post-alignment LLMs, including temperature scaling, distribution calibration, and score range adjustment. Among these, score range adjustment is most effective in reducing bias and improving performance, though still heuristic. Our findings highlight the need for further work on optimal score range selection and more robust mitigation strategies.

</details>


### [20] [Mixing Expert Knowledge: Bring Human Thoughts Back To the Game of Go](https://arxiv.org/abs/2601.16447)
*Yichuan Ma,Linyang Li,Yongkang Chen,Peiji Li,Jiasheng Ye,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 提出LoGos，一种通过混合微调结构化Go专业知识数据与通用长链式思考数据的冷启动，再结合强化学习以整合领域专家知识与通用推理能力的大型语言模型，在Go对弈中达到近乎职业水平并具自然语言描述能力，显著超越现有LLMs。


<details>
  <summary>Details</summary>
Motivation: 当前通用LLMs在领域专门任务（如围棋Go）的推理与专业知识应用存在明显缺口，难以达到专业水平，限制在领域级应用的推进；需要在保持通用推理能力的同时融入领域专家知识。

Method: 先进行混合微调：使用结构化的Go专门知识数据与通用长Chain-of-Thought数据作为冷启动；随后通过强化学习将专家知识与通用推理能力融合，训练出LoGos。

Result: LoGos在Go对弈的自然语言推理与策略预测方面达到接近人类职业玩家的水平，显著优于现有所有LLMs。

Conclusion: 该工作证明了将通用大型语言模型的推理能力与领域专家知识结合的可行性，为Go等领域的高水平AI应用提供路径，并将发布大规模Go数据集与评测基准。

Abstract: Large language models (LLMs) have demonstrated exceptional performance in reasoning tasks such as mathematics and coding, matching or surpassing human capabilities. However, these impressive reasoning abilities face significant challenges in specialized domains. Taking Go as an example, although AlphaGo has established the high performance ceiling of AI systems in Go, mainstream LLMs still struggle to reach even beginner-level proficiency, let alone perform natural language reasoning. This performance gap between general-purpose LLMs and domain experts is significantly limiting the application of LLMs on a wider range of domain-specific tasks. In this work, we aim to bridge the divide between LLMs' general reasoning capabilities and expert knowledge in domain-specific tasks. We perform mixed fine-tuning with structured Go expertise and general long Chain-of-Thought (CoT) reasoning data as a cold start, followed by reinforcement learning to integrate expert knowledge in Go with general reasoning capabilities. Through this methodology, we present \textbf{LoGos}, a powerful LLM that not only maintains outstanding general reasoning abilities, but also conducts Go gameplay in natural language, demonstrating effective strategic reasoning and accurate next-move prediction. LoGos achieves performance comparable to human professional players, substantially surpassing all existing LLMs. Through this work, we aim to contribute insights on applying general LLM reasoning capabilities to specialized domains. We will release the first large-scale Go dataset for LLM training, the first LLM Go evaluation benchmark, and the first general LLM that reaches human professional-level performance in Go at: https://github.com/Entarochuan/LoGos.

</details>


### [21] [Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16462)
*Zhenghao Liu,Mingyan Wu,Xinze Li,Yukun Yan,Shuo Wang,Cheng Yang,Minghe Yu,Zheni Zeng,Maosong Sun*

Main category: cs.CL

TL;DR: A novel GraphAnchor approach for RAG that maintains an evolving knowledge graph to anchor key entities/relations during iterative retrieval, guiding subqueries and evaluation of knowledge sufficiency; final answer fuses retrieved docs and the evolved graph.


<details>
  <summary>Details</summary>
Motivation: To address the challenge in retrieval-augmented generation (RAG) of effectively integrating and interpreting scattered, noisy evidence, which can lead to hallucinations, by providing a structured, active knowledge index.

Method: Construct an active, evolving graph during iterative retrieval that anchors salient entities and relations; the graph is incrementally updated to reflect newly retrieved information and guides subsequent subqueries; the final answer is produced by jointly leveraging all retrieved documents and the final graph.

Result: Empirical evaluation on four multi-hop question answering benchmarks shows improved performance. GraphAnchor helps the LLM attend to dispersed information across documents more effectively; code and data are released on GitHub.

Conclusion: GraphAnchor provides a structured, evolving knowledge index that links evidence across documents, enhancing grounding and coordination of retrieval and reasoning in RAG systems, with demonstrated gains on multi-hop QA.

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge for existing RAG systems. In this paper, we propose GraphAnchor, a novel Graph-Anchored Knowledge Indexing approach that reconceptualizes graph structures from static knowledge representations into active, evolving knowledge indices. GraphAnchor incrementally updates a graph during iterative retrieval to anchor salient entities and relations, yielding a structured index that guides the LLM in evaluating knowledge sufficiency and formulating subsequent subqueries. The final answer is generated by jointly leveraging all retrieved documents and the final evolved graph. Experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of GraphAnchor, and reveal that GraphAnchor modulates the LLM's attention to more effectively associate key information distributed in retrieved documents. All code and data are available at https://github.com/NEUIR/GraphAnchor.

</details>


### [22] [Persona Jailbreaking in Large Language Models](https://arxiv.org/abs/2601.16466)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 提出并评估一种对抗性“个性编辑”攻击框架PHISH，在黑盒推理设定下通过用户历史输入逐步诱导LLM反向人格，评估在多领域的鲁棒性与成本，强调需提升对上下文的个性鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLMs在教育、心理健康与客户支持等领域需要稳定且一致的角色设定，但现有研究多关注叙事或角色扮演，忽略 adversarial 的对话历史对个性影响以及黑盒攻击的风险，存在鲁棒性薄弱的隐患。

Method: 提出PHISH框架，通过在用户查询中嵌入语义充足的线索，在黑盒、仅推理访问的条件下逐步诱导LLM呈现“反向人格”。定义攻击成功度量，在3个基准和8个LLM上评估；比较多轮对话下的效果；通过人类评估和LLM作为评估者的评价进行验证；提供代码与数据集。

Result: PHISH 能predictably地改变受试LLM的人格特质，并引发相关特质的协同变化；多轮场景增强攻击效果；在高风险领域（心理健康、辅导、客户支持）同样有效且经人类与LLM-评估者验证；对推理基准的性能影响较小，总体效用基本保持；现有防护措施对持续攻击仍显脆弱；在3个基准、8个模型上具备可重复性与广泛性。

Conclusion: 揭示了面向上下文的个性操控的新脆弱性，强调需要对上下文鲁棒的个性安全进行研究与防御；项目公开代码与数据集以促进复现与对抗性研究。

Abstract: Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational history alone can reshape induced personas. Black-box persona manipulation remains unexplored, raising concerns for robustness in realistic interactions. In response, we introduce the task of persona editing, which adversarially steers LLM traits through user-side inputs under a black-box, inference-only setting. To this end, we propose PHISH (Persona Hijacking via Implicit Steering in History), the first framework to expose a new vulnerability in LLM safety that embeds semantically loaded cues into user queries to gradually induce reverse personas. We also define a metric to quantify attack success. Across 3 benchmarks and 8 LLMs, PHISH predictably shifts personas, triggers collateral changes in correlated traits, and exhibits stronger effects in multi-turn settings. In high-risk domains mental health, tutoring, and customer support, PHISH reliably manipulates personas, validated by both human and LLM-as-Judge evaluations. Importantly, PHISH causes only a small reduction in reasoning benchmark performance, leaving overall utility largely intact while still enabling significant persona manipulation. While current guardrails offer partial protection, they remain brittle under sustained attack. Our findings expose new vulnerabilities in personas and highlight the need for context-resilient persona in LLMs. Our codebase and dataset is available at: https://github.com/Jivnesh/PHISH

</details>


### [23] [DeepEra: A Deep Evidence Reranking Agent for Scientific Retrieval-Augmented Generated Question Answering](https://arxiv.org/abs/2601.16478)
*Haotian Chen,Qingqing Long,Siyu Pu,Xiao Luo,Wei Ju,Meng Xiao,Yuanchun Zhou,Jianghua Zhao,Xuezhi Wang*

Main category: cs.CL

TL;DR: DeepEra 提出通过整合逐步推理的证据重排序，解决两阶段 RAG 中语义相似但逻辑无关的问题，建立 SciRAG-SSLI 数据集（约30万 SciQA 实例，覆盖 10 主题，基于 1000 万级语料），实验表明优于领先重排器，首次系统研究两阶段 RAG 框架中的显著 SSLI 问题并给出实证。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索的科学问答系统易被语义相近但逻辑不相关的上下文误导，导致事实性错误和幻觉，需更严格的证据评估与大规模、具挑战性的数据集来检验逻辑鲁棒性与事实 grounding。

Method: 提出 DeepEra，嵌入逐步推理以增强证据筛选的逻辑评估；构建 SciRAG-SSLI 数据集，综合自然检索上下文与系统生成的干扰项以测试逻辑鲁棒性；在两阶段 RAG 框架中对比与评估与领先重排器的表现。

Result: 实验显示 DeepEra 在证据重排方面优于主流重排器，SciRAG-SSLI 能有效揭示 SSLI 问题；这是首次对两阶段 RAG 框架中显著的 SSLI 问题进行系统研究并给出实证。

Conclusion: 本文首次系统研究并验证两阶段 RAG 框架中不可忽视的 SSLI 问题，提出的 DeepEra 显著提升证据重排效果，SciRAG-SSLI 为相关研究提供大规模基准。

Abstract: With the rapid growth of scientific literature, scientific question answering (SciQA) has become increasingly critical for exploring and utilizing scientific knowledge. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating knowledge from external sources, thereby providing credible evidence for scientific question answering. But existing retrieval and reranking methods remain vulnerable to passages that are semantically similar but logically irrelevant, often reducing factual reliability and amplifying hallucinations.To address this challenge, we propose a Deep Evidence Reranking Agent (DeepEra) that integrates step-by-step reasoning, enabling more precise evaluation of candidate passages beyond surface-level semantics. To support systematic evaluation, we construct SciRAG-SSLI (Scientific RAG - Semantically Similar but Logically Irrelevant), a large-scale dataset comprising about 300K SciQA instances across 10 subjects, constructed from 10M scientific corpus. The dataset combines naturally retrieved contexts with systematically generated distractors to test logical robustness and factual grounding. Comprehensive evaluations confirm that our approach achieves superior retrieval performance compared to leading rerankers. To our knowledge, this work is the first to comprehensively study and empirically validate innegligible SSLI issues in two-stage RAG frameworks.

</details>


### [24] [TL-GRPO: Turn-Level RL for Reasoning-Guided Iterative Optimization](https://arxiv.org/abs/2601.16480)
*Peiji Li,Linyang Li,Handa Sun,Wenjin Mai,Yongkang Chen,Xiaozhe Li,Yue Shen,Yichuan Ma,Yiliu Sun,Jiaxi Cao,Zhishu He,Bo Wang,Xiaoqing Zheng,Zhaori Bi,Xipeng Qiu,Qipeng Guo,Kai Chen,Dahua Lin*

Main category: cs.CL

TL;DR: 提出 Turn-Level GRPO (TL-GRPO)，一种轻量化 RL 算法，用于迭代优化任务中的逐轮（turn-level）优化，具有相同环境状态的连续交互特性。通过逐轮分组采样实现细粒度优化，在模拟环境下的类比电路容量大小（ACS）任务上优于标准 GRPO 与贝叶斯优化；以 TL-GRPO 训练的 30B 模型在相同仿真预算下达到 ACS 任务的最新最佳性能，具备良好泛化与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于 GRPO 的方法难以在需要在同一环境状态下进行逐轮精细优化的迭代优化任务中实现粒度更细的策略优化，且以最优轮次奖励而非累计回报来衡量结果。黑箱优化方法则可能忽略已有推理能力与先验知识。需要一种能在保持环境信息复用的前提下进行逐轮优化的策略。

Method: 提出 Turn-Level GRPO (TL-GRPO)；通过 turn-level group sampling 实现逐轮级别的策略优化，兼容与同一环境状态的多轮交互特性；在需要多次仿真和领域知识的模拟任务（ACS）上进行评估，与标准 GRPO 与贝叶斯优化方法对比。并在 TL-GRPO 框架下训练一个 30B 模型，验证其在相同仿真预算下的性能。

Result: TL-GRPO 在多种规格的 ACS 任务中优于标准 GRPO 与贝叶斯优化；使用 TL-GRPO 训练的 30B 模型在同一仿真预算下实现 ACS 任务的最新最佳性能，展现出良好的泛化能力与实际应用价值。

Conclusion: TL-GRPO 成功填补了迭代优化任务中对逐轮粒度优化的空白，证明了在保留环境状态信息的前提下进行逐轮策略优化的有效性与高效性，并具备对其他需要多轮交互的科学与工程任务的广泛适用性。

Abstract: Large language models have demonstrated strong reasoning capabilities in complex tasks through tool integration, which is typically framed as a Markov Decision Process and optimized with trajectory-level RL algorithms such as GRPO. However, a common class of reasoning tasks, iterative optimization, presents distinct challenges: the agent interacts with the same underlying environment state across turns, and the value of a trajectory is determined by the best turn-level reward rather than cumulative returns. Existing GRPO-based methods cannot perform fine-grained, turn-level optimization in such settings, while black-box optimization methods discard prior knowledge and reasoning capabilities. To address this gap, we propose Turn-Level GRPO (TL-GRPO), a lightweight RL algorithm that performs turn-level group sampling for fine-grained optimization. We evaluate TL-GRPO on analog circuit sizing (ACS), a challenging scientific optimization task requiring multiple simulations and domain expertise. Results show that TL-GRPO outperforms standard GRPO and Bayesian optimization methods across various specifications. Furthermore, our 30B model trained with TL-GRPO achieves state-of-the-art performance on ACS tasks under same simulation budget, demonstrating both strong generalization and practical utility.

</details>


### [25] [Timely Machine: Awareness of Time Makes Test-Time Scaling Agentic](https://arxiv.org/abs/2601.16486)
*Yichuan Ma,Linyang Li,Yongkang chen,Peiji Li,Xiaozhe Li,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: Timely Machine redefines test-time as wall-clock time for agentic reasoning, introducing Timely-Eval benchmark and Timely-RL to optimize performance under time budgets; findings show model size and tool latency mediate performance, with RL improving time-budget awareness.


<details>
  <summary>Details</summary>
Motivation: Existing test-time scaling relies on generation length, which breaks down when frequent tool calls introduce variable latency. A wall-clock time perspective is needed to evaluate and improve agentic reasoning under realistic time constraints.

Method: Propose Timely Machine framework for time-aware reasoning; create Timely-Eval benchmark covering high-frequency and low-frequency tool calls and time-constrained tasks; vary tool latency to study effects; apply Timely-RL with cold-start supervised fine-tuning followed by reinforcement learning to improve temporal planning.

Result: Smaller models gain from fast feedback via more interactions; larger models excel under high-latency settings due to higher-quality interactions; many existing models fail to adapt reasoning to time budgets; Timely-RL consistently improves performance across Timely-Eval by enhancing time-budget awareness.

Conclusion: Redefining test-time scaling as wall-clock time offers a new perspective on agentic reasoning; Timely-RL provides a practical method to improve temporal planning and performance under time constraints.

Abstract: As large language models (LLMs) increasingly tackle complex reasoning tasks, test-time scaling has become critical for enhancing capabilities. However, in agentic scenarios with frequent tool calls, the traditional generation-length-based definition breaks down: tool latency decouples inference time from generation length. We propose Timely Machine, redefining test-time as wall-clock time, where models dynamically adjust strategies based on time budgets. We introduce Timely-Eval, a benchmark spanning high-frequency tool calls, low-frequency tool calls, and time-constrained reasoning. By varying tool latency, we find smaller models excel with fast feedback through more interactions, while larger models dominate high-latency settings via superior interaction quality. Moreover, existing models fail to adapt reasoning to time budgets. We propose Timely-RL to address this gap. After cold-start supervised fine-tuning, we use reinforcement learning to enhance temporal planning. Timely-RL improves time budget awareness and consistently boosts performance across Timely-Eval. We hope our work offers a new perspective on test-time scaling for the agentic era.

</details>


### [26] [MRAG: Benchmarking Retrieval-Augmented Generation for Bio-medicine](https://arxiv.org/abs/2601.16503)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出 MRAG 基准与 MRAG-Toolkit，面向医学领域的 RAG 评估；跨英中语言任务，使用 Wikipedia 与 PubMed 构建语料；实验证明 RAG 提高可靠性，但检索策略、模型规模和提示策略影响性能；对长期问答可读性略有下降；计划以 CC BY-4.0 发布数据集与工具包。


<details>
  <summary>Details</summary>
Motivation: 医学领域缺乏系统的 RAG 评估基准，难以在多语言场景下比较方法；需要一个可扩展的工具箱来系统性地研究 RAG 组件对结果的影响。

Method: 构建 MRAG 基准，覆盖中英多任务；使用 Wikipedia 与 PubMed 构筑检索语料；开发 MRAG-Toolkit 以便对检索、合并、推理等组件进行实验；在多任务上评估不同检索策略、模型规模和提示策略的影响。

Result: RAG 增强了 LLM 的可靠性；检索策略、模型规模和提示策略显著影响性能；RAG 提高有用性与推理质量，但对长问答的可读性可能略有下降。

Conclusion: 将 MRAG-Bench 的数据集和工具包以 CC BY-4.0 发布，以促进学术界与工业界应用；为医学领域的多语言 RAG 研究提供基准与实验平台。

Abstract: While Retrieval-Augmented Generation (RAG) has been swiftly adopted in scientific and clinical QA systems, a comprehensive evaluation benchmark in the medical domain is lacking. To address this gap, we introduce the Medical Retrieval-Augmented Generation (MRAG) benchmark, covering various tasks in English and Chinese languages, and building a corpus with Wikipedia and Pubmed. Additionally, we develop the MRAG-Toolkit, facilitating systematic exploration of different RAG components. Our experiments reveal that: (a) RAG enhances LLM reliability across MRAG tasks. (b) the performance of RAG systems is influenced by retrieval approaches, model sizes, and prompting strategies. (c) While RAG improves usefulness and reasoning quality, LLM responses may become slightly less readable for long-form questions. We will release the MRAG-Bench's dataset and toolkit with CCBY-4.0 license upon acceptance, to facilitate applications from both academia and industry.

</details>


### [27] [LOGICAL-COMMONSENSEQA: A Benchmark for Logical Commonsense Reasoning](https://arxiv.org/abs/2601.16504)
*Obed Junias,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: 提出 LOGICAL-COMMONSENSEQA，将常识推理从单标签转为由原子陈述对构成的逻辑组合，使用 AND、OR、NEITHER/NOR 等可控运算符，揭示模型在组合推理中的局限，尤其是在否定问题上的显著劣势。


<details>
  <summary>Details</summary>
Motivation: 现有基准多以单标签评估，难以区分 statements 的联合可置信性、相互排斥性或共同不可置信性；需要一个可控的、可组合的常识推理框架来评估和推动更高层次的组合性推理。

Method: 把常识推理重设为对原子陈述对的逻辑组合任务，定义 plausibility-level 运算符（AND、OR、NEITHER/NOR），并构建一个对应的数据集 LOGICAL-COMMONSENSEQA；对指令微调、推理专用微调以及精细微调模型，在零-shot、少样本、链式推理提示下进行评估。

Result: 模型在合取（AND）推理上表现尚可，在析取（OR）推理上中等，在否定（NEITHER/NOR）的问法上出现显著下降；整体揭示模型存在基本的推理能力和组合性限制。

Conclusion: LOGICAL-COMMONSENSEQA 提供一个受控的框架，用于揭示和推动跨原子陈述的逻辑组合推理能力，帮助分析现有模型的局限并为未来改进提供方向。

Abstract: Commonsense reasoning often involves evaluating multiple plausible interpretations rather than selecting a single atomic answer, yet most benchmarks rely on single-label evaluation, obscuring whether statements are jointly plausible, mutually exclusive, or jointly implausible. We introduce LOGICAL-COMMONSENSEQA, a benchmark that re-frames commonsense reasoning as logical composition over pairs of atomic statements using plausibility-level operators (AND, OR, NEITHER/NOR). Evaluating instruction-tuned, reasoning-specialized, and fine-tuned models under zero-shot, few-shot, and chain-of-thought prompting, we find that while models perform reasonably on conjunctive and moderately on disjunctive reasoning, performance degrades sharply on negation-based questions. LOGICAL-COMMONSENSEQA exposes fundamental reasoning limitations and provides a controlled framework for advancing compositional commonsense reasoning.

</details>


### [28] [Is Length Really A Liability? An Evaluation of Multi-turn LLM Conversations using BoolQ](https://arxiv.org/abs/2601.16508)
*Karl Neergaard,Le Qiu,Emmanuele Chersoni*

Main category: cs.CL

TL;DR: 单轮评测不足以发现对话长度和分层引导对回答真实性的影响，需通过多轮对话进行评估。


<details>
  <summary>Details</summary>
Motivation: 探究对话长度是否影响回答正确性，以及单轮评估是否能捕捉真实部署中的风险；在 BoolQ 数据集上比较三种大型语言模型，揭示静态评估的局限。

Method: 在 BoolQ 数据集上对三种 LLM 进行多轮对话评估，改变对话长度和分层引导（scaffolding），观察模型在不同条件下的表现与脆弱性。

Result: 三种模型呈现特定于模型的脆弱性，这些脆弱性在单轮测试中不可见；对话长度和分层引导对结果有显著影响，揭示了长度依赖和分层特异效应。

Conclusion: 静态评估存在本质性局限，可能掩盖部署相关的脆弱性，必须在多轮对话情景中进行评估以获得更真实的风险评估。

Abstract: Single-prompt evaluations dominate current LLM benchmarking, yet they fail to capture the conversational dynamics where real-world harm occurs. In this study, we examined whether conversation length affects response veracity by evaluating LLM performance on the BoolQ dataset under varying length and scaffolding conditions. Our results across three distinct LLMs revealed model-specific vulnerabilities that are invisible under single-turn testing. The length-dependent and scaffold-specific effects we observed demonstrate a fundamental limitation of static evaluations, as deployment-relevant vulnerabilities could only be spotted in a multi-turn conversational setting.

</details>


### [29] [Retrieve-Refine-Calibrate: A Framework for Complex Claim Fact-Checking](https://arxiv.org/abs/2601.16555)
*Mingwei Sun,Qianlong Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 提出了Retrieve-Refine-Calibrate (RRC) 框架，用LLMs实现基于实体驱动的证据检索、证据精炼和预测校准的事实核查方法，在HOVER和FEVEROUS-S数据集上优于基线。


<details>
  <summary>Details</summary>
Motivation: 解耦的分解式核查容易引入无关实体/证据的噪声，降低核查准确性；需要更精准的证据选择、信息过滤与结果校准来提升鲁棒性。

Method: 1) 识别并提取 claim 中的实体，检索与实体相关的证据；2) 根据 claim 对检索证据进行精炼，去除无关信息；3) 对低置信预测进行再评估以校准结果。

Result: 在两个广泛使用的事实核查数据集 HOVER 与 FEVEROUS-S 上，RRC 框架相较于竞争基线展现出 superior performance（具体指标未在摘要中披露）。

Conclusion: 通过 Retrieve-Refine-Calibrate 三阶段流程，显著降低因分解带来的噪声、提升核查准确性和鲁棒性；该方法适用于基于 LLM 的事实核查任务。

Abstract: Fact-checking aims to verify the truthfulness of a claim based on the retrieved evidence. Existing methods typically follow a decomposition paradigm, in which a claim is broken down into sub-claims that are individually verified. However, the decomposition paradigm may introduce noise to the verification process due to irrelevant entities or evidence, ultimately degrading verification accuracy. To address this problem, we propose a Retrieve-Refine-Calibrate (RRC) framework based on large language models (LLMs). Specifically, the framework first identifies the entities mentioned in the claim and retrieves evidence relevant to them. Then, it refines the retrieved evidence based on the claim to reduce irrelevant information. Finally, it calibrates the verification process by re-evaluating low-confidence predictions. Experiments on two popular fact-checking datasets (HOVER and FEVEROUS-S) demonstrate that our framework achieves superior performance compared with competitive baselines.

</details>


### [30] [AuroraEdge-V-2B: A Faster And Stronger Edge Visual Large Language Model](https://arxiv.org/abs/2601.16615)
*Xiang Chen*

Main category: cs.CL

TL;DR: 提出 AuroraEdge-V-2B，一种2B参数的视觉大语言模型，面向边缘部署，结合压缩-融合方法提高推理效率；在相同参数规模下，在9项基准测试中优于对比模型，且可显著减少视觉 token 数和 FLOPs。


<details>
  <summary>Details</summary>
Motivation: 工业生产场景对边缘端、低延迟的 VLLMs 需求日益增强；现有 VLLMs 参数规模大、算力要求高、推理慢，难以直接部署于边缘设备；需要更紧凑、速度更快、适合边缘的模型及有效的推理加速方法。

Method: 提出 AuroraEdge-V-2B 架构，2B 参数，采用压缩-融合策略以减少视觉 token 数并降低推理成本；面向边缘部署，提升实时性；对比同参数规模的模型在基准测试中的表现。

Result: 在9项同参数量对比中获得更高分数（如 Qwen2-VL-2B、Qwen2.5-VL-3B、InternVL-2.5-2B 等），并通过减少视觉 token 数实现推理 FLOPs 降低约一半，提升边缘场景的可用性与性价比。

Conclusion: AuroraEdge-V-2B 展示了高效、可在边缘端部署的视觉语言模型的可行性，压缩-融合策略是实现高效推理的关键，适合工业应用场景。

Abstract: Recently, due to the advancement of multimodal technology, people are attempting to use visual large language models (VLLMs) in industrial production. Many deep learning models (DLMs) deployed in the production environment are gradually being replaced by VLLMs. Compared with DLMs, VLLMs have some advantages in industrial applications: (1) Their strong generalization ability enables them to perform well across a wide range of tasks. (2) They are flexible and can deal with unfamiliar samples through context learning quickly. However, VLLMs also have obvious drawbacks: (1) VLLMs do not perform as well as custom-developed DLMs in specific domains. (2) The number of parameters in VLLMs is generally quite large, and their deployment requires substantial computational resources. (3) VLLMs generally operate much slower than DLMs, making real-time response challenging to achieve. To better utilize VLLMs in industrial applications, we introduce AuroraEdge-V-2B in this work, a compact, robust, and high-speed VLLM designed for edge deployment. To make the model run faster, we also propose a compression-fusion method to improve inference efficiency. AuroraEdge-V-2B has the following notable features: (1) Easy deployment and faster: It has only 2B parameters and is highly suitable for edge deployment, offering better real-time performance. (2) Fewer visual tokens and cheaper: It significantly reduces the number of visual tokens in the decoding process, thereby reducing the floating-point operations by half during inference and making it cheaper to use. (3) Strong performance: It gets a higher score on 9 benchmarks than models with the same number of parameter (e.g., Qwen2-VL-2B, Qwen2.5-VL-3B, InternVL-2.5-2B).

</details>


### [31] [PROST-LLM: Progressively Enhancing the Speech-to-Speech Translation Capability in LLMs](https://arxiv.org/abs/2601.16618)
*Jing Xu,Jiaqi Wang,Daxin Tan,Xiao Chen*

Main category: cs.CL

TL;DR: 通过渐进式训练和自监督数据生成，PROST-LLM显著提升LLM在语音到语音翻译（S2ST）上的能力。


<details>
  <summary>Details</summary>
Motivation: 解决S2ST数据稀缺导致的性能不足，利用CVSS语料和自监督偏好学习来提升LLM的跨模态翻译能力。

Method: 分阶段策略：1) 在CVSS语料上进行三任务学习和模态链式设计对LLM进行初步微调；2) 基于微调模型通过自采样和回译生成偏好对；3) 使用偏好对进行偏好优化以进一步提升S2ST能力。

Result: 大量实验结果表明该方法有效，显著提升S2ST能力，相较基线表现更优（未给出具体指标）。

Conclusion: PROST-LLM提供了一条渐进、数据高效的路径来提升S2ST性能，结合模态链式设计、自监督数据生成和偏好优化。

Abstract: Although Large Language Models (LLMs) excel in many tasks, their application to Speech-to-Speech Translation (S2ST) is underexplored and hindered by data scarcity. To bridge this gap, we propose PROST-LLM (PROgressive Speech-to-speech Translation) to enhance the S2ST capabilities in LLMs progressively. First, we fine-tune the LLMs with the CVSS corpus, employing designed tri-task learning and chain of modality methods to boost the initial performance. Then, leveraging the fine-tuned model, we generate preference pairs through self-sampling and back-translation without human evaluation. Finally, these preference pairs are used for preference optimization to enhance the model's S2ST capability further. Extensive experiments confirm the effectiveness of our proposed PROST-LLM in improving the S2ST capability of LLMs.

</details>


### [32] [How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants](https://arxiv.org/abs/2601.16621)
*Xueyang Feng,Weinan Gan,Xu Chen,Quanyu Dai,Yong Liu*

Main category: cs.CL

TL;DR: 提出 RPEval 基准与 RP-Reasoner，研究个性化记忆对大型语言模型的双重影响，帮助筛选性地整合个性化信息以提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 探究个性化记忆在提升与干扰用户意图理解之间的双重作用，亟需一个能系统评估与抑制非理性个性化的基准和方法。

Method: 构建 RPEval（个性化意图推理数据集与多粒度评估协议），开展错误模式分析，提出 RP-Reasoner 将记忆利用视为语用推理，进行有选择的个性化信息整合。

Result: RP-Reasoner 在 RPEval 上显著优于精心设计的基线；在大规模商用个性化助手中解决了约 80% 的坏案例，展示了语用推理在缓解非理性个性化中的潜力。

Conclusion: 以语用推理为核心的记忆利用策略有效减缓非理性个性化，RP-Reasoner 与基准可为个性化对话系统的安全与用户体验改进提供有力工具。

Abstract: Large language model (LLM)-powered assistants have recently integrated memory mechanisms that record user preferences, leading to more personalized and user-aligned responses. However, irrelevant personalized memories are often introduced into the context, interfering with the LLM's intent understanding. To comprehensively investigate the dual effects of personalization, we develop RPEval, a benchmark comprising a personalized intent reasoning dataset and a multi-granularity evaluation protocol. RPEval reveals the widespread phenomenon of irrational personalization in existing LLMs and, through error pattern analysis, illustrates its negative impact on user experience. Finally, we introduce RP-Reasoner, which treats memory utilization as a pragmatic reasoning process, enabling the selective integration of personalized information. Experimental results demonstrate that our method significantly outperforms carefully designed baselines on RPEval, and resolves 80% of the bad cases observed in a large-scale commercial personalized assistant, highlighting the potential of pragmatic reasoning to mitigate irrational personalization. Our benchmark is publicly available at https://github.com/XueyangFeng/RPEval.

</details>


### [33] [MultiLexNorm++: A Unified Benchmark and a Generative Model for Lexical Normalization for Asian Languages](https://arxiv.org/abs/2601.16623)
*Weerayut Buaphet,Thanh-Nhi Nguyen,Risa Kondo,Tomoyuki Kajiwara,Yumin Kim,Jimin Lee,Hwanhee Lee,Holy Lovenia,Peerat Limkonchotiwat,Sarana Nutanong,Rob Van der Goot*

Main category: cs.CL

TL;DR: 扩展 MultiLexNorm 覆盖 5 种亚洲语言及 4 种书写系统，揭示现有 SOTA 在新语言上的不足，提出基于大语言模型（LLM）的新架构以提升鲁棒性，并对残留错误进行分析以指明未来方向。


<details>
  <summary>Details</summary>
Motivation: NLP 的社媒文本存在多样的语言变体和社会方言，现有以印欧语系和拉丁字母为主的基准数据集无法覆盖广泛的语言多样性，亟需评估并提升跨语言、跨脚本的词汇标准化（lexical normalization）能力。

Method: 在 MultiLexNorm 基础上扩展至包含 5 种亚洲语言（来自不同语言家族）及 4 种脚本；比较现有 SOTA 模型在新语言上的表现，提出基于大语言模型的改进架构，并进行实验评估；对错误类型进行分析以指明未来工作。

Result: 发现原有 SOTA 在新语言上的性能显著下降；基于 LLM 的新架构在鲁棒性方面表现更好；通过错误分析指出仍有若干方面需要改进，如跨脚本的一致性、低资源语言的字形变体处理等。

Conclusion: 扩展数据覆盖范围可提升跨语言词汇标准化的评估与研究；LLM 驱动的架构对多语言、多脚本场景更具鲁棒性，未来工作应聚焦更细粒度的错误分析和跨域迁移性提升。

Abstract: Social media data has been of interest to Natural Language Processing (NLP) practitioners for over a decade, because of its richness in information, but also challenges for automatic processing. Since language use is more informal, spontaneous, and adheres to many different sociolects, the performance of NLP models often deteriorates. One solution to this problem is to transform data to a standard variant before processing it, which is also called lexical normalization. There has been a wide variety of benchmarks and models proposed for this task. The MultiLexNorm benchmark proposed to unify these efforts, but it consists almost solely of languages from the Indo-European language family in the Latin script. Hence, we propose an extension to MultiLexNorm, which covers 5 Asian languages from different language families in 4 different scripts. We show that the previous state-of-the-art model performs worse on the new languages and propose a new architecture based on Large Language Models (LLMs), which shows more robust performance. Finally, we analyze remaining errors, revealing future directions for this task.

</details>


### [34] [Sycophancy Hides Linearly in the Attention Heads](https://arxiv.org/abs/2601.16644)
*Rifo Genadi,Munachiso Nwadike,Nurdaulet Mukhituly,Hilal Alquabeh,Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究发现正确对错之间的 sycophancy 信号在多头注意力激活中最易线性分离。通过线性探针分析残差流、MLP 与注意力层，在中间层注意力头的稀疏子集上对信号进行引导最有效。以 TruthfulQA 为基准数据，探针训练后能良好转移至其他事实性问答基准；与先前标注的“_truthful/真实_”方向重叠有限，表明事实准确性与对用户怀疑的抗拒来自相关但不同机制。进一步的注意力模式分析显示，关键头关注用户表达的疑虑，从而推动 sycophantic 转变。总体认为可通过基于注意力激活内部几何的简单线性干预来减轻 sycophancy。


<details>
  <summary>Details</summary>
Motivation: 揭示模型内部表征中 sycophancy 信号的几何结构，以及是否存在可通过线性方法干预以降低此现象的可行路径。

Method: 训练线性探针，分别放置于模型的残差流、MLP 与注意力层，用以检测正确-错误之间的线性可分性；分析不同层级的信号分布，并对探针引导在中间层注意力头进行实验；以 TruthfulQA 为基线数据评估探针的迁移性；将发现的方向与既有“truthful”方向进行对比；对注意力头的注意力模式进行分析以定位关键头。

Result: 在残差流与 MLP 层可观测到信号的线性可分性；对信号进行有效引导的最好效果出现在中间层的一组稀疏注意力头；用 TruthfulQA 训练的探针能较好迁移到其他事实性问答数据集；与先前的“ truthful”方向重叠有限；影响力头往往聚焦于用户表达怀疑的片段，推动 sycophantic 转变；总体上表明通过简单的线性干预即可在注意力激活的几何中减小 sycophancy。

Conclusion: 通过利用注意力激活的内部几何结构，存在可行的简单线性干预来缓解 sycophancy，尤其在选定的中间层注意力头上实现较显著的影响。

Abstract: We find that correct-to-incorrect sycophancy signals are most linearly separable within multi-head attention activations. Motivated by the linear representation hypothesis, we train linear probes across the residual stream, multilayer perceptron (MLP), and attention layers to analyze where these signals emerge. Although separability appears in the residual stream and MLPs, steering using these probes is most effective in a sparse subset of middle-layer attention heads. Using TruthfulQA as the base dataset, we find that probes trained on it transfer effectively to other factual QA benchmarks. Furthermore, comparing our discovered direction to previously identified "truthful" directions reveals limited overlap, suggesting that factual accuracy, and deference resistance, arise from related but distinct mechanisms. Attention-pattern analysis further indicates that the influential heads attend disproportionately to expressions of user doubt, contributing to sycophantic shifts. Overall, these findings suggest that sycophancy can be mitigated through simple, targeted linear interventions that exploit the internal geometry of attention activations.

</details>


### [35] [Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations](https://arxiv.org/abs/2601.16651)
*Lukas Hinterleitner,Loris Schoenegger,Benjamin Roth*

Main category: cs.CL

TL;DR: 贪婪选择的组件子集在大模型梯度的实例级解释中优于直接使用全梯度或随机投影，具备更好信息捕获且计算更高效。


<details>
  <summary>Details</summary>
Motivation: 高维梯度使得基于梯度的实例解释成本高且难以评估；需要一个系统性的降维策略，比较“选择少量架构信息组件”与“将全梯度投影到低维空间”的两种路径。

Method: 提出并实现两种降维策略：1）贪婪地从模型组件中选择一个小子集（与架构信息相关），2）将全梯度投影到低维空间。使用一个新颖基准对影响信息进行评估，任务为检索任务。

Result: 所选子集在保留对训练数据影响的信息方面优于全梯度和随机投影；并且在计算上也优于随机投影，证实了目标化的组件选择是一种在可行性和效果之间的折中策略。

Conclusion: 有针对性的组件选择为大模型的实例级解释提供了更可行的降维路径，能够在保持解释有效性的同时降低计算成本。

Abstract: Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.

</details>


### [36] [PLawBench: A Rubric-Based Benchmark for Evaluating LLMs in Real-World Legal Practice](https://arxiv.org/abs/2601.16669)
*Yuzhen Shi,Huanghai Liu,Yiran Hu,Gaojie Song,Xinran Xu,Yubo Ma,Tianyi Tang,Li Zhang,Qingjing Chen,Di Feng,Wenbo Lv,Weiheng Wu,Kexin Yang,Sen Yang,Wei Wang,Rongyao Shi,Yuanyang Qiu,Yuemeng Qi,Jingwen Zhang,Xiaoyu Sui,Yifan Chen,Yi Zhang,An Yang,Bowen Yu,Dayiheng Liu,Junyang Lin,Weixing Shen,Bing Zhao,Charles L. A. Clarke,Hu Wei*

Main category: cs.CL

TL;DR: PLawBench: a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice with 850 questions across 13 scenarios and ~12,500 rubric items for fine-grained legal reasoning; none of the evaluated models achieve strong performance.


<details>
  <summary>Details</summary>
Motivation: Existing legal benchmarks rely on simplified, standardized tasks and coarse metrics, failing to capture ambiguity, complexity, and reasoning demands of real legal practice; need evaluation aligned with real-world legal workflows.

Method: Construct PLawBench around three task categories (public legal consultation, practical case analysis, legal document generation); include 850 questions across 13 realistic scenarios with expert-crafted rubrics totaling ~12,500 rubric items; deploy an LLM-based evaluator aligned with human expert judgments; evaluate 10 state-of-the-art LLMs.

Result: None of the evaluated models achieve strong performance on PLawBench; reveals substantial gaps in fine-grained legal reasoning of current LLMs.

Conclusion: PLawBench provides a more realistic, multi-dimensional evaluation framework for legal LLMs and highlights the need for further advancement in legal reasoning capabilities and evaluation methodologies; data available at the provided repository.

Abstract: As large language models (LLMs) are increasingly applied to legal domain-specific tasks, evaluating their ability to perform legal work in real-world settings has become essential. However, existing legal benchmarks rely on simplified and highly standardized tasks, failing to capture the ambiguity, complexity, and reasoning demands of real legal practice. Moreover, prior evaluations often adopt coarse, single-dimensional metrics and do not explicitly assess fine-grained legal reasoning. To address these limitations, we introduce PLawBench, a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice scenarios. Grounded in real-world legal workflows, PLawBench models the core processes of legal practitioners through three task categories: public legal consultation, practical case analysis, and legal document generation. These tasks assess a model's ability to identify legal issues and key facts, perform structured legal reasoning, and generate legally coherent documents. PLawBench comprises 850 questions across 13 practical legal scenarios, with each question accompanied by expert-designed evaluation rubrics, resulting in approximately 12,500 rubric items for fine-grained assessment. Using an LLM-based evaluator aligned with human expert judgments, we evaluate 10 state-of-the-art LLMs. Experimental results show that none achieves strong performance on PLawBench, revealing substantial limitations in the fine-grained legal reasoning capabilities of current LLMs and highlighting important directions for future evaluation and development of legal LLMs. Data is available at: https://github.com/skylenage/PLawbench.

</details>


### [37] [Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach](https://arxiv.org/abs/2601.16724)
*Kevin Fan,Eric Yun*

Main category: cs.CL

TL;DR: 通过对 DeBERTa-v3 的微调在 ASAP 2.0 和 ELLIPSE 数据集上的偏见研究，提出对比学习（匹配文本对的三元组损失）以缓解 ESL 与母语写作的分数差异，显著降低高水平 ESL 的分数偏差，同时保持高斯加权 κ（QWK）0.76。


<details>
  <summary>Details</summary>
Motivation: AES 系统在高风险教育领域的对 ESL 学习者的算法偏见日益引起关注。现有基于 Transformer 的回归模型在母语语料上训练，容易将表层的 L2 语言特征与写作质量建立错配关联，导致对 ESL 的不公平评分。

Method: 在 ASAP 2.0 与 ELLIPSE 上对 DeBERTa-v3 进行微调，并提出对比学习的三元组构建策略：匹配作文对的对比学习。构建了 17,161 对匹配的作文对，使用 Triplet Margin Loss 对潜在表示进行对齐，使 ESL 与母语写作在潜在空间接近。

Result: 偏差降低 39.9%（差距降至 6.2%），同时保持 Quadratic Weighted Kappa（QWK）为 0.76。

Conclusion: 研究表明所提出的方法能让模型将句子复杂度与语法错误分离，不再对有效的 L2 句法结构进行惩罚，从而提高高水平 ESL 写作的评分公平性；未来工作可进一步扩大数据集、多维度偏差分析及在其他语言/任务上的推广。

Abstract: As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.

</details>


### [38] [Standardizing Longitudinal Radiology Report Evaluation via Large Language Model Annotation](https://arxiv.org/abs/2601.16753)
*Xinyi Wang,Grazziela Figueredo,Ruizhe Li,Xin Chen*

Main category: cs.CL

TL;DR: 提出基于大模型（LLM）的自动标注管线，用于 radiology 报告中的纵向信息，能够识别相关句子并提取疾病进展；在五种主流LLM上进行比较，选取 Qwen2.5-32B 对 95,169 份公开数据进行标注，构建标准化基准并评估七种报告生成模型，结果在纵向信息检测和疾病跟踪的 F1 上分别提升了11.3%和5.3%。


<details>
  <summary>Details</summary>
Motivation: 缺乏一致、可复现的纵向信息标注工具，现有标注方法耗时且难以迁移；需要标准化数据集来公平评估纵向信息相关的报告生成模型；大型语言模型具备捕捉细粒度语言和语义相似性的潜力，且可迁移至新场景。

Method: 建立一个两步式LLM标注管线：先筛选包含相关信息的句子，再提取疾病进展。对五种主流LLM进行比较并选出表现最佳的 Qwen2.5-32B，用其对 MIMIC-CXR 的95,169份报告进行自动标注，形成纵向信息和疾病跟踪的标注数据集；以此基准评估七种前沿报告生成模型的性能。

Result: 提出的LLM标注方法在纵向信息检测和疾病跟踪任务上分别达到比现有方案高11.3%和5.3%的F1分数；建立了一个大规模、标准化的标注数据集，作为评估报导生成模型的基准。

Conclusion: 基于LLM的标注管线可有效自动化标注纵向信息，提升标注质量并提供可重复的Benchmark，推动 radiology 报告生成与纵向分析的评估研究。

Abstract: Longitudinal information in radiology reports refers to the sequential tracking of findings across multiple examinations over time, which is crucial for monitoring disease progression and guiding clinical decisions. Many recent automated radiology report generation methods are designed to capture longitudinal information; however, validating their performance is challenging. There is no proper tool to consistently label temporal changes in both ground-truth and model-generated texts for meaningful comparisons. Existing annotation methods are typically labor-intensive, relying on the use of manual lexicons and rules. Complex rules are closed-source, domain specific and hard to adapt, whereas overly simple ones tend to miss essential specialised information. Large language models (LLMs) offer a promising annotation alternative, as they are capable of capturing nuanced linguistic patterns and semantic similarities without extensive manual intervention. They also adapt well to new contexts. In this study, we therefore propose an LLM-based pipeline to automatically annotate longitudinal information in radiology reports. The pipeline first identifies sentences containing relevant information and then extracts the progression of diseases. We evaluate and compare five mainstream LLMs on these two tasks using 500 manually annotated reports. Considering both efficiency and performance, Qwen2.5-32B was subsequently selected and used to annotate another 95,169 reports from the public MIMIC-CXR dataset. Our Qwen2.5-32B-annotated dataset provided us with a standardized benchmark for evaluating report generation models. Using this new benchmark, we assessed seven state-of-the-art report generation models. Our LLM-based annotation method outperforms existing annotation solutions, achieving 11.3\% and 5.3\% higher F1-scores for longitudinal information detection and disease tracking, respectively.

</details>


### [39] [Do LLM hallucination detectors suffer from low-resource effect?](https://arxiv.org/abs/2601.16766)
*Debtanu Datta,Mohan Kishore Chilukuri,Yash Kumar,Saptarshi Ghosh,Muhammad Bilal Zafar*

Main category: cs.CL

TL;DR: 低资源语言中，LLM幻觉检测器的降级幅度通常小于任务本身的降级；检测器在单语言和多语言场景鲁棒，但跨语言迁移需要语言内监督。


<details>
  <summary>Details</summary>
Motivation: 探究幻觉检测在跨语言和低资源场景中的鲁棒性，以评估检测器能否缓解低资源语言的幻觉风险。

Method: 在五项任务、三大领域（事实回忆、STEM、人文）、四个LLM与三个检测器上进行实验，比较英文与孟加拉等低资源语言的表现，包含单语言、跨语言与多语言设定。

Result: 低资源语言任务准确度显著下降，但检测器准确度下降往往比任务下降小；检测器在同语言和多语言设置中表现稳健，跨语言设置若无语言内监督则表现不足；模型内部可能仍编码不确定性信号。

Conclusion: 检测器仍有缓解低资源风险的潜力，需在目标语言进行监督训练以实现跨语言迁移，未来应加强跨语言迁移策略和对低资源语言的不确定性信号的利用。

Abstract: LLMs, while outperforming humans in a wide range of tasks, can still fail in unanticipated ways. We focus on two pervasive failure modes: (i) hallucinations, where models produce incorrect information about the world, and (ii) the low-resource effect, where the models show impressive performance in high-resource languages like English but the performance degrades significantly in low-resource languages like Bengali. We study the intersection of these issues and ask: do hallucination detectors suffer from the low-resource effect? We conduct experiments on five tasks across three domains (factual recall, STEM, and Humanities). Experiments with four LLMs and three hallucination detectors reveal a curious finding: As expected, the task accuracies in low-resource languages experience large drops (compared to English). However, the drop in detectors' accuracy is often several times smaller than the drop in task accuracy. Our findings suggest that even in low-resource languages, the internal mechanisms of LLMs might encode signals about their uncertainty. Further, the detectors are robust within language (even for non-English) and in multilingual setups, but not in cross-lingual settings without in-language supervision.

</details>


### [40] [Persuasion Tokens for Editing Factual Knowledge in LLMs](https://arxiv.org/abs/2601.16781)
*Paul Youssef,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 提出 P-Tokens，通过训练的特殊标记替代 IKE 演示，实现更高效的知识编辑，实验显示与 IKE 相当甚至优于 IKE，且对干扰项具鲁棒性，增加标记数量可提升性能，给出更实用的可扩展替代方案。


<details>
  <summary>Details</summary>
Motivation: 解决 IKE 需要大量事实性演示且占用大量上下文窗口的问题，寻求更高效、可扩展的知识编辑方法。

Method: 提出 P-Tokens：一组专门训练的标记，用以复制 IKE 演示的效果，减少对事实性演示的依赖；在两个编辑数据集和三种大模型上评估；分析对干扰项的鲁棒性以及标记数量对性能的影响。

Result: P-Tokens 的编辑性能与 IKE 相当，甚至在某些情形超过 IKE；对带有轻微负向影响的邻近事实的干扰具有鲁棒性；增加 P-Tokens 数量可提升性能。

Conclusion: P-Tokens 为 LLM 知识编辑提供一个更实用、可扩展的替代方案，缓解 IKE 的成本和上下文开销等局限。

Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.

</details>


### [41] [Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis](https://arxiv.org/abs/2601.16800)
*Gaurav Negi,MA Waskow,Paul Buitelaar*

Main category: cs.CL

TL;DR: 本研究探讨将大型语言模型（LLM）作为自动注释者与裁决者，用于细粒度观点分析（如 ASTE、ACOS），通过声明式注释流水线降低提示工程差异，并在多模型试验中实现较高的 IAA，从而降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 细粒度观点分析需要大量标注，成本高且领域间差异大；LLM 可作为自动注释工具以缓解数据稀缺与标注成本问题，且手工提示的变异性影响显著。

Method: 提出声明式注释流水线以降低提示工程的变异性；设计 LLM 的多标签裁决机制，输出最终注释；以不同规模的模型对 ASTE 与 ACOS 任务进行试验，评估 LLM 作为自动注释者和裁决者的可行性，关注跨注释者一致性（Inter-Annotator Agreement, IAA）。

Result: LLMs 能作为自动注释者与裁决者；各模型间的 IAA 结果较高，说明可用来自动生成细粒度观点数据集，并显著降低人工成本和工作量。

Conclusion: LLM 在细粒度观点数据集的自动标注领域具有可用性，提出的声明式流水线有助于减少提示设计的变异性与成本，具备在不同领域的推广潜力。

Abstract: Fine-grained opinion analysis of text provides a detailed understanding of expressed sentiments, including the addressed entity. Although this level of detail is sound, it requires considerable human effort and substantial cost to annotate opinions in datasets for training models, especially across diverse domains and real-world applications. We explore the feasibility of LLMs as automatic annotators for fine-grained opinion analysis, addressing the shortage of domain-specific labelled datasets. In this work, we use a declarative annotation pipeline. This approach reduces the variability of manual prompt engineering when using LLMs to identify fine-grained opinion spans in text. We also present a novel methodology for an LLM to adjudicate multiple labels and produce final annotations. After trialling the pipeline with models of different sizes for the Aspect Sentiment Triplet Extraction (ASTE) and Aspect-Category-Opinion-Sentiment (ACOS) analysis tasks, we show that LLMs can serve as automatic annotators and adjudicators, achieving high Inter-Annotator Agreement across individual LLM-based annotators. This reduces the cost and human effort needed to create these fine-grained opinion-annotated datasets.

</details>


### [42] [SoS: Analysis of Surface over Semantics in Multilingual Text-To-Image Generation](https://arxiv.org/abs/2601.16803)
*Carolin Holtermann,Florian Schneider,Anne Lauscher*

Main category: cs.CL

TL;DR: T2I 模型在多语言场景中普遍存在表层优先于语义的偏见（SoS），通过对171个文化身份、14种语言的提示、以及七个模型的系统评估，揭示了表层提示在编码器深层更明显且与刻板印象呈相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究指出 T2I 对输入语言高度敏感，导致同一语义但表层形式不同的提示产生文化刻板的图片，但缺乏跨语言、跨模型的系统分析。本研究提出 SoS（Surface-over-Semantics）并进行量化分析。

Method: 设计覆盖 171 种文化身份的提示，并将其翻译成 14 种语言，使用七个 T2I 模型进行评估。提出一个新颖的 SoS 度量方法，分析在不同语言、模型和文化上的 SoS 趋势，并考察编码器各层对该趋势的放大效果，以及其在视觉输出中的表现。

Result: 几乎所有模型（除一个）在至少两种语言中呈现强烈的表层偏向，且该效应在 T2I 文本编码器的层级中逐渐强化；表层倾向与刻板化视觉呈现之间存在显著相关性。

Conclusion: SoS 是跨语言、跨模型的普遍现象，语言层面的表述而非语义理解驱动偏见，给多语言场景下的公平性和安全性带来挑战，需通过设计、训练或后处理等途径进行缓解。

Abstract: Text-to-image (T2I) models are increasingly employed by users worldwide. However, prior research has pointed to the high sensitivity of T2I towards particular input languages - when faced with languages other than English (i.e., different surface forms of the same prompt), T2I models often produce culturally stereotypical depictions, prioritizing the surface over the prompt's semantics. Yet a comprehensive analysis of this behavior, which we dub Surface-over-Semantics (SoS), is missing. We present the first analysis of T2I models' SoS tendencies. To this end, we create a set of prompts covering 171 cultural identities, translated into 14 languages, and use it to prompt seven T2I models. To quantify SoS tendencies across models, languages, and cultures, we introduce a novel measure and analyze how the tendencies we identify manifest visually. We show that all but one model exhibit strong surface-level tendency in at least two languages, with this effect intensifying across the layers of T2I text encoders. Moreover, these surface tendencies frequently correlate with stereotypical visual depictions.

</details>


### [43] [Trapped in the past? Disentangling fluid and crystallized intelligence of large language models using chess](https://arxiv.org/abs/2601.16823)
*Leonard S. Pleiss,Maximilian Schiffer,Robert K. von Weizsäcker*

Main category: cs.CL

TL;DR: 以棋局为受控测试床，区分记忆化（晶化智力）与推理（流动智力），揭示当前LLMs在需要推理的任务上的局限性及对分布外任务的崩溃现象，尽管新模型有所提升，但边际收益递减，指出需超越纯规模的鲁棒泛化机制。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型在记忆与推理能力上的分布与极限，评估是否具备稳健的流动智力，以及仅扩大模型规模是否能提升系统泛化能力。

Method: 将棋作为受控测试床，利用棋局结构和可扩展的引擎评估，建立从训练语料的近似性到需要第一性原理推理的棋位分层；在不同推理强度下对多代GPT进行系统评估，比较分布内与分布外任务的表现。

Result: 结果显示：性能呈梯度下降，随着对流动智力需求的增加而下降；在分布外任务中表现降至随机水平；尽管更新的模型有所提升，但在分布外任务的改进显著放缓；推理增强推断的边际收益随分布接近性下降而下降；表明现有架构在系统泛化方面受限，需要超越仅依赖规模的机制。

Conclusion: 需要引入超越规模扩展的新的机制，以实现对鲁棒流动智力的稳健支撑。

Abstract: Large Language Models (LLMs) exhibit remarkable capabilities, yet it remains unclear to what extent these reflect sophisticated recall (crystallized intelligence) or reasoning ability (fluid intelligence). We introduce chess as a controlled testbed for disentangling these faculties. Leveraging the game's structure and scalable engine evaluations, we construct a taxonomy of positions varying in training corpus proximity--ranging from common states solvable by memorization to novel ones requiring first-principles reasoning. We systematically evaluate multiple GPT generations under varying reasoning intensities. Our analysis reveals a clear gradient: performance consistently degrades as fluid intelligence demands increase. Notably, in out-of-distribution tasks, performance collapses to random levels. While newer models improve, progress slows significantly for tasks outside the training distribution. Furthermore, while reasoning-augmented inference improves performance, its marginal benefit per token decreases with distributional proximity. These results suggest current architectures remain limited in systematic generalization, highlighting the need for mechanisms beyond scale to achieve robust fluid intelligence.

</details>


### [44] [LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems](https://arxiv.org/abs/2601.16890)
*João A. Leite,Olesya Razuvayevskaya,Kalina Bontcheva,Carolina Scarton*

Main category: cs.CL

TL;DR: 提出以说服技巧为手段的对抗性攻击框架，利用生成式大语言模型改写声明以误导事实核查系统，影响证据检索和验证，在 FEVER/FEVEROUS 上显著降低性能，强调需要更鲁棒的 AFC 系统。


<details>
  <summary>Details</summary>
Motivation: 自动化事实核查系统容易受到对抗性攻击，现有攻击多为噪声注入或语义改变，尚未充分利用说服技术在信息操控中的潜在威力。

Method: 提出一种新颖的“说服性对抗攻击”类框架，利用生成式大语言模型对声明进行改写，融入 15 种说服技法，分为 6 类，并采用解耦评估策略分别评估证据检索与声明验证的影响。

Result: 在 FEVER 和 FEVEROUS 基准上，说服攻击显著降低了验证性能与证据检索的准确性，证明说服技法是强有力的对抗攻击手段。

Conclusion: 需要构建更鲁棒的 AFC 系统以对抗说服性攻击，未来研究可聚焦于鲁棒性提升、对抗训练与证据分析等方向。

Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.

</details>


### [45] [Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias](https://arxiv.org/abs/2601.16934)
*Elias Schuhmacher,Andrianos Michail,Juri Opitz,Rico Sennrich,Simon Clematide*

Main category: cs.CL

TL;DR: 在嵌入式检索中，文档各部分的嵌入表征存在系统性偏差，导致早段和高资源语言（如英语）被过度反映，后段和低资源语言被边缘化。通过置换基于的评估框架量化该偏差，并提出推理时的注意力校准方法以更均匀地分布注意力，从而提升后段的可发现性。


<details>
  <summary>Details</summary>
Motivation: 确保文档的每一部分都能在嵌入表示中得到体现，量化并减轻跨段落和跨语言的偏差，从而提高长文档多段的检索公平性和覆盖率。

Method: 提出置换型评估框架来量化偏差；分析 pooling-token 嵌入中的前置注意力分布导致的前段偏置；提出推理时注意力校准方法以重新分配注意力，使其在文档位置上更加均匀。

Result: 研究发现长文多段中存在系统性位置和语言偏差：早段和高资源语言被过度表示，后段和低资源语言被边缘化；前端注意力导致该偏置；推理时的注意力校准有效提升后段的可发现性；提供评估框架与校准方法的开源实现。

Conclusion: 嵌入式检索的偏差可在推理阶段通过注意力重新分配得到缓解，从而提升多段文档的全面可发现性，相关工具已开源。

Abstract: To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers

</details>


### [46] [Strategies for Span Labeling with Large Language Models](https://arxiv.org/abs/2601.16946)
*Danil Semin,Ondřej Dušek,Zdeněk Kasner*

Main category: cs.CL

TL;DR: 提出 LogitMatch 的约束解码方法以确保生成输出严格对齐输入的有效跨度，并系统比较三类跨越策略，发现标记法最稳健，LogitMatch 在某些场景优于其他匹配方法。


<details>
  <summary>Details</summary>
Motivation: LLMs 缺乏对输入特定部分的显式引用，导致跨度标注的提示策略多样且结果不一致；需要一个系统的分类与改进解码机制。

Method: 将跨度标注策略分为三类：1) 对输入文本的标记（tagging）；2) 基于输入中跨度的数值位点索引（indexing）；3) 直接内容匹配（content matching）。提出 LogitMatch 作为受限解码技术，使输出映射到输入的有效跨度，四个任务上评估。

Result: 标记法作为稳健基线；LogitMatch 能解决内容匹配的跨度匹配问题，在对比的匹配方法中表现优越，在某些设置优于其他策略。

Conclusion: 系统化分析表明，结合约束解码的 LogitMatch 有助于提升生成式模型的跨度标注稳定性与一致性，提供可扩展的解码范式。

Abstract: Large language models (LLMs) are increasingly used for text analysis tasks, such as named entity recognition or error detection. Unlike encoder-based models, however, generative architectures lack an explicit mechanism to refer to specific parts of their input. This leads to a variety of ad-hoc prompting strategies for span labeling, often with inconsistent results. In this paper, we categorize these strategies into three families: tagging the input text, indexing numerical positions of spans, and matching span content. To address the limitations of content matching, we introduce LogitMatch, a new constrained decoding method that forces the model's output to align with valid input spans. We evaluate all methods across four diverse tasks. We find that while tagging remains a robust baseline, LogitMatch improves upon competitive matching-based methods by eliminating span matching issues and outperforms other strategies in some setups.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [47] [LLM-based Semantic Search for Conversational Queries in E-commerce](https://arxiv.org/abs/2601.16492)
*Emad Siddiqui,Venkatesh Terikuti,Xuan Lu*

Main category: cs.IR

TL;DR: 提出一个基于LLM的语义检索框架，结合领域嵌入与结构化筛选，通过合成数据微调嵌入模型及将自然语言查询转化为结构化约束的生成模型，以提升对话式检索的精确度与召回率。


<details>
  <summary>Details</summary>
Motivation: 传统电商检索对关键词优化，难以理解对话式查询；标注数据稀缺，需通过数据增广提升模型能力。

Method: 1) 用LLM生成合成数据以指导微调；2) 微调嵌入模型，使语义相近商品在嵌入空间更接近；3) 微调生成模型将自然语言查询转化为结构化约束；4) 将基于相似度的检索与基于约束的筛选相结合；5) 在真实数据集上与基线方法比较。

Result: 在真实数据集上实现了较高的精准度和召回率，且对不同设置具有稳健性，相较基线有显著提升。

Conclusion: 通过将相似性检索与结构化过滤结合，能够更好地捕捉对话式查询中的用户意图，具有良好的实际落地潜力；在数据稀缺场景下，合成数据的使用也展现出较高的推广价值。

Abstract: Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.

</details>


### [48] [PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework](https://arxiv.org/abs/2601.16815)
*Shaoqing Wang,Yingcai Ma,Kairui Fu,Ziyang Wang,Dunxian Huang,Yuliang Yan,Jian Wu*

Main category: cs.IR

TL;DR: 两阶段个性化 Item-to-Item 检索框架 PI2I：通过扩展候选池和交互式打分提升个性化与检索效果，在Taobao上线提升在线交易率并公开大规模数据集作为基准。


<details>
  <summary>Details</summary>
Motivation: 现有的 item-to-item 传统协同过滤（CF）和两塔模型在捕捉复杂的用户-物品交互方面存在局限性，主要原因包括统一截断策略导致候选集不足，以及缺乏对复杂交互的建模能力。需要一种更强的个性化检索框架来提升召回和排序的一致性。

Method: 提出 PI2I 的两阶段检索框架：1) IBS（Indexer Building Stage）通过放宽截断阈值、最大化命中率来扩展候选池；2) PRS（Personalized Retrieval Stage）引入交互式打分模型，超越简单内积，更丰富地建模用户-物品交互。并基于触发-目标（item-to-item）关系构建负样本，确保离线训练与在线推理的一致性。

Result: 离线实验显示 PI2I 在性能上优于传统 CF 方法，并与部分两塔模型相媲美；在Taobao的“猜你喜欢”上线工程中实现了在线交易率提升约 1.05%；同时公开了含有 1.3 亿条真实用户交互的大规模 Taobao 数据集，供研究社区使用。

Conclusion: PI2I 通过将检索过程分为扩展候选池和更丰富的交互建模两个阶段，显著提升个性化推荐能力，具备良好的离线–在线一致性和落地性，并提供可公开的基准数据集，具备较强的工程化与研究价值。

Abstract: Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the "Guess You Like" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.

</details>


### [49] [Explaining Group Recommendations via Counterfactuals](https://arxiv.org/abs/2601.16882)
*Maria Stratigi,Nikos Bikakis*

Main category: cs.IR

TL;DR: 提出面向群体的对因解释框架，用于群推荐系统的群体对因解释，给出群体效用和公平性度量，并设计 Pareto 基筛选与增‑删（grow‑and‑prune）等启发式算法以高效发现解释，实验表明成本-解释规模/公平性之间存在权衡，且 Pareto 筛选在稀疏数据中效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决群体推荐缺乏透明性的问题；现有解释多聚焦于个体，难以处理群体成员偏好及其相互作用；需要揭示若移除某些历史交互对群体推荐的影响的机制。

Method: 形式化群体对因解释的概念，提出面向群体的效用与公平性度量，设计 Pareto 基筛选和 grow-and-prune 等启发式算法以高效发现解释。

Result: 在 MovieLens 与 Amazon 数据集上的实验显示：低成本解释往往规模较大且公平性较差；较高成本的解释更简洁且在公平性方面更平衡，但成本更高；Pareto 筛选在稀疏数据场景下显著提升效率。

Conclusion: 提出的群体对因解释框架实现透明度与权衡控制，所提启发式算法具有实际应用潜力与扩展性，未来工作可进一步完善度量并提升在不同数据分布下的鲁棒性。

Abstract: Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [50] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 提出离散数据的叶节点判别分数法，拓展分数匹配因果发现框架以识别 DAG 拓扑排序并进行边裁剪；在模拟与真实数据上验证，提升现有因果发现基线的准确性。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据学习 DAG 结构一直具有挑战性。通过数据分布的分数来初步识别拓扑顺序（通过叶节点检测），再进行边裁剪以恢复图结构。本文将分数匹配框架扩展到离散数据，给出基于离散分数函数的叶判别准则。

Method: 将离散分数函数用于叶节点判别，以获得底层有向无环图的拓扑排序；在此排序基础上进行边剪枝以完成图恢复；给出理论分析并通过仿真与真实数据实验验证。

Result: 理论上能够从观测的离散数据中准确推断真实的因果顺序；所得到的拓扑序可显著提升现有因果发现基线在大多数设置的准确性。

Conclusion: 在离散数据上扩展分数匹配框架有望提升因果发现的准确性与鲁棒性，并具广泛应用潜力。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [51] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 使用 Fitbit 数据集对大学生的抑郁、焦虑和压力进行早期筛查的可行性评估。心率和睡眠等生理模态在多种时间聚合水平下可实现较高的综合表现，焦虑F1最高可达0.79，压力由心率模态F1达0.77，抑郁由睡眠模态F1达0.78，显示可穿戴设备在持续监测心理健康方面有潜在价值。


<details>
  <summary>Details</summary>
Motivation: 弥补文献在心理评估工具种类、生理模态和时间序列参数方面的不足，利用可穿戴设备的无创生理数据实现对抑郁、焦虑、压力等心理疾病的早期筛查，且在 pandemia 场景下评估其可行性。

Method: 构建并评估基于 Fitbit 模态的预测性机器学习模型，使用学生群体的 StudentMEH 数据集，比较心率、睡眠等生理模态在不同数据聚合层次下的筛查性能，覆盖抑郁、焦虑、压力三种心理指标。

Result: 结果显示生理模态在筛查中具有潜力，焦虑的 F1 最高可达 0.79，心率模态在压力筛查中的 F1 为 0.77，睡眠模态在抑郁筛查中的 F1 为 0.78，强调数据聚合层次与模态选择对不同心理疾病筛查的影响。

Conclusion: 可穿戴设备具有支持持续心理健康监测的潜力；需要进一步明确不同心理疾病的最佳数据聚合水平和模态组合，以优化筛查性能。

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [52] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出了一种基于数据低维线性投影的GP训练目标（投影似然PL），给出信息损失的闭式表达，并通过单位球面上的随机投影减少信息损失。PL在准确性和计算效率方面优于精确GP训练和稀疏GP的变分自由能方法，在多种优化器、核函数及中等规模数据集上表现出优势。


<details>
  <summary>Details</summary>
Motivation: 解决高维GP训练的计算瓶颈与信息损失问题。通过低维线性投影构造的训练目标，理论上量化信息损失并通过随机投影减少该损失，提升可扩展性与效率。

Method: 提出投影似然（PL）作为GP训练的新目标；给出PL相关信息损失的闭式表达；在单位球面上使用随机投影以减小信息损失；在多种优化器、核函数和中等规模数据集上对比精确GP、稀疏GP的变分自由能方法，评估准确性与计算效率。

Result: 理论上给出信息损失的闭式表达并证明随机单位投影可降低信息损失；实验结果表明PL在准确性与计算效率方面优于精确GP训练和稀疏GP的变分自由能方法，且鲁棒性跨不同优化器和核函数及中等规模数据集。

Conclusion: PL为基于投影的GP训练提供了有效且高效的替代方案，具备可扩展性和实用性，适用于中等规模数据集的GP学习。未来可进一步分析其他投影形式、理论上界、以及在大规模数据集上的扩展性。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [53] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出一种单环第一阶演员-批评家算法，通过惩罚性 Reformulation 解决结构化双层优化问题；引入衰减熵正则化实现对上层超梯度的无偏估计；给出在特定 Polyak–Lojasiewicz 条件下的有限时间/样本收敛性分析；在 GridWorld 和 RLHF 任务上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中的双层优化难题：现有方法依赖二阶信息、对下层强正则化或需嵌套循环采样，计算成本高且不够高效。需要一个单环、一阶且理论可控的方法。

Method: 将下层 RL 目标改写为带 attenuating entropy 的正则化形式，提出单环、第一阶的演员- critic 算法来优化双层目标；通过惩罚项实现对上层 hyper-gradient 的近似无偏估计；利用下层残差分析和一种特殊的 Polyak–Lojasiewicz 条件，推导有限时间与有限样本收敛性到原始非正则化问题的驻点。

Result: 给出在有限时间和有限样本规模下的收敛性保证，收敛到原始未正则化双层问题的驻点；在 GridWorld 定位目标问题及 RLHF 的 happy tweet 生成任务中验证了方法的有效性。

Conclusion: 提供一种高效且带理论保证的双层 RL 优化框架，克服嵌套循环与对二阶信息的依赖，且在实际任务中表现良好。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [54] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 在对数线性奖励模型的RLHF框架下，本文基于算法稳定性给出端到端RLHF的泛化界限：在特征覆盖条件下，经验最优解的泛化误差为 O(n^{-1/2})，并可推广到梯度上升及随机梯度上升等优化算法。


<details>
  <summary>Details</summary>
Motivation: 弥补现有RLHF理论研究多聚焦MLE一致性而忽略端到端学习的泛化性质的问题，提供在高维LLM中的理论支撑。

Method: 在端到端RLHF设定下，采用算法稳定性分析，假设线性奖励模型，推导出经验最优的泛化界限；讨论特征覆盖条件下的收敛速率，并将结论推广至GA/SGA。

Result: 得到的泛化界限为 O(n^{-1/2})；且可外推至通过梯度算法得到的参数。

Conclusion: 为RLHF后LLM的经验泛化提供新理论证据，并为端到端RLHF的泛化分析提供可行框架。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [55] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 在 VC 理论框架下，使用正态近似与 Berry-Esseen 控制对统一收敛速率进行温和偏差的改进，在 ε√n 大时 leading term 增加一个 (ε√n)^{-1} 的修正因子。


<details>
  <summary>Details</summary>
Motivation: 克服以往 VC 估计中用 Hoeffding 不等式的保守性，提升对经验概率与理论概率之间差距的精确度，尤其在中等偏差区域。

Method: 不是在最后一步直接应用 Hoeffding，而是采用正态近似并给出显式 Berry-Esseen 误差界，从而得到一个中等偏差范围内的改进界。

Result: 得到比传统 VC 估计更紧的界，主导项的指数衍生出一个 (ε√n)^{-1} 级别的修正，当 ε√n 较大时，该修正显著。

Conclusion: 通过引入 Berry-Esseen 控制，提升了 VC 估计的理论强度和应用范围，提供对高概率容忍度区域的更精细分析。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [56] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0 是一个开源的临床深度学习工具包，统一数据集/任务/模型/可解释性/不确定性，并支持多模态临床数据与多语言扩展，致力于高可复现性和低成本部署。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基线难以复现、高计算成本及对领域专业知识的高门槛，亟需一个易用、可复现且高效的工具框架。

Method: 在单一框架中整合15+数据集、20+临床任务、25+模型、5+可解释性方法，以及包含保序/不确定性量化（包括 conformal prediction）的能力；支持信号、影像、电子健康记录等多模态数据，映射5+医学编码标准；并通过高效设计实现最高39x加速、20x内存降低；拥有400+成员的开源社区及 RHealth 多语言支持。

Result: 实现仅需约7行代码即可进行预测建模；在速度、内存等方面实现显著提升，便于从16GB笔记本到生产系统的部署；形成活跃的开源社区和跨机构合作。

Conclusion: PyHealth 2.0 建立了开源基础与社区，推动可访问、可复现实验室级别与临床应用的医疗AI。可通过 pip install pyhealth 获取。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [57] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: BED中KL与Wasserstein作为效用函数的优缺点对比：KL在无模型误差时收敛更快；Wasserstein在存在模型误差时更鲁棒；Wasserstein在固定形状后验下可能因主峰位置而产生与信息增益无关的奖励，尤在均匀先验下更明显。


<details>
  <summary>Details</summary>
Motivation: BED中的效用函数直接决定信息获取与鲁棒性，因此系统比较KL与Wasserstein在不同情形下的表现具有实用价值。

Method: 通过一个 toy 示例揭示Wasserstein可能的“伪奖励”问题；在经典源反演问题中对比KL与Wasserstein在序列BED中的表现与鲁棒性。

Result: 在无模型差异时，KL趋向于更快收敛；在存在模型差异时，Wasserstein提供更鲁棒的序列BED结果。对固定形状后验，Wasserstein的值会受主峰在支撑内的相对位置影响，可能产生与信息增益无关的奖励，尤其当先验信息较弱时更为明显。

Conclusion: 明确KL与Wasserstein在BED效用函数上的权衡，给出在实际应用中选择合适标准的指南。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [58] [Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction](https://arxiv.org/abs/2601.16426)
*Shuang Wu,Meijie Wang,Lun Yu*

Main category: cs.LG

TL;DR: 本工作聚焦香气相关性质VP（汽化压）与OP（嗅阈）建模，在Bemis-Murcko骨架分割的OOD设置下评估泛化能力，使用A20/E17特征与GINE/PNA骨架，并提出“安全多任务学习”以提升VP的泛化，同时提供完整可复现的实验与消融分析。


<details>
  <summary>Details</summary>
Motivation: 在药物小分子性质预测场景中，OOD泛化是关键挑战。对香气相关属性，容易受训练集分布偏差影响；通过丰富的分子图特征、先进的GNN骨架以及对任务关系的控制，期望提升VP/OP的鲁棒性与泛化性能。

Method: 1) 特征：A20（20维原子特征）+ E17（17维键特征）组合。2) 验证骨架：Bemis-Murcko分割的OOD评估。3) 骨架对比：GINE vs PNA；4) VP回归头简单线性/非线性回归；5) OP单任务：在相同特征下使用鲁棒损失（Huber/Winsor）训练；6) 多任务：将VP设为主任务，OP为辅助任务，采用延迟激活、梯度裁剪、权重小化的安全多任务策略；7) 附带消融、误差相似性分析、数据噪声与方法局限性的讨论，且有完整可复现性。

Result: VP方面，使用PNA+简单回归头，在归一化空间下Val MSE约0.21。OP单任务，在A20/E17与鲁棒训练下，Val MSE约0.60–0.61。多任务方面，安全多任务策略使VP的泛化性能达到最佳，同时OP不受显著负面影响。论文提供完整的可复现实验、消融和误差相似性分析，并讨论数据噪声与方法局限。

Conclusion: 提出的安全多任务学习策略在不损及主任务VP的前提下提升其泛化，且在结合丰富特征与BMS分割的OOD评估下，展示出稳定的VP与OP性能，并具备良好的可复现性与分析深度。

Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\approx$ 0.60-0.61. For multitask training, we propose a **"safe multitask"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.

</details>


### [59] [Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network](https://arxiv.org/abs/2601.16446)
*George Awiakye-Marfo,Elijah Agbosu,Victoria Mawuena Barns,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: BrownianReLU是一种由布朗运动引入的随机激活函数，嵌入到LSTM中以提升对噪声性、非平稳金融时间序列的梯度传播与学习稳定性。通过蒙特卡洛采样实现对负输入的平滑自适应响应，缓解“死神经元”问题。实验在股票、市场指数和贷款分类数据上显示更低的MSE和更高的R^2（回归任务），并在分类任务中对ROC-AUC的局限性做出讨论，激活函数对准确性与灵敏度的折中影响显著。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数（如ReLU、LeakyReLU、PReLU）在噪声性强、非平稳的金融时间序列上易导致梯度不稳定和死神经元现象，迫切需要一种在负输入区域具有更平滑、可自适应响应的激活函数，以改善梯度传播与模型鲁棒性。

Method: 提出BrownianReLU：一种受布朗运动启发的随机激活函数，通过蒙特卡洛模拟在负输入区生成平滑、随机但可控的响应，并将其嵌入LSTM以提升梯度传播与学习稳定性。评估对象包括苹果、GCB、S&P 500 等金融时间序列及 LendingClub 的分类数据，比较回归任务的MSE、R^2，以及分类任务的ROC-AUC等指标。

Result: 在回归任务中，BrownianReLU实现了更低的均方误差和更高的R^2，显示出更好的预测精度和泛化能力。对于分类任务，尽管ROC-AUC存在局限性，但激活函数选择对准确性与灵敏度的权衡影响显著，BrownianReLU及所选的其他激活函数实现了具有实际意义的性能提升。

Conclusion: 激活函数的选择对金融任务中的模型性能有显著影响。BrownianReLU作为一种基于随机过程的自适应激活，能够提升梯度传播与模型稳定性，具有潜在的实际应用价值，值得在更广泛的时间序列任务中进一步比较和扩展。

Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.

</details>


### [60] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 在浮点设定下，变换器的表达能力出现偏离：可表示非置换等变函数、对有界序列长度可完美表示所有置换等变函数、对较长序列不可表示所有置换等变函数；并且最小等变结构被识别，任何非平凡的加性位置编码会降低表示能力。


<details>
  <summary>Details</summary>
Motivation: 解决理论分析（连续域、精确运算）与实际实现（浮点数、舍入误差）之间的差距，探究浮点参数/运算下变换器的表示能力。

Method: 通过理论构造和证明：首先给出在不使用位置编码时，浮点变换器可表示一类非置换等变函数；随后证明当序列长度有界时，浮点变换器可表示所有置换等变函数；但当序列长度增大时，则不可能表示所有这类函数；并分析最小等变结构以及加性位置编码对表示能力的影响。

Result: 关键结果包括：浮点参数和运算引入额外表示能力，能够表示部分非对称函数；对有界长度的置换等变函数保持完备；对无界或较大长度则不完备；识别出最小的等变结构，以及非平凡加性位置编码对可表示性的负面影响。

Conclusion: 对实际实现的启示在于需考虑舍入误差对理论表达力的影响，长度约束和位置编码设计显著影响性能；未来工作可研究鲁棒性、其他数值格式的影响，以及在不同任务中的应用。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [61] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: 通过引入残差噪声对比估计（R-NCE）并结合FreeSurfer特征的自监督学习框架，在MRI数据上发现更具生物学相关性的生物标志物，提升疾病预测和脑年龄相关特征的遗传学解释能力。


<details>
  <summary>Details</summary>
Motivation: 挑战当前SSL在结构MRI中提取的标志物与手工特征（皮质厚度、体积等）相比仍有限，需开发能揭示更强表型的自监督信号，且需评估其生物学相关性。

Method: 提出R-NCE，将外部FreeSurfer辅助特征融入，最大化额外的augmentation不变信息；在多个基准任务上评估（包括AD转归预测、病理状态预测等）；推导脑龄差距(BAG)，并做全基因组关联研究(GWAS)。

Result: R-NCE在传统特征和现有SSL方法之上表现更优；R-NCE-BAG具有高遗传性并与MAPT、IRAG1相关，在星形胶质细胞和少突胶质细胞中富集，提示对神经退行性和脑血管过程的敏感性。

Conclusion: R-NCE-BAG可提供更具生物学意义的MRI标志物，增强自监督特征的生物学解释力；方法可作为早期检测和监测的潜在工具。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [62] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出 MGCPL-guided Categorical Data Clustering (MCDC) 框架，结合多粒度竞争惩罚学习与基于编码的聚合，实现对分类型数据的自动多粒度嵌套聚类，具有线性时间复杂度，适合大规模数据与分布式预分区，并在公开数据集上优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 分类型数据的距离度量受限，存在嵌套粒度的聚类结构，传统方法难以定义合适距离并发现多层次的小簇与大簇，需要一个在不同阶段自适应调整聚类数且具可扩展性的聚类方法。

Method: 提出 Multi-Granular Competitive Penalization Learning (MGCPL)，使潜在簇在多粒度上交互并分阶段收敛；并提出 Cluster Aggregation 基于 MGCPL 编码（CAME），对数据对象进行编码后在嵌入空间进行最终聚类；整个 MCDC 框架具有线性时间复杂度。

Result: 在多组真实公开数据集上的广泛实验表明，MCDC 相较于现有最先进方法具有更高鲁棒性和更优的聚类效果，且对来自不同领域的分类数据具有良好适用性；线性时间特性使其对大规模数据具备良好扩展性，亦适合作为大规模数据的预分区或分布式计算的前置步骤。

Conclusion: MCDC 能自动探索多粒度的嵌套分布、对分类数据聚类具有鲁棒性与可扩展性，是对现有方法的有效提升。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [63] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: Proposes BoostFGL, a boosting-style fairness framework for federated graph learning to mitigate disparities across disadvantaged node groups; introduces client-side node/topology boosting and server-side model boosting; shows 8.43% improvement in Overall-F1 across 9 datasets while maintaining competitive accuracy.


<details>
  <summary>Details</summary>
Motivation: Fairness gaps in federated graph learning (FGL) arise from label skew, topology confounding in message passing, and update aggregation dilution across heterogeneous clients; there is a need to address per-group performance rather than just average accuracy.

Method: Three coordinated boosting mechanisms: (1) Client-side node boosting to emphasize under-served nodes during local training; (2) Client-side topology boosting to reallocate propagation toward reliable yet underused structures and attenuate misleading neighborhoods; (3) Server-side model boosting to perform difficulty- and reliability-aware aggregation that preserves informative updates from hard clients while stabilizing the global model.

Result: Extensive experiments on 9 datasets show substantial fairness gains, with Overall-F1 improving by 8.43%, while maintaining competitive overall performance compared with strong FGL baselines.

Conclusion: A coordinated boosting framework can effectively reduce fairness disparities in FGL by addressing data distribution, graph topology, and aggregation dynamics; shows promise for practical deployment and invites further analysis of component contributions and theoretical guarantees.

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [64] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出了CRISPNAM-FG，一种基于神经加法模型的可解释生存分析模型，结合Fine-Gray子模型，具备透明性和竞争性预测性能，并应用于糖尿病足病并发症预测。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在临床生存分析中的黑箱问题，提升可解释性与可审计性，增强临床信任和AI安全。

Method: 以NAM结构为基础，为每个风险构建独立投影向量，使用Fine-Gray框架预测累积发病函数，输出形状函数和特征重要性图以实现可解释性。

Result: 在若干基准数据集上达到与其他深度生存模型相当的预测性能，同时提供透明性分析工具；在29家安大略省医院的糖尿病患者未来足部并发症预测方面进行应用。

Conclusion: 该模型实现了高预测性能与内在解释性兼容，可以实现可审计的临床预测，利于AI在医疗中的安全部署。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [65] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出一种自适应图模型，将kNN的最近邻选择与权重计算推向训练阶段，通过在HNSW图中分层导航实现推理阶段的低延迟，不损失精度。


<details>
  <summary>Details</summary>
Motivation: 解决大规模场景中kNN在推断阶段的计算瓶颈；现有近似最近邻在加速的同时往往牺牲精度，且缺乏对最优邻居数的自适应选取。需要将邻居选择与权重化的计算转移到训练阶段，保持推理时的快速性与准确性。

Method: 将Hierarchical Navigable Small World (HNSW)图与预计算投票机制结合：高层负责快速导航，低层负责细粒度决策边界，并以自适应邻居数进行权重投票。推理阶段不再进行邻居搜索与权重计算，将复杂度从推理转移到训练阶段。

Result: 与六个数据集上的八个基线对比，显著提升推理速度，达到实时性能，同时保持分类准确性，显示出在大规模场景中对kNN推理瓶颈的有效缓解。

Conclusion: 给出一种可扩展、鲁棒的图结构范式，解决非参数学习中kNN的推理瓶颈；通过在训练中完成邻居筛选与投票权重化，实现推理阶段的高效性与稳健性。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [66] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出 DANCE：基于图凝聚的 TAG-FGL，通过轮次、模型内循环的凝聚刷新，兼顾成本与性能，提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决文本属性在联邦图学习中的计算开销、一次性图凝聚导致的子最优，以及缺乏可解释性的问题。

Method: 引入图凝聚（GC）并在多轮循环中以最新全局模型为驱动进行凝聚刷新，同时保留可证据包以便本地溯源，提升模型适应性与可解释性。

Result: 在8个 TAG 数据集上，准确率提升约2.33%，在8% 的凝聚比下实现33.42%的 token 节省，相较基线。

Conclusion: DANCE有效缓解了 overhead、suboptimal 与可解释性不足的问题，通过轮次刷新和可溯源证据提高性能与可审计性。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [67] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: 提出 SARE 框架，通过 Targeted-SAM 将未学习过程中的“幻觉”概念周围的损失地形扁平化，结合目标化极大化求解，提升对幻觉的擦除鲁棒性并抗再学习/权重更新的影响。


<details>
  <summary>Details</summary>
Motivation: 对象幻觉在多模态大模型中广泛存在，常规擦除方法仅获得表层抑制，易在轻度再学习后幻觉回潮；需要一种几何稳定性强、对权重扰动鲁棒的擦除方法。

Method: 将未学习视为带有对抗扰动的极小-极大化问题，提出 Targeted-SAM 以显式扁平化幻觉概念附近的损失地形，并在模拟的最坏参数扰动下进行擦除，以实现对抗性稳定的幻觉移除。

Result: 在擦除效果上显著优于基线，同时保持生成质量；对再学习和参数更新具有持久的幻觉抑制效果，证实了几何稳定性的有效性。

Conclusion: 提出的几何稳定化策略（SARE）为多模态模型的幻觉擦除提供更稳健、持久的解决方案，尤其在权重更新场景下表现出更强的鲁棒性。

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [68] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: Engram-Nine 提出一种基于最小完美哈希函数（MPHF）的高频n-gram热层的无冲突设计，并保留冷层多头哈希以对比。结果表明，在严格等参数条件下，单纯提高查找精度并不稳定提升验证损失；热-冷损失的时序变化揭示冲突可能提供隐式正则化，且门控赋权的问题（gate）在训练早期偏向热位，且这种偏好甚至在翻转后仍残留，指向门控分配权重的瓶颈。结论认为提升查找精度并非解决训练问题的唯一途径，冲突噪声可能带来有益的正则化效应，需谨慎处理。


<details>
  <summary>Details</summary>
Motivation: 系统地评估高频冲突是否为 Engram 风格条件记忆的主要瓶颈，藉由分离冲突效应来评估查找精度对训练动态、热/冷贡献和门控credit assignment的影响；通过路由分层评估揭示训练过程中的热位与冷位损失在不同阶段的变化规律。

Method: 提出 Engram-Nine：对高频n-gram采用最小完美哈希函数实现冲突免费映射，同时保留原有多头哈希的冷层；在严格的等参数设置下进行对比；通过按-token 的热/冷贡献分解来评估损失；分析训练早期与后期的动力学，以及 gate 的学习行为。

Result: 在冲突免费设计下，热位优势的损失下降领先翻转的现象提前出现，冷位在后期超过热位，显示热位初期更易拟合但长期性能被冷位超越；冲突导致的噪声似乎提供了一种隐式正则化，冲突越多的基线翻转时间越晚；gate 学习在训练早期偏好热位，甚至在翻转后仍保持高损失位的权重分配；总体上仅提升查找精度不足以普遍提升训练效果。

Conclusion: 核心问题可能并非索引精度本身，而是门控Credit Assignment 的瓶颈；冲突噪声带来潜在的正则化效应，不应被简单消除。未来工作应聚焦于门控机制的动态调整、来匹配热/冷贡献的权重分配，并在考虑冲突带来的正则化收益的前提下优化 Engram 风格记忆系统的整体训练信号。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [69] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: 提出的 JORC-UMAP 将 Ollivier-Ricci 曲率作为几何先验，并结合 Jaccard 相似度引入拓扑先验，对 UMAP 的 k 最近邻图进行加强与一致化，显著缓解几何扭曲（tearing）和结构塌陷，提高流形保真度，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: UMAP 的局部欧几里得距离假设难以捕捉数据的真实流形几何，且对 kNN 图敏感，易导致拓扑撕裂和结构坍塌。需要一种几何+拓扑的先验来稳健保留真是流形结构。

Method: 在 UMAP 框架中引入 Ollivier-Ricci 曲率作为边的几何先验，用以在几何瓶颈处强化边、减少冗余连边；同时用 Jaccard 相似度作为拓扑先验，确保邻域的一致性，得到 JORC-UMAP。

Result: 在合成与真实数据集上的实验显示，JORC-UMAP 相较于标准 UMAP 和其他降维方法，在减少 tearing 与 collapse 方面更有效，体现在 SVM 分类准确度和三元组保留分数的提升，同时保持了较低的计算开销。

Conclusion: 将几何与拓扑先验融入 UMAP，得到对数据可视化更忠实的几何感知增强降维方法。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [70] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: Proposes kNN-ICL, a k-nearest-neighbor-based in-context learning framework for startup success prediction using LLMs, addressing data scarcity by using a small set of labeled startups as demonstrations; achieves higher accuracy than baselines with as few as 50 examples.


<details>
  <summary>Details</summary>
Motivation: Data scarcity limits traditional supervised ML for predicting early-stage startup success; VC firms often have labeled data for only a few dozen startups, hindering model training and performance.

Method: Introduce kNN-ICL: select the most similar past startups as in-context demonstrations for an LLM, without any model training; uses real Crunchbase profiles for evaluation; compares against supervised ML baselines and vanilla ICL.

Result: kNN-ICL outperforms baselines and vanilla ICL in prediction accuracy on Crunchbase data; high balanced accuracy achievable with roughly 50 in-context examples.

Conclusion: In-context learning, particularly with a kNN-based demonstration selection, can serve as a practical decision-support tool for VC firms operating in data-scarce environments.

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [71] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD 提出动态双原型库与上下文感知路由，通过常用模式库与稀有模式库实现模式分解并提供上下文定制化输出，辅以解耦导向损失，模型无关地提升时序预测性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度时序预测很容易学习静态、平均化的表示，难以动态分离并利用趋势、季节性及罕见事件等 intertwined 的时序模式，导致缺乏上下文感知能力。

Method: 提出 DPAD：Dynamic Dual-Prototype bank (DDP)，包含带强时间先验的公有模式库和动态记忆关键稀有事件的稀有模式库；Dual-Path Context-aware routing (DPC) 从 DDP 提取并有选择地检索上下文特定的模式表示以增强输出；以及 Disentanglement-Guided Loss (DGLoss)，促使每个原型库专注于其分工并保持覆盖。

Result: 实证实验表明 DPAD 在多项真实世界基准上对现有模型的预测性能和鲁棒性有一致性提升，且具有模型无关的辅助性。

Conclusion: DPAD 通过模式分解与上下文感知自适应，提升时序 forecasting 的准确性和可靠性，具备对多种模型和数据集的泛化能力。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [72] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: PSCE 提出一种基于贝叶斯原理的可概率安全对照性解释（CE），实现 δ-安全和 ε-鲁棒性，以保证在模型更新下仍具有高预测置信度与低方差。定义 ⟨δ,ε⟩-集合并在优化中引入不确定性约束，实证显示相较于现有贝叶斯 CE 方法，PSCE 具有更高的可行性、辨识力与对模型变化的鲁棒性，并具可证明的鲁pdo?robustness under model change.


<details>
  <summary>Details</summary>
Motivation: 在实际部署中模型频繁更新，传统 CE 容易失效或不可靠；需要在模型变动下仍提供可信、稳定的解释。

Method: 提出 PSCE：以贝叶斯框架给出对 CE 的概率保证，在优化中嵌入不确定性约束，定义 ⟨δ,ε⟩-集合以覆盖在给定置信度下的稳健性；实现 δ-安全和 ε-鲁棒性并与多数据集上的基线贝叶斯 CE 方法比较。

Result: 实证结果表明，PSCE 产生的解释在可行性、辨识力和对模型变动的鲁棒性方面优于基线方法，并提供理论上的概率保证。

Conclusion: 为在模型更新环境下的对抗性解释提供一个带概率保障的框架，提升解释的可靠性与实用性。

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [73] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出基于动态请求专家知识的模型平均方法，用于对多种因果发现算法进行集成，在有专家知识不完备或不可靠时提升鲁棒性与实用性。


<details>
  <summary>Details</summary>
Motivation: 因果发现算法众多且假设各异，单一算法在现实场景中的适用性受限。现实案例常违背算法假设，需要借助专家知识；同时，LLMs等新兴专家的表现不稳定，因此通过多算法集成并动态请求专家以提高稳健性与可解释性成为一个有价值的方向。

Method: 提出灵活的模型平均框架，动态地请求专家知识以对不同因果发现算法进行加权融合，支持将不完美的专家（如LLMs）作为知识来源。通过在清洁与带噪数据上的实验，以及对不同程度专家正确性的分析，评估方法在临床相关数据上的可应用性。

Result: 实验表明，在存在不完美专家（如LLMs）的情况下，该方法能够有效地集成多种因果发现算法，提升在清洁与噪声数据上的性能。系统地分析了专家正确性对结果的影响，并评估了LLMs在临床因果发现中的潜力，提供了对从业者有价值的见解。

Conclusion: 将专家知识与多算法集成结合，能够提升实际因果发现的鲁棒性和可用性，尤其在需要领域专家知识的场景（如临床）中具有实际意义。未来可进一步优化专家质量评估与动态权重调整机制。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [74] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种序贯惩罚法用于在优化中将样本级约束作为严格约束处理，并给出收敛性与实用性证据。


<details>
  <summary>Details</summary>
Motivation: 在需要将对单个样本的处理约束严格化为优化约束的任务中，单纯罚项可能无法准确表达约束意图，故提出可直接处理约束的学习方法，并在深度学习场景中具备合理假设。

Method: 采用序贯惩罚法将约束逐步纳入优化过程，设计的算法具备在深度学习常见假设下的收敛性保证。

Result: 在图像处理任务的实验中，所提方法表现出可行性，能够有效实现约束处理并获得良好性能。

Conclusion: 序贯惩罚法为将严格约束融入学习优化提供了可行且具备理论保证的途径，且在实际的图像处理任务中具备应用潜力。

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [75] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: 用 Attentive Neural Processes (ANP) 实现对 GEDI 数据的概率建模，提升局部条件化预测与不确定性校准，兼顾准确性与可转移性。


<details>
  <summary>Details</summary>
Motivation: 现有随机森林/XGBoost在跨异质地貌的生物量映射中未能提供良好校准的预测区间，原因是混淆了集成方差与本征不确定性，且忽略局部空间上下文。

Method: 提出 ANP 作为概率元学习框架，显式以局部观测集和地理基础模型嵌入来条件化预测，学习灵活的空间协方差函数，区分全局与局部不确定性。

Result: 在五个生物群落中实现竞争性准确性，同时达到几乎理想的校准，不同区域的少样本自适应可显著缩小跨区域转移的性能差距。

Conclusion: ANP 为大陆尺度地球观测提供了可扩展、理论上严格的替代集成方差的方案。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [76] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 人-机协作通过对 FunSearch 输出的迭代改进，获得若干组合优化问题的新的下界与对手实例，覆盖层次化 k-中值聚类、装箱、背包问题以及 Lovász 汽油问题的推广；表明 LLM 提供初始模式，需人类专家将其转化为严格的数学构造。


<details>
  <summary>Details</summary>
Motivation: 探索人-机协作在理论计算机科学中的潜力，借助 LLM 产生的模式作为种子，通过人类专业知识将其转化为可证明的、具有实际意义的对手实例和下界。

Method: 基于对 FunSearch 输出的迭代改进，设计并验证改进的对手实例与构造，覆盖层次化 k-中值聚类、装箱、knapsack、以及 Lovász 的汽油问题的推广；结合 LLM 的演化性输出与人类的数学推导和严格性。

Result: 在层次化 k-中值聚类、装箱、背包等标准启发式算法上获得了新的下界，达到或接近当前已知的最强界，且在某些问题上为十多年未有显著进展的领域带来突破性改进；同时，研究表明部分改进来自对 FunSearch 输出的再加工与人类的严密化。

Conclusion: 证实 LLMs 作为初始模式提供者具备价值，但要转化为可证明的数学构造，仍需强有力的人类专业指导；这表明 LLMs 是数学与计算机科学研究中的有力协作工具。

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [77] [Provably Learning Attention with Queries](https://arxiv.org/abs/2601.16873)
*Satwik Bhattamishra,Kulin Shah,Michael Hahn,Varun Kanade*

Main category: cs.LG

TL;DR: 对 Transformer-基序列模型在黑箱输出访问下的可学习性进行分析，给出单头注意力的精确学习算法及多头不可辨识性结论；在 r<<d 的情形提出基于压缩感知的 O(rd) 查询方法；并讨论噪声鲁棒性以及在缺失结构条件下的推广性。


<details>
  <summary>Details</summary>
Motivation: 在仅能查询模型输出的前提下，理解 Transformer 及其单头/多头注意力的可学习性与可辨识性，探讨从黑箱数据反演参数的边界与条件。

Method: 给出单头注意力参数的精确学习算法，复杂度为 O(d^2) 查询；若存在可学习 ReLU FFN 的算法，则可将单头算法推广至单头注意力的一层 Transformer；在 head 维度 r<<d 时，提出随机化算法，基于压缩感知思想实现 O(rd) 查询的学习；分析噪声条件下的鲁棒性，证明在一定范数和 margin 条件下可用多项式数量查询估计到 ε 精度；讨论多头注意力在值查询下的一般不可辨性。

Result: 单头注意力的参数可在 O(d^2) 查询内被精确学习；若存在可学会的 ReLU FFN，则可将该方法扩展到一层 Transformer 的单头注意力；在 r<<d 时，利用压缩感知思想实现 O(rd) 查询的学习；噪声条件下，给出多项式查询数即可在 ε 精度内估计参数；多头注意力在值查询下通常不可辨，需额外结构假设以获得与单头等价的保证。

Conclusion: 单头注意力在若干设定下具备高效可学习性与鲁棒性，但多头注意力在一般情况下不可辨，强调需要额外结构或假设来获得类似于单头的可学习性保证。

Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.

</details>


### [78] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM is a projection-free, unified framework for federated constrained optimization that tackles functional constraints, communication compression with error feedback, multiple local updates, and partial participation; it achieves O(1/√T) convergence of the averaged iterate and introduces a soft-switching variant; validated on Neyman-Pearson and CMDP.


<details>
  <summary>Details</summary>
Motivation: Federated learning systems face functional constraints, communication limits, local computation with multiple local updates, and partial client participation. Existing approaches handle some aspects but lack a unified theoretical treatment with guarantees under compression and constraints.

Method: Adopts switching gradient method to obtain projection-free, primal-only updates. Introduces bi-directional error feedback to handle compression noise, analyzes interaction with multi-step local updates, and derives convergence for averaged iterate with high-probability bounds. Introduces soft switching variant to stabilize near feasibility boundary.

Result: The averaged iterate achieves canonical O(1/√T) rate with high-probability bounds decoupling optimization progress from sampling noise due to partial participation. Demonstrates convergence guarantees and empirical validation on Neyman-Pearson classification and CMDP tasks.

Conclusion: FedSGM unifies functional constraints, compression, multiple local updates, and partial participation in a theoretically grounded framework for constrained federated learning; supports practical deployment and future extensions.

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [79] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: 四分框架评估：基于嵌入的作物类型映射方法在塞内加尔展现最佳性能、可行性、可迁移性与可获取性，其中 TESSERA 嵌入在一个时序转移中比次优方法高出约 28%。


<details>
  <summary>Details</summary>
Motivation: 小农地区的作物类型地图受限于现有卫星方法的适用性，需构建具性能、合理性、可迁移性及可访问性的嵌入式方法来提升作物分类与映射的准确性与普适性。

Method: 评估地理空间基础模型（FM）嵌入方法在 TESSERA 与 AlphaEarth 的表现，并与现有基线方法在塞内加尔 groundnut basin 的作物类型映射任务上比较；提出并使用四项标准（性能、可置信性/合理性、可迁移性、可访问性）进行评估。

Result: TESSERA 基于嵌入的方法在四项评估标准上均达到最佳或接近最佳；在一个时序转移案例中，相较于次优方法，准确率提升约 28%。

Conclusion: TESSERA 嵌入在塞内加尔的作物类型分类和映射任务中表现出色，具备对小农区域广泛推广的潜力。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [80] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP是一种适配器式几何约束框架，通过将路由器梯度投影到专家特定的零空间，保持MoE中的路由稳定性，同时将知识从专家参数中删除，从而实现对大语言模型的有效无忘记。


<details>
  <summary>Details</summary>
Motivation: 解决现有MoE无忘记方法在路由层面通过重定向查询来“忘记”知识，导致模型效用下降和表面化遗忘的问题，需在不破坏路由稳定性的前提下实现对专家参数的直接遗忘。

Method: 提出GRIP：几何约束的适配器，利用将路由梯度投影到专家特定的零空间来实现路由参数可塑性与路由稳定性的解耦，允许内部重新配置以满足无忘记目标，同时不改变底层无忘记算法。

Result: 实验表明，在大规模MoE模型上，GRIP作为适配器使所有测试的无忘记方法均实现>95%的路由稳定性，并维持了模型效用，阻止了现有算法对MoE路由漏洞的利用。

Conclusion: GRIP提供了一种架构感知的无忘记方法，可以作为现有无忘记算法在MoE上的通用适配器，将无忘记研究从密集模型推广到MoE。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [81] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: 提出 Trajectory Alignment Coefficient (TAC) 来辅助奖赏调参，并提出可微分近似的 Soft-TAC 以从人类偏好数据训练奖赏模型；在 Lunar Lander 与 Gran Turismo 7 中验证，表明 TAC 可提升性能并降低认知负荷，但手动设计仍然劳动密集；Soft-TAC 作为奖赏学习目标展现出更具区分性的策略行为。


<details>
  <summary>Details</summary>
Motivation: RL 的奖赏设计与任务目标往往错配，导致学习效果不佳。需要工具来评估和对齐人类偏好，并开发可学习的奖赏模型以降低设计成本。

Method: 引入 TAC 度量，评估奖励函数诱导的偏好与领域专家偏好的一致性；通过面向 RL 实践者的人类研究让参与者在 Lunar Lander 中调参并比较有无 TAC；提出 Soft-TAC，作为可微分的 TAC 的近似，用作从人类偏好数据训练奖赏模型的损失函数；在 Gran Turismo 7 中验证可训练的奖赏模型是否捕获偏好目标。

Result: 在使用 TAC 辅助的调参中，参与者得到更高性能的奖赏函数并报告较低的认知负荷；但手动奖赏设计仍然劳动密集。Soft-TAC 训练的奖赏模型能够更好地捕捉偏好目标，产生与标准交叉熵损失相比更加具有区分性的策略行为。

Conclusion: TAC 既可作为实用的奖赏调参工具，也可作为复杂领域中的奖赏学习目标，具备潜在的实践价值与扩展性。

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [82] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 用有序回归（Isotonic regression）对余弦相似度进行单调校准，获得近乎完美的校准，同时保持排序关系与局部稳定性；无需修改嵌入几何结构，仅通过单调变换提升绝对值的可解释性。


<details>
  <summary>Details</summary>
Motivation: 嵌入向量的各向异性导致余弦相似度的绝对值难以解释，存在系统性偏差；先前的改造（ whitening、对比学习微调）虽可改善校准，但改变了几何结构并需重新计算嵌入。

Method: 利用人类相似性判断训练的有序回归，构建单调变换以校准相似度分数；保持原有的秩相关与在七种扰动下的局部稳定性（98%）。理论上将有序校准视为保持序的重参数化，证明所有基于顺序的构造（角度排序、最近邻、阈值图与分位点决策）在该变换下保持不变。

Result: 实现近乎完美的绝对值校准，同时保留原有的秩序关系；在七类扰动中实现约98% 的局部稳定性。

Conclusion: 通过单调校准恢复余弦相似度绝对值的可解释性，而不改变其排序特性；有序校准是保持顺序的重参数化，对基于顺序的结构具有不变性，且无需修改嵌入的几何结构。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [83] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多组学习中的样本复杂度在 group-realizable 设置相对于 agnostic 设置有提升，即使组族是无限的，只要其 VC 维度有限。通过对 group-realizable 概念集进行经验风险最小化（ERM）来实现提升，但该方法在计算上不可高效；可采用基于不当学习的替代方案。


<details>
  <summary>Details</summary>
Motivation: 研究目标：比较 group-realizable 与 agnostic 设置下的样本复杂度，探索无限组族在有限 VC 条件下的可学习性，以及在统计与计算之间的权衡。

Method: 主方法为对 group-realizable 概念族进行 ERM 以获得更佳样本效率；若该族的 VC 维度可能无限，则实际 ERM 难以实现，因而分析其计算不可行性；提出基于不当学习的替代路线作为可行方案。

Result: 在组族具有有限 VC 维的前提下， group-realizable 设置确实带来比 agnostic 设置更低的样本复杂度；但对该族进行严格的 ERM 计算上不可行，需要采用不当学习的替代策略来实现实际可行性。

Conclusion: 统计优势存在，但实现的计算代价很高；不当学习提供一个可行的替代框架以在统计与计算之间进行折中。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [84] [Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles](https://arxiv.org/abs/2601.16936)
*Anton Zamyatin,Patrick Indri,Sagar Malhotra,Thomas Gärtner*

Main category: cs.LG

TL;DR: BatchEnsemble reduces parameter/memory cost for ensembles via rank-1 perturbations but underperforms Deep Ensembles and behaves similarly to a single model, lacking distinct predictive modes.


<details>
  <summary>Details</summary>
Motivation: Efficiently obtaining epistemic uncertainty (EU) in resource-constrained, low-latency settings where deep ensembles are too costly.

Method: Apply learned rank-1 perturbations to a shared base network to simulate an ensemble; compare against Deep Ensembles on CIFAR-10/10C/SVHN for accuracy, calibration, OOD detection; conduct MNIST controlled study to assess parameter-function diversity.

Result: BatchEnsemble underperforms compared with Deep Ensembles; closely tracks a single-model baseline in accuracy, calibration, and OOD detection on CIFAR-10/10C/SVHN; MNIST study shows members are near-identical in function and parameter space, indicating limited capacity for distinct predictive modes.

Conclusion: BatchEnsemble behaves more like a single model than a true ensemble; limited ability to realize diverse predictive modes reduces its suitability as a drop-in replacement for deep ensembles for reliable EU estimation.

Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.

</details>


### [85] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 提出一种基于片段的3D分子生成框架，将分子视为刚性基元集合，使用SE(3)-等变生成模型进行从片段到3D分子的自发生成，在性能上与最先进方法相当甚至优越，且在GEOM-Drugs上原子稳定性更好，生成步数减少2–10倍，分子表示压缩约3.5x。


<details>
  <summary>Details</summary>
Motivation: 解决 atom级三维生成成本高、表示冗长的问题；通过片段化与刚性基元、以及SE(3)等变生成模型提升效率、可扩展性与稳定性。

Method: 将分子建模为一组刚性 motif，扩展自 frame-based 蛋白质结构生成思路，使用 SE(3)-equivariant generative modeling 对这些刚性基元进行 de novo 3D 分子生成。

Result: 在基准测试中达到与最先进方法相当甚至更优的结果，尤其在 GEOM-Drugs 数据集上原子稳定性方面优于对比，生成步数减少2x-10x，分子表示相比原子级方法压缩约3.5x。

Conclusion: 通过片段化与等变生成，提供更高效、稳定且紧凑的三维分子生成框架，适用于 de novo 设计。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [86] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD 将掩码扩散视为块级因果模型，通过严格因果且置换等价的架构，在单次前向中并行计算多步条件概率，实现自回归风格解码与分块并行生成的结合，采用渐进的置换训练学习多种 token 排序，并提出分步并行生成以提升推理速度。实证在标准语言建模基准上达到SOTA，且训练步骤显著减少，建立并行文本生成新基准。


<details>
  <summary>Details</summary>
Motivation: 缩小掩码扩散模型（MDM）与自回归模型（ARM）之间的性能差距，同时提升训练效率与并行生成能力，推动扩散模型在语言建模中的竞争力。

Method: 将掩码扩散过程重新表述为块级因果模型，设计严格因果、 permutation-equivariant 的体系，在一个前向传播中计算跨多步的所有条件概率；引入渐进的置换训练以覆盖左→右和随机排序；提出分步并行生成策略，使用多条并行流实现高吞吐、并保持全局一致性。

Result: 在标准语言建模基准上实现SOTA，优于现有扩散基线且显著减少训练步数；建立了新的并行文本生成基准，拉近并行解码与自回归解码的性能差距。

Conclusion: ARMD将自回归训练效率与并行扩展性结合，通过块级因果建模和分步并行生成，提供高效解码与更少训练迭代的语言建模解决方案，并为扩散模型在文本生成中的应用设立新基准。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [87] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 使用潜在扩散模型（LDM）对IoT入侵数据进行增强，解决类别不平衡问题，提升基于机器学习的入侵检测系统（IDS）性能，并在低维潜在空间中生成样本以提高效率。结果显示：对DDoS、Mirai的F1可达0.99，且优于竞争方法；在保留特征依赖性的同时生成多样样本，且相比直在数据空间的扩散模型采样时间降低约25%。


<details>
  <summary>Details</summary>
Motivation: 在物联网(IoT)的ML型入侵检测中，正负样本严重不平衡导致检测性能下降。现有数据增强多采用简单的过采样或在数据空间进行的生成模型，往往难以在样本保真度、多样性和计算效率之间同时兼顾。

Method: 提出在IoT入侵检测中使用潜在扩散模型（LDM）进行攻击数据增强。对DDoS、Mirai、Man-in-the-Middle三种典型IoT攻击进行实验，与最新基线方法对比。评估包括下游IDS性能（F1）与内在生成质量（分布、依赖关系和多样性指标），并比较数据空间扩散模型在采样速度上的差异。

Result: 通过LDM生成的样本显著提升IDS性能，对DDoS和Mirai攻击的F1达到接近0.99，且整体优于竞争方法。定量与定性分析显示LDM在生成样本的同时较好地保持特征依赖性并具备多样性；相比在数据空间直接进行扩散的模型，采样时间减少约25%。

Conclusion: 潜在扩散能够作为一种高效且可扩展的解决方案，用于合成IoT攻击数据，显著缓解ML型IoT IDS中的类别不平衡问题。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


### [88] [A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs](https://arxiv.org/abs/2601.16979)
*Dayal Singh Kalra,Jean-Christophe Gagnon-Audet,Andrey Gromov,Ishita Mediratta,Kelvin Niu,Alexander H Miller,Michael Shvartsman*

Main category: cs.LG

TL;DR: 提出一种计算成本远低于全Hessian的方法：临界锐度（λ_c），需要小于10次前向传播即可在给定更新方向Δθ下评估曲率，并引入相对临界锐度λ_c^{1→2}以比较不同损失景观的曲率。该方法在规模达7B参数的OLMo-2模型上重现了Hessian锐度的经典现象（渐进性锐化、边缘稳定性），用于分析从预训练到微调的转变及数据混合策略，具备实际诊断作用。


<details>
  <summary>Details</summary>
Motivation: 理解损失面曲率随训练演化的本质问题，以及现有的Hessian锐度度量在大规模模型上的计算成本高企，迫切需要一种可扩展、低成本的曲率度量来指导大规模训练中的数据选择与训练策略。

Method: 提出并定义临界锐度λ_c，它只需在给定更新方向Δθ下进行少于10次前向传播即可评估损失面的局部曲率；通过λ_c与更新方向的关系捕捉曲率信息，并引入相对临界锐度λ_c^{1→2}以量化在优化一个损失函数时另一个损失函数的曲率。

Result: 在规模高达7B参数的OLMo-2模型上，使用临界锐度方法成功复现了渐进性锐化和边缘稳定性等Hessian锐度现象，覆盖模型的预训练和中期训练阶段，并给出从预训练到微调的转变分析与数据混合策略的指引。

Conclusion: 可扩展的曲率度量（如λ_c及λ_c^{1→2}）为大规模训练提供可操作的诊断工具，能够在不直接计算完整Hessian的情况下监测和解释损失面的曲率动力学，并支持数据组成与训练阶段的决策。

Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: 提出 Doc2AHP：一个将层次分析法（AHP）结构原理嵌入到大语言模型（LLM）中的结构化推理框架，在无需大量标注数据的前提下，从无结构文档中构建高质量决策模型，确保父子节点的逻辑蕴含和权重分配的一致性，并通过多智能体权重与自适应一致性优化提升数值一致性。实验显示显著优于直接生成基线，在逻辑完备性和下游任务准确性方面更优。


<details>
  <summary>Details</summary>
Motivation: 解决 AHP 等经验密集型决策框架的专家瓶颈问题；弥合 LLM 的泛化能力与决策理论的严格性之间的差距；在没有大量标注数据和手工干预的情况下，提升跨领域决策建模的可扩展性与可靠性。

Method: 以 AHP 的结构原则作为约束，指导 LLM 在非结构化文档空间内进行受限搜索，确保父节点到子节点的逻辑蕴含；引入多智能体权重机制以及自适应一致性优化策略以保障权重分配的数值一致性。

Result: 实验结果表明 Doc2AHP 能让非专业用户从零开始构建高质量决策模型，并在逻辑完整性和下游任务准确性方面显著优于直接的生成基线。

Conclusion: Doc2AHP 成功 bridg es LLM 与 AHP 的差距，提供一种可访问且更具理性推理约束的决策建模方案，适用于从无结构文档中提取并构建可解释的层级决策结构，同时具备权重一致性的保障，具有良好的泛化潜力。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [90] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 在四个公开数据集上对文本与图像的医疗分类任务进行对比评估，传统机器学习方法在多数任务中表现最佳，LoRA等PEFT微调模型表现不佳；零-shot 的大模型在文本任务表现不佳但在多类图像任务接近或达到 ResNet-50 基线，表明 foundation 模型并非在所有场景都占优。


<details>
  <summary>Details</summary>
Motivation: 系统性比对传统 ML、提示式大模型/视觉语言模型、以及 PEFT 微调模型在跨模态医疗分类任务中的性能，检验是否普遍存在 foundation 模型优越性假设。

Method: 在四个公开数据集（覆盖文本和图像模态、二分类与多类任务）上，对每类任务评估三类模型：经典 ML（LR、LightGBM、ResNet-50）、提示式LLM/VLM（Gemini 2.5）、微调PEFT模型（LoRA 适配 Gemma3 变体）；统一数据划分与评测指标。

Result: 传统 ML 模型在大多数医疗分类任务中总体表现最好，尤其是结构化文本数据；LoRA-微调的 Gemma3 变体在文本和图像任务上普遍表现最差，难以泛化；零-shot 的 Gemini 2.5 在文本任务表现不佳，但在多类图像任务上接近 ResNet-50 基线，甚至具竞争力。

Conclusion: 在多种医疗分类场景中，传统机器学习仍是最可靠选项；foundation 模型并非处处优越；PEFT 的有效性强烈依赖于具体的适配策略，极简微调可能适得其反。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [91] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: A 560B open-source Mixture-of-Experts model (LongCat-Flash-Thinking-2601) delivers state-of-the-art agentic reasoning among open-source models across benchmarks for agentic search, tool use, and tool-integrated reasoning, with strong generalization to complex tool interactions and robustness in noisy real-world environments. It achieves this via a unified training framework combining domain-parallel expert training with fusion, end-to-end co-design of data, environments, algorithms, and infrastructure, and an extended asynchronous RL framework (DORA) for stable large-scale multi-environment training, plus a Heavy Thinking mode for scalable test-time reasoning depth and width.


<details>
  <summary>Details</summary>
Motivation: To push open-source agentic capabilities by improving reasoning depth/width, tool use, and robustness in diverse, noisy real-world environments, while ensuring scalable training across hundreds of environments and multiple domains.

Method: 560B MoE architecture with domain-parallel expert training and fusion; end-to-end co-design of data, environments, algorithms, and infrastructure from pre-training to post-training; extension of the DORA asynchronous RL framework for stable large-scale multi-environment training (>10k environments across 20+ domains); systematic analysis of real-world noise patterns and training procedures to inject imperfections; Heavy Thinking mode enabling test-time scaling via deeper and wider reasoning through parallel thinking.

Result: Claims state-of-the-art performance among open-source models on agentic benchmarks (agentic search, agentic tool use, tool-integrated reasoning); strong generalization to complex tool interactions; robustness in noisy environments; effective long-tailed generation and multi-turn interactions; scalable training across many environments.

Conclusion: A comprehensive, scalable framework for open-source agentic AI that achieves superior performance by integrating specialized MoE architectures, large-scale multi-environment RL, robust noise-aware training, and a test-time scaling mode, suggesting strong potential for real-world agentic tasks.

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [92] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: RLVR-based reasoning LLMs show robustness improvements in Theory of Mind tasks, but gains are more likely due to robustness in finding correct solutions rather than the emergence of new ToM capabilities.


<details>
  <summary>Details</summary>
Motivation: There is ongoing debate whether improved ToM performance in LLMs reflects true social-cognitive reasoning or superficial task-solving. This work investigates whether reasoning models’ ToM performance reflects genuine ToM or robustness artifacts.

Method: Apply novel adaptations of machine psychology experiments and established ToM benchmarks to RLVR-trained reasoning LLMs and standard LLMs, examining robustness to prompt variations and task perturbations.

Result: Reasoning models display increased robustness to prompt variations and task perturbations. The observed gains appear to arise from robustness in locating the correct solution rather than from fundamentally new ToM reasoning abilities.

Conclusion: Caution is warranted when interpreting ToM abilities in LLMs. Evaluation of social-cognitive behavior should account for robustness and experimental design to distinguish true ToM from artifact-driven performance.

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [93] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: 提出 MAGE-KT，利用多视角异构图结合多智能体 KC 关系提取器与学生-题目互动图，按目标学生历史检索子图，通过不对称跨注意融合模块进行高效信息聚合，提升 KC 关系推断与下一题预测。


<details>
  <summary>Details</summary>
Motivation: KT 在建模学生学习轨迹时，需更好地表征概念之间的关系，且全图编码成本高且易引入噪声。现有方法对概念关系的挖掘不足且受限于交互序列信息，存在注意力扩散问题。

Method: 构建多视角异构图，由多智能体 KC 关系提取器提取概念关系与学生-题目交互图耦合；在预测时以目标学生历史为条件检索紧凑高价值子图，并用不对称跨注意力融合模块进行融合，避免注意力扩散。

Result: 在三个公开KT数据集上，KC 关系推断精度和下一题预测均有显著提升，相较于现有方法具有优势。

Conclusion: 通过子图高效筛选与不对称融合，提升对知识关系与学习行为的刻画，兼顾计算效率与鲁棒性；提出的框架具有较高的泛化潜力。

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [94] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: Spatial-Agent grounds geo-analytical question answering in spatial information theory by transforming natural-language questions into executable GeoFlow Graphs (DAGs). This approach aims to produce interpretable, executable geospatial workflows and outperforms baseline agents on geospatial benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-based agents struggle with genuine geospatial computation, rely on web search or pattern matching, and often hallucinate spatial relationships. A principled, theory-grounded approach is needed for accurate, interpretable geospatial reasoning.

Method: Formulate geo-analytical QA as a concept-transformation problem. Parse natural-language questions into executable workflows represented as GeoFlow Graphs (directed acyclic graphs) where nodes denote spatial concepts and edges denote transformations. Use spatial information theory to extract spatial concepts, assign functional roles with ordering constraints, and compose transformation sequences via template-based generation.

Result: Extensive experiments on MapEval-API and MapQA show Spatial-Agent significantly outperforms baselines such as ReAct and Reflexion, producing interpretable and executable geospatial workflows.

Conclusion: Spatial-Agent demonstrates a theory-grounded, interpretable framework for geospatial reasoning and QA, with practical performance gains on standard benchmarks and potential applicability to real-world geospatial problems.

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>
