<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 55]
- [cs.IR](#cs.IR) [Total: 12]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.LG](#cs.LG) [Total: 50]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EmbeddingRWKV: State-Centric Retrieval with Reusable States](https://arxiv.org/abs/2601.07861)
*Haowen Hou,Jie Yang*

Main category: cs.CL

TL;DR: A unified state-centric retrieval framework that uses EmbeddingRWKV to unify embedding and state extraction, enabling a fast state-based reranker; achieves substantial speedups (5.4x-44.8x) and strong retention of performance (98.62% with 25% layers).


<details>
  <summary>Details</summary>
Motivation: Two-stage Retrieval-Augmented Generation (RAG) pipelines are inefficient due to lack of shared information between embedding and reranking stages, causing redundant computation. A unified approach with reusable 'states' can improve efficiency without sacrificing quality.

Method: Fine-tune an RWKV-based LLM to create EmbeddingRWKV as a unified embedding model and state backbone; extract compact, reusable states; design a state-based reranker that uses only query tokens during reranking; apply a uniform layer selection strategy to reduce model size while preserving performance (e.g., 25% of layers).

Result: Substantial speedups in reranking (5.4x–44.8x); high-quality retrieval and reranking; retains 98.62% of full-model performance with only 25% of layers; code released at GitHub.

Conclusion: State-Centric Retrieval demonstrates that a unified embedding-and-reranking framework via reusable states can significantly improve overall RAG efficiency while maintaining comparable performance.

Abstract: Current Retrieval-Augmented Generation (RAG) systems typically employ a traditional two-stage pipeline: an embedding model for initial retrieval followed by a reranker for refinement. However, this paradigm suffers from significant inefficiency due to the lack of shared information between stages, leading to substantial redundant computation. To address this limitation, we propose \textbf{State-Centric Retrieval}, a unified retrieval paradigm that utilizes "states" as a bridge to connect embedding models and rerankers. First, we perform state representation learning by fine-tuning an RWKV-based LLM, transforming it into \textbf{EmbeddingRWKV}, a unified model that serves as both an embedding model and a state backbone for extracting compact, reusable states. Building upon these reusable states, we further design a state-based reranker to fully leverage precomputed information. During reranking, the model processes only query tokens, decoupling inference cost from document length and yielding a 5.4$\times$--44.8$\times$ speedup. Furthermore, we observe that retaining all intermediate layer states is unnecessary; with a uniform layer selection strategy, our model maintains 98.62\% of full-model performance using only 25\% of the layers. Extensive experiments demonstrate that State-Centric Retrieval achieves high-quality retrieval and reranking results while significantly enhancing overall system efficiency. Code is available at \href{https://github.com/howard-hou/EmbeddingRWKV}{our GitHub repository}.

</details>


### [2] [A Human-Centric Pipeline for Aligning Large Language Models with Chinese Medical Ethics](https://arxiv.org/abs/2601.07954)
*Haoan Jin,Han Ying,Jiacheng Ji,Hanhui Xu,Mengyue Wu*

Main category: cs.CL

TL;DR: 用 MedES 基准与 guardian-in-the-loop 对齐7B LLM，在中国医学伦理任务上优于更大基线。


<details>
  <summary>Details</summary>
Motivation: 弥合 LLM 在复杂现实医疗伦理中的不足，尤其是面向中国语境的法规、伦理规范和临床决策需求。

Method: 构建 MedES：基于260个权威中文医学、伦理与法律来源，创建情景中心化基准；引入 guardian-in-the-loop 框架，利用基于专家标注数据训练的自动评估器生成定向提示并提供结构化伦理反馈；通过该流水线对7B参数模型进行监督微调和领域特定偏好优化。

Result: 在中国医学伦理情境下的实验表明，已对齐模型在核心伦理任务上显著优于更大基线，且在质量和综合评估指标上有所提升；自动评估器的准确率超过97%。

Conclusion: 该框架为医疗伦理对齐提供可操作、可定制的路径，具备可扩展性，可通过模块化替换规范性语料库实现跨文化/法域迁移。

Abstract: Recent advances in large language models have enabled their application to a range of healthcare tasks. However, aligning LLMs with the nuanced demands of medical ethics, especially under complex real world scenarios, remains underexplored. In this work, we present MedES, a dynamic, scenario-centric benchmark specifically constructed from 260 authoritative Chinese medical, ethical, and legal sources to reflect the challenges in clinical decision-making. To facilitate model alignment, we introduce a guardian-in-the-loop framework that leverages a dedicated automated evaluator (trained on expert-labeled data and achieving over 97% accuracy within our domain) to generate targeted prompts and provide structured ethical feedback. Using this pipeline, we align a 7B-parameter LLM through supervised fine-tuning and domain-specific preference optimization. Experimental results, conducted entirely within the Chinese medical ethics context, demonstrate that our aligned model outperforms notably larger baselines on core ethical tasks, with observed improvements in both quality and composite evaluation metrics. Our work offers a practical and adaptable framework for aligning LLMs with medical ethics in the Chinese healthcare domain, and suggests that similar alignment pipelines may be instantiated in other legal and cultural environments through modular replacement of the underlying normative corpus.

</details>


### [3] [Knowing But Not Doing: Convergent Morality and Divergent Action in LLMs](https://arxiv.org/abs/2601.07972)
*Jen-tse Huang,Jiantong Qin,Xueli Qiu,Sharon Levy,Michelle R. Kaufman,Mark Dredze*

Main category: cs.CL

TL;DR: ValAct-15k dataset with 3,000 Reddit-derived advice scenarios to elicit 10 Schwartz values, evaluating ten frontier LLMs (5 US, 5 CN) and 55 humans. Cross-model scenario decisions show near-perfect consistency (r ~ 1.0), while human judgments are highly variable (r in [-0.79, 0.98]). Weak correspondence between self-reported and enacted values (humans r=0.4; LLMs r=0.3). When asked to hold a value, LLMs' performance drops up to 6.6% versus simply selecting the value (role-play aversion). Implication: alignment training yields normative convergence but does not eliminate the knowledge-action gap.


<details>
  <summary>Details</summary>
Motivation: Investigate how LLMs represent and enact human values in real-world decision contexts and quantify value alignment across AI models and humans using a standardized dataset grounded in Schwartz's value theory.

Method: Create ValAct-15k by extracting 3,000 advice-seeking scenarios from Reddit aimed at eliciting ten Schwartz values. Use both scenario-based questions and a traditional value questionnaire. Evaluate ten frontier LLMs (5 US, 5 CN) and human participants (n=55). Analyze cross-model consistency, self-reported vs enacted values, and effects of instruction to hold a value.

Result: - Near-perfect cross-model consistency in scenario-based decisions (r ≈ 1.0). - Humans show broad variability (r ∈ [-0.79, 0.98]). - Weak correspondence between self-reported and enacted values (humans r=0.4; LLMs r=0.3). - When instructed to hold a value, LLM performance declines up to 6.6% compared to merely selecting the value (role-play aversion).

Conclusion: Alignment-focused training yields normative convergence of values across models but does not eradicate the knowledge–action gap between knowing and enacting values; future work should address role-play aversion and translation of value knowledge into action.

Abstract: Value alignment is central to the development of safe and socially compatible artificial intelligence. However, how Large Language Models (LLMs) represent and enact human values in real-world decision contexts remains under-explored. We present ValAct-15k, a dataset of 3,000 advice-seeking scenarios derived from Reddit, designed to elicit ten values defined by Schwartz Theory of Basic Human Values. Using both the scenario-based questions and the traditional value questionnaire, we evaluate ten frontier LLMs (five from U.S. companies, five from Chinese ones) and human participants ($n = 55$). We find near-perfect cross-model consistency in scenario-based decisions (Pearson $r \approx 1.0$), contrasting sharply with the broad variability observed among humans ($r \in [-0.79, 0.98]$). Yet, both humans and LLMs show weak correspondence between self-reported and enacted values ($r = 0.4, 0.3$), revealing a systematic knowledge-action gap. When instructed to "hold" a specific value, LLMs' performance declines up to $6.6%$ compared to merely selecting the value, indicating a role-play aversion. These findings suggest that while alignment training yields normative value convergence, it does not eliminate the human-like incoherence between knowing and acting upon values.

</details>


### [4] [Explaining Generalization of AI-Generated Text Detectors Through Linguistic Analysis](https://arxiv.org/abs/2601.07974)
*Yuxi Xia,Kinga Stańczak,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文系统分析AI文本检测器在跨提示、跨模型、跨领域的泛化能力受限的原因。通过构建覆盖6种提示策略、7个LLMs、4个领域的数据集的综合基准，对检测器在不同生成设定下的表现进行微调与评估，并通过对训练–测试之间80个语言特征的分布变化进行相关性分析，发现某些语言特征（如时态使用、代词频率等）显著关联泛化性能的差异。


<details>
  <summary>Details</summary>
Motivation: 揭示泛化瓶颈的潜在语言学原因，提升检测器对跨条件文本的稳健性。

Method: (1) 构建包含6种提示策略、7个LLM、4个领域的数据集的基准，覆盖人类与AI生成文本；(2) 在不同生成设定下微调分类检测器，并评估其跨提示、跨模型、跨数据集的泛化能力；(3) 计算训练与测试之间80个语言特征的分布差异，并与泛化准确率进行相关分析。

Result: 泛化性能与关键语言特征的移位显著相关；时态使用、代词频率等特征对不同检测器和评估条件的泛化表现具有显著解释力，揭示语言学差异是跨-condition泛化差异的主要线索。

Conclusion: 语言学特征的系统性变动可解释AI文本检测器的泛化差异；需在检测器训练中引入语言特征敏感性、领域自适应或对特征分布的鲁棒优化来提升跨条件泛化能力。

Abstract: AI-text detectors achieve high accuracy on in-domain benchmarks, but often struggle to generalize across different generation conditions such as unseen prompts, model families, or domains. While prior work has reported these generalization gaps, there are limited insights about the underlying causes. In this work, we present a systematic study aimed at explaining generalization behavior through linguistic analysis. We construct a comprehensive benchmark that spans 6 prompting strategies, 7 large language models (LLMs), and 4 domain datasets, resulting in a diverse set of human- and AI-generated texts. Using this dataset, we fine-tune classification-based detectors on various generation settings and evaluate their cross-prompt, cross-model, and cross-dataset generalization. To explain the performance variance, we compute correlations between generalization accuracies and feature shifts of 80 linguistic features between training and test conditions. Our analysis reveals that generalization performance for specific detectors and evaluation conditions is significantly associated with linguistic features such as tense usage and pronoun frequency.

</details>


### [5] [Multilingual, Multimodal Pipeline for Creating Authentic and Structured Fact-Checked Claim Dataset](https://arxiv.org/abs/2601.07985)
*Z. Melce Hüsünbeyi,Virginie Mouilleron,Leonie Uhling,Daniel Foppe,Tatjana Scheffler,Djamé Seddah*

Main category: cs.CL

TL;DR: 提出一个法语和德语的多模态事实核查数据集建设与处理流水线，聚合ClaimReview、抓取全文、规范化判决并配以结构元数据和对齐的视觉内容，辅以LLMs进行证据提取与理由生成。


<details>
  <summary>Details</summary>
Motivation: 当前的假信息检测资源缺乏跨语言、跨模态证据、结构化注释，以及证据-结论的明确对应，限制了可解释性和可比性。

Method: 构建数据流水线，聚合ClaimReview，抓取全文，标准化判决，丰富结构化元数据并对齐视觉内容；使用大型语言模型和多模态LLMs执行证据提取（按预定义证据类别）和把证据与判决联系起来的理由生成。

Result: 通过G-Eval和人工评估，证明流水线可实现跨机构/市场的细粒度比较，促进可解释、证据支撑的核查模型发展，并为多语言、多模态误传验证研究奠定基础。

Conclusion: 该工作建立了一个可用于多语言、多模态事实核查研究和对比的综合数据收集与处理框架，弥补现有数据集在覆盖范围、模态融合、结构化注释和证据-结论对齐方面的不足。

Abstract: The rapid proliferation of misinformation across online platforms underscores the urgent need for robust, up-to-date, explainable, and multilingual fact-checking resources. However, existing datasets are limited in scope, often lacking multimodal evidence, structured annotations, and detailed links between claims, evidence, and verdicts. This paper introduces a comprehensive data collection and processing pipeline that constructs multimodal fact-checking datasets in French and German languages by aggregating ClaimReview feeds, scraping full debunking articles, normalizing heterogeneous claim verdicts, and enriching them with structured metadata and aligned visual content. We used state-of-the-art large language models (LLMs) and multimodal LLMs for (i) evidence extraction under predefined evidence categories and (ii) justification generation that links evidence to verdicts. Evaluation with G-Eval and human assessment demonstrates that our pipeline enables fine-grained comparison of fact-checking practices across different organizations or media markets, facilitates the development of more interpretable and evidence-grounded fact-checking models, and lays the groundwork for future research on multilingual, multimodal misinformation verification.

</details>


### [6] [VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding](https://arxiv.org/abs/2601.07986)
*Haorui Yu,Ramon Ruiz-Dolz,Diji Yang,Hang He,Fengrui Zhang,Qiufeng Yi*

Main category: cs.CL

TL;DR: A new benchmark, VULCA-Bench, assesses VLMs' cultural understanding beyond basic perception using 7,410 image-critique pairs across eight cultures, with bilingual Chinese-English critiques. A five-layer framework (L1-L5) covers Visual Perception to Philosophical Aesthetics, comprising 225 culture-specific dimensions. Expert critiques accompany data; higher-layer reasoning (L3-L5) proves more challenging than L1-L2. Resources (dataset, scripts, tools) are CC BY 4.0 in supplementary materials.


<details>
  <summary>Details</summary>
Motivation: Current VLM benchmarks overemphasize surface-level perception (object recognition, scene description) and factual QA. There is a need to evaluate deeper cultural interpretation to ensure models can understand cross-cultural aesthetics, norms, and critique. VULCA-Bench targets this gap by operationalizing a structured, multilingual, culture-centered evaluation framework.

Method: Construct a large, matched image-critique dataset: 7,410 image-critique pairs across eight cultural traditions with Chinese-English bilingual coverage. Implement a five-layer framework (L1-L5) spanning from Visual Perception to Philosophical Aesthetics, instantiated as 225 culture-specific dimensions. Each item is paired with expert-written bilingual critiques. Provide evaluation scripts and annotation tools; release under CC BY 4.0. Conduct pilot experiments showing relative difficulty of higher-layer reasoning (L3-L5) compared to L1-L2.

Result: Dataset and tools enable systematic assessment of cultural understanding in VLMs. Pilot results indicate higher-layer reasoning (L3-L5) is consistently more challenging for models than visual/technical analysis (L1-L2).

Conclusion: VULCA-Bench fills a gap in VLM evaluation by focusing on nuanced cultural interpretation across traditions. The bilingual, expert-annotated design and layered framework offer a robust foundation for measuring and improving cultural competence in multimodal models.

Abstract: We introduce VULCA-Bench, a multicultural art-critique benchmark for evaluating Vision-Language Models' (VLMs) cultural understanding beyond surface-level visual perception. Existing VLM benchmarks predominantly measure L1-L2 capabilities (object recognition, scene description, and factual question answering) while under-evaluate higher-order cultural interpretation. VULCA-Bench contains 7,410 matched image-critique pairs spanning eight cultural traditions, with Chinese-English bilingual coverage. We operationalise cultural understanding using a five-layer framework (L1-L5, from Visual Perception to Philosophical Aesthetics), instantiated as 225 culture-specific dimensions and supported by expert-written bilingual critiques. Our pilot results indicate that higher-layer reasoning (L3-L5) is consistently more challenging than visual and technical analysis (L1-L2). The dataset, evaluation scripts, and annotation tools are available under CC BY 4.0 in the supplementary materials.

</details>


### [7] [From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP](https://arxiv.org/abs/2601.07988)
*Adithya V Ganesan,Vasudha Varadarajan,Oscar NE Kjell,Whitney R Ringwald,Scott Feltman,Benjamin J Luft,Roman Kotov,Ryan L Boyd,H Andrew Schwartz*

Main category: cs.CL

TL;DR: 提出在NLP中引入行为序列的纵向建模与评估框架，区分跨个体与时间的泛化，改进四个管线环节，以解决文档独立性假设的局限；在日记-PTSD数据集上显示传统文档级评估可能导致不同甚至相反的结论。


<details>
  <summary>Details</summary>
Motivation: 解决NLP在纵向数据中的独立样本与无序假设的局限，强调个体内动态与跨个体差异对模型评估与泛化的影响，与现实世界纵向数据的价值。

Method: 提出四部分纵向建模与评估范式：1) 将评估拆分为跨个体（横截面）和/或随时间的前瞻性评估；2) 使用区分个体间差异与个体内动态的准确性指标；3) 将历史信息作为序列输入纳入模型默认；4) 设计支持不同历史粒度（聚合摘要、显式动态、交互型模型）的潜在状态结构。

Result: 在17k份日记文本与238名参与者的PTSD症状数据集上，传统文档级评估与生态有效建模评估的结论显著不同，且有时甚至相反，凸显纵向建模的必要性。

Conclusion: 推动NLP从单一词序列评估转向行为序列范式，强调考虑时序性、个体差异和历史依赖以提升泛化与解释性。

Abstract: While NLP typically treats documents as independent and unordered samples, in longitudinal studies, this assumption rarely holds: documents are nested within authors and ordered in time, forming person-indexed, time-ordered $\textit{behavioral sequences}$. Here, we demonstrate the need for and propose a longitudinal modeling and evaluation paradigm that consequently updates four parts of the NLP pipeline: (1) evaluation splits aligned to generalization over people ($\textit{cross-sectional}$) and/or time ($\textit{prospective}$); (2) accuracy metrics separating between-person differences from within-person dynamics; (3) sequence inputs to incorporate history by default; and (4) model internals that support different $\textit{coarseness}$ of latent state over histories (pooled summaries, explicit dynamics, or interaction-based models). We demonstrate the issues ensued by traditional pipeline and our proposed improvements on a dataset of 17k daily diary transcripts paired with PTSD symptom severity from 238 participants, finding that traditional document-level evaluation can yield substantially different and sometimes reversed conclusions compared to our ecologically valid modeling and evaluation. We tie our results to a broader discussion motivating a shift from word-sequence evaluation toward $\textit{behavior-sequence}$ paradigms for NLP.

</details>


### [8] [DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs](https://arxiv.org/abs/2601.07994)
*Nayoung Choi,Jonathan Zhang,Jinho D. Choi*

Main category: cs.CL

TL;DR: DyCP is a lightweight, dynamic context management approach for long-form dialogue that segments and retrieves relevant memory at query time, preserving dialogue order without fixed topic boundaries while reducing latency and improving answer quality.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with long dialogue histories: increased latency and degraded answer quality. Existing memory methods require extra LLM calls or offline memory construction that may waste resources or disrupt conversation. There is a need for efficient, on-demand memory retrieval that respects current user utterances.

Method: DyCP dynamically segments the dialogue and retrieves memory relevant to the current query at runtime. It preserves the sequential structure, avoids predefined topic boundaries, and enables adaptive context retrieval with minimal overhead.

Result: Across three long-form dialogue benchmarks (LoCoMo, MT-Bench+, SCM4LLMs) and multiple LLMs, DyCP consistently improves answer quality and reduces response latency.

Conclusion: There remains a gap between expanded context windows in modern LLMs and their capacity for long-context processing; effective context management remains crucial for scalable, high-quality dialogue systems.

Abstract: Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. However, existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. We introduce DyCP, a lightweight context management method that dynamically segment and retrieve relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks, LoCoMo, MT-Bench+, and SCM4LLMs, and multiple LLMs, DyCP consistently improves answer quality while reducing response latency. We also examine the gap between modern LLMs' expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.

</details>


### [9] [Is Sentiment Banana-Shaped? Exploring the Geometry and Portability of Sentiment Concept Vectors](https://arxiv.org/abs/2601.07995)
*Laurits Lyngbaek,Pascale Feldkamp,Yuri Bizzoni,Kristoffer L. Nielbo,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: CVP将情感建模为嵌入向量空间中的方向，给出连续、多语种的情感分数；在跨体裁、历史时期、语言与情感维度的迁移性方面表现良好，但线性假设为近似，存在潜在改进空间。


<details>
  <summary>Details</summary>
Motivation: 解决人文领域对情感分析的上下文化、连续分数的需求，并评估CVP在跨领域、跨语言场景中的泛化能力与其线性假设的有效性。

Method: 在多种体裁、历史时期、语言和情感维度的语料上训练CVP向量，并在目标语料上进行迁移评估，量化性能损失；同时检验CVP的线性假设的成立程度与近似性。

Result: CVP在一个语料上训练后可迁移至其他语料，表现的性能损失很小；线性假设是近似的，但CVP能捕捉到普遍的、可迁移的情感模式。

Conclusion: CVP是一种可移植、能有效捕捉一般化情感模式的方法，但需对线性假设进行改进以提升精度与适用性。

Abstract: Use cases of sentiment analysis in the humanities often require contextualized, continuous scores. Concept Vector Projections (CVP) offer a recent solution: by modeling sentiment as a direction in embedding space, they produce continuous, multilingual scores that align closely with human judgments. Yet the method's portability across domains and underlying assumptions remain underexplored. We evaluate CVP across genres, historical periods, languages, and affective dimensions, finding that concept vectors trained on one corpus transfer well to others with minimal performance loss. To understand the patterns of generalization, we further examine the linearity assumption underlying CVP. Our findings suggest that while CVP is a portable approach that effectively captures generalizable patterns, its linearity assumption is approximate, pointing to potential for further development.

</details>


### [10] [Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models](https://arxiv.org/abs/2601.08058)
*Zhenghao He,Guangzhi Xiong,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: 通过对LLM内部表征进行稀疏自编码分析，发现少量潜在特征与推理行为因果相关；通过外部干预（潜在特征定向）即可在不使用CoT的情况下显著提升推理准确性，且对大型模型与CoT性能相当或更高效，证实多步推理由内部潜在激活支撑，CoT仅是触发机制之一。


<details>
  <summary>Details</summary>
Motivation: 揭示CoT prompting为何有效以及是否存在唯一的触发推理的内部机制；通过直接干预LLM内部表征来定位与推理相关的潜在特征。

Method: 在多种模型家族与推理基准上，使用稀疏自编码器（SAE）提取内部潜在特征，定位与推理行为因果相关的一个或少量特征；通过外部干预 steering 单一推理相关潜在特征来评估对推理性能的影响，并与标准CoT prompting进行对比。

Result: 通过对单一推理相关潜在特征的定向干预，显著提高在没有CoT提示条件下的推理准确率；在大型模型中，潜在特征定向与CoT提示的性能相当，且输出更高效；推理相关的内部状态在生成早期被触发，且能够覆盖不鼓励显式推理的提示。

Conclusion: 多步推理由可被外部激活的内部潜在激活支撑，CoT提示只是其中一种有效而非必要的触发机制；这一发现强调探索内部表征及可控性对提升LLM推理能力的重要性。

Abstract: Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in large language models. In this work, we study this question by directly analyzing and intervening on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features that are causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, we find that steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. We further observe that this reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. Overall, our results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause.

</details>


### [11] [Universal computation is intrinsic to language model decoding](https://arxiv.org/abs/2601.08061)
*Alex Lewandowski,Marlos C. Machado,Dale Schuurmans*

Main category: cs.CL

TL;DR: 将自回归输出串联起来即可实现通用计算；即使是随机初始化的语言模型，在训练前也具备通用计算能力，训练的作用是提升可编程性而非引入表达能力。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型在自然语言接口之外的计算能力本质：语言模型是否具备固有的计算普适性，以及训练是否真正扩展了表达能力，还是主要提高了可编程性。

Method: 给出形式化证明，表明对语言模型输出的自回归链条可以模拟任意算法对任意输入的执行；并通过理论构造与可能的实验性原型，展示即使在未训练、随机初始化的模型上也能实现通用计算。

Result: 证明语言模型的自回归输出链足以实现任意算法的执行，从而具备通用计算性；训练并非增加表达能力，而是提升通过自然语言提示访问和编排这些内在能力的可编程性。

Conclusion: 结论是语言模型具有内在的计算表达能力，训练的作用是提高可编程性和接口友好性，使自然语言成为访问这些潜在能力的入口。

Abstract: Language models now provide an interface to express and often solve general problems in natural language, yet their ultimate computational capabilities remain a major topic of scientific debate. Unlike a formal computer, a language model is trained to autoregressively predict successive elements in human-generated text. We prove that chaining a language model's autoregressive output is sufficient to perform universal computation. That is, a language model can simulate the execution of any algorithm on any input. The challenge of eliciting desired computational behaviour can thus be reframed in terms of programmability: the ease of finding a suitable prompt. Strikingly, we demonstrate that even randomly initialized language models are capable of universal computation before training. This implies that training does not give rise to computational expressiveness -- rather, it improves programmability, enabling a natural language interface for accessing these intrinsic capabilities.

</details>


### [12] [Calibration Is Not Enough: Evaluating Confidence Estimation Under Language Variations](https://arxiv.org/abs/2601.08064)
*Yuxi Xia,Dennis Ulmer,Terra Blevins,Yihong Liu,Hinrich Schütze,Benjamin Roth*

Main category: cs.CL

TL;DR: 提出一个面向CE的新综合评估框架，重点衡量对提示扰动鲁棒性、等价语义回答的稳定性，以及对语义差异回答的敏感性，揭示现有CE方法在这些维度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有CE评估主要关注校准与区分度，忽略在提示变换与语义变化下的稳定性，可能导致在实际应用中CE不可靠。

Method: 建立三维评估维度：对提示扰动的鲁棒性、对等价回答的稳定性、对语义不同回答的敏感性，并与传统校准/区分指标联合评估CE方法。

Result: 多方法在新指标上的表现差异显著，常见CE方法在鲁棒性、稳定性、敏感性上均存在不足，框架提供对CE方法的更全面比较与选择。

Conclusion: 框架揭示CE评估的新偏差，给实际应用提供指导，并有助于设计更可靠的CE方法。

Abstract: Confidence estimation (CE) indicates how reliable the answers of large language models (LLMs) are, and can impact user trust and decision-making. Existing work evaluates CE methods almost exclusively through calibration, examining whether stated confidence aligns with accuracy, or discrimination, whether confidence is ranked higher for correct predictions than incorrect ones. However, these facets ignore pitfalls of CE in the context of LLMs and language variation: confidence estimates should remain consistent under semantically equivalent prompt or answer variations, and should change when the answer meaning differs. Therefore, we present a comprehensive evaluation framework for CE that measures their confidence quality on three new aspects: robustness of confidence against prompt perturbations, stability across semantic equivalent answers, and sensitivity to semantically different answers. In our work, we demonstrate that common CE methods for LLMs often fail on these metrics: methods that achieve good performance on calibration or discrimination are not robust to prompt variations or are not sensitive to answer changes. Overall, our framework reveals limitations of existing CE evaluations relevant for real-world LLM use cases and provides practical guidance for selecting and designing more reliable CE methods.

</details>


### [13] [AdaJudge: Adaptive Multi-Perspective Judging for Reward Modeling](https://arxiv.org/abs/2601.08097)
*Yongliang Miao,Yangyang Liang,Mengnan Du*

Main category: cs.CL

TL;DR: AdaJudge通过门控 refinement 与自适应多视角池化替代静态读取，以联合优化表示和聚合，提升奖励建模的判别能力。


<details>
  <summary>Details</summary>
Motivation: 现有奖励建模多采用静态池化，导致对任务信号的对齐不足且表征偏向生成任务；需同时优化表示和聚合以实现更细粒度的判别。

Method: 引入门控精炼块，将骨干表示重塑为更利于判别的空间；采用自适应多视角池化模块，动态路由与融合证据，替代静态只读的结构；端到端训练以同时优化表示和聚合。

Result: 在 RM-Bench 与 JudgeBench 上，AdaJudge 超越强基线的现成奖励模型与传统池化方法。

Conclusion: 联合优化表示与聚合可提升奖励建模的对齐性和判别能力，适用于需要对偏好信号进行细粒度区分的任务。

Abstract: Reward modeling is essential for aligning large language models with human preferences, yet predominant architectures rely on a static pooling strategy to condense sequences into scalar scores. This paradigm, however, suffers from two key limitations: a static inductive bias that misaligns with task-dependent preference signals, and a representational mismatch, as the backbone is optimized for generation rather than fine-grained discrimination. To address this, we propose AdaJudge, a unified framework that jointly adapts representation and aggregation. AdaJudge first refines backbone representations into a discrimination-oriented space via gated refinement blocks. It then replaces the static readout with an adaptive multi-view pooling module that dynamically routes and combines evidence. Extensive experiments on RM-Bench and JudgeBench show that AdaJudge outperforms strong off-the-shelf reward models and traditional pooling baselines.

</details>


### [14] [Query Suggestion for Retrieval-Augmented Generation via Dynamic In-Context Learning](https://arxiv.org/abs/2601.08105)
*Fabian Spaeh,Tianyi Chen,Chen-Hao Chiang,Bin Shen*

Main category: cs.CL

TL;DR: 提出 agentic RAG 的查询建议框架，解决可问答性不足的问题，采用鲁棒动态少样本学习和工作流检索以生成相关且可回答的查询。


<details>
  <summary>Details</summary>
Motivation: 在工具调用的多步 RAG 工作流中，超出知识范围的问题易产生幻觉，需引导用户提出可解答的查询以提升交互安全性和效果。

Method: 引入鲁棒动态少样本学习，检索相关工作流的示例，以自我学习的方式在先前用户查询上进行适应；在三个基准数据集和两个未标注数据集上进行评估，优于少样本与仅检索基线。

Result: 系统能够生成更相关且可回答的查询建议，提升交互的安全性与效率。

Conclusion: 为 agentic RAG 的人机交互提供可操作且可解释的查询建议机制，便于在现实工具受限场景中的应用。

Abstract: Retrieval-augmented generation with tool-calling agents (agentic RAG) has become increasingly powerful in understanding, processing, and responding to user queries. However, the scope of the grounding knowledge is limited and asking questions that exceed this scope may lead to issues like hallucination. While guardrail frameworks aim to block out-of-scope questions (Rodriguez et al., 2024), no research has investigated the question of suggesting answerable queries in order to complete the user interaction.
  In this paper, we initiate the study of query suggestion for agentic RAG. We consider the setting where user questions are not answerable, and the suggested queries should be similar to aid the user interaction. Such scenarios are frequent for tool-calling LLMs as communicating the restrictions of the tools or the underlying datasets to the user is difficult, and adding query suggestions enhances the interaction with the RAG agent. As opposed to traditional settings for query recommendations such as in search engines, ensuring that the suggested queries are answerable is a major challenge due to the RAG's multi-step workflow that demands a nuanced understanding of the RAG as a whole, which the executing LLM lacks. As such, we introduce robust dynamic few-shot learning which retrieves examples from relevant workflows. We show that our system can be self-learned, for instance on prior user queries, and is therefore easily applicable in practice. We evaluate our approach on three benchmark datasets based on two unlabeled question datasets collected from real-world user queries. Experiments on real-world datasets confirm that our method produces more relevant and answerable suggestions, outperforming few-shot and retrieval-only baselines, and thus enable safer, more effective user interaction with agentic RAG.

</details>


### [15] [Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought](https://arxiv.org/abs/2601.08108)
*Bowen Li,Ziqi Xu,Jing Ren,Renqiang Luo,Xikun Zhang,Xiuzhen Zhang,Yongli Ren,Feng Xia*

Main category: cs.CL

TL;DR: ACPS通过结构因果模型自适应选择前门/条件前门干预，使用Sketch-of-Thought替代冗长的Chain-of-Thought，实现跨任务的可泛化因果推理，显著降低令牌开销与推理成本，在多项基准与LLM上优于现有提示基线。


<details>
  <summary>Details</summary>
Motivation: 现有的 prompting 方法（如CoT）在推理成本和泛化能力方面存在不足：需要大量令牌来引导推理且难以跨任务泛化；亟需可在多任务场景中无需任务特定再训练的因果推理框架。

Method: 基于结构因果模型，推断查询对答案的因果效应，并自适应选择干预（标准前门与条件前门）以实现通用的因果推理；用Sketch-of-Thought替代冗长的CoT，降低令牌开销与推理成本；无需对具体任务进行再训练。

Result: 在多项推理基准与多种LLM上，ACPS在准确性、鲁棒性和计算效率方面持续优于现有提示基线。

Conclusion: ACPS实现了可扩展的可泛化因果推理，显著降低令牌使用与推理成本，并且无需任务特定的再训练。

Abstract: Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.

</details>


### [16] [Attention Projection Mixing and Exogenous Anchors](https://arxiv.org/abs/2601.08131)
*Jonathan Su*

Main category: cs.CL

TL;DR: ExoFormer introduces external exogenous anchor projections to address the tension in early-layer attention residuals; uses a unified normalized mixing framework across attention paths; shows improved accuracy and data efficiency and reduced attention sink, but exhibits representation collapse; explained by Offloading Hypothesis; releases code and models.


<details>
  <summary>Details</summary>
Motivation: 解决 Transformer 在复用早层注意力投影作为残差时的矛盾，即第一层需同时作为深层层的稳定参考和有效的计算块。

Method: 引入外部的 exogenous anchor 投影，与序列层堆栈解耦；提出统一的归一化混合框架，研究不同系数粒度（elementwise、headwise、scalar）在查询、键、值和门控对数的应用；比较 ExoFormer 的不同变体与内部锚点的对比；在下游任务上评估动态变体的准确度、数据效率和注意力汇聚；

Result: 动态变体在下游准确度上比基线提升 2.13 点；数据效率提升，使用 1.84x 更少的 tokens 达到相同的验证损失；注意力汇聚（attention sink）减少约 2x；所有变体出现表示崩溃现象，通过 Offloading Hypothesis 进行解释；发布代码和模型。

Conclusion: 外部锚点有望提升学习效率与稳定性，但可能引发表示崩溃问题，需要进一步研究缓解策略；外部锚点在注意力机制中的潜力得到初步验证。

Abstract: Transformers that reuse early-layer attention projections as residuals face a fundamental tension: the first layer must simultaneously serve as a stable reference for all deeper layers and as an effective computational block. To resolve this, we propose ExoFormer, which learns dedicated exogenous anchor projections outside the sequential layer stack, decoupling the anchor role from computational refinement. Through a unified normalized mixing framework (studying different coefficient granularities: elementwise, headwise, scalar) across all attention pathways (queries, keys, values, and gate logits), ExoFormer variants consistently outperform their internal-anchor counterparts. Moreover, the dynamic variant achieves a 2.13-point increase in downstream accuracy over the baseline and demonstrates superior data efficiency, matching baseline validation loss with 1.84x fewer tokens. ExoFormer also achieves a 2x reduction in attention sink compared to standard Gated Attention. Paradoxically, all ExoFormer variants exhibit signs of representation collapse. We explain this via an Offloading Hypothesis: external anchors preserve essential token identity, allowing layers to specialize exclusively in computational refinement. We release codes and models to facilitate future research.

</details>


### [17] [How Reliable are Confidence Estimators for Large Reasoning Models? A Systematic Benchmark on High-Stakes Domains](https://arxiv.org/abs/2601.08134)
*Reza Khanmohammadi,Erfan Miahi,Simerjot Kaur,Ivan Brugere,Charese H. Smiley,Kundan Thind,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: 提出 Reasoning Model Confidence estimation Benchmark (RMCB)，包含347,496条推理轨迹，覆盖六大LRM家族和跨领域数据集，提供正确性注释；评估十余种表示方法，揭示区分性与校准性之间的权衡，文本编码器在AUROC上领先，结构化编码在ECE上领先；高等级的架构复杂度并不必然优于简单基线；提供迄今最全面的基准并揭示现有方法局限。


<details>
  <summary>Details</summary>
Motivation: 大规模推理模型在长篇多步输出中的置信度估计不足，需建立可公开的高质量基准以评估与提升置信度校准和判别能力，尤其在临床、金融、法律等高风险领域。

Method: 构建 RMCB，汇集347,496条推理轨迹，覆盖六大LRM架构家族；跨临床、金融、法律、数学等高风险领域及一般推理数据集；对所有样本给出正确性标注；对超过10种表示学习方法进行评测，涵盖顺序、图结构、文本三类架构。

Result: 在区分性（AUROC）与校准性（ECE）之间存在持续权衡：文本编码器获得最佳AUROC 0.672，结构感知模型获得最佳ECE 0.148；无单一方法在两者上都处于领先；更高架构复杂度不稳定超越简单的顺序基线。

Conclusion: 该工作提供迄今最全面的推理置信度基准，建立了严格的基线，并揭示基于表示的方法在当前范式下的局限性。

Abstract: The miscalibration of Large Reasoning Models (LRMs) undermines their reliability in high-stakes domains, necessitating methods to accurately estimate the confidence of their long-form, multi-step outputs. To address this gap, we introduce the Reasoning Model Confidence estimation Benchmark (RMCB), a public resource of 347,496 reasoning traces from six popular LRMs across different architectural families. The benchmark is constructed from a diverse suite of datasets spanning high-stakes domains, including clinical, financial, legal, and mathematical reasoning, alongside complex general reasoning benchmarks, with correctness annotations provided for all samples. Using RMCB, we conduct a large-scale empirical evaluation of over ten distinct representation-based methods, spanning sequential, graph-based, and text-based architectures. Our central finding is a persistent trade-off between discrimination (AUROC) and calibration (ECE): text-based encoders achieve the best AUROC (0.672), while structurally-aware models yield the best ECE (0.148), with no single method dominating both. Furthermore, we find that increased architectural complexity does not reliably outperform simpler sequential baselines, suggesting a performance ceiling for methods relying solely on chunk-level hidden states. This work provides the most comprehensive benchmark for this task to date, establishing rigorous baselines and demonstrating the limitations of current representation-based paradigms.

</details>


### [18] [Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training](https://arxiv.org/abs/2601.08141)
*Muhammad Taimoor Hassan,Jawad Ahmed,Muhammad Awais*

Main category: cs.CL

TL;DR: Qalb 在 LLaMA 3.1 8B-Instruct 基础上，通过继续预训练和有监督微调，针对乌尔都语的低资源情景，达到 SOTA 表现，显著优于以前的 Alif-1.0-Instruct 与 基线模型。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语在 NLP 中严重低资源，现有多语言模型在乌尔都语任务上表现不佳，需解决复杂形态、右到左书写和丰富文学传统等挑战。

Method: 两阶段训练：在 LLaMA 3.1 8B-Instruct 基础上进行继续预训练，使用 19.7 亿 token 数据（18.4 亿乌尔都文本、1.4 亿英语文本以防止遗忘），然后在 Alif Urdu-instruct 数据集上进行监督微调。

Result: 在七个任务的评估中实现加权平均 90.34，超越前一代 Alif-1.0-Instruct (87.1) 3.24 点；相对基线 LLaMA-3.1 8B-Instruct 提升 44.64 点；在分类、情感分析、推理等任务达到 SOTA。

Conclusion: 持续预训练结合目标指令微调可有效将大型基础模型适配为低资源语言的能力提升。

Abstract: Despite remarkable progress in large language models, Urdu-a language spoken by over 230 million people-remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks, struggling with the language's complex morphology, right-to-left Nastaliq script, and rich literary traditions. Even the base LLaMA-3.1 8B-Instruct model shows limited capability in generating fluent, contextually appropriate Urdu text. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens. This corpus comprises 1.84 billion tokens of diverse Urdu text-spanning news archives, classical and contemporary literature, government documents, and social media-combined with 140 million tokens of English Wikipedia data to prevent catastrophic forgetting. We then fine-tune the resulting model on the Alif Urdu-instruct dataset. Through extensive evaluation on Urdu-specific benchmarks, Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model (87.1) by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance with comprehensive evaluation across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages.

</details>


### [19] [Relational Knowledge Distillation Using Fine-tuned Function Vectors](https://arxiv.org/abs/2601.08169)
*Andrea Kang,Yingnian Wu,Hongjing Lu*

Main category: cs.CL

TL;DR: 通过对函数向量进行少量示例微调，并引入基于微调向量的复合向量以及在推理阶段进行激活补丁，显著提升关系推理、关系词解码与类比推理的表现，且适用于不同规模的语言模型。


<details>
  <summary>Details</summary>
Motivation: 关系概念之间的联系是智能系统理解世界的关键，作者基于因果中介分析揭示的注意力头任务表征，旨在更高效地编码关系知识并提升可解释性与推理能力。

Method: 1) 使用约20对词对对原始函数向量进行微调；2) 基于微调向量构建加权组合的复合函数向量以提取关系知识；3) 推理阶段将复合向量“插入”到LLM激活中进行激活补丁；4) 在关系词解码、认知科学与SAT基准的类比任务等场景进行评估，覆盖小型与大型语言模型。

Result: 微调后的函数向量在关系基于的词补全任务上优于原始向量，且对小型和大型模型均有效；关系词解码更准确、与人类相似度判定的一致性提升；引入的复合函数向量在认知科学和SAT基准的类比题上显著提升表现，激活补丁被证明是可控地编码和操纵关系知识的有效手段。

Conclusion: 该工作展示了激活补丁与微调向量融合的潜力，使关系知识的可解释性和推理能力得到提升，为大语言模型的关系推理与推理推导提供了新的工具与思路。

Abstract: Representing relations between concepts is a core prerequisite for intelligent systems to make sense of the world. Recent work using causal mediation analysis has shown that a small set of attention heads encodes task representation in in-context learning, captured in a compact representation known as the function vector. We show that fine-tuning function vectors with only a small set of examples (about 20 word pairs) yields better performance on relation-based word-completion tasks than using the original vectors derived from causal mediation analysis. These improvements hold for both small and large language models. Moreover, the fine-tuned function vectors yield improved decoding performance for relation words and show stronger alignment with human similarity judgments of semantic relations. Next, we introduce the composite function vector - a weighted combination of fine-tuned function vectors - to extract relational knowledge and support analogical reasoning. At inference time, inserting this composite vector into LLM activations markedly enhances performance on challenging analogy problems drawn from cognitive science and SAT benchmarks. Our results highlight the potential of activation patching as a controllable mechanism for encoding and manipulating relational knowledge, advancing both the interpretability and reasoning capabilities of large language models.

</details>


### [20] [Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering](https://arxiv.org/abs/2601.08176)
*Lavanya Prahallad,Sai Utkarsh Choudarypally,Pragna Prahallad,Pranathi Prahallad*

Main category: cs.CL

TL;DR: GPT-5.2 with prompt design improves automatic clarity evaluation on CLARITY; chain-of-thought prompting, especially with few-shot examples, boosts accuracy; evasion benefits from reasoning prompts but varies across categories; topic identification also improves with reasoning prompts; overall, prompt design enhances high-level clarity while fine-grained evasion and topic detection remain challenging.


<details>
  <summary>Details</summary>
Motivation: Examine how prompt design affects automatic clarity and evasion judgments for political Q&A using the CLARITY dataset, addressing a gap where prior work focuses on annotations but not prompt effects.

Method: Compare GPT-3.5 baseline vs GPT-5.2 across three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Evaluate predictions against human annotations using accuracy and class-wise metrics for clarity and evasion, plus hierarchical exact match; also assess topic identification.

Result: GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity. Accuracy improves from 56% to 63% under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy at 34%, though improvements are less stable across fine-grained evasion categories. Topic identification accuracy rises from 60% to 74% relative to human annotations.

Conclusion: Prompt design reliably improves high-level clarity evaluation; fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.

Abstract: Automatic evaluation of large language model (LLM) responses requires not only factual correctness but also clarity, particularly in political question-answering. While recent datasets provide human annotations for clarity and evasion, the impact of prompt design on automatic clarity evaluation remains underexplored. In this paper, we study prompt-based clarity evaluation using the CLARITY dataset from the SemEval 2026 shared task. We compare a GPT-3.5 baseline provided with the dataset against GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Model predictions are evaluated against human annotations using accuracy and class-wise metrics for clarity and evasion, along with hierarchical exact match. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56 percent to 63 percent under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy at 34 percent, though improvements are less stable across fine-grained evasion categories. We further evaluate topic identification and find that reasoning-based prompting improves accuracy from 60 percent to 74 percent relative to human annotations. Overall, our findings indicate that prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.

</details>


### [21] [Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis](https://arxiv.org/abs/2601.08196)
*Da Song,Yuheng Huang,Boqi Chen,Tianshuo Cong,Randy Goebel,Lei Ma,Foutse Khomh*

Main category: cs.CL

TL;DR: The paper proposes LogiSafetyGen and LogiSafetyBench to enforce latent regulatory safety constraints in LLM-driven autonomous tasks, revealing a safety-function gap in larger models.


<details>
  <summary>Details</summary>
Motivation: In high-stakes settings, LLM-enabled agents must adhere to implicit safety/regulatory constraints beyond functional correctness; existing benchmarks under-evaluate compliance with these latent rules.

Method: Convert unstructured regulations into Linear Temporal Logic (LTL) oracles and use logic-guided fuzzing to synthesize safety-critical traces; assemble a benchmark of 240 tasks where LLMs generate Python programs that satisfy functional objectives and latent compliance rules.

Result: Evaluation across 13 SOTA LLMs shows larger models improve functional correctness but often prioritize task completion over safety, resulting in non-compliant behavior.

Conclusion: A framework and benchmark to assess and promote adherence to latent safety constraints in LLM-powered autonomous systems, highlighting a gap between task achievement and regulatory compliance and suggesting the need for safety-aware optimization and tooling.

Abstract: The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. However, existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To fill this gap, we introduce LogiSafetyGen, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LogiSafetyBench, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, which results in non-compliant behavior.

</details>


### [22] [Triplets Better Than Pairs: Towards Stable and Effective Self-Play Fine-Tuning for LLMs](https://arxiv.org/abs/2601.08198)
*Yibo Wang,Hai-Long Sun,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.CL

TL;DR: T-SPIN在SPIN的基础上引入三元组结构的历史优势和熵约束，提升自我对弈微调的稳定性与数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决SPIN在迭代中当前优势逐渐消散导致的优化不稳定，以及使用参考策略引入的训练目标与生成评估之间的错配问题；需要无参考微调以适应数据稀缺场景。

Method: 引入两大设计：1) 将迭代生成的响应与初始策略产生的原型合成响应之间的历史优势加入到优化中，即使当前优势减弱，历史优势仍有效；2) 在自我对弈框架中加入熵约束，以实现无参考微调并缓解训练-生成之间的错配。

Result: 在多任务设置下，T-SPIN优于SPIN，且在迭代过程中的性能提升更为稳定。相较于有监督微调，在标注数据仅占25%时，T-SPIN可达到相当甚至更好的效果。

Conclusion: T-SPIN通过历史优势的三元组设计与熵约束，显著提升自我对弈微调的稳定性与数据效率，适用于数据稀缺的下游任务，并缓解训练-生成错配问题。

Abstract: Recently, self-play fine-tuning (SPIN) has been proposed to adapt large language models to downstream applications with scarce expert-annotated data, by iteratively generating synthetic responses from the model itself. However, SPIN is designed to optimize the current reward advantages of annotated responses over synthetic responses at hand, which may gradually vanish during iterations, leading to unstable optimization. Moreover, the utilization of reference policy induces a misalignment issue between the reward formulation for training and the metric for generation. To address these limitations, we propose a novel Triplet-based Self-Play fIne-tuNing (T-SPIN) method that integrates two key designs. First, beyond current advantages, T-SPIN additionally incorporates historical advantages between iteratively generated responses and proto-synthetic responses produced by the initial policy. Even if the current advantages diminish, historical advantages remain effective, stabilizing the overall optimization. Second, T-SPIN introduces the entropy constraint into the self-play framework, which is theoretically justified to support reference-free fine-tuning, eliminating the training-generation discrepancy. Empirical results on various tasks demonstrate not only the superior performance of T-SPIN over SPIN, but also its stable evolution during iterations. Remarkably, compared to supervised fine-tuning, T-SPIN achieves comparable or even better performance with only 25% samples, highlighting its effectiveness when faced with scarce annotated data.

</details>


### [23] [Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models](https://arxiv.org/abs/2601.08209)
*Rongji Li,Jian Xu,Xueqing Chen,Yisheng Yang,Jiayi Wang,Xingyu Chen,Chunyu Xie,Dawei Leng,Xu-Yao Zhang*

Main category: cs.CL

TL;DR: GAG是一种把私有领域知识视作额外的专家模态的生成增强生成方法，通过一个紧凑的表示层接口对齐到冻结的基础模型，从而避免提示时证据序列化、实现可插拔的跨域专精与可扩展多域组合，并在评估中显著优于RAG，同时保持通用基准性能与实现近似理想的选择性激活。


<details>
  <summary>Details</summary>
Motivation: 在生物医学、材料、金融等高风险领域，需要注入私有、快速迭代且公开预训练中稀缺的专有知识。现有的微调成本高且易遗忘，RAG在私有语料上易受证据碎片化、检索漂移、长上下文压力等影响而不稳定。

Method: 提出Generation-Augmented Generation，将私有知识视为一个额外的专家模态，构建紧凑的表示级接口对齐到冻结的基础模型，实现无提示级证据序列化、可插拔的专精、以及跨域的可扩展组合，同时支持可靠的选择性激活以实现大规模部署。

Result: 在两个私有科学问答基准（免疫佐剂与催化材料）及混合域评估中，GAG相较强RAG基线分别提升15.34%与14.86%；在六个开放通用基准上保持性能，并实现近似理想的选择性激活，支持可扩展的多域部署。

Conclusion: GAG为私有领域知识注入提供了高效、可扩展、鲁棒的新范式，克服了微调成本与遗忘、以及RAG的证据碎片化等局限，适合跨域协同部署。

Abstract: In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining. However, the two dominant paradigms for private knowledge injection each have pronounced drawbacks: fine-tuning is expensive to iterate, and continual updates risk catastrophic forgetting and general-capability regression; retrieval-augmented generation (RAG) keeps the base model intact but is brittle in specialized private corpora due to chunk-induced evidence fragmentation, retrieval drift, and long-context pressure that yields query-dependent prompt inflation. Inspired by how multimodal LLMs align heterogeneous modalities into a shared semantic space, we propose Generation-Augmented Generation (GAG), which treats private expertise as an additional expert modality and injects it via a compact, representation-level interface aligned to the frozen base model, avoiding prompt-time evidence serialization while enabling plug-and-play specialization and scalable multi-domain composition with reliable selective activation. Across two private scientific QA benchmarks (immunology adjuvant and catalytic materials) and mixed-domain evaluations, GAG improves specialist performance over strong RAG baselines by 15.34% and 14.86% on the two benchmarks, respectively, while maintaining performance on six open general benchmarks and enabling near-oracle selective activation for scalable multi-domain deployment.

</details>


### [24] [Towards Principled Design of Mixture-of-Experts Language Models under Memory and Inference Constraints](https://arxiv.org/abs/2601.08215)
*Seng Pei Liew,Kenta Shinzato,Yuyang Dong*

Main category: cs.CL

TL;DR: MoE模型的性能主要由总参数量(N_total)和稀疏度(s)决定，而不仅仅是活跃参数的数量。增大N_total若伴随更高的s将受限；在内存约束下，增大N_total并降低s（即增大n_topk、减少n_exp）往往提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅以内存占用和推理成本来衡量模型规模，难以解释MoE架构的性能差异。本工作通过系统性实验揭示N_total与稀疏度对性能的主导作用。

Method: 在受内存约束的条件下，系统性地改变MoE架构中的总参数量、专家数量(n_exp)、每次选择的专家数(n_topk)等参数，评估对模型性能的影响，分析其相互关系。

Result: MoE的性能由N_total和s决定，n_exp与n_topk不会简单“抵消”；增大专家数量若导致核心维度（深度、宽度）下降以满足内存约束，反而略微降低性能。基于此，提出设计原则：在给定约束下最大化N_total，同时最小化s（即最大化n_topk）与n_exp。此结果为解决MoE架构不确定性提供了鲁棒框架。

Conclusion: 建立了一套以N_total和s为核心的MoE设计框架，能在内存/参数约束下给出更具指导性的架构选择，与以往仅看总参数或活跃参数的方法相比，更能解释性能波动。

Abstract: Modern Mixture-of-Experts (MoE) language models are designed based on total parameters (memory footprint) and active parameters (inference cost). However, we find these two factors alone are insufficient to describe an optimal architecture. Through a systematic study, we demonstrate that MoE performance is primarily determined by total parameters ($N_{total}$) and expert sparsity ($s:=n_{exp}/n_{topk}$).
  Moreover, $n_{exp}$ and $n_{topk}$ do not "cancel out" within the sparsity ratio; instead, a larger total number of experts slightly penalizes performance by forcing a reduction in core model dimensions (depth and width) to meet memory constraints. This motivates a simple principle for MoE design which maximizes $N_{total}$ while minimizing $s$ (maximizing $n_{topk}$) and $n_{exp}$ under the given constraints. Our findings provide a robust framework for resolving architectural ambiguity and guiding MoE design.

</details>


### [25] [User-Oriented Multi-Turn Dialogue Generation with Tool Use at scale](https://arxiv.org/abs/2601.08225)
*Jungho Cho,Minbyul Jeong,Sungrae Park*

Main category: cs.CL

TL;DR: 提出一个可扩展的生成框架，用于在大语言模型驱动的仿真环境中动态生成领域专用工具，结合独立的用户仿真器实现多轮、真实的工具使用对话，从而产出高密度、具现实性的对话数据。


<details>
  <summary>Details</summary>
Motivation: 解决当前数据集受限于静态、预定义工具集的瓶颈，提升开放式人机协作中多轮工具使用数据的规模、丰富性与真实性。

Method: 以LRM驱动的仿真器初步生成任务相关的工具并完成任务；随后转向用户导向的仿真，通过分离的用户模拟器刻画增量请求与逐轮反馈，从而获得更自然的对话过程；生成管线具备“即插即用”特性，能从任意状态开始，且单条轨迹内可完成多次任务，提升数据密度。

Result: 能够生成高密度、真实且可扩展的多轮工具使用数据集，反映现实场景中人机交互的复杂性与多任务需求。

Conclusion: 通过引入用户导向的仿真来提升对话数据的真实感与覆盖面，克服仅聚焦任务完成的陈旧数据模式，从而更好支持LRMs的工具使用能力训练。

Abstract: The recent paradigm shift toward large reasoning models (LRMs) as autonomous agents has intensified the demand for sophisticated, multi-turn tool-use capabilities. Yet, existing datasets and data-generation approaches are limited by static, predefined toolsets that cannot scale to the complexity of open-ended human-agent collaboration. To address this, we initially developed a framework for automated task-oriented multi-turn dialogue generation at scale, utilizing an LRM-based simulator to dynamically generate high-value, domain-specific tools to solve specified tasks. However, we observe that a purely task-oriented design often results in "solely task-solving" trajectories, where the agent completes the objective with minimal interaction, failing to generate the high turn-count conversations seen in realistic scenarios. To bridge this gap, we shift toward a user-oriented simulation paradigm. By decoupling task generation from a dedicated user simulator that mimics human behavioral rules - such as incremental request-making and turn-by-turn feedback - we facilitate more authentic, extended multi-turn dialogues that reflect the iterative nature of real-world problem solving. Our generation pipeline operates as a versatile, plug-and-play module capable of initiating generation from any state, ensuring high scalability in producing extended tool-use data. Furthermore, by facilitating multiple task completions within a single trajectory, it yields a high-density dataset that reflects the multifaceted demands of real-world human-agent interaction.

</details>


### [26] [Med-CoReasoner: Reducing Language Disparities in Medical Reasoning via Language-Informed Co-Reasoning](https://arxiv.org/abs/2601.08267)
*Fan Gao,Sherry T. Tong,Jiwoong Sohn,Jiahao Huang,Junfeng Jiang,Ding Xia,Piyalitt Ittichaiwong,Kanyakorn Veerakanjana,Hyunjae Kim,Qingyu Chen,Edison Marrese Taylor,Kazuma Kobayashi,Akkiko Aizawa,Irene Li*

Main category: cs.CL

TL;DR: Med-CoReasoner 提出一个语言信息的共推理框架，进行英语与当地语言并行推理、概念化抽象并概念级对齐，结合本地临床知识在英语框架中检索与嵌入，以提升多语言医学推理并在 MultiMed-X 基准上建立 7 种语言的长篇问答与自然语言推理任务，结果显示平均提升约5%，低资源语言收益尤为显著；此外通过模型蒸馏与专家评估，证实推理轨迹临床可信且具文化 grounding。


<details>
  <summary>Details</summary>
Motivation: 缓解以英语为中心的医学推理在多语言环境中的差距，提升低资源语言的推理能力与临床可用性，确保全球范围的公平部署。

Method: 提出 Med-CoReasoner：语言感知的共推理框架，进行英语与本地语言并行推理并抽象成结构化概念，然后通过概念级对齐将本地知识納入英语逻辑骨架，并进行检索式整合；建立 MultiMed-X 基准，覆盖七种语言，包含长篇问答与自然语言推理任务，逐步评估多语言推理。

Result: 在三个基准上实验，平均提升约5%的多语言推理性能，低资源语言的增益尤为显著；蒸馏与专家评估分析显示 Med-CoReasoner 能产生临床上合乎逻辑、并具文化背景的推理轨迹。

Conclusion:  Med-CoReasoner 将英语推理的结构鲁棒性与本地语言的实践知识结合，提升多语言医学推理能力；MultiMed-X 的建立为多语言医学评估提供新基准，方法对全球医用部署具有现实意义。

Abstract: While reasoning-enhanced large language models perform strongly on English medical tasks, a persistent multilingual gap remains, with substantially weaker reasoning in local languages, limiting equitable global medical deployment. To bridge this gap, we introduce Med-CoReasoner, a language-informed co-reasoning framework that elicits parallel English and local-language reasoning, abstracts them into structured concepts, and integrates local clinical knowledge into an English logical scaffold via concept-level alignment and retrieval. This design combines the structural robustness of English reasoning with the practice-grounded expertise encoded in local languages. To evaluate multilingual medical reasoning beyond multiple-choice settings, we construct MultiMed-X, a benchmark covering seven languages with expert-annotated long-form question answering and natural language inference tasks, comprising 350 instances per language. Experiments across three benchmarks show that Med-CoReasoner improves multilingual reasoning performance by an average of 5%, with particularly substantial gains in low-resource languages. Moreover, model distillation and expert evaluation analysis further confirm that Med-CoReasoner produces clinically sound and culturally grounded reasoning traces.

</details>


### [27] [Discovery and Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees](https://arxiv.org/abs/2601.08274)
*Kun Li,Zenan Xu,Junan Li,Zengrui Jin,Jinghao Deng,Zexuan Qiu,Bo Zhou*

Main category: cs.CL

TL;DR: DART is an RL framework that enables spontaneous tool-use in long Chain-of-Thought without human annotations, using dynamic rollout trees and tree-based advantage estimation to discover and credit tool-integrated trajectories; it outperforms baselines on AIME and GPQA-Diamond.


<details>
  <summary>Details</summary>
Motivation: To address scarcity of training data for tool-use in long CoT and to integrate tool-use without degrading intrinsic long-chain reasoning.

Method: Train with dynamic rollout trees that branch at promising points to discover tool-use opportunities; use tree-based process advantage estimation to credit sub-trajectories where tool invocations improve solutions; optimize via reinforcement learning.

Result: DART significantly outperforms existing methods on challenging benchmarks such as AIME and GPQA-Diamond, demonstrating effective integration of tool execution with long CoT reasoning.

Conclusion: DART provides a viable, annotation-free pathway to spontaneous tool-use in long CoT, leveraging rollout-tree dynamics and credit assignment to harmonize computation and reasoning.

Abstract: Tool-Integrated Reasoning has emerged as a key paradigm to augment Large Language Models (LLMs) with computational capabilities, yet integrating tool-use into long Chain-of-Thought (long CoT) remains underexplored, largely due to the scarcity of training data and the challenge of integrating tool-use without compromising the model's intrinsic long-chain reasoning. In this paper, we introduce DART (Discovery And Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees), a reinforcement learning framework that enables spontaneous tool-use during long CoT reasoning without human annotation. DART operates by constructing dynamic rollout trees during training to discover valid tool-use opportunities, branching out at promising positions to explore diverse tool-integrated trajectories. Subsequently, a tree-based process advantage estimation identifies and credits specific sub-trajectories where tool invocation positively contributes to the solution, effectively reinforcing these beneficial behaviors. Extensive experiments on challenging benchmarks like AIME and GPQA-Diamond demonstrate that DART significantly outperforms existing methods, successfully harmonizing tool execution with long CoT reasoning.

</details>


### [28] [Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques](https://arxiv.org/abs/2601.08302)
*Marvin Schmitt,Anne Schwerk,Sebastian Lempert*

Main category: cs.CL

TL;DR: Advanced prompting improves sentiment analysis with LLMs; few-shot best for GPT-4o-mini, chain-of-thought boosts irony detection for gemini-1.5-flash; prompts must be tailored to model and task.


<details>
  <summary>Details</summary>
Motivation: Evaluate how prompting strategies affect LLM sentiment analysis across models and tasks (classification, ABSA, irony detection).

Method: Compare few-shot, chain-of-thought, self-consistency against baseline using GPT-4o-mini and gemini-1.5-flash; metrics: accuracy, recall, precision, F1.

Result: Advanced prompting improves performance; few-shot strongest for GPT-4o-mini; chain-of-thought enhances irony detection for gemini-1.5-flash by up to 46%.

Conclusion: Prompt design should be tailored to model architecture and task semantic complexity; alignment of prompts with model and task is crucial.

Abstract: This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLM's architecture and the semantic complexity of the task.

</details>


### [29] [CLaS-Bench: A Cross-Lingual Alignment and Steering Benchmark](https://arxiv.org/abs/2601.08331)
*Daniil Gurgurov,Yusser Al Ghussin,Tanja Baeumel,Cheng-Ting Chou,Patrick Schramowski,Marius Mosbach,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: 提出并评估 CLaS-Bench，一个用于评估跨 32 语言的语言驱动行为的轻量并行问题基准，结果表明 DiffMean 等简单方法通常最优，语言结构多在后层显现并按语言家族聚类。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门的基准与评估协议来量化多语言 steering 技术的有效性，需在低成本、可解释的框架中评估模型对目标语言的控制与语义保持。

Method: 提出 CLaS-Bench，作为轻量级并行问题基准，用于在多语言 LLM 上评估语言驱动（steering）技术。对比检测了多种 steering 方法（ residual-stream DiffMean、探针派生方向、语言特异性神经元、PCA/LDA 向量、稀疏自编码器、以及提示基线），以语言控制与语义相关性两轴，合成调和均值评分。

Result: 在多语言实验中，简单的残差流 DiffMean 方法总体优于其他方法。层级分析显示语言特征在后层更明显，操控方向按语言家族聚类。

Conclusion: CLaS-Bench 作为首个标准化的多语言 steering 基准，便于对语言表示进行科学分析并评估 steering 作为低成本适配替代方案的可行性。

Abstract: Understanding and controlling the behavior of large language models (LLMs) is an increasingly important topic in multilingual NLP. Beyond prompting or fine-tuning, , i.e.,~manipulating internal representations during inference, has emerged as a more efficient and interpretable technique for adapting models to a target language. Yet, no dedicated benchmarks or evaluation protocols exist to quantify the effectiveness of steering techniques. We introduce CLaS-Bench, a lightweight parallel-question benchmark for evaluating language-forcing behavior in LLMs across 32 languages, enabling systematic evaluation of multilingual steering methods. We evaluate a broad array of steering techniques, including residual-stream DiffMean interventions, probe-derived directions, language-specific neurons, PCA/LDA vectors, Sparse Autoencoders, and prompting baselines. Steering performance is measured along two axes: language control and semantic relevance, combined into a single harmonic-mean steering score. We find that across languages simple residual-based DiffMean method consistently outperforms all other methods. Moreover, a layer-wise analysis reveals that language-specific structure emerges predominantly in later layers and steering directions cluster based on language family. CLaS-Bench is the first standardized benchmark for multilingual steering, enabling both rigorous scientific analysis of language representations and practical evaluation of steering as a low-cost adaptation alternative.

</details>


### [30] [Detecting Mental Manipulation in Speech via Synthetic Multi-Speaker Dialogue](https://arxiv.org/abs/2601.08342)
*Run Chen,Wen Liang,Ziwei Gong,Lin Ai,Julia Hirschberg*

Main category: cs.CL

TL;DR: 首次研究口语对操控性语言的检测，提出 SPEECHMENTALMANIP 多说话人合成基准，比较文本与语音的检测表现，发现语音模式下召回率低、特异性高，提示需关注声学线索缺失对检测的影响。


<details>
  <summary>Details</summary>
Motivation: 填补口语场景中操控性语言检测的空白，评估模态差异对检测与人类感知的影响，推动安全对齐的多模态对话系统研究。

Method: 构建合成语音基准 SPEECHMENTALMANIP，基于文本数据用高质量 TTS 生成音频；采用少-shot 大型音频-语言模型与人工标注对文本与音频两模态进行操控检测评估；分析检测性能与人类标注的一致性。

Result: 模型在语音上表现出高特异性但召回率显著下降，原因在于缺乏声学/韵律线索的训练不足；人类评审在音频条件下也存在较大不确定性；结论强调模态感知评估和多模态对话系统的安全对齐需求。

Conclusion: 强调在多模态对话系统中进行模态感知评估的重要性，提出未来方向包括改进音频特征、跨模态对齐，以及在少-shot场景中的鲁棒性提升。

Abstract: Mental manipulation, the strategic use of language to covertly influence or exploit others, is a newly emerging task in computational social reasoning. Prior work has focused exclusively on textual conversations, overlooking how manipulative tactics manifest in speech. We present the first study of mental manipulation detection in spoken dialogues, introducing a synthetic multi-speaker benchmark SPEECHMENTALMANIP that augments a text-based dataset with high-quality, voice-consistent Text-to-Speech rendered audio. Using few-shot large audio-language models and human annotation, we evaluate how modality affects detection accuracy and perception. Our results reveal that models exhibit high specificity but markedly lower recall on speech compared to text, suggesting sensitivity to missing acoustic or prosodic cues in training. Human raters show similar uncertainty in the audio setting, underscoring the inherent ambiguity of manipulative speech. Together, these findings highlight the need for modality-aware evaluation and safety alignment in multimodal dialogue systems.

</details>


### [31] [PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors](https://arxiv.org/abs/2601.08402)
*Donya Rooein,Sankalan Pal Chowdhury,Mariia Eremeeva,Yuan Qin,Debora Nozza,Mrinmaya Sachan,Dirk Hovy*

Main category: cs.CL

TL;DR: 基于人格-教学法的框架，使LLM tutor 根据学生性格自适应教学策略，实验显示人类教师偏好该自适应方法并增加高影响力策略如角色扮演。


<details>
  <summary>Details</summary>
Motivation: 教育领域需要个性化的LLM辅导，以避免策略与学生性格不匹配导致学习效果下降；现有系统缺乏对性格特征的考虑。

Method: 建立将教学法与性格画像联系起来的分类体系；基于教育学文献；在仿真师生对话中让LLM根据模拟的学生性格自适应教学策略；以人类教师对比评估，比较两基线；评估使用如角色扮演等高影响力策略的应用情况。

Result: 人类教师普遍偏好该自适应方法；相较基线，增加了不太常用但高影响力的教学策略（如角色扮演），人类与LLM注释者均显著偏好该方法。

Conclusion: 将人格化教学策略融入LLM辅导具有潜力，推动个性化、有效的LLM教育应用发展。

Abstract: Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Despite this, current LLM tutoring systems do not take into account student personality traits. To address this problem, we first construct a taxonomy that links pedagogical methods to personality profiles, based on pedagogical literature. We simulate student-teacher conversations and use our framework to let the LLM tutor adjust its strategy to the simulated student personality. We evaluate the scenario with human teachers and find that they consistently prefer our approach over two baselines. Our method also increases the use of less common, high-impact strategies such as role-playing, which human and LLM annotators prefer significantly. Our findings pave the way for developing more personalized and effective LLM use in educational applications.

</details>


### [32] [Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering](https://arxiv.org/abs/2601.08427)
*Nonghai Zhang,Weitao Ma,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Jingwen Xu*

Main category: cs.CL

TL;DR: Latent-GRPO提出在潜在空间几何中自给奖励，基于IRCE的鲁棒质心估计实现连续稠密奖励，降低对外部验证和人工规则的依赖，显著提升训练效率并具备良好泛化和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决GRPO对外部验证器/人工规则的高度依赖带来的高算力成本、训练时延和稀疏奖励问题，提升优化效率及训练速度，同时保持模型性能与鲁棒性。

Method: 发现终态词表示在正确推理轨迹上形成高密度、类内相似的聚类，而错误轨迹分散为离群点；提出迭代鲁棒质心估计(IRCE)，通过球投影抹平幅度波动，并迭代聚合估计“真实质心”以生成密集、连续的奖励。

Result: 在多个数据集上，Latent-GRPO保持模型性能的同时实现训练速度提升 (>2x)；并展示出较强的泛化能力和鲁棒性。

Conclusion: 基于潜在空间几何的内在奖励结合IRCE方法，能有效高效地驱动GRPO训练，具备良好泛化与鲁棒性，代码将很快公开。

Abstract: Group Relative Policy Optimization (GRPO) significantly enhances the reasoning performance of Large Language Models (LLMs). However, this success heavily relies on expensive external verifiers or human rules. Such dependency not only leads to significant computational costs and training latency, but also yields sparse rewards that hinder optimization efficiency. To address these challenges, we propose Latent-GRPO, a framework that derives intrinsic rewards directly from latent space geometry. Crucially, our empirical analysis reveals a compelling geometric property: terminal token representations of correct reasoning trajectories form dense clusters with high intra-class similarity, whereas incorrect trajectories remain scattered as outliers. In light of this discovery, we introduce the Iterative Robust Centroid Estimation (IRCE) algorithm, which generates dense, continuous rewards by mitigating magnitude fluctuations via spherical projection and estimating a robust ``truth centroid'' through iterative aggregation. Experimental results on multiple datasets show that our method maintains model performance while achieving a training speedup of over 2x compared to baselines. Furthermore, extensive results demonstrate strong generalization ability and robustness. The code will be released soon.

</details>


### [33] [JudgeRLVR: Judge First, Generate Second for Efficient Reasoning](https://arxiv.org/abs/2601.08468)
*Jiangshan Duo,Hanyu Li,Hailin Zhang,Yudong Wang,Sujian Li,Liang Zhao*

Main category: cs.CL

TL;DR: 提出 JudgeRLVR，两阶段判别再生成框架，通过先训练模型判别可验证解，再以此初始化生成 RLVR，显著提升在数学任务中的准确性与效率，且具更强泛化。


<details>
  <summary>Details</summary>
Motivation: 改进以最终答案正确性为唯一目标的 RLVR 框架导致的冗长推理与可验证性不足的问题，强调判别能力是高效生成的前提。

Method: 阶段1：训练模型对可验证答案的解进行判别；阶段2：在判别器初始化的基础上对同一模型进行 Vanilla RLVR 微调。与在相同数学领域训练数据上的 Vanilla RLVR 相比，JudgeRLVR 在质量-效率上取得更好折中。

Result: 在 in-domain 数学任务上，平均正确率提升约 3.7 点，生成长度下降约 42%；在 out-of-domain 基准上，平均正确率提升约 4.5 点，显示更强泛化，且以 Qwen3-30B-A3B 为评估对象。

Conclusion: 判别能力是高效生成的前提，JudgeRLVR 通过判别引导的搜索剪枝与生成初始化，显著提升解题质量、效率与跨域泛化。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reasoning steps, creating a difficult trade-off between efficiency and verification. In this paper, we argue that discriminative capability is a prerequisite for efficient generation: by learning to distinguish valid solutions, a model can internalize a guidance signal that prunes the search space. We propose JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, we train the model to judge solution responses with verifiable answers. In the second stage, we fine-tune the same model with vanilla generating RLVR initialized from the judge. Compared to Vanilla RLVR using the same math-domain training data, JudgeRLVR achieves a better quality--efficiency trade-off for Qwen3-30B-A3B: on in-domain math, it delivers about +3.7 points average accuracy gain with -42\% average generation length; on out-of-domain benchmarks, it delivers about +4.5 points average accuracy improvement, demonstrating enhanced generalization.

</details>


### [34] [BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts](https://arxiv.org/abs/2601.08490)
*Erin Feiglin,Nir Hutnik,Raz Lapid*

Main category: cs.CL

TL;DR: The paper investigates Overflow: excessive plain-text prompt outputs from LLMs, introduces BenchOverflow to benchmark length amplification under a fixed token budget, evaluates nine models with nine prompting strategies, shows tail-risk in output length, and demonstrates a simple conciseness reminder mitigates tail growth, arguing length control is essential for reliability, cost, and sustainability.


<details>
  <summary>Details</summary>
Motivation: Overflow increases token costs, latency, energy use, and cross-user degradation in large-scale deployments, even without adversarial prompts. There is a need to quantify length-control robustness and develop defenses.

Method: Define BenchOverflow: nine plain-text prompting strategies to amplify output volume without adversarial suffixes. Use a fixed budget of 5000 new tokens. Evaluate nine open- and closed-source models. Analyze output length distributions with CSR@1k/3k/5k, ECDFs, within-prompt variance, and cross-model correlations. Propose a lightweight mitigation: a conciseness reminder.

Result: Observed pronounced rightward shifts and heavy tails in output length distributions across models. CSR metrics reveal tail risk; overflow is reproducible but varies across model families and attack vectors. A concise reminder mitigates tail growth and reduces CSR for most strategies and models, under a fixed budget.

Conclusion: Length control is a measurable reliability, cost, and sustainability concern rather than a stylistic issue. BenchOverflow enables standardized comparison of length-control robustness across models, guiding deployment choices to minimize resource waste and energy use, and aiding evaluation of defenses that curb compute amplification without sacrificing task performance.

Abstract: We investigate a failure mode of large language models (LLMs) in which plain-text prompts elicit excessive outputs, a phenomenon we term Overflow. Unlike jailbreaks or prompt injection, Overflow arises under ordinary interaction settings and can lead to elevated serving cost, latency, and cross-user performance degradation, particularly when scaled across many requests. Beyond usability, the stakes are economic and environmental: unnecessary tokens increase per-request cost and energy consumption, compounding into substantial operational spend and carbon footprint at scale. Moreover, Overflow represents a practical vector for compute amplification and service degradation in shared environments. We introduce BenchOverflow, a model-agnostic benchmark of nine plain-text prompting strategies that amplify output volume without adversarial suffixes or policy circumvention. Using a standardized protocol with a fixed budget of 5000 new tokens, we evaluate nine open- and closed-source models and observe pronounced rightward shifts and heavy tails in length distributions. Cap-saturation rates (CSR@1k/3k/5k) and empirical cumulative distribution functions (ECDFs) quantify tail risk; within-prompt variance and cross-model correlations show that Overflow is broadly reproducible yet heterogeneous across families and attack vectors. A lightweight mitigation-a fixed conciseness reminder-attenuates right tails and lowers CSR for all strategies across the majority of models. Our findings position length control as a measurable reliability, cost, and sustainability concern rather than a stylistic quirk. By enabling standardized comparison of length-control robustness across models, BenchOverflow provides a practical basis for selecting deployments that minimize resource waste and operating expense, and for evaluating defenses that curb compute amplification without eroding task performance.

</details>


### [35] [It's All About the Confidence: An Unsupervised Approach for Multilingual Historical Entity Linking using Large Language Models](https://arxiv.org/abs/2601.08500)
*Cristian Santini,Marieke Van Erp,Mehwish Alam*

Main category: cs.CL

TL;DR: 提出 MHEL-LLaMo，一种无监督的多语言历史实体链接方法，结合小模型与大模型，在候选检索与 NIL 预测中通过提示链实现，利用小模型置信度区分简单与困难样本，仅对困难样本调用大模型，降低成本并避免简单样本的幻觉。


<details>
  <summary>Details</summary>
Motivation: 历史文本具有语言变异、噪声和语义演变，现有方法依赖大量标注数据或大量领域规则，难以大规模泛化。需要一种无需微调、跨语言、适用于低资源历史EL的解决方案。

Method: 采用多语言双编码器 BELA 进行候选检索；使用指令微调（instruction-tuned）的大语言模型进行 NIL 预测和候选项选择，借助提示链路实现；以 SLM 的置信度将样本分为简单与困难，简单样本仅用 SLM 处理，困难样本才调用 LLM；在六种欧洲语言的四个历史基准数据集上进行评估。

Result: 实验结果显示，在六种语言、四个基准上，MHEL-LLaMo 的表现超越现有无微调模型和部分需微调的方法，且未使用微调即可实现较强性能，证明该无监督分层检索+提示推理策略对低资源历史EL具备良好可扩展性。代码公开在 GitHub。

Conclusion: 基于分层模型与提示推理的联合方案在跨语言、跨时态的历史EL任务中具有显著的效果与成本优势，适用于资源受限场景，未来可进一步优化样本分层策略与提示设计以提升鲁棒性与可解释性。

Abstract: Despite the recent advancements in NLP with the advent of Large Language Models (LLMs), Entity Linking (EL) for historical texts remains challenging due to linguistic variation, noisy inputs, and evolving semantic conventions. Existing solutions either require substantial training data or rely on domain-specific rules that limit scalability. In this paper, we present MHEL-LLaMo (Multilingual Historical Entity Linking with Large Language MOdels), an unsupervised ensemble approach combining a Small Language Model (SLM) and an LLM. MHEL-LLaMo leverages a multilingual bi-encoder (BELA) for candidate retrieval and an instruction-tuned LLM for NIL prediction and candidate selection via prompt chaining. Our system uses SLM's confidence scores to discriminate between easy and hard samples, applying an LLM only for hard cases. This strategy reduces computational costs while preventing hallucinations on straightforward cases. We evaluate MHEL-LLaMo on four established benchmarks in six European languages (English, Finnish, French, German, Italian and Swedish) from the 19th and 20th centuries. Results demonstrate that MHEL-LLaMo outperforms state-of-the-art models without requiring fine-tuning, offering a scalable solution for low-resource historical EL. The implementation of MHEL-LLaMo is available on Github.

</details>


### [36] [STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays](https://arxiv.org/abs/2601.08510)
*Qiuyu Tian,Yiding Li,Fengyi Chen,Zequn Liu,Youyong Kong,Fan Guo,Yuyao Li,Jinjing Shen,Zhijing Xie,Yiyun Luo,Xin Zhang*

Main category: cs.CL

TL;DR: 提出 STAGE 基准，面向完整长篇电影剧本的叙事理解，涵盖知识图谱构建、场景级事件摘要、长上下文问答和剧中角色扮演等四任务，旨在评估模型在统一叙事世界中的一致性与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准多聚焦单一子任务，缺乏对跨任务、跨模态与跨长文本叙事的一致世界观建模与长期推理的评估。

Method: 提供 cleaned scripts、知识图谱、事件与角色注释，覆盖150部英中剧本；定义四个互补任务，在共享叙事世界表示的前提下进行评估；面向全球化语言对齐，强调长文本上下文的综合推理与生成。

Result: 构建一个统一、跨任务的评估框架，能评估模型的世界建模、叙事事件抽象与验证、长文本推理与角色一致性生成等能力；为多任务评估提供数据集与注释。

Conclusion: STAGE 作为统一叙事理解基准，促进对长篇叙事世界观的一致性建模和跨任务、跨语言的评估；未来可扩展到更多语言和类型，提升生成与推理质量。

Abstract: Movie screenplays are rich long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. While prior benchmarks target individual subtasks such as question answering or dialogue generation, they rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. We introduce STAGE (Screenplay Text, Agents, Graphs and Evaluation), a unified benchmark for narrative understanding over full-length movie screenplays. STAGE defines four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric annotations for 150 films across English and Chinese, enabling holistic evaluation of models' abilities to build world representations, abstract and verify narrative events, reason over long narratives, and generate character-consistent responses.

</details>


### [37] [STAR: Detecting Inference-time Backdoors in LLM Reasoning via State-Transition Amplification Ratio](https://arxiv.org/abs/2601.08511)
*Seong-Gyu Park,Sohee Park,Jisu Lee,Hyunsik Na,Daeseon Choi*

Main category: cs.CL

TL;DR: STAR detects backdoors in LLMs with Chain-of-Thought by measuring state-transition amplification: higher posterior than prior signals malicious reasoning paths. Uses CUSUM to detect persistent anomalies; offers near-perfect AUROC (~1.0), ~42x efficiency over baselines, robust to adaptive attacks across 8B-70B models and 5 datasets.


<details>
  <summary>Details</summary>
Motivation: Explicit reasoning paths in Chain-of-Thought mechanisms create a new inference-time backdoor attack surface that is hard to detect with conventional methods since malicious paths are linguistically coherent. There is a need for a model-agnostic, efficient detector that can identify abnormal probability shifts caused by injected reasoning steps.

Method: Introduce STAR (State-Transition Amplification Ratio) framework. Quantify state-transition amplification as the ratio between high posterior probability of a malicious reasoning path and low prior probability in the model's general knowledge. Detect anomalies with the CUSUM algorithm to identify persistent shifts. Evaluate on diverse models (8B-70B) and five benchmark datasets, demonstrating generalization and robustness.

Result: STAR achieves near-perfect AUROC (~1.0) and ~42x efficiency compared with existing baselines. Demonstrates robust performance against adaptive attacks designed to bypass detection across multiple model scales and datasets.

Conclusion: STAR provides an effective, efficient defense against inference-time backdoors in LLMs with Chain-of-Thought by identifying abnormal probability shifts in reasoning paths. Its state-transition amplification metric and CUSUM-based detection offer strong generalization and resistance to adaptive adversaries, suitable for practical deployment.

Abstract: Recent LLMs increasingly integrate reasoning mechanisms like Chain-of-Thought (CoT). However, this explicit reasoning exposes a new attack surface for inference-time backdoors, which inject malicious reasoning paths without altering model parameters. Because these attacks generate linguistically coherent paths, they effectively evade conventional detection. To address this, we propose STAR (State-Transition Amplification Ratio), a framework that detects backdoors by analyzing output probability shifts. STAR exploits the statistical discrepancy where a malicious input-induced path exhibits high posterior probability despite a low prior probability in the model's general knowledge. We quantify this state-transition amplification and employ the CUSUM algorithm to detect persistent anomalies. Experiments across diverse models (8B-70B) and five benchmark datasets demonstrate that STAR exhibits robust generalization capabilities, consistently achieving near-perfect performance (AUROC $\approx$ 1.0) with approximately $42\times$ greater efficiency than existing baselines. Furthermore, the framework proves robust against adaptive attacks attempting to bypass detection.

</details>


### [38] [Algorithmic Stability in Infinite Dimensions: Characterizing Unconditional Convergence in Banach Spaces](https://arxiv.org/abs/2601.08512)
*Przemysław Spyra*

Main category: cs.CL

TL;DR: 在无限维Banach空间中，绝对收敛、条件收敛与无条件收敛不再等价；提出一个统一的七重等价条件的特征定理，用以刻画无条件收敛并给出对称换序、子列测试、符号稳定性、乘子有界性、弱一致性等等价性。


<details>
  <summary>Details</summary>
Motivation: 回答在算法层面为何需要对无条件收敛有一个统一的理论框架，以确保梯度累积、信号处理中的系数截断等操作的顺序鲁棒性，并解释Dvoretzky–Rogers定理在无限维中的严格分离现象对计算稳定性的影响。

Method: 给出一个包含七种等价条件的无条件收敛的统一特征定理，逐条证明这些条件在一般Banach空间下等价；并将结论应用于算法稳定性分析（如SGD的梯度累积的置换不变性、帧理论中的系数阈值化）来展示理论与计算实践的连接。

Result: 证明无条件收敛等价于以下七种条件：排列不变性、网际收敛、子列测试、符号稳定性、乘子有界性、弱一致性和若干相关的收敛性表述，揭示在无限维空间中它们彼此等价且与Dvoretzky-Rogers分离相呼应；并给出这些等价性在优化与信号处理中的具体应用场景。

Conclusion: 为无序、顺序不可控的求和过程提供严格的order-independence与数值鲁棒性基础，使得算法中的梯度累积及信号系数处理可以在不依赖特定求和顺序的前提下保持稳定性与可解释性。

Abstract: The distinction between conditional, unconditional, and absolute convergence in infinite-dimensional spaces has fundamental implications for computational algorithms. While these concepts coincide in finite dimensions, the Dvoretzky-Rogers theorem establishes their strict separation in general Banach spaces. We present a comprehensive characterization theorem unifying seven equivalent conditions for unconditional convergence: permutation invariance, net convergence, subseries tests, sign stability, bounded multiplier properties, and weak uniform convergence. These theoretical results directly inform algorithmic stability analysis, governing permutation invariance in gradient accumulation for Stochastic Gradient Descent and justifying coefficient thresholding in frame-based signal processing. Our work bridges classical functional analysis with contemporary computational practice, providing rigorous foundations for order-independent and numerically robust summation processes.

</details>


### [39] [DeepResearch Bench II: Diagnosing Deep Research Agents via Rubrics from Expert Report](https://arxiv.org/abs/2601.08536)
*Ruizhe Li,Mingxuan Du,Benfeng Xu,Chiwei Zhu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: Deep Research Bench II introduces a rigorous, human-aligned benchmark for Deep Research Systems, featuring 132 tasks across 22 domains and 9,430 binary rubrics across information recall, analysis, and presentation, derived via a four-stage LLM+human pipeline; studies show current models satisfy <50% of rubrics, highlighting a gap to expert performance.


<details>
  <summary>Details</summary>
Motivation: Existing deep-research benchmarks fail to rigorously assess evidence analysis and coherent reporting, and often rely on coarse or LM-defined evaluation criteria that bias results. A more granular, human-aligned evaluation is needed to drive progress in DRS.

Method: Construct 132 grounded research tasks spanning 22 domains. Each task requires a long-form report. Evaluate with 9,430 fine-grained binary rubrics across three dimensions (information recall, analysis, presentation). Rubrics are created through a four-stage LLM+human pipeline, combining automatic extraction with 400+ hours of expert review to ensure atomicity, verifiability, and alignment with expert judgment.

Result: Evaluation of state-of-the-art DRS shows strongest models satisfy fewer than 50% of rubrics, indicating a substantial gap to human expert performance.

Conclusion: Deep Research Bench II offers a more rigorous, interpretable evaluation framework that exposes current limitations of DRS and provides a benchmark to drive progress towards human-level investigative reporting.

Abstract: Deep Research Systems (DRS) aim to help users search the web, synthesize information, and deliver comprehensive investigative reports. However, how to rigorously evaluate these systems remains under-explored. Existing deep-research benchmarks often fall into two failure modes. Some do not adequately test a system's ability to analyze evidence and write coherent reports. Others rely on evaluation criteria that are either overly coarse or directly defined by LLMs (or both), leading to scores that can be biased relative to human experts and are hard to verify or interpret. To address these issues, we introduce Deep Research Bench II, a new benchmark for evaluating DRS-generated reports. It contains 132 grounded research tasks across 22 domains; for each task, a system must produce a long-form research report that is evaluated by a set of 9430 fine-grained binary rubrics in total, covering three dimensions: information recall, analysis, and presentation. All rubrics are derived from carefully selected expert-written investigative articles and are constructed through a four-stage LLM+human pipeline that combines automatic extraction with over 400 human-hours of expert review, ensuring that the criteria are atomic, verifiable, and aligned with human expert judgment. We evaluate several state-of-the-art deep-research systems on Deep Research Bench II and find that even the strongest models satisfy fewer than 50% of the rubrics, revealing a substantial gap between current DRSs and human experts.

</details>


### [40] [Ministral 3](https://arxiv.org/abs/2601.08584)
*Alexander H. Liu,Kartik Khandelwal,Sandeep Subramanian,Victor Jouault,Abhinav Rastogi,Adrien Sadé,Alan Jeffares,Albert Jiang,Alexandre Cahill,Alexandre Gavaudan,Alexandre Sablayrolles,Amélie Héliou,Amos You,Andy Ehrenberg,Andy Lo,Anton Eliseev,Antonia Calvi,Avinash Sooriyarachchi,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Clémence Lanfranchi,Corentin Barreau,Cyprien Courtot,Daniele Grattarola,Darius Dabert,Diego de las Casas,Elliot Chane-Sane,Faruk Ahmed,Gabrielle Berrada,Gaëtan Ecrepont,Gauthier Guinet,Georgii Novikov,Guillaume Kunsch,Guillaume Lample,Guillaume Martin,Gunshi Gupta,Jan Ludziejewski,Jason Rute,Joachim Studnia,Jonas Amar,Joséphine Delas,Josselin Somerville Roberts,Karmesh Yadav,Khyathi Chandu,Kush Jain,Laurence Aitchison,Laurent Fainsin,Léonard Blier,Lingxiao Zhao,Louis Martin,Lucile Saulnier,Luyu Gao,Maarten Buyl,Margaret Jennings,Marie Pellat,Mark Prins,Mathieu Poirée,Mathilde Guillaumin,Matthieu Dinot,Matthieu Futeral,Maxime Darrin,Maximilian Augustin,Mia Chiquier,Michel Schimpf,Nathan Grinsztajn,Neha Gupta,Nikhil Raghuraman,Olivier Bousquet,Olivier Duchenne,Patricia Wang,Patrick von Platen,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Pavankumar Reddy Muddireddy,Philomène Chagniot,Pierre Stock,Pravesh Agrawal,Quentin Torroba,Romain Sauvestre,Roman Soletskyi,Rupert Menneer,Sagar Vaze,Samuel Barry,Sanchit Gandhi,Siddhant Waghjale,Siddharth Gandhi,Soham Ghosh,Srijan Mishra,Sumukh Aithal,Szymon Antoniak,Teven Le Scao,Théo Cachet,Theo Simon Sorg,Thibaut Lavril,Thiziri Nait Saada,Thomas Chabal,Thomas Foubert,Thomas Robert,Thomas Wang,Tim Lawson,Tom Bewley,Tom Bewley,Tom Edwards,Umar Jamil,Umberto Tomasini,Valeriia Nemychnikova,Van Phung,Vincent Maladière,Virgile Richard,Wassim Bouaziz,Wen-Ding Li,William Marshall,Xinghui Li,Xinyu Yang,Yassine El Ouahidi,Yihan Wang,Yunhao Tang,Zaccharie Ramzi*

Main category: cs.CL

TL;DR: Ministral 3 是一组高效参数密集型语言模型家族，覆盖 3B/8B/14B 三种规模。每种规模提供预训练基础模型、指令微调模型和推理模型三种变体，且通过 Cascade Distillation（迭代剪枝 + 蒸馏继续训练）获得。模型具备图像理解能力，授权为 Apache 2.0。


<details>
  <summary>Details</summary>
Motivation: 在计算和内存受限的场景中提供高效且多任务能力的密集型语言模型，兼顾通用性、指令遵循和复杂推理能力，并通过高效的蒸馏/剪枝方法降低资源需求。

Method: 提出 Cascade Distillation 的实现路线：迭代剪枝与蒸馏继续训练的组合，用于从较大规模基模型推导出 3B/8B/14B 的 Ministral 3 系列；同时针对每个规模提供基础、指令微调和推理三种变体，并加入图像理解能力。许可证为 Apache 2.0。

Result: 提出并实现 Ministal 3 家族及 Cascade Distillation 的可复现流程，产出包含三种规模和三类变体的模型，同时具备图像理解能力，适用于资源受限的部署环境。

Conclusion: Ministral 3 提供面向计算/内存受限场景的高效密集语言模型家族，覆盖通用、指令跟随和复杂推理任务的多变体设计，并通过 Cascade Distillation 实现参数高效的模型获取，且开放许可。

Abstract: We introduce the Ministral 3 series, a family of parameter-efficient dense language models designed for compute and memory constrained applications, available in three model sizes: 3B, 8B, and 14B parameters. For each model size, we release three variants: a pretrained base model for general-purpose use, an instruction finetuned, and a reasoning model for complex problem-solving. In addition, we present our recipe to derive the Ministral 3 models through Cascade Distillation, an iterative pruning and continued training with distillation technique. Each model comes with image understanding capabilities, all under the Apache 2.0 license.

</details>


### [41] [ExpSeek: Self-Triggered Experience Seeking for Web Agents](https://arxiv.org/abs/2601.08605)
*Wenyuan Zhang,Xinghua Zhang,Haiyang Yu,Shuaiyi Nie,Bingli Wu,Juwei Yue,Tingwen Liu,Yongbin Li*

Main category: cs.CL

TL;DR: Proposes ExpSeek: step-level, self-triggered experience intervention using entropy to decide when and what content to inject; improves web agent performance on large models.


<details>
  <summary>Details</summary>
Motivation: Existing methods inject experience only as global context before task execution and fail to adapt to dynamic observations during interaction; need proactive, context-aware, step-level intervention.

Method: Entropy-based estimation of step-level intervention thresholds using model intrinsic signals; design of step-level tailored experience content; evaluation on Qwen3-8B and 32B across four web agent benchmarks.

Result: ExpSeek yields absolute performance gains of 9.3% (Qwen3-8B) and 7.5% (32B) across benchmarks; demonstrates feasibility of entropy as a self-triggering signal; shows that a 4B experience model can significantly boost larger agent models.

Conclusion: Entropy serves as an effective self-triggering signal for experience intervention; step-level, proactive content can substantially improve large web agents, even with a small auxiliary experience model.

Abstract: Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations during agent-environment interaction. We propose ExpSeek, which shifts experience toward step-level proactive seeking: (1) estimating step-level entropy thresholds to determine intervention timing using the model's intrinsic signals; (2) designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four challenging web agent benchmarks demonstrate that ExpSeek achieves absolute improvements of 9.3% and 7.5%, respectively. Our experiments validate the feasibility and advantages of entropy as a self-triggering signal, reveal that even a 4B small-scale experience model can significantly boost the performance of larger agent models.

</details>


### [42] [How Order-Sensitive Are LLMs? OrderProbe for Deterministic Structural Reconstruction](https://arxiv.org/abs/2601.08626)
*Yingjie He,Zhaolu Kang,Kehan Jiang,Qianyuan Zhang,Jiachen Qian,Chunlei Meng,Yujie Feng,Yuan Wang,Jiabao Dou,Aming Wu,Leqi Zheng,Pengxiang Zhao,Jiaxin Liu,Zeyu Zhang,Lei Wang,Guansu Wang,Qishi Zhan,Xiaomin He,Meisheng Zhang,Jianyuan Ni*

Main category: cs.CL

TL;DR: 提出 OrderProbe 作为确定性结构重建基准，借助具有唯一规范顺序的四字汉字表达，比较跨中日韩的结构重建能力；并给出一个诊断框架评价语义保真、逻辑有效性、一致性、鲁棒性敏感性与信息密度等维度。


<details>
  <summary>Details</summary>
Motivation: 当前 LLM 在语义理解方面表现突出，但从打乱的输入中重建内部结构的能力研究不足，且句级重建因多种有效排序而难以自动评估。对于中日韩这类具有固定字序特征的语言，构建一个可精确评分的基准尤为重要。

Method: 提出 OrderProbe：使用固定四字表达，具有唯一的规范顺序，从而实现精确匹配的结构重建评测；并提出一个诊断框架，在回收准确率之外评估语义保真、逻辑有效性、一致性、鲁棒性敏感性和信息密度等多维度指标。

Result: 在十二种广泛使用的语言模型（LLMs）上进行实验，零-shot 回收通常低于 35%，结构重建对前沿系统仍具挑战性；同时观察到语义回忆与结构规划之间存在解耦或一致性缺口，表明结构鲁棒性并非自动由语义能力带来。

Conclusion: 该工作提出的诊断框架揭示了结构层面的瓶颈，强调需要针对性地提升模型在结构层面的鲁棒性；未来工作可在训练目标、数据设计及评估标准上进一步优化，以提升跨语言的结构重建能力与一致性。

Abstract: Large language models (LLMs) excel at semantic understanding, yet their ability to reconstruct internal structure from scrambled inputs remains underexplored. Sentence-level restoration is ill-posed for automated evaluation because multiple valid word orders often exist. We introduce OrderProbe, a deterministic benchmark for structural reconstruction using fixed four-character expressions in Chinese, Japanese, and Korean, which have a unique canonical order and thus support exact-match scoring. We further propose a diagnostic framework that evaluates models beyond recovery accuracy, including semantic fidelity, logical validity, consistency, robustness sensitivity, and information density. Experiments on twelve widely used LLMs show that structural reconstruction remains difficult even for frontier systems: zero-shot recovery frequently falls below 35%. We also observe a consistent dissociation between semantic recall and structural planning, suggesting that structural robustness is not an automatic byproduct of semantic competence.

</details>


### [43] [Get away with less: Need of source side data curation to build parallel corpus for low resource Machine Translation](https://arxiv.org/abs/2601.08629)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: LALITA: a lexical- and linguistically informed sentence selection framework that curates parallel corpora to improve MT with less data, focusing on complex sentences and leveraging both existing and synthetic data.


<details>
  <summary>Details</summary>
Motivation: Low-resource MT suffers from data scarcity and high labeling costs. Efficient sentence screening is needed to maximize MT performance with limited parallel data.

Method: LALITA (Lexical And Linguistically Informed Text Analysis) selects source sentences for parallel corpora using lexical and linguistic features. It emphasizes training on complex sentences from both existing and synthetic datasets and evaluates English–Hindi; tested across 50K–800K English sentences and extended to multiple languages.

Result: Significant improvements in translation quality across all data sizes; data efficiency improved by over 50% (reducing required data) and demonstrated applicability to multiple languages (Hindi, Odia, Nepali, Norwegian Nynorsk, German).

Conclusion: LALITA is an effective data-curation framework that reduces MT training data requirements while improving or maintaining translation quality, with potential for data augmentation and broader cross-linguistic applicability.

Abstract: Data curation is a critical yet under-researched step in the machine translation training paradigm. To train translation systems, data acquisition relies primarily on human translations and digital parallel sources or, to a limited degree, synthetic generation. But, for low-resource languages, human translation to generate sufficient data is prohibitively expensive. Therefore, it is crucial to develop a framework that screens source sentences to form efficient parallel text, ensuring optimal MT system performance in low-resource environments. We approach this by evaluating English-Hindi bi-text to determine effective sentence selection strategies for optimal MT system training. Our extensively tested framework, (Lexical And Linguistically Informed Text Analysis) LALITA, targets source sentence selection using lexical and linguistic features to curate parallel corpora. We find that by training mostly on complex sentences from both existing and synthetic datasets, our method significantly improves translation quality. We test this by simulating low-resource data availabilty with curated datasets of 50K to 800K English sentences and report improved performances on all data sizes. LALITA demonstrates remarkable efficiency, reducing data needs by more than half across multiple languages (Hindi, Odia, Nepali, Norwegian Nynorsk, and German). This approach not only reduces MT systems training cost by reducing training data requirement, but also showcases LALITA's utility in data augmentation.

</details>


### [44] [Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs](https://arxiv.org/abs/2601.08634)
*Chenchen Yuan,Bolei Ma,Zheyu Zhang,Bardh Prenkaj,Frauke Kreuter,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 对道德价值观作为可控条件对LLM政治取向的因果影响进行了实验性研究，显示价值观条件化会导致经济/社会维度的显著偏移。


<details>
  <summary>Details</summary>
Motivation: 探究道德直觉为何成为政治立场的下游结果，以及如何将道德框架作为对齐过程中的可控变量，以实现更具社会价值的对齐。

Method: 将道德价值视为镜头，条件化模型认可或否定特定道德价值；以政治罗盘测试评估政治取向，比较角色框架、模型规模及替代评估工具的稳健性。

Result: 道德条件化会带来明显且价值特异的政治坐标偏移，且受角色框架与模型规模调制，在不同工具中均可复现。

Conclusion: 强调对齐需在更广泛社会价值（包括道德）背景下评估政治取向，推动更具社会 grounding 的对齐方法。

Abstract: While recent research has systematically documented political orientation in large language models (LLMs), existing evaluations rely primarily on direct probing or demographic persona engineering to surface ideological biases. In social psychology, however, political ideology is also understood as a downstream consequence of fundamental moral intuitions. In this work, we investigate the causal relationship between moral values and political positioning by treating moral orientation as a controllable condition. Rather than simply assigning a demographic persona, we condition models to endorse or reject specific moral values and evaluate the resulting shifts on their political orientations, using the Political Compass Test. By treating moral values as lenses, we observe how moral conditioning actively steers model trajectories across economic and social dimensions. Our findings show that such conditioning induces pronounced, value-specific shifts in models' political coordinates. We further notice that these effects are systematically modulated by role framing and model scale, and are robust across alternative assessment instruments instantiating the same moral value. This highlights that effective alignment requires anchoring political assessments within the context of broader social values including morality, paving the way for more socially grounded alignment techniques.

</details>


### [45] [A Parallel Cross-Lingual Benchmark for Multimodal Idiomaticity Understanding](https://arxiv.org/abs/2601.08645)
*Dilara Torunoğlu-Selamet,Dogukan Arslan,Rodrigo Wilkens,Wei He,Doruk Eryiğit,Thomas Pickard,Adriana S. Pagano,Aline Villavicencio,Gülşen Eryiğit,Ágnes Abuczki,Aida Cardoso,Alesia Lazarenka,Dina Almassova,Amalia Mendes,Anna Kanellopoulou,Antoni Brosa-Rodríguez,Baiba Saulite,Beata Wojtowicz,Bolette Pedersen,Carlos Manuel Hidalgo-Ternero,Chaya Liebeskind,Danka Jokić,Diego Alves,Eleni Triantafyllidi,Erik Velldal,Fred Philippy,Giedre Valunaite Oleskeviciene,Ieva Rizgeliene,Inguna Skadina,Irina Lobzhanidze,Isabell Stinessen Haugen,Jauza Akbar Krito,Jelena M. Marković,Johanna Monti,Josue Alejandro Sauca,Kaja Dobrovoljc,Kingsley O. Ugwuanyi,Laura Rituma,Lilja Øvrelid,Maha Tufail Agro,Manzura Abjalova,Maria Chatzigrigoriou,María del Mar Sánchez Ramos,Marija Pendevska,Masoumeh Seyyedrezaei,Mehrnoush Shamsfard,Momina Ahsan,Muhammad Ahsan Riaz Khan,Nathalie Carmen Hau Norman,Nilay Erdem Ayyıldız,Nina Hosseini-Kivanani,Noémi Ligeti-Nagy,Numaan Naeem,Olha Kanishcheva,Olha Yatsyshyna,Daniil Orel,Petra Giommarelli,Petya Osenova,Radovan Garabik,Regina E. Semou,Rozane Rebechi,Salsabila Zahirah Pranida,Samia Touileb,Sanni Nimb,Sarfraz Ahmad,Sarvinoz Nematkhonova,Shahar Golan,Shaoxiong Ji,Sopuruchi Christian Aboh,Srdjan Sucur,Stella Markantonatou,Sussi Olsen,Vahide Tajalli,Veronika Lipp,Voula Giouli,Yelda Yeşildal Eraydın,Zahra Saaberi,Zhuohan Xie*

Main category: cs.CL

TL;DR: XMPIE is a large parallel multilingual and multimodal dataset for potentially idiomatic expressions, covering 34 languages and over 10k items, with five images per PIE to enable cross-language and cross-modal evaluation.


<details>
  <summary>Details</summary>
Motivation: PIEs encode meanings tied to everyday cultural experience and pose a challenge for NLP; a multilingual multimodal benchmark is needed to assess and compare idiomatic understanding across languages and modalities and to study cultural patterns.

Method: Data collected by language experts with both textual and visual components following multilingual guidelines. Each PIE comes with five images illustrating a spectrum from idiomatic to literal meanings, including semantically related and random distractors. The dataset comprises 34 languages and over 10k items.

Result: Provides a high-quality benchmark for evaluating multilingual and multimodal idiomatic language understanding, enabling analyses of cross-language transfer, cross-modal transfer, and comparative idiomatic patterns across languages.

Conclusion: XMPIE offers a valuable resource for studying and evaluating multilingual and multimodal idiomatic understanding, with potential insights into shared cultural aspects and cross-language/cross-modal transfer.

Abstract: Potentially idiomatic expressions (PIEs) construe meanings inherently tied to the everyday experience of a given language community. As such, they constitute an interesting challenge for assessing the linguistic (and to some extent cultural) capabilities of NLP systems. In this paper, we present XMPIE, a parallel multilingual and multimodal dataset of potentially idiomatic expressions. The dataset, containing 34 languages and over ten thousand items, allows comparative analyses of idiomatic patterns among language-specific realisations and preferences in order to gather insights about shared cultural aspects. This parallel dataset allows to evaluate model performance for a given PIE in different languages and whether idiomatic understanding in one language can be transferred to another. Moreover, the dataset supports the study of PIEs across textual and visual modalities, to measure to what extent PIE understanding in one modality transfers or implies in understanding in another modality (text vs. image). The data was created by language experts, with both textual and visual components crafted under multilingual guidelines, and each PIE is accompanied by five images representing a spectrum from idiomatic to literal meanings, including semantically related and random distractors. The result is a high-quality benchmark for evaluating multilingual and multimodal idiomatic language understanding.

</details>


### [46] [Safe Language Generation in the Limit](https://arxiv.org/abs/2601.08648)
*Antonios Anastasopoulos,Giuseppe Ateniese,Evgenios M. Kornaropoulos*

Main category: cs.CL

TL;DR: 在学习极限框架下，语言识别不可行但语言生成可行；本文首次理论化安全语言生成，给出安全语言识别与生成的形式化定义，结果为：安全语言识别不可能，安全语言生成至少与常规语言识别同样困难（后者也不可行），并讨论了若干难解与可解情形。


<details>
  <summary>Details</summary>
Motivation: 探讨在现实场景中的安全性问题对学习极限下的语言任务的影响，明确安全约束对语言识别/生成的理论极限，以指导实际系统设计与风险评估。

Method: 在学习极限的计算范式内，对安全语言识别与生成给出形式化定义；证明在该模型下安全语言识别不可能实现，安全语言生成的难度至少等同于语言识别（而后者在该框架下也是不可行的），并讨论若干可解与不可解的特例。

Result: 得出结论：安全语言识别在该模型中不可实现；安全语言生成的难度至少与普通语言识别相同，而普通语言识别在该框架下也不可实现；并指出存在若干在 theory 上可辨别的、也可能不可解的情形。

Conclusion: 整体而言，在学习极限的理论框架下，安全性约束无法挽救这两项任务的可实现性，提出对未来研究的边界条件及对特定情形的深入分析。

Abstract: Recent results in learning a language in the limit have shown that, although language identification is impossible, language generation is tractable. As this foundational area expands, we need to consider the implications of language generation in real-world settings.
  This work offers the first theoretical treatment of safe language generation. Building on the computational paradigm of learning in the limit, we formalize the tasks of safe language identification and generation. We prove that under this model, safe language identification is impossible, and that safe language generation is at least as hard as (vanilla) language identification, which is also impossible. Last, we discuss several intractable and tractable cases.

</details>


### [47] [RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation](https://arxiv.org/abs/2601.08654)
*Yihan Hong,Huaiyuan Yao,Bolin Shen,Wanpeng Xu,Hua Wei,Yushun Dong*

Main category: cs.CL

TL;DR: 提出 RULERS 框架，通过可执行的标准化评估来提升 LLM 评审的一致性和可核验性，显著改善人类一致性和对抗性扰动。


<details>
  <summary>Details</summary>
Motivation: 解决 LLM 作为评审者在稳定性、可验证性和尺度对齐方面的挑战，尤其是对黑盒模型的鲁棒性与人类评估界限的对齐。

Method: 将评判标准转化为可执行规范（可版本化、不可变的打包），引入编译-执行框架，强制结构化解码、可验证证据、以及基于 Wasserstein 的后验标尺校准；不更新模型参数。

Result: 在作文与摘要基准上显著优于基线，达到较高的人类一致性，抗对抗性 rubric 改动，较小模型能媲美大型评测模型；显示可执行化的评估标准和证据将提升鲁棒性。

Conclusion: 可靠的 LLM 评审需可执行的 rubric、可核验的证据和校准的尺度，而非仅靠提示词设计；代码公开。

Abstract: The LLM-as-a-Judge paradigm promises scalable rubric-based evaluation, yet aligning frozen black-box models with human standards remains a challenge due to inherent generation stochasticity. We reframe judge alignment as a criteria transfer problem and isolate three recurrent failure modes: rubric instability caused by prompt sensitivity, unverifiable reasoning that lacks auditable evidence, and scale misalignment with human grading boundaries. To address these issues, we introduce RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a compiler-executor framework that transforms natural language rubrics into executable specifications. RULERS operates by compiling criteria into versioned immutable bundles, enforcing structured decoding with deterministic evidence verification, and applying lightweight Wasserstein-based post-hoc calibration, all without updating model parameters. Extensive experiments on essay and summarization benchmarks demonstrate that RULERS significantly outperforms representative baselines in human agreement, maintains strong stability against adversarial rubric perturbations, and enables smaller models to rival larger proprietary judges. Overall, our results suggest that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales rather than prompt phrasing alone. Code is available at https://github.com/LabRAI/Rulers.git.

</details>


### [48] [Analyzing Bias in False Refusal Behavior of Large Language Models for Hate Speech Detoxification](https://arxiv.org/abs/2601.08668)
*Kyuri Im,Shuzhou Yuan,Michael Färber*

Main category: cs.CL

TL;DR: 对LLM在仇恨言论净化中的误拒绝行为进行系统分析，并提出跨翻译的轻量化缓解策略。


<details>
  <summary>Details</summary>
Motivation: 揭示触发误拒绝的上下文与语言偏见，提升多语言场景下的安全对齐与实用性。

Method: 在九种LLM上用英语与多语言数据集评估，分析语义毒性、目标群体等因素的触发模式；提出将英语转为中文再转回的跨翻译策略以降低误拒绝。

Result: 模型对更高语义毒性和针对特定群体的输入（如国家、宗教、政治理念）有更高的误拒绝率；多语言数据集总体误拒绝率低于英语，但仍存在语言依赖的目标偏见；跨翻译策略显著降低误拒绝并保留原始内容。

Conclusion: 跨翻译是一种有效且轻量的缓解手段，但需结合更全面的安全对齐与偏见缓解策略。

Abstract: While large language models (LLMs) have increasingly been applied to hate speech detoxification, the prompts often trigger safety alerts, causing LLMs to refuse the task. In this study, we systematically investigate false refusal behavior in hate speech detoxification and analyze the contextual and linguistic biases that trigger such refusals. We evaluate nine LLMs on both English and multilingual datasets, our results show that LLMs disproportionately refuse inputs with higher semantic toxicity and those targeting specific groups, particularly nationality, religion, and political ideology. Although multilingual datasets exhibit lower overall false refusal rates than English datasets, models still display systematic, language-dependent biases toward certain targets. Based on these findings, we propose a simple cross-translation strategy, translating English hate speech into Chinese for detoxification and back, which substantially reduces false refusals while preserving the original content, providing an effective and lightweight mitigation approach.

</details>


### [49] [QuantEval: A Benchmark for Financial Quantitative Tasks in Large Language Models](https://arxiv.org/abs/2601.08689)
*Zhaolu Kang,Junhao Gong,Wenqing Hu,Shuo Yin,Kehan Jiang,Zhicheng Fang,Yingjie He,Chunlei Meng,Rong Fu,Dongyang Chen,Leqi Zheng,Eric Hanchen Jiang,Yunfei Feng,Yitong Leng,Junfan Zhu,Xiaoyou Chen,Xi Yang,Richeng Xuan*

Main category: cs.CL

TL;DR: 提出 QuantEval 基准，用于评估语言模型在量化金融中的知识问答、定量推理和策略编码三个维度，并结合 CTA 风格回测框架对模型生成的策略进行实盘级评估。结果显示与人类专家仍存在显著差距，尤其在推理和策略编码方面；通过大规模监督微调和强化学习获得一致性提升，并提供可重复的回测配置以促进复现实验。


<details>
  <summary>Details</summary>
Motivation: 弥补现有金融基准在知识问答之外，对模型在定量推理与策略生成/执行能力的系统评估不足的问题，提供一个更贴近真实交易工作流的评测框架。

Method: 构建三维评测维度：知识型QA、定量数学推理、定量策略编码；引入 CTA 风格回测框架，直接在资产组合上执行模型生成的交易策略并用金融绩效指标评估；对开源与专有 LLM 进行评测；在域对齐数据上进行大规模有监督微调与强化学习；并公开确定性回测配置以确保可重复性。

Result: 评估显示模型在推理和策略编码方面与人类专家存在显著差距；经过领域对齐的数据进行监督微调与强化学习后，性能呈现一致性提升；发布了可重复的回测配置以促进复现实验。

Conclusion: QuantEval 为量化金融领域的 LLM 研究提供可比性基准，促进其在实际交易工作流中的应用潜力；同时通过公开的回测配置提高研究的可复现性与透明度。

Abstract: Large Language Models (LLMs) have shown strong capabilities across many domains, yet their evaluation in financial quantitative tasks remains fragmented and mostly limited to knowledge-centric question answering. We introduce QuantEval, a benchmark that evaluates LLMs across three essential dimensions of quantitative finance: knowledge-based QA, quantitative mathematical reasoning, and quantitative strategy coding. Unlike prior financial benchmarks, QuantEval integrates a CTA-style backtesting framework that executes model-generated strategies and evaluates them using financial performance metrics, enabling a more realistic assessment of quantitative coding ability. We evaluate some state-of-the-art open-source and proprietary LLMs and observe substantial gaps to human experts, particularly in reasoning and strategy coding. Finally, we conduct large-scale supervised fine-tuning and reinforcement learning experiments on domain-aligned data, demonstrating consistent improvements. We hope QuantEval will facilitate research on LLMs' quantitative finance capabilities and accelerate their practical adoption in real-world trading workflows. We additionally release the full deterministic backtesting configuration (asset universe, cost model, and metric definitions) to ensure strict reproducibility.

</details>


### [50] [Nationality and Region Prediction from Names: A Comparative Study of Neural Models and Large Language Models](https://arxiv.org/abs/2601.08692)
*Keito Inoshita*

Main category: cs.CL

TL;DR: LLMs outperform neural models for nationality prediction across different granularity levels, though performance drops for low-frequency nationalities. Simple ML methods show strongest frequency robustness. LLMs make near-miss errors (correct region but wrong nationality), while neural models show more cross-regional errors and high-frequency bias. Implications: leverage world knowledge with LLMs, tailor model choice to required granularity, and evaluate using error quality beyond accuracy.


<details>
  <summary>Details</summary>
Motivation: Address generalization to low-frequency nationalities and disambiguation of similar nationalities; assess whether pre-trained world knowledge in LLMs can improve nationality prediction beyond task-specific training.

Method: Empirically compare six neural models and six LLM prompting strategies across three granularity levels (nationality, region, continent). Use frequency-stratified analysis and error analysis to evaluate performance and error types.

Result: LLMs outperform neural models at all granularity levels; the performance gap decreases as granularity becomes coarser. Simple ML methods are most robust to high-frequency bias. Pre-trained models and LLMs show degradation for low-frequency nationalities. Error analysis reveals LLMs yield near-miss errors (predict correct region but incorrect nationality) whereas neural models exhibit more cross-regional errors and high-frequency bias.

Conclusion: LLMs gain from world knowledge and can outperform traditional neural models in nationality prediction. Model selection should align with the desired granularity, and evaluation should consider error quality in addition to accuracy.

Abstract: Predicting nationality from personal names has practical value in marketing, demographic research, and genealogical studies. Conventional neural models learn statistical correspondences between names and nationalities from task-specific training data, posing challenges in generalizing to low-frequency nationalities and distinguishing similar nationalities within the same region. Large language models (LLMs) have the potential to address these challenges by leveraging world knowledge acquired during pre-training. In this study, we comprehensively compare neural models and LLMs on nationality prediction, evaluating six neural models and six LLM prompting strategies across three granularity levels (nationality, region, and continent), with frequency-based stratified analysis and error analysis. Results show that LLMs outperform neural models at all granularity levels, with the gap narrowing as granularity becomes coarser. Simple machine learning methods exhibit the highest frequency robustness, while pre-trained models and LLMs show degradation for low-frequency nationalities. Error analysis reveals that LLMs tend to make ``near-miss'' errors, predicting the correct region even when nationality is incorrect, whereas neural models exhibit more cross-regional errors and bias toward high-frequency classes. These findings indicate that LLM superiority stems from world knowledge, model selection should consider required granularity, and evaluation should account for error quality beyond accuracy.

</details>


### [51] [PrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation](https://arxiv.org/abs/2601.08739)
*Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: PrivGemo是一种隐私保护的KG检索增强推理框架，通过双塔结构、匿名化视图和记忆驱动的曝光控制，在本地KG grounding的同时实现远程推理，支持多跳和多实体推理，且在六个基准上达到SOTA且可使小模型达到接近GPT-4-Turbo的性能。


<details>
  <summary>Details</summary>
Motivation: 解决私有知识图谱在利用闭源LLM进行知识密集型问答时的隐私泄露风险，以及现有基于名称遮蔽的方法在结构泄露、远程交互不可控、多跳推理和经验复用方面的不足。

Method: 提出双塔设计保留原始KG在本地，同时在经过匿名化处理的视图上进行远程推理；通过检索匿名化的长跳路径将主题实体连接起来，完成多跳/多实体推理；引入分层控制器和隐私感知的经验记忆以减少不必要的探索与远程交互。

Result: 在六个基准数据集上实现了整体SOTA，最强基线领先幅度高达17.1%；并且使得像Qwen3-4B这样的较小模型可以达到接近GPT-4-Turbo的推理性能。

Conclusion: PrivGemo为KG-grounded推理提供一种高效且具隐私保护的框架，通过本地 grounding 与匿名化远程推理结合，兼顾多跳推理能力与隐私安全，并提升了模型规模对性能的可承载性。

Abstract: Knowledge graphs (KGs) provide structured evidence that can ground large language model (LLM) reasoning for knowledge-intensive question answering. However, many practical KGs are private, and sending retrieved triples or exploration traces to closed-source LLM APIs introduces leakage risk. Existing privacy treatments focus on masking entity names, but they still face four limitations: structural leakage under semantic masking, uncontrollable remote interaction, fragile multi-hop and multi-entity reasoning, and limited experience reuse for stability and efficiency. To address these issues, we propose PrivGemo, a privacy-preserving retrieval-augmented framework for KG-grounded reasoning with memory-guided exposure control. PrivGemo uses a dual-tower design to keep raw KG knowledge local while enabling remote reasoning over an anonymized view that goes beyond name masking to limit both semantic and structural exposure. PrivGemo supports multi-hop, multi-entity reasoning by retrieving anonymized long-hop paths that connect all topic entities, while keeping grounding and verification on the local KG. A hierarchical controller and a privacy-aware experience memory further reduce unnecessary exploration and remote interactions. Comprehensive experiments on six benchmarks show that PrivGemo achieves overall state-of-the-art results, outperforming the strongest baseline by up to 17.1%. Furthermore, PrivGemo enables smaller models (e.g., Qwen3-4B) to achieve reasoning performance comparable to that of GPT-4-Turbo.

</details>


### [52] [From Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding](https://arxiv.org/abs/2601.08741)
*Anmol Gulati,Sahil Sen,Waqar Sarguroh,Kevin Paul*

Main category: cs.CL

TL;DR: 提出 FRTR-Bench 与 From Rows to Reasoning (FRTR) 框架，解决大规模企业电子表格的多模态推理挑战，通过分解单元、混合检索和多模态嵌入实现对数值和视觉信息的推理，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的表格推理方法要么仅能处理单页压缩要么需要全上下文编码，难以扩展到包含数千行、跨工作表、嵌入图像/收据等复杂多模态企业工作簿。此外，缺乏面向大规模多模态电子表格的公开基准。

Method: FRTR-Bench 作为首个大规模多模态电子表格基准，包含约400万单元和50+嵌入图片的30个企业级 Excel 工作簿。FRTR 框架将工作簿拆解为逐行/逐列/区块的向量嵌入，结合混合的词汇-密集检索（包含 Reciprocal Rank Fusion）并融合多模态嵌入，以对数值与视觉信息进行推理。

Result: 在六种大语言模型上测试，FRTR 在 FRTR-Bench 上以 Claude Sonnet 4.5 获得 74% 的正确率，显著高于之前方法的 24%。在 SpreadsheetLLM 基准上，FRTR 与 GPT-5 配合达到 87% 的准确性，同时相比上下文压缩方法将 token 使用量降低约 50%。

Conclusion: FRTR 通过分解、混合检索和多模态嵌入的整合，提升了对大规模多模态电子表格的推理能力和可扩展性，提供了有力的基准测试并显著降低 token 需求，展示了企业级电子表格推理的新方向。

Abstract: Large Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users interact with complex, multimodal workbooks. We introduce FRTR-Bench, the first large-scale benchmark for multimodal spreadsheet reasoning, comprising 30 enterprise-grade Excel workbooks spanning nearly four million cells and more than 50 embedded images. To address these challenges, we present From Rows to Reasoning (FRTR), an advanced, multimodal retrieval-augmented generation framework that decomposes Excel workbooks into granular row, column, and block embeddings, employs hybrid lexical-dense retrieval with Reciprocal Rank Fusion (RRF), and integrates multimodal embeddings to reason over both numerical and visual information. We tested FRTR on six LLMs, achieving 74% answer accuracy on FRTR-Bench with Claude Sonnet 4.5, a substantial improvement over prior state-of-the-art approaches that reached only 24%. On the SpreadsheetLLM benchmark, FRTR achieved 87% accuracy with GPT-5 while reducing token usage by roughly 50% compared to context-compression methods.

</details>


### [53] [TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL](https://arxiv.org/abs/2601.08743)
*Jinbo Su,Yuxuan Hu,Cuiping Li,Hong Chen,Jia Li,Lintao Ma,Jing Zhang*

Main category: cs.CL

TL;DR: Offline precomputation of table KV caches and a Table Trie to accelerate Text-to-SQL inference, achieving up to 3.62x TTFT with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Reduce long context prompts and redundant prefix caches in LLM-based Text-to-SQL by reusing table representations across queries.

Method: Compute table representations as KV caches offline while preserving primary-foreign key relationships; construct a Table Trie for fast KV cache lookups; implement a cache management system with query reranking and a parallel computation/loading pipeline.

Result: TTFT speedup up to 3.62x with negligible performance degradation.

Conclusion: TableCache effectively speeds up Text-to-SQL inference via offline KV cache precomputation, structured caching, and parallel caching pipeline, with minimal impact on accuracy.

Abstract: In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders. To address this inefficiency, we propose precomputing table representations as KV caches offline and querying the required ones online. A key aspect of our approach is the computation of table caches while preserving primary foreign key relationships between tables. Additionally, we construct a Table Trie structure to facilitate efficient KV cache lookups during inference. To enhance cache performance, we introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that our proposed TableCache achieves up to a 3.62x speedup in Time to First Token (TTFT) with negligible performance degradation.

</details>


### [54] [Spatial Context Improves the Integration of Text with Remote Sensing for Mapping Environmental Variables](https://arxiv.org/abs/2601.08750)
*Valerie Zermatten,Chiara Vanalli,Gencer Sumbul,Diego Marcos,Devis Tuia*

Main category: cs.CL

TL;DR: 提出一种基于注意力的多模态融合方法，将航空影像、地理定位文本及地理位置信息在局部空间邻域内结合，用于预测103个环境变量，在EcoWikiRS数据集上超越单模态和单地点基线，且对气候、土壤、人口、土地覆被等变量改进显著。


<details>
  <summary>Details</summary>
Motivation: 文本数据在生态学中的潜力尚未充分挖掘，文本与地理空间数据的整合面临文本稀疏性、不规则性、邻域选择等挑战，需要一种在空间上下文中动态选择相关邻近观测的融合方法，以提升多变量环境预测的精度。

Method: 提出一个注意力驱动的多模态框架：将视觉表征、文本表征与地理位置编码相结合，通过一个邻域注意力模块，动态选择对预测有贡献的空间邻居。对EcoWikiRS数据集（瑞士局部环境条件的航空影像+维基文本）进行训练与评估，目标是从SWECO25数据立方预测103个环境变量。

Result: 该方法在与单地点、仅图像或仅文本的基线相比具有一致的性能提升；按主题变量分组分析时，在气候、土壤、人口、土地利用/土地覆盖等变量上尤显显著，显示在文本和图像的空间上下文融合中，空间信息对预测的贡献明显。

Conclusion: 将文本信息与影像在空间邻域中融合的策略有效提升多变量环境预测，证明了文本在局部环境条件推断中的补充作用，且这种方法可扩展到其他地区和数据源。

Abstract: Recent developments in natural language processing highlight text as an emerging data source for ecology. Textual resources carry unique information that can be used in complementarity with geospatial data sources, thus providing insights at the local scale into environmental conditions and properties hidden from more traditional data sources. Leveraging textual information in a spatial context presents several challenges. First, the contribution of textual data remains poorly defined in an ecological context, and it is unclear for which tasks it should be incorporated. Unlike ubiquitous satellite imagery or environmental covariates, the availability of textual data is sparse and irregular; its integration with geospatial data is not straightforward. In response to these challenges, this work proposes an attention-based approach that combines aerial imagery and geolocated text within a spatial neighbourhood, i.e. integrating contributions from several nearby observations. Our approach combines vision and text representations with a geolocation encoding, with an attention-based module that dynamically selects spatial neighbours that are useful for predictive tasks.The proposed approach is applied to the EcoWikiRS dataset, which combines high-resolution aerial imagery with sentences extracted from Wikipedia describing local environmental conditions across Switzerland. Our model is evaluated on the task of predicting 103 environmental variables from the SWECO25 data cube. Our approach consistently outperforms single-location or unimodal, i.e. image-only or text-only, baselines. When analysing variables by thematic groups, results show a significant improvement in performance for climatic, edaphic, population and land use/land cover variables, underscoring the benefit of including the spatial context when combining text and image data.

</details>


### [55] [Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge](https://arxiv.org/abs/2601.08808)
*Yao Tang,Li Dong,Yaru Hao,Qingxiu Dong,Furu Wei,Jiatao Gu*

Main category: cs.CL

TL;DR: 提出“Multiplex Thinking”：在每一步推理中多次采样K个候选令牌，并将它们的嵌入聚合成一个连续的多路令牌，从而在保持词汇嵌入先验和离散生成采样动态的同时，得到一个可优化的多路滚动的概率分布。该机制在自适应地实现近似离散的CoT时，又在不增加序列长度的情况下表示多种可能的下一个步骤，使得可直接使用在策略梯度等强化学习中进行训练。在数学推理基准上优于强基线，且序列更短。


<details>
  <summary>Details</summary>
Motivation: 解决像Chain-of-Thought（CoT）那样的长序列带宽成本与人类的软推理过程之间的矛盾，保持嵌入词汇的先验并引入可训练的概率分布以进行强化学习优化；使模型在自适应时接近离散CoT，在不确定时压缩表示多种可能的下一个步骤。

Method: 在每一步思考时，采样K个候选令牌并将它们的嵌入聚合成一个连续的“多路令牌”（multiplex token），保留词汇嵌入的先验与离散生成的采样动力学，得到一个可处理的Multiplex滚动（rollout）分布，使得序列可直接用于On-policy RL优化。该机制具有自适应性：当模型置信时，多路令牌接近离散行为，等同于标准CoT；当不确定时，紧凑地表示多种可行的下一步，且不增加序列长度。

Result: 在具有挑战性的数学推理基准上，Multiplex Thinking持续优于强基线的离散CoT和RL，从Pass@1到Pass@1024均有提升，同时产生更短的序列。Code与检查点在GitHub公开。

Conclusion: Multiplex Thinking提供一种自适应、高效的推理机制，克服常规CoT的高带宽成本并改善在强化学习框架中的训练效果，尤其在需要处理多种潜在推理路径时表现突出；并给出可重复的实现资源以便后续研究与应用。

Abstract: Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [56] [A survey: Information search time optimization based on RAG (Retrieval Augmentation Generation) chatbot](https://arxiv.org/abs/2601.07838)
*Jinesh Patel,Arpit Malhotra,Ajay Pande,Prateek Caire*

Main category: cs.IR

TL;DR: 使用RAG的聊天机器人在组织内部的信息检索中显著节省搜索时间，与传统搜索相比，平均提高80-95%。


<details>
  <summary>Details</summary>
Motivation: 评估RAG在处理组织内部复杂信息检索任务时的效率提升，比较其与标准搜索的时间成本。

Method: 以105名员工为样本，对同一查询在标准搜索与RAG聊天机器人下的信息检索时间进行对比，评估平均时间成本。

Result: RAG聊天机器人在信息检索上实现80-95%的时间改进/节省，且对搜索过程有优化作用。

Conclusion: 在组织信息检索场景中，RAG基于的聊天机器人具有显著的效率优势，具有潜在的应用价值，但需注意对私人数据的使用和系统集成的实际可行性。

Abstract: Retrieval-Augmented Generation (RAG) based chatbots are not only useful for information retrieval through questionanswering but also for making complex decisions based on injected private data.we present a survey on how much search time can be saved when retrieving complex information within an organization called "X Systems"(a stealth mode company) by using a RAG-based chatbot compared to traditional search methods. We compare the information retrieval time using standard search techniques versus the RAG-based chatbot for the same queries. Our results conclude that RAG-based chatbots not only save time in information retrieval but also optimize the search process effectively. This survey was conducted with a sample of 105 employees across departments, average time spending on information retrieval per query was taken as metric. Comparison shows us, there are average 80-95% improvement on search when use RAG based chatbot than using standard search.

</details>


### [57] [Cost and accuracy of long-term graph memory in distributed LLM-based multi-agent systems](https://arxiv.org/abs/2601.07978)
*Benedict Wolff,Jacopo Bennati*

Main category: cs.IR

TL;DR: Mem0 (vector-based memory) outperforms Graphiti (graph-based knowledge graph) in efficiency for Distributed Multi-Agent Systems (DMAS) under network constraints, with no significant accuracy difference. Pareto efficiency analysis identifies mem0 as optimal for balancing cost and accuracy using LOCOMO long-context benchmark.


<details>
  <summary>Details</summary>
Motivation: Systematic evaluation of long-term memory in distributed multi-agent systems under network constraints is limited. There is a need to compare memory architectures (vector-based vs graph-based) to understand trade-offs in efficiency, cost, and accuracy.

Method: Develop a flexible testbed and evaluate two memory architectures (mem0, vector-based; Graphiti, graph-based KG) using the LOCOMO long-context benchmark. Conduct experiments under unconstrained and constrained network conditions. Measure computational metrics (loading time, resource use), financial metrics (cost proxies), and accuracy. Apply statistical Pareto efficiency to identify optimal balance of cost and accuracy.

Result: mem0 significantly outperforms Graphiti in efficiency (faster loading, lower resource consumption, reduced network overhead) with no statistically significant difference in accuracy. Pareto analysis identifies mem0 as the optimal choice balancing cost and accuracy in DMAS.

Conclusion: For DMAS with long-context memory under network constraints, mem0 is the preferred memory architecture due to superior efficiency and comparable accuracy. The study provides a methodological framework for evaluating memory systems and demonstrates the trade-offs between vector-based and graph-based memory under network constraints.

Abstract: Distributed multi-agent systems use large language models to enable collaborative intelligence while preserving privacy, yet systematic evaluations of long-term memory under network constraints remain limited. This study presents a flexible testbed comparing mem0, a vector-based memory framework, and Graphiti, a graph-based knowledge graph, using the LOCOMO long-context benchmark. Experiments were conducted under unconstrained and constrained network conditions, measuring computational, financial, and accuracy metrics. Results indicate that mem0 significantly outperforms Graphiti in efficiency, with faster loading times, lower resource consumption, and minimal network overhead, while accuracy differences are not statistically significant. Applying a statistical pareto efficiency framework, mem0 is identified as the optimal choice that balances cost and accuracy in DMAS.

</details>


### [58] [Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models](https://arxiv.org/abs/2601.08148)
*Seokho Ahn,Sungbok Shin,Young-Duk Seo*

Main category: cs.IR

TL;DR: SPiKE是一种基于画像的推荐模型，通过将LLMs生成的实体语义画像与知识图谱传播整合，实现对用户偏好的更好建模，实验证明优于最新的KG-与LLM基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于画像的推荐在如何构建和利用用户/实体画像方面缺乏共识。本工作从知识基、偏好指示、影响范围和主体四个维度重新审视，指出LLMs擅长提取压缩的推理理由（rationales），KGs更擅长将画像传播扩展到更大范围，二者协同能提升推荐覆盖与效果。

Method: (i) 实体画像生成：使用LLMs为所有KG实体生成语义画像；(ii) 基于画像的KG聚合：将这些画像融入KG中以扩展知识传播；(iii) 成对画像偏好匹配：在训练中对齐LLM-与KG基表示，进行对比学习或对比偏好匹配。

Result: 在真实数据集和场景中，SPiKE持续超越最先进的KG-和LLM基线模型。

Conclusion: 将LLM提取的实体语义画像与KG传播机制结合，提升了画像驱动的推荐质量，SPiKE为此提供了可行的端到端架构。

Abstract: Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is still no consensus on how best to construct and utilize such profiles. To address this, we revisit recent profiling-based approaches in recommender systems along four dimensions: 1) knowledge base, 2) preference indicator, 3) impact range, and 4) subject. We argue that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. Building on this insight, we propose a new recommendation model, called SPiKE. SPiKE consists of three core components: i) Entity profile generation, which uses LLMs to generate semantic profiles for all KG entities; ii) Profile-aware KG aggregation, which integrates these profiles into the KG; and iii) Pairwise profile preference matching, which aligns LLM- and KG-based representations during training. In experiments, we demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.

</details>


### [59] [Markovian Pre-Trained Transformer for Next-Item Recommendation](https://arxiv.org/abs/2601.08275)
*Cong Xu,Guoliang Li,Jun Wang,Wei Zhang*

Main category: cs.IR

TL;DR: 提出 Markovian Pre-trained Transformer (MPT)，在合成马尔可夫链上进行预训练，并通过微调一个轻量级适配器，在五个公开数据集上对下一项推荐达到或超过 state-of-the-art。


<details>
  <summary>Details</summary>
Motivation: 解释序列推荐中对最近交互的强依赖，寻求一个可迁移、通用的推荐模型。通过在可控的合成数据上进行预训练，提升模型容量与泛化能力，弥补真实数据标注与规模的不足。

Method: 以合成马尔可夫链为预训练目标，训练一个Transformer来估计上下文中的转移概率，并强调对最后状态的关注；在下游任务中通过一个轻量级适配器对真实数据进行微调以实现高效迁移。

Result: 在来自三个平台的五个公开数据集上，MPT的预训练+适配器方案优于传统的推荐预训练和最近的语言预训练方法，达到更优的性能。

Conclusion: MPT具备普适性和可迁移性的潜力；通过合成马尔可夫链的预训练，可以有效总结序列、尤其强调最新交互，为统一的推荐建模提供新途径。未来可扩展到其他序列任务，进一步研究适配器设计与不同预训练对象的对比。

Abstract: We introduce the Markovian Pre-trained Transformer (MPT) for next-item recommendation, a transferable model fully pre-trained on synthetic Markov chains, yet capable of achieving state-of-the-art performance by fine-tuning a lightweight adaptor. This counterintuitive success stems from the observation of the `Markovian' nature: advanced sequential recommenders coincidentally rely on the latest interaction to make predictions, while the historical interactions serve mainly as auxiliary cues for inferring the user's general, non-sequential identity. This characteristic necessitates the capabilities of a universal recommendation model to effectively summarize the user sequence, with particular emphasis on the latest interaction. MPT inherently has the potential to be universal and transferable. On the one hand, when trained to predict the next state of Markov chains, it acquires the capabilities to estimate transition probabilities from the context (one adaptive manner for summarizing sequences) and attend to the last state to ensure accurate state transitions. On the other hand, unlike the heterogeneous interaction data, an unlimited amount of controllable Markov chains is available to boost the model capacity. We conduct extensive experiments on five public datasets from three distinct platforms to validate the superiority of Markovian pre-training over traditional recommendation pre-training and recent language pre-training paradigms.

</details>


### [60] [AgriLens: Semantic Retrieval in Agricultural Texts Using Topic Modeling and Language Models](https://arxiv.org/abs/2601.08283)
*Heba Shakeel,Tanvir Ahmad,Tanya Liyaqat,Chandni Saxena*

Main category: cs.IR

TL;DR: A unified, scalable framework for interpretable topic modeling, zero-shot labeling, and topic-guided retrieval on large agricultural text corpora, using BERTopic for topics, structured prompts for zero-shot labels/summaries, and dense embeddings for retrieval with an evaluation module for coherence/bias.


<details>
  <summary>Details</summary>
Motivation: Growing volumes of unstructured text across domains demand scalable, interpretable organization, summarization, and retrieval. In specialized domains with limited labeled data (e.g., agriculture), a unified approach is needed to make topics interpretable and retrievable.

Method: Apply BERTopic to extract semantically coherent topics from large agricultural corpora. Convert each topic into a structured prompt to enable a language model to generate topic labels and summaries in a zero-shot fashion. Support querying and exploration via dense embeddings and vector search. Incorporate an evaluation module to assess topical coherence and bias.

Result: Semantically coherent topics are extracted; topics are converted into structured prompts for zero-shot label and summary generation by a language model; retrieval and exploration are facilitated through dense embeddings and vector search; an evaluation module assesses topical coherence and bias, enabling scalable and interpretable information access in domains with limited labeled data.

Conclusion: The framework offers a scalable, interpretable information access solution for specialized domains with limited labeled data by coupling topic modeling (BERTopic) with prompt-based zero-shot labeling and vector-based retrieval, along with coherence and bias evaluation.

Abstract: As the volume of unstructured text continues to grow across domains, there is an urgent need for scalable methods that enable interpretable organization, summarization, and retrieval of information. This work presents a unified framework for interpretable topic modeling, zero-shot topic labeling, and topic-guided semantic retrieval over large agricultural text corpora. Leveraging BERTopic, we extract semantically coherent topics. Each topic is converted into a structured prompt, enabling a language model to generate meaningful topic labels and summaries in a zero-shot manner. Querying and document exploration are supported via dense embeddings and vector search, while a dedicated evaluation module assesses topical coherence and bias. This framework supports scalable and interpretable information access in specialized domains where labeled data is limited.

</details>


### [61] [MLPlatt: Simple Calibration Framework for Ranking Models](https://arxiv.org/abs/2601.08345)
*Piotr Bajger,Roman Dusek,Krzysztof Galias,Paweł Młyniec,Aleksander Wawer,Paweł Zawistowski*

Main category: cs.IR

TL;DR: MLPlatt 提出一种简单的排名模型后验标定方法，在保持排序的前提下将输出映射为可解释的 CTR 概率，并具备全局及分层（按类别字段）标定能力，提升 F-ECE 超过 10%，且不降低排序质量。


<details>
  <summary>Details</summary>
Motivation: 现有排序模型在可解释性和概率校准方面存在不足，常用的排序损失未必能提供良好的概率输出，且缺乏对不同业务分组的上下文感知标定。需要一种在不改变排序结果的前提下提供可解释 CTR 概率输出的后验标定方法，并能对不同分组进行有效标定。

Method: MLPlatt 作为一种简单的排名模型标定方法，在不破坏原有排序顺序的前提下，将排名器输出映射为 CTR 概率，具备上下文感知能力，能够在全局和按指定分层字段的分组内进行标定，提升全局与分层标定指标（如 F-ECE / Field-ECE）。

Result: 在两组数据集上，MLPlatt 相对于现有方法在 F-ECE 指标提升超过 10%，并且未对排序质量造成下降，表明在不牺牲排序性能的前提下实现高质量标定。

Conclusion: MLPlatt 提供一种实用且有效的后验标定方案，兼具全局与分层标定能力，具备良好的业务落地性，尤其适用于需要对不同用户、设备等分组进行概率输出和校准的商业场景。

Abstract: Ranking models are extensively used in e-commerce for relevance estimation. These models often suffer from poor interpretability and no scale calibration, particularly when trained with typical ranking loss functions. This paper addresses the problem of post-hoc calibration of ranking models. We introduce MLPlatt: a simple yet effective ranking model calibration method that preserves the item ordering and converts ranker outputs to interpretable click-through rate (CTR) probabilities usable in downstream tasks. The method is context-aware by design and achieves good calibration metrics globally, and within strata corresponding to different values of a selected categorical field (such as user country or device), which is often important from a business perspective of an E-commerce platform. We demonstrate the superiority of MLPlatt over existing approaches on two datasets, achieving an improvement of over 10\% in F-ECE (Field Expected Calibration Error) compared to other methods. Most importantly, we show that high-quality calibration can be achieved without compromising the ranking quality.

</details>


### [62] [Scalable Sequential Recommendation under Latency and Memory Constraints](https://arxiv.org/abs/2601.08360)
*Adithya Parthasarathy,Aswathnarayan Muthukrishnan Kirubakaran,Vinoth Punniyamoorthy,Nachiappan Chockalingam,Lokesh Butra,Kabilan Kannan,Abhirup Mazumder,Sumit Saha*

Main category: cs.IR

TL;DR: 提出 HoloMambaRec，一种轻量级序列推荐架构，结合全息映射与选择性状态空间编码，实现线性时间序列处理，在内存/延迟受限条件下优于 SASRec、与 GRU4Rec 相当，同时具备向前兼容性和元数据感知能力。


<details>
  <summary>Details</summary>
Motivation: 需要在严格的内存与延迟约束下建模长距离用户行为；Transformer 的二次复杂度限制了对长时间历史的利用。

Method: 将物品与属性信息通过圆周卷积绑定成全息表示；采用浅层的选择性状态空间骨干，受最近的 Mamba 风格模型启发，实现线性时间的序列处理；引入前向兼容的时间捆绑与推理时压缩机制。

Result: 在 Amazon Beauty 与 MovieLens-1M 数据集上，持续优于 SASRec，并在 10 轮训练预算下与 GRU4Rec 相当，同时显著降低内存复杂度。

Conclusion: HoloMambaRec 为可扩展的、元数据感知的序列推荐提供实用且可扩展的替代方案，具备常数时间的递归推断并支持前向兼容的捆绑与压缩。

Abstract: Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.

</details>


### [63] [PosIR: Position-Aware Heterogeneous Information Retrieval Benchmark](https://arxiv.org/abs/2601.08363)
*Ziyang Zeng,Dun Zhang,Yu Yan,Xu Sun,Yudong Zhou,Yuqing Yang*

Main category: cs.IR

TL;DR: 提出 PosIR 作为一个多语言多领域、位置感知的信息检索基准，用于诊断和量化检索中的位置信偏见，揭示现有模型对信息位置的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有评测常使用位置无关的相关性标签，难以将文档长度与信息所在位置的偏见分离，导致对长上下文中的位置信偏见缺乏系统性评估。

Method: 构建包含310个数据集、覆盖10种语言和31个领域的基准，通过将相关性绑定到精确的参考区间来严格解耦文档长度和信息位置信息。对10种最先进的嵌入式检索模型进行实验，并结合梯度显著性分析以揭示内部注意力机制。

Result: 在长上下文设置中，PosIR 的性能与 MMTEB 基准相关性较差，暴露当前短文本基准的局限性；位置信偏见普遍存在且随文档长度增加而加强，大多数模型表现出主位置偏好，少数模型出现意外的最近位置偏好；基于梯度的显著性分析揭示了驱动这些位置偏好 的内部注意力机制。

Conclusion: PosIR 作为诊断框架，促使开发对位置鲁棒的检索系统。

Abstract: While dense retrieval models have achieved remarkable success, rigorous evaluation of their sensitivity to the position of relevant information (i.e., position bias) remains largely unexplored. Existing benchmarks typically employ position-agnostic relevance labels, conflating the challenge of processing long contexts with the bias against specific evidence locations. To address this challenge, we introduce PosIR (Position-Aware Information Retrieval), a comprehensive benchmark designed to diagnose position bias in diverse retrieval scenarios. PosIR comprises 310 datasets spanning 10 languages and 31 domains, constructed through a rigorous pipeline that ties relevance to precise reference spans, enabling the strict disentanglement of document length from information position. Extensive experiments with 10 state-of-the-art embedding models reveal that: (1) Performance on PosIR in long-context settings correlates poorly with the MMTEB benchmark, exposing limitations in current short-text benchmarks; (2) Position bias is pervasive and intensifies with document length, with most models exhibiting primacy bias while certain models show unexpected recency bias; (3) Gradient-based saliency analysis further uncovers the distinct internal attention mechanisms driving these positional preferences. In summary, PosIR serves as a valuable diagnostic framework to foster the development of position-robust retrieval systems.

</details>


### [64] [GraphFusionSBR: Denoising Multi-Channel Graphs for Session-Based Recommendation](https://arxiv.org/abs/2601.08497)
*Jia-Xin He,Hung-Hsuan Chen*

Main category: cs.IR

TL;DR: 提出多通道会话推荐模型，整合知识图、会话超图、会话直线图通道，具备自适应知识图边缘去噪、跨通道协同、会话内注意力去噪，以及将超图与直线图通道最大化互信息作为辅助任务，显著提升推荐准确性并公开代码。


<details>
  <summary>Details</summary>
Motivation: 解决会话中的隐性用户意图捕捉不足、项之间的霸占效应和噪声会话的问题；通过多源信息融合与噪声抑制来提升对隐性意图的建模。

Method: 多通道架构：知识图通道、会话超图通道、会话直线图通道；在知识图通道中自适应去除冗余边以降低噪声；知识图与超图协同用于预测以缓解项的主导效应；在会话中生成注意力以实现去噪；将超图和直线图通道之间的互信息作为辅助任务进行最大化。

Result: 实验结果表明在电商与多媒体推荐等多种场景中提升准确性；并提供GitHub代码以提高可复现性。

Conclusion: 证实多通道融合、边噪声抑制和互信息对齐策略对提升会话推荐的有效性，具备良好的泛化性和可重复性。

Abstract: Session-based recommendation systems must capture implicit user intents from sessions. However, existing models suffer from issues such as item interaction dominance and noisy sessions. We propose a multi-channel recommendation model, including a knowledge graph channel, a session hypergraph channel, and a session line graph channel, to capture information from multiple sources. Our model adaptively removes redundant edges in the knowledge graph channel to reduce noise. Knowledge graph representations cooperate with hypergraph representations for prediction to alleviate item dominance. We also generate in-session attention for denoising. Finally, we maximize mutual information between the hypergraph and line graph channels as an auxiliary task. Experiments demonstrate that our method enhances the accuracy of various recommendations, including e-commerce and multimedia recommendations. We release the code on GitHub for reproducibility.\footnote{https://github.com/hohehohe0509/DSR-HK}

</details>


### [65] [VeriTaS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking](https://arxiv.org/abs/2601.08611)
*Mark Rothermel,Marcus Kornmann,Marcus Rohrbach,Anna Rohrbach*

Main category: cs.IR

TL;DR: VeriTaS 是首个动态的多模态自动化事实核查基准，涵盖 24,000 条来自 108 家机构、54 种语言的真实主张，支持文本与视听内容，按七阶段自动化管线季度更新，具备抗数据泄露能力并采用标准化、可解耦的评分与文本理由。


<details>
  <summary>Details</summary>
Motivation: 现有 AFC 基准普遍在任务范围、模态、领域与语言覆盖、现实性及误导信息类型等方面受限，且多为静态数据，易在大规模预训练中被数据泄露影响导致性能失真，因此需要一个随时间更新且对预训练数据具有鲁棒性的基准。

Method: 设计并实现一个七阶段自动化管线：主张表达规范化、原始媒体检索、将异构专家 verdict 映射到统一且可解耦的评分体系并提供文本理由；每季度新增数据，覆盖文本与视听内容，支持多语言处理与自动注释；通过人类评估验证自动注释与人类判断的一致性。

Result: 实验显示自动注释与人类判断高度一致；基准规模大、覆盖广、多模态且具备持续更新能力；证明其在对抗数据泄露的场景下仍能提供有意味的 AFC 评估。

Conclusion: VeriTaS 为 AFC 评估提供一个可持续且抵抗数据泄露的动态基准，未来将持续更新并公开代码与数据，以促进在快速发展的基础模型时代的多模态事实核查评估。

Abstract: The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems, however, are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Theses and Statements (VeriTaS), the first dynamic benchmark for multimodal AFC, designed to remain robust under ongoing large-scale pretraining of foundation models. VeriTaS currently comprises 24,000 real-world claims from 108 professional fact-checking organizations across 54 languages, covering textual and audiovisual content. Claims are added quarterly via a fully automated seven-stage pipeline that normalizes claim formulation, retrieves original media, and maps heterogeneous expert verdicts to a novel, standardized, and disentangled scoring scheme with textual justifications. Through human evaluation, we demonstrate that the automated annotations closely match human judgments. We commit to update VeriTaS in the future, establishing a leakage-resistant benchmark, supporting meaningful AFC evaluation in the era of rapidly evolving foundation models. We will make the code and data publicly available.

</details>


### [66] [RMBRec: Robust Multi-Behavior Recommendation towards Target Behaviors](https://arxiv.org/abs/2601.08705)
*Miaomiao Cai,Zhijie Zhang,Junfeng Fang,Zhiyong Cheng,Xiang Wang,Meng Wang*

Main category: cs.IR

TL;DR: 提出 RMBRec，基于信息论鲁棒性原理的多行为推荐框架，通过局部表示鲁棒性和全局优化鲁棒性实现对目标行为的稳健预测。


<details>
  <summary>Details</summary>
Motivation: 辅助行为常带来噪声、弱相关或与目标行为语义错配，导致偏置学习和性能下降；现有融合方法缺乏对行为不一致性的鲁棒性保障。

Method: RMBRec 包含 Representation Robustness Module（RRM）和 Optimization Robustness Module（ORM）。RRM 最大化辅助与目标用户表征之间的互信息，提升局部语义一致性；ORM 最小化不同行为之间预测风险的方差，近似不变风险最小化，提供全局稳定性。两者协同实现局部净化与全局不变性的理论性对接。

Result: 在三个真实数据集上，RMBRec 在准确性上优于现有最优方法，且对多种噪声扰动保持显著稳定性。为可重复性，提供公开代码：https://github.com/miaomiao-cai2/RMBRec/

Conclusion: 提出一个理论自洽且实用的鲁棒多行为推荐框架，能在噪声存在的多行为场景中实现稳健且高效的偏好学习；代码公开促进复现和后续研究。

Abstract: Multi-behavior recommendation faces a critical challenge in practice: auxiliary behaviors (e.g., clicks, carts) are often noisy, weakly correlated, or semantically misaligned with the target behavior (e.g., purchase), which leads to biased preference learning and suboptimal performance. While existing methods attempt to fuse these heterogeneous signals, they inherently lack a principled mechanism to ensure robustness against such behavioral inconsistency.
  In this work, we propose Robust Multi-Behavior Recommendation towards Target Behaviors (RMBRec), a robust multi-behavior recommendation framework grounded in an information-theoretic robustness principle. We interpret robustness as a joint process of maximizing predictive information while minimizing its variance across heterogeneous behavioral environments. Under this perspective, the Representation Robustness Module (RRM) enhances local semantic consistency by maximizing the mutual information between users' auxiliary and target representations, whereas the Optimization Robustness Module (ORM) enforces global stability by minimizing the variance of predictive risks across behaviors, which is an efficient approximation to invariant risk minimization. This local-global collaboration bridges representation purification and optimization invariance in a theoretically coherent way. Extensive experiments on three real-world datasets demonstrate that RMBRec not only outperforms state-of-the-art methods in accuracy but also maintains remarkable stability under various noise perturbations. For reproducibility, our code is available at https://github.com/miaomiao-cai2/RMBRec/.

</details>


### [67] [FusID: Modality-Fused Semantic IDs for Generative Music Recommendation](https://arxiv.org/abs/2601.08764)
*Haven Kim,Yupeng Hou,Julian McAuley*

Main category: cs.IR

TL;DR: FusID 通过模态融合、表征学习和产物量化，解决跨模态冗余与交互缺失问题，零ID冲突并提升MRR/Recall。


<details>
  <summary>Details</summary>
Motivation: 现有将每种模态独立tokenize的问题导致信息冗余和模态间互动建模不足，限制生成式推荐系统的表示能力。

Method: 三大组件：1) 多模态融合，联合编码以学习统一表示；2) 表征学习，拉近高频共现嵌入，保持区分性并抑制冗余；3) 产物量化，将融合后的连续嵌入离散化为若干 token，降低ID冲突并提升编码利用率。

Result: 在多模态下的下一首歌/播放列表续写基准上，FusID 实现零ID冲突，确保每个 token 序列映射到唯一歌曲，缓解码本低利用，并在 MRR 与 Recall@k（k=1,5,10,20）上优于基线。

Conclusion: 通过模态融合、稳健的表征学习和有效的产物量化，FusID 提升多模态表示的鲁棒性与检索性能，解决跨模态冗余与互动建模不足的问题。

Abstract: Generative recommendation systems have achieved significant advances by leveraging semantic IDs to represent items. However, existing approaches that tokenize each modality independently face two critical limitations: (1) redundancy across modalities that reduces efficiency, and (2) failure to capture inter-modal interactions that limits item representation. We introduce FusID, a modality-fused semantic ID framework that addresses these limitations through three key components: (i) multimodal fusion that learns unified representations by jointly encoding information across modalities, (ii) representation learning that brings frequently co-occurring item embeddings closer while maintaining distinctiveness and preventing feature redundancy, and (iii) product quantization that converts the fused continuous embeddings into multiple discrete tokens to mitigate ID conflict. Evaluated on a multimodal next-song recommendation (i.e., playlist continuation) benchmark, FusID achieves zero ID conflicts, ensuring that each token sequence maps to exactly one song, mitigates codebook underutilization, and outperforms baselines in terms of MRR and Recall@k (k = 1, 5, 10, 20).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [68] [Bridging the Trust Gap: Clinician-Validated Hybrid Explainable AI for Maternal Health Risk Assessment in Bangladesh](https://arxiv.org/abs/2601.07866)
*Farjana Yesmin,Nusrat Shirmin,Suraiya Shabnam Bristy*

Main category: cs.AI

TL;DR: 提出混合可解释AI框架（ante-hoc模糊逻辑+后验SHAP）用于产妇健康风险预测，达到高性能并获得临床信任与偏好。


<details>
  <summary>Details</summary>
Motivation: 资源受限环境中缺乏可解释且可信的AI决策支持，需将可解释性与临床知识融合以促进临床采纳。

Method: 构建Fuzzy-XGBoost模型，基于1,014份产妇健康记录；前置模糊规则提高解释性，后置SHAP解释特征贡献；跨学科临床评测：14名孟加拉卫生专业人员；评估混合解释的偏好与信任；分析SHAP特征并对比模糊风险分数的地位；识别临床知识中的空白点。

Result: 模型性能高：准确率88.67%（ROC-AUC 0.9703）；临床评估显示对混合解释的偏好71.4%，有54.8%表达信任用于临床；SHAP显示就医可及性为首要预测因子，模糊风险分数排名第三；相关性r=0.298，显示与临床知识整合的部分一致性；同时识别 obstetric history、gestational age 与连接性障碍等关键知识缺口。

Conclusion: 将可解释的模糊规则与SHAP解释结合可提升实用性与信任，支持在资源受限产科场景部署XAI；需关注覆盖关键临床参数并解决连接性挑战以实现更广泛的临床应用。

Abstract: While machine learning shows promise for maternal health risk prediction, clinical adoption in resource-constrained settings faces a critical barrier: lack of explainability and trust. This study presents a hybrid explainable AI (XAI) framework combining ante-hoc fuzzy logic with post-hoc SHAP explanations, validated through systematic clinician feedback. We developed a fuzzy-XGBoost model on 1,014 maternal health records, achieving 88.67% accuracy (ROC-AUC: 0.9703). A validation study with 14 healthcare professionals in Bangladesh revealed strong preference for hybrid explanations (71.4% across three clinical cases) with 54.8% expressing trust for clinical use. SHAP analysis identified healthcare access as the primary predictor, with the engineered fuzzy risk score ranking third, validating clinical knowledge integration (r=0.298). Clinicians valued integrated clinical parameters but identified critical gaps: obstetric history, gestational age, and connectivity barriers. This work demonstrates that combining interpretable fuzzy rules with feature importance explanations enhances both utility and trust, providing practical insights for XAI deployment in maternal healthcare.

</details>


### [69] [When Models Know When They Do Not Know: Calibration, Cascading, and Cleaning](https://arxiv.org/abs/2601.07965)
*Chenjie Hao,Weyl Lu,Yuko Ishiwaka,Zengyi Li,Weier Wan,Yubei Chen*

Main category: cs.AI

TL;DR: 一个训练无成本的校准+级联+数据清洗框架，利用模型 calibrated confidence 来识别未知，从而在视觉和文本任务中实现高效、可靠的AI。


<details>
  <summary>Details</summary>
Motivation: 解决模型在“知道自己不知道”时的自信估计问题，通过内部信号的校准置信度实现对未知状态的识别，并提升系统效率与可信度。

Method: 提出训练无成本的方法，结合模型校准、级联路由和数据清洗。通过校准信心在不同规模模型之间进行级联，提升效率；并用多专家的校准信心实现对数据的清洗，以改进 ImageNet 和 MMLU 的标签质量。

Result: 级联实现近乎无精度损失的效率提升，且在相当规模的模型间级联可超越任一单模型的表现；数据清洗基于多模型信心的一致性，显著改进 ImageNet 和 MMLU 的数据质量。

Conclusion: 使模型能够识别自身不知道的情况，是实现更高效、可靠和可信 AI 的实际步骤。

Abstract: When a model knows when it does not know, many possibilities emerge. The first question is how to enable a model to recognize that it does not know. A promising approach is to use confidence, computed from the model's internal signals, to reflect its ignorance. Prior work in specific domains has shown that calibration can provide reliable confidence estimates. In this work, we propose a simple, effective, and universal training-free method that applies to both vision and language models, performing model calibration, cascading, and data cleaning to better exploit a model's ability to recognize when it does not know. We first highlight two key empirical observations: higher confidence corresponds to higher accuracy within a single model, and models calibrated on the validation set remain calibrated on a held-out test set. These findings empirically establish the reliability and comparability of calibrated confidence. Building on this, we introduce two applications: (1) model cascading with calibrated advantage routing and (2) data cleaning based on model ensemble. Using the routing signal derived from the comparability of calibrated confidences, we cascade large and small models to improve efficiency with almost no compromise in accuracy, and we further cascade two models of comparable scale to achieve performance beyond either model alone. Leveraging multiple experts and their calibrated confidences, we design a simple yet effective data-cleaning method that balances precision and detection rate to identify mislabeled samples in ImageNet and Massive Multitask Language Understanding (MMLU) datasets. Our results demonstrate that enabling models to recognize when they do not know is a practical step toward more efficient, reliable, and trustworthy AI.

</details>


### [70] [Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety](https://arxiv.org/abs/2601.08000)
*Can Jin,Rui Wu,Tong Che,Qixin Zhang,Hongwu Peng,Jiahui Zhao,Zhenting Wang,Wenqi Wei,Ligong Han,Zhao Zhang,Yuan Cao,Ruixiang Tang,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: 将显式安全代码与通过案例演示的两种方法进行比较，发现依赖代码的做法在 harmlessness 上有不一致提升且削弱 helpfulness，而带有案例的简单代码更具鲁棒性；提出 CADA，通过对自生成的安全推理链进行强化学习的案例增强推理，提升安全性并保持有用性。


<details>
  <summary>Details</summary>
Motivation: 缓解开源大模型在不牺牲有用性的前提下提升安全性的挑战；现有的透彻安全规则（deliberative alignment）往往依赖复杂推理能力，但开源模型不足以有效执行这种推理，因此需要更灵活的策略。

Method: 系统性比较两种策略：显式编码的冗长安全规则 vs 通过案例演示的简单代码；在此基础上提出 CADA：基于自生成的安全推理链进行强化学习，结合案例增益来引导推理。

Result: 显式规则引用在 harmlessness 上有不一致的提升且普遍降低了 helpfulness；基于案例的简单代码训练带来更鲁棒的安全行为；CADA 在 harmlessness、对抗性鲁棒性、降低过度拒绝方面表现良好，同时保持广泛基准上的实用性。

Conclusion: 面向开源模型的安全对齐应优先使用案例增强的推理策略，而非单纯的规则枚举；通过自我生成推理链的强化学习（CADA）可在提高安全性的同时维持有用性，提供规则导向 DA 的可操作替代方案。

Abstract: Ensuring that Large Language Models (LLMs) adhere to safety principles without refusing benign requests remains a significant challenge. While OpenAI introduces deliberative alignment (DA) to enhance the safety of its o-series models through reasoning over detailed ``code-like'' safety rules, the effectiveness of this approach in open-source LLMs, which typically lack advanced reasoning capabilities, is understudied. In this work, we systematically evaluate the impact of explicitly specifying extensive safety codes versus demonstrating them through illustrative cases. We find that referencing explicit codes inconsistently improves harmlessness and systematically degrades helpfulness, whereas training on case-augmented simple codes yields more robust and generalized safety behaviors. By guiding LLMs with case-augmented reasoning instead of extensive code-like safety rules, we avoid rigid adherence to narrowly enumerated rules and enable broader adaptability. Building on these insights, we propose CADA, a case-augmented deliberative alignment method for LLMs utilizing reinforcement learning on self-generated safety reasoning chains. CADA effectively enhances harmlessness, improves robustness against attacks, and reduces over-refusal while preserving utility across diverse benchmarks, offering a practical alternative to rule-only DA for improving safety while maintaining helpfulness.

</details>


### [71] [Internal Deployment Gaps in AI Regulation](https://arxiv.org/abs/2601.08005)
*Joe Kwon,Stephen Casper*

Main category: cs.AI

TL;DR: 聚焦美欧在2025年对内部部署的前沿AI监管，识别并分析三大监管缺口及其成因，提出对策与取舍。


<details>
  <summary>Details</summary>
Motivation: 在外部部署监管日益强化的背景下，内部部署的高能力系统仍可能规避监管，威胁安全和竞争公平，因此需要系统性分析与应对。

Method: 对法规框架进行比较分析，识别范围、评估时点、信息不对称等缺口，分析成因（可衡量性、激励与信息获取），并映射潜在对策及权衡。

Result: 确认三大缺口：范围模糊导致内部系统逃避义务、点对点的合规评估无法覆盖持续演化的系统、信息不对称削弱监管知觉与执行；提出相应的对策及权衡，供未来政策设计参考。

Conclusion: 通过揭示内部部署监管的模式与博弈，促使政策制定者在设计相关规定时作出更有意识、前瞻性的选择，而非被动响应事件。

Abstract: Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations, such as for automating R\&D, accelerating critical business processes, and handling sensitive proprietary data. This paper examines how frontier AI regulations in the United States and European Union in 2025 handle internal deployment. We identify three gaps that could cause internally-deployed systems to evade intended oversight: (1) scope ambiguity that allows internal systems to evade regulatory obligations, (2) point-in-time compliance assessments that fail to capture the continuous evolution of internal systems, and (3) information asymmetries that subvert regulatory awareness and oversight. We then analyze why these gaps persist, examining tensions around measurability, incentives, and information access. Finally, we map potential approaches to address them and their associated tradeoffs. By understanding these patterns, we hope that policy choices around internally deployed AI systems can be made deliberately rather than incidentally.

</details>


### [72] [Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms](https://arxiv.org/abs/2601.08049)
*Keith Ainebyona,Ann Move Oguti,Joseph Walusimbi,Ritah Kobusingye*

Main category: cs.AI

TL;DR: 提出SCASED系统，将自动点名与面部情绪识别结合，用于高等教育课堂情感与参与监测，情绪分类准确率约89.5%。


<details>
  <summary>Details</summary>
Motivation: 现有智能教室多聚焦于出勤自动化，忽视学生的情感与认知参与度，难以实时识别离席与参与度下降，从而限制教学策略的个性化调整。需要将情感分析整合到课堂管理中，以提升教学敏捷性与教学干预效果。

Method: 基于物联网架构，采用Raspberry Pi 摄像头 + OpenCV 实现人脸检测；对MobileNetV2进行微调以分类四种学习相关情绪（参与、无聊、困惑、挫折）；采用会话式机制，在每场课中记录一次点名，随后进行持续的情绪分析；将出勤与情绪数据通过云端仪表板可视化，供教师决策使用。

Result: 在DAiSEE数据集上实现情绪分类准确率89.5%；结果表明将出勤数据与情绪分析整合能够为教师提供额外的课堂动态洞察，支持更具响应性的教学实践。

Conclusion: 将出勤数据与情绪分析结合有助于提升教师对课堂动态的洞察与干预能力，促进更动态、以学习者情感为导向的教学策略。

Abstract: The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students' emotional and cognitive engagement during lectures. This limits instructors' ability to identify disengagement and adapt teaching strategies in real time. This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring. The system uses a Raspberry Pi camera and OpenCV for face detection, and a finetuned MobileNetV2 model to classify four learning-related emotional states: engagement, boredom, confusion, and frustration. A session-based mechanism is implemented to manage attendance and emotion monitoring by recording attendance once per session and performing continuous emotion analysis thereafter. Attendance and emotion data are visualized through a cloud-based dashboard to provide instructors with insights into classroom dynamics. Experimental evaluation using the DAiSEE dataset achieved an emotion classification accuracy of 89.5%. The results show that integrating attendance data with emotion analytics can provide instructors with additional insight into classroom dynamics and support more responsive teaching practices.

</details>


### [73] [Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms](https://arxiv.org/abs/2601.08052)
*Nawazish Alia,Rachael Shawb,Karl Mason*

Main category: cs.AI

TL;DR: 提出一个以预测感知 PPO 为核心的深度强化学习框架用于 dairy farms 的负载调度，结合电池储能和水加热，利用短期预测和自适应 KL 控制，提升能效并降低电力成本。


<details>
  <summary>Details</summary>
Motivation: 能源成本高、可再生能源渗透增加导致供需平衡挑战，现实环境中难以获取未来价格与发电的完全信息。现有强化学习对 PPO 的固定裁剪/KL 限制易致训练不稳定，需在现实约束下实现高效调度。

Method: 提出 Forecast Aware PPO，结合基于时段（日时、月）的残差校准的短期需求与可再生发电预测；以及 PID KL PPO，使用比例-积分-微分控制器自适应调节 KL 边界以实现稳定的策略更新。以真实奶场数据进行训练，重点关注电池储能和热水加热的运行约束。

Result: 与 PPO、DQN、SAC 相比，成本降低分别达 1%、4.8%、1.5%。在电池调度方面，PPO 将对电网的进口降低 13.1%。显示出在现实数据上的可扩展性与有效性。

Conclusion: 该方法将预测感知与自适应 KL 控制结合的深度强化学习应用于 dairy farm 能源管理，能在现实约束下显著提升经济性与可持续性，具有推广到大规模应用的潜力。

Abstract: Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean energy. However, the intermittent nature of renewables poses challenges in balancing supply and demand in real time. Intelligent load scheduling is therefore crucial to minimize operational costs while maintaining reliability. Reinforcement Learning has shown promise in improving energy efficiency and reducing costs. However, most RL-based scheduling methods assume complete knowledge of future prices or generation, which is unrealistic in dynamic environments. Moreover, standard PPO variants rely on fixed clipping or KL divergence thresholds, often leading to unstable training under variable tariffs. To address these challenges, this study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating under realistic operational constraints. The proposed Forecast Aware PPO incorporates short term forecasts of demand and renewable generation using hour of day and month based residual calibration, while the PID KL PPO variant employs a proportional integral derivative controller to regulate KL divergence for stable policy updates adaptively. Trained on real world dairy farm data, the method achieves up to 1% lower electricity cost than PPO, 4.8% than DQN, and 1.5% than SAC. For battery scheduling, PPO reduces grid imports by 13.1%, demonstrating scalability and effectiveness for sustainable energy management in modern dairy farming.

</details>


### [74] [Semantic Gravity Wells: Why Negative Constraints Backfire](https://arxiv.org/abs/2601.08070)
*Shailesh Rana*

Main category: cs.AI

TL;DR: 对负指令失败的机制性分析：发现与语义压力呈显著的对数关系，失败中抑制信号被削弱，揭示两类独立的失败模式（诱发性 priming 与 覆盖性 override），并通过层间激活补丁验证23–27层的因果作用，指出命名禁词本身会“使禁词更易生成”的设计矛盾。


<details>
  <summary>Details</summary>
Motivation: 理解为何简单直观的负指令在大语言模型中频繁失效，从而揭示与指令遵循相关的内在机制与设计局限，为对齐与鲁棒性研究提供因果证据。

Method: 激活补丁与逐层logit分析揭示层级因果关系，层23–27在抑制效果与违规效应的转向中起核心作用；统计检验显示失败的抑制效果远弱于成功，且两类失败模式具有不同的机制通路。

Result: 违例发生概率与语义压力呈紧密的对数关系，成功样本中的抑制效应显著（约22.8个百分点），而失败样本仅约5.2个百分点，存在约4.4倍的抑制信号弱化。两类失败模式共存：priming主导（87.5%）导致禁词被激活；override主导（12.5%）在后期层产出向目标概率的正向贡献，达到+0.39，远超成功时的抑制水平。23–27层被证实为因果驱动的关键区域。

Conclusion: 负指令的设计存在本质张力：直接命名禁词的行为会在某些条件下“触发”禁词生成，暴露出对齐与鲁棒性中的潜在矛盾与挑战。

Abstract: Negative constraints (instructions of the form "do not use word X") represent a fundamental test of instruction-following capability in large language models. Despite their apparent simplicity, these constraints fail with striking regularity, and the conditions governing failure have remained poorly understood. This paper presents the first comprehensive mechanistic investigation of negative instruction failure. We introduce semantic pressure, a quantitative measure of the model's intrinsic probability of generating the forbidden token, and demonstrate that violation probability follows a tight logistic relationship with pressure ($p=σ(-2.40+2.27\cdot P_0)$; $n=40{,}000$ samples; bootstrap $95%$ CI for slope: $[2.21,,2.33]$). Through layer-wise analysis using the logit lens technique, we establish that the suppression signal induced by negative instructions is present but systematically weaker in failures: the instruction reduces target probability by only 5.2 percentage points in failures versus 22.8 points in successes -- a $4.4\times$ asymmetry. We trace this asymmetry to two mechanistically distinct failure modes. In priming failure (87.5% of violations), the instruction's explicit mention of the forbidden word paradoxically activates rather than suppresses the target representation. In override failure (12.5%), late-layer feed-forward networks generate contributions of $+0.39$ toward the target probability -- nearly $4\times$ larger than in successes -- overwhelming earlier suppression signals. Activation patching confirms that layers 23--27 are causally responsible: replacing these layers' activations flips the sign of constraint effects. These findings reveal a fundamental tension in negative constraint design: the very act of naming a forbidden word primes the model to produce it.

</details>


### [75] [How vehicles change lanes after encountering crashes: Empirical analysis and modeling](https://arxiv.org/abs/2601.08125)
*Kequan Chen,Yuxuan Wang,Pan Liu,Victor L. Knoop,David Z. W. Wang,Yu Han*

Main category: cs.AI

TL;DR: A dataset and prediction framework for post-crash lane changes (LCs). Post-crash LCs show longer durations, slower insertion, higher crash risk, and frequent non-yielding followers. A graph-based attention module treats yielding as an auxiliary task to guide CVAE and Transformer decoders, achieving >10% gains in ADE/FDE and better crash risk/conflict metrics; transferability validated across sites.


<details>
  <summary>Details</summary>
Motivation: Post-crash LCs pose higher risk due to potential non-yielding followers, yet their behavior and motion patterns are poorly understood. There is a need to characterize post-crash LCs, quantify their risk, and develop predictive models that account for interactive yielding dynamics for safety analysis and traffic management.

Method: Construct a post-crash LC trajectory dataset from drone videos. Develop a graph-based attention module that models yielding as an auxiliary interaction-aware task to guide a conditional variational autoencoder (CVAE) and a Transformer-based decoder for trajectory prediction. Evaluate on ADE/FDE and crash/conflict metrics; validate transferability with cross-site datasets.

Result: Post-crash LCs exhibit longer durations, lower insertion speeds, and higher crash risk than MLCs and DLCs. 79.4% involve non-yielding followers, vs. 21.7% (DLC) and 28.6% (MLC). The proposed model yields >10% improvements in ADE and FDE across horizons, reduces false crash rates, improves conflict prediction, and transfers well to new sites.

Conclusion: Modeling yielding as an auxiliary interaction-aware task within a graph-attention framework improves trajectory prediction and crash risk analysis for post-crash LCs and generalizes across sites.

Abstract: When a traffic crash occurs, following vehicles need to change lanes to bypass the obstruction. We define these maneuvers as post crash lane changes. In such scenarios, vehicles in the target lane may refuse to yield even after the lane change has already begun, increasing the complexity and crash risk of post crash LCs. However, the behavioral characteristics and motion patterns of post crash LCs remain unknown. To address this gap, we construct a post crash LC dataset by extracting vehicle trajectories from drone videos captured after crashes. Our empirical analysis reveals that, compared to mandatory LCs (MLCs) and discretionary LCs (DLCs), post crash LCs exhibit longer durations, lower insertion speeds, and higher crash risks. Notably, 79.4% of post crash LCs involve at least one instance of non yielding behavior from the new follower, compared to 21.7% for DLCs and 28.6% for MLCs. Building on these findings, we develop a novel trajectory prediction framework for post crash LCs. At its core is a graph based attention module that explicitly models yielding behavior as an auxiliary interaction aware task. This module is designed to guide both a conditional variational autoencoder and a Transformer based decoder to predict the lane changer's trajectory. By incorporating the interaction aware module, our model outperforms existing baselines in trajectory prediction performance by more than 10% in both average displacement error and final displacement error across different prediction horizons. Moreover, our model provides more reliable crash risk analysis by reducing false crash rates and improving conflict prediction accuracy. Finally, we validate the model's transferability using additional post crash LC datasets collected from different sites.

</details>


### [76] [Embedded AI Companion System on Edge Devices](https://arxiv.org/abs/2601.08128)
*Rahul Gupta,Stephen D. H. Hsu*

Main category: cs.AI

TL;DR: 在边缘设备上提出一种活跃/非活跃阶段的记忆范式以实现低延迟对话和长期个性化，并设计一个综合评估记忆与对话的基准；实验显示即使使用极小量化模型也优于无记忆对照，且接近具16k上下文的GPT-3.5水平。


<details>
  <summary>Details</summary>
Motivation: 边缘设备资源有限，难以直接部署现有的AI伴侣和记忆系统以获得持续个性化与低延迟用户体验；需要在嵌入式硬件上实现高效的记忆维护与对话能力。

Method: 提出活跃/非活跃交替的记忆范式：活跃阶段进行低延迟的实时对话，基于轻量检索和现有记忆进行推理；非活跃阶段进行更密集的记忆提取、整合与跨会话维护。设计AI Companion基准以综合评测对话质量与记忆能力。用Qwen2.5-7B-Instruct量化int4模型在实验中评估。

Result: 在实验中，所提系统在使用极弱模型的情况下，优于等效无记忆的LLM，在大多数评价指标上表现更好；并且性能接近GPT-3.5（16k上下文）水平。

Conclusion: 该记忆范式在嵌入式硬件的严格资源约束下实现低延迟同时维持长期个性化，提升用户体验；并提出了一个综合评估基准以同时衡量对话质量与记忆能力。

Abstract: Computational resource constraints on edge devices make it difficult to develop a fully embedded AI companion system with a satisfactory user experience. AI companion and memory systems detailed in existing literature cannot be directly used in such an environment due to lack of compute resources and latency concerns. In this paper, we propose a memory paradigm that alternates between active and inactive phases: during phases of user activity, the system performs low-latency, real-time dialog using lightweight retrieval over existing memories and context; whereas during phases of user inactivity, it conducts more computationally intensive extraction, consolidation, and maintenance of memories across full conversation sessions. This design minimizes latency while maintaining long-term personalization under the tight constraints of embedded hardware. We also introduce an AI Companion benchmark designed to holistically evaluate the AI Companion across both its conversational quality and memory capabilities. In our experiments, we found that our system (using a very weak model: Qwen2.5-7B-Instruct quantized int4) outperforms the equivalent raw LLM without memory across most metrics, and performs comparably to GPT-3.5 with 16k context window.

</details>


### [77] [Improving LLM Reasoning with Homophily-aware Structural and Semantic Text-Attributed Graph Compression](https://arxiv.org/abs/2601.08187)
*Zijun Di,Bin Lu,Huquan Kang,Luoyi Fu,Jiaxin Ding,Xiaoying Gan,Lei Zhou,Xinbing Wang,Chenghu Zhou*

Main category: cs.AI

TL;DR: 通过结构-语义的同质性压缩，HS2C利用同质性社区来压缩文本-图上下文，提升LLM推理表现与压缩率，同时具备跨节点和图级任务的泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在受限的上下文窗口下通过随机采样来简化图信息，但会引入噪声、降低推理稳定性。图包含丰富的结构和语义信息，若能有效利用同质性可提升LLM推理。

Method: 1) 结构方面：基于结构熵最小化，进行全局分层划分，识别同质性高的社群，抛弃噪声连接；2) 语义方面：将检测到的结构同质性传递给LLM，使其对目标节点进行基于社区类型的分化语义聚合；3) 将冗余背景上下文压缩为社区层面的共识，保留与目标节点对齐的同质语义信息；4) 在10个节点级基准和多家LLM规模上评估，证明结构-语义压缩提高压缩率和下游推理准确性；并扩展到7个图级基准，验证泛化。

Result: 在不同规模/族的LLMs上，输入的结构化和语义压缩提升了压缩率与下游推理准确性，且方法可扩展性强，跨任务有效。

Conclusion: 利用图的结构与语义同质性进行压缩可显著提升TAG理解的LLM推理性能，具有良好的泛化性和可扩展性。

Abstract: Large language models (LLMs) have demonstrated promising capabilities in Text-Attributed Graph (TAG) understanding. Recent studies typically focus on verbalizing the graph structures via handcrafted prompts, feeding the target node and its neighborhood context into LLMs. However, constrained by the context window, existing methods mainly resort to random sampling, often implemented via dropping node/edge randomly, which inevitably introduces noise and cause reasoning instability. We argue that graphs inherently contain rich structural and semantic information, and that their effective exploitation can unlock potential gains in LLMs reasoning performance. To this end, we propose Homophily-aware Structural and Semantic Compression for LLMs (HS2C), a framework centered on exploiting graph homophily. Structurally, guided by the principle of Structural Entropy minimization, we perform a global hierarchical partition that decodes the graph's essential topology. This partition identifies naturally cohesive, homophilic communities, while discarding stochastic connectivity noise. Semantically, we deliver the detected structural homophily to the LLM, empowering it to perform differentiated semantic aggregation based on predefined community type. This process compresses redundant background contexts into concise community-level consensus, selectively preserving semantically homophilic information aligned with the target nodes. Extensive experiments on 10 node-level benchmarks across LLMs of varying sizes and families demonstrate that, by feeding LLMs with structurally and semantically compressed inputs, HS2C simultaneously enhances the compression rate and downstream inference accuracy, validating its superiority and scalability. Extensions to 7 diverse graph-level benchmarks further consolidate HS2C's task generalizability.

</details>


### [78] [Adapting Rules of Official International Mahjong for Online Players](https://arxiv.org/abs/2601.08211)
*Chucai Wang,Lingfeng Li,Yunlong Lu,Wenxin Li*

Main category: cs.AI

TL;DR: 基于AI自我对弈分析揭示线上国际麻将的平衡问题，提出补偿分和子目标分数调整等改良规则，并实现线上修订版本以适应在线环境。


<details>
  <summary>Details</summary>
Motivation: 解决在线麻将单局对战中玩家分散对局、对手不固定导致的公平性挑战；评估线下规则在在线场景的适用性，并利用AI数据驱动规则改进。

Method: 使用世界冠军级AI进行自我对弈并进行统计分析，识别先手优势与子目标计分设置问题，提出并实现线上规则改良及修订版本的上线实现。

Result: 发现存在先手优势与子目标计分问题，提出补偿分机制和对不同牌型的子目标分数微调等改动；相较于传统多局轮换平衡方式，逐局补偿更便于在线使用；实现了修订后的在线麻将版本。

Conclusion: 这是初步尝试，展示了利用AI数据评估游戏平衡并开发更适合在线玩家的改进版本的可行性，未来需进一步验证与优化。

Abstract: As one of the worldwide spread traditional game, Official International Mahjong can be played and promoted online through remote devices instead of requiring face-to-face interaction. However, online players have fragmented playtime and unfixed combination of opponents in contrary to offline players who have fixed opponents for multiple rounds of play. Therefore, the rules designed for offline players need to be modified to ensure the fairness of online single-round play. Specifically, We employ a world champion AI to engage in self-play competitions and conduct statistical data analysis. Our study reveals the first-mover advantage and issues in the subgoal scoring settings. Based on our findings, we propose rule adaptations to make the game more suitable for the online environment, such as introducing compensatory points for the first-mover advantage and refining the scores of subgoals for different tile patterns. Compared with the traditional method of rotating positions over multiple rounds to balance first-mover advantage, our compensatory points mechanism in each round is more convenient for online players. Furthermore, we implement the revised Mahjong game online, which is open for online players. This work is an initial attempt to use data from AI systems to evaluate Official Internatinoal Mahjong's game balance and develop a revised version of the traditional game better adapted for online players.

</details>


### [79] [An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3](https://arxiv.org/abs/2601.08224)
*Daesuk Kwon,Won-gi Paeng*

Main category: cs.AI

TL;DR: 提出 SANC(E3) 框架：代表性单位不预先给定，而在有限激活容量下通过竞争、重建和压缩的能量最小化 E3 自发稳定形成，统一感知、想象、预测、规划和行动。


<details>
  <summary>Details</summary>
Motivation: 解决固定原始单位（tokens、像素等）预设的问题，解释在资源受限下表示单元如何自组织并稳定出现，统一多种认知功能。

Method: 提出五条公理和能量泛函 E3，区分系统记号与感知源，通过自监督的竞争-重建-压缩-更新过程形成言表性单位；引入伪记忆映射I/O机制，使内部回放的 Gestalts 也沿同一路径处理；由此导出12条命题。

Result: 从公理推导出类别形成、层级组织、无监督学习及高阶认知（如感知、想象、预测、规划、行动）皆可视为在 E3 最小化下的 Gestalt 完成实例。

Conclusion: 该框架为从能量最小化出发解释自发形成的表示及认知功能提供统一理论基础，具理论吸引力但需通过经验验证与实现来评估普适性与可操作性。

Abstract: General intelligence must reorganize experience into internal structures that enable prediction and action under finite resources. Existing systems implicitly presuppose fixed primitive units -- tokens, subwords, pixels, or predefined sensor channels -- thereby bypassing the question of how representational units themselves emerge and stabilize. This paper proposes SANC(E3), an axiomatic framework in which representational units are not given a priori but instead arise as stable outcomes of competitive selection, reconstruction, and compression under finite activation capacity, governed by the explicit minimization of an energy functional E3. SANC(E3) draws a principled distinction between system tokens -- structural anchors such as {here, now, I} and sensory sources -- and tokens that emerge through self-organization during co-occurring events. Five core axioms formalize finite capacity, association from co-occurrence, similarity-based competition, confidence-based stabilization, and the reconstruction-compression-update trade-off. A key feature is a pseudo-memory-mapped I/O mechanism, through which internally replayed Gestalts are processed via the same axiomatic pathway as external sensory input. As a result, perception, imagination, prediction, planning, and action are unified within a single representational and energetic process. From the axioms, twelve propositions are derived, showing that category formation, hierarchical organization, unsupervised learning, and high-level cognitive activities can all be understood as instances of Gestalt completion under E3 minimization.

</details>


### [80] [Large Artificial Intelligence Model Guided Deep Reinforcement Learning for Resource Allocation in Non Terrestrial Networks](https://arxiv.org/abs/2601.08254)
*Abdikarim Mohamed Ibrahim,Rosdiadee Nordin*

Main category: cs.AI

TL;DR: LLM-guided DRL for Non-Terrestrial Networks (NTN): a DRL agent is guided by a Large Language Model that provides textual reward shaping guidance, improving performance over heuristic baselines. Significant gains: about 40% in nominal weather and 64% in extreme weather in throughput, fairness, and outage probability.


<details>
  <summary>Details</summary>
Motivation: Enhance DRL performance and generalization for NTN tasks by leveraging LLM-based high-level guidance to shape rewards, reducing reliance on task-specific training data.

Method: A DRL agent is steered by an LLM acting as a high-level coordinator. The LLM provides textual guidance that shapes the DRL reward signal during training. The approach is evaluated under nominal and extreme weather conditions against heuristic baselines.

Result: LAM-DRL achieves substantial improvements over heuristic baselines: ~40% gain in nominal weather and ~64% in extreme weather for throughput, fairness, and outage probability.

Conclusion: Integrating LLM guidance into DRL can significantly boost NTN performance under varying weather conditions, suggesting a promising direction for combining LLMs with DRL for network control.

Abstract: Large AI Model (LAM) have been proposed to applications of Non-Terrestrial Networks (NTN), that offer better performance with its great generalization and reduced task specific trainings. In this paper, we propose a Deep Reinforcement Learning (DRL) agent that is guided by a Large Language Model (LLM). The LLM operates as a high level coordinator that generates textual guidance that shape the reward of the DRL agent during training. The results show that the LAM-DRL outperforms the traditional DRL by 40% in nominal weather scenarios and 64% in extreme weather scenarios compared to heuristics in terms of throughput, fairness, and outage probability.

</details>


### [81] [T3: Benchmarking Sycophancy and Skepticism in Causal Judgment](https://arxiv.org/abs/2601.08258)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 提出 T3 基准评估 LLM 的因果判断能力，覆盖 Pearl 层级的 454 条专业情境，通过 Utility/Safety/Wise Refusal 三维分析诊断模型路径ologies，如 Skepticism Trap 与 Scaling Paradox，并验证 RCA 过程验证协议在恢复决定性因果判断方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 需要高分辨率、可诊断的因果推理评估，克服现有基准在对因果判断的评估中的不足，尤其是在前沿模型的安全和推理行为方面。

Method: 构建 454 条专家策划的 vignette，对照 Pearl 的因果层级；提出 Utility（敏感度）、Safety（特异性）、Wise Refusal（在不确定性情境下的理智拒绝）三个指标；对前沿模型应用，分析两类病态：L1 的 Skepticism Trap、L3 的 Scaling Paradox；并验证 RCA（过程验证协议）对诊断结论的帮助。

Result: 发现两类病态：Skepticism Trap（L1）下，安全优化模型如 Claude Haiku 拒绝 60% 的有效链接；L3 处出现非单调缩放悖论，即更大模型 GPT-5.2 在模糊反事实上比 GPT-4-Turbo 低 55 分，原因是进入瘫痪状态（过度犹豫/回避），非幻觉所致；T3 还能通过 RCA 的结构化验证，捕捉到决断性因果判断的恢复。

Conclusion: T3 提供一种可细粒度诊断 LLM 因果判断能力的基准框架，能够揭示模型在安全性与决策性推理方面的病态，并证明了结构化验证协议在提升判断 decisiveness 的有效性。

Abstract: We introduce T3 (Testing Trustworthy Thinking), a diagnostic benchmark designed to rigorously evaluate LLM causal judgment across Pearl's Ladder of Causality. Comprising 454 expert-curated vignettes, T3 prioritizes high-resolution failure analysis, decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. By applying T3 to frontier models, we diagnose two distinct pathologies: a "Skepticism Trap" at L1 (where safety-tuned models like Claude Haiku reject 60% of valid links) and a non-monotonic Scaling Paradox at L3. In the latter, the larger GPT-5.2 underperforms GPT-4-Turbo by 55 points on ambiguous counterfactuals, driven by a collapse into paralysis (excessive hedging) rather than hallucination. Finally, we use the benchmark to validate a process-verified protocol (RCA), showing that T3 successfully captures the restoration of decisive causal judgment under structured verification.

</details>


### [82] [VGG Induced Deep Hand Sign Language Detection](https://arxiv.org/abs/2601.08262)
*Subham Sharma,Sharmila Subudhi*

Main category: cs.AI

TL;DR: 使用VGG-16迁移学习与数据增强进行手势识别，在NUS数据集上验证，结合Google API捕捉的手势测试集，达到约98%准确率（10类手势）。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互的可访问性，为视障及其他能力受限人群提供手势/手势语言识别解决方案。

Method: 基于预训练的VGG-16，通过迁移学习在通用图像数据集上进行微调，结合图像数据增强；采用Python与Keras实现。在NUS公开数据集进行验证，构建以Google开放API捕捉的10类手势的测试集，评估系统性能。

Result: 在迁移学习加数据增强的设置下，VGG-16达到约98%准确率，10类手势识别效果良好。

Conclusion: 迁移学习与数据增强对手势识别性能提升显著，但需进一步评估在真实世界场景的泛化能力、跨设备鲁棒性及数据多样性，且方法描述需提供更多实现细节与对比实验。

Abstract: Hand gesture recognition is an important aspect of human-computer interaction. It forms the basis of sign language for the visually impaired people. This work proposes a novel hand gesture recognizing system for the differently-abled persons. The model uses a convolutional neural network, known as VGG-16 net, for building a trained model on a widely used image dataset by employing Python and Keras libraries. Furthermore, the result is validated by the NUS dataset, consisting of 10 classes of hand gestures, fed to the model as the validation set. Afterwards, a testing dataset of 10 classes is built by employing Google's open source Application Programming Interface (API) that captures different gestures of human hand and the efficacy is then measured by carrying out experiments. The experimental results show that by combining a transfer learning mechanism together with the image data augmentation, the VGG-16 net produced around 98% accuracy.

</details>


### [83] [OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System](https://arxiv.org/abs/2601.08288)
*Yuyang Wu,Hanzhong Cao,Jianhao Chen,Yufei Li*

Main category: cs.AI

TL;DR: OpenMic 是一个基于 AutoGen 的端到端多智能体系统，将生活话题转化为 3-5 分钟中文 stand-up 演出并生成叙述式视频，结合检索增强生成与 JokeWriter，提升幽默、时机与表演性。


<details>
  <summary>Details</summary>
Motivation: 长篇中文 stand-up 需要文化幽默、精准时机、舞台表演线索以及隐性多步推理；现有中文幽默数据集多适用于理解/评估而非长篇生成，导致数据与任务错配。需一个端到端系统来解决这一错配并实现可执行的表演输出。

Method: OpenMic 架构基于 AutoGen 的多智能体系统，通过多轮迭代式环路规划共同优化幽默、时机与可表演性；使用检索增强生成（RAG）进行材料 grounding 与思路扩展；微调 JokeWriter 以更好内化单口结构（setup–punchline、长程回调等）；输出长度为 3-5 分钟的演出并生成叙述性视频。

Result: 摘要中未给出具体实验结果或定量评估；没有提供对比基线、数据集、或用户研究的结果。

Conclusion: 提出一个可执行的端到端生成-评估框架，强调多智能体协作、数据集对齐与长程推理的重要性，未来需要在真实数据集上进行评估并可能扩展到其他语言/场景。

Abstract: Chinese stand-up comedy generation goes beyond plain text generation, requiring culturally grounded humor, precise timing, stage-performance cues, and implicit multi-step reasoning. Moreover, commonly used Chinese humor datasets are often better suited for humor understanding and evaluation than for long-form stand-up generation, making direct supervision misaligned with the target task. To address these challenges, we present OpenMic, an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 3-5 minute Chinese stand-up performance and further produces a narrated comedy video. OpenMic orchestrates multiple specialized agents in a multi-round iterative loop-planning to jointly optimize humor, timing, and performability. To mitigate the dataset-task mismatch, we augment generation with retrieval-augmented generation (RAG) for material grounding and idea expansion, and we fine-tune a dedicated JokeWriter to better internalize stand-up-specific setup-punchline structures and long-range callbacks.

</details>


### [84] [AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation](https://arxiv.org/abs/2601.08323)
*Yupeng Huo,Yaxi Lu,Zhong Zhang,Haotian Chen,Yankai Lin*

Main category: cs.AI

TL;DR: AtomMem 将记忆管理重构为可学习的原子 CRUD 操作序列，通过监督微调与强化学习相结合，学习在长时记忆任务中的自适应记忆策略，在 3 个长上下文基准上优于静态工作流方法。


<details>
  <summary>Details</summary>
Motivation: 现有记忆机制多使用静态、手工设计的工作流，限制了性能与泛化，需要一个更灵活、可学习的记忆框架来应对长时任务的需求。

Method: 将内存流程拆分为 Create/Read/Update/Delete 原子操作，形成一个可学习的决策过程；通过监督微调与强化学习训练，获得与任务需求对齐的记忆策略；在多项基准上进行评估。

Result: AtomMem-8B 在 3 个长上下文基准上持续超越先前的静态工作流记忆方法；分析显示学习框架能发现结构化、任务对齐的记忆管理策略。

Conclusion: 将记忆管理视为可学习的动态决策过程的框架具有显著的性能和适应性优势，优于固定的记忆工作流。

Abstract: Equipping agents with memory is essential for solving real-world long-horizon problems. However, most existing agent memory mechanisms rely on static and hand-crafted workflows. This limits the performance and generalization ability of these memory designs, which highlights the need for a more flexible, learning-based memory framework. In this paper, we propose AtomMem, which reframes memory management as a dynamic decision-making problem. We deconstruct high-level memory processes into fundamental atomic CRUD (Create, Read, Update, Delete) operations, transforming the memory workflow into a learnable decision process. By combining supervised fine-tuning with reinforcement learning, AtomMem learns an autonomous, task-aligned policy to orchestrate memory behaviors tailored to specific task demands. Experimental results across 3 long-context benchmarks demonstrate that the trained AtomMem-8B consistently outperforms prior static-workflow memory methods. Further analysis of training dynamics shows that our learning-based formulation enables the agent to discover structured, task-aligned memory management strategies, highlighting a key advantage over predefined routines.

</details>


### [85] [Thematic Working Group 5 -- Artificial Intelligence (AI) literacy for teaching and learning: design and implementation](https://arxiv.org/abs/2601.08380)
*Mary Webb,Matt Bower,Ana Amélia Carvalho,Fredrik Mørk Røkenes,Jodie Torrington,Jonathan D. Cohen,Yousra Chtouki,Kathryn Maccallum,Tanya Linden,Deirdre Butler,Juliana Elisa Raffaghelli,Henriikka Vartiainen,Martina Ronci,Peter Tiernan,David M. Smith,Chris Shelton,Joyce Malyn-smith,Pierre Gorissen*

Main category: cs.AI

TL;DR: TWG 5 seeks to empower teachers with AI literacy and agency through curriculum design, professional development, classroom practice, and policy guidelines to integrate AI in education and enhance student AI understanding.


<details>
  <summary>Details</summary>
Motivation: Address the gap between rapid AI advancement and classroom readiness; build educator capacity to teach and apply AI responsibly and effectively.

Method: Exploratory work across curriculum design, professional development programs, practical classroom applications, and policy guidelines to enable integration of AI tools in teaching.

Result: Not specified in the abstract; the text outlines aims and areas of exploration rather than empirical findings.

Conclusion: If implemented, these strategies are expected to enable teachers to confidently use AI tools and foster deeper AI understanding among students.

Abstract: TWG 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. Explorations covered curriculum design, professional development programs, practical classroom applications, and policy guidelines aiming to empower educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students.

</details>


### [86] [A Qualitative Model to Reason about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT)](https://arxiv.org/abs/2601.08382)
*Zoe Falomir*

Main category: cs.AI

TL;DR: 提出定性的对象旋转推理模型QOR，并将其应用于Ekstrom等人(1976)的Cube Comparison Test(CCT)。建立了一个将旋转 movement、位置变化和方向变化联系起来的概念邻域图CNGRLO，并据此产生推理组合表用于旋转推理。


<details>
  <summary>Details</summary>
Motivation: 解决对对象旋转的定性推理问题，特别是通过Cube Comparison Test来理解旋转、位置和方向的关系，并提供一个系统化的推理框架。

Method: 构建定性模型QOR，并建立CNGRLO(旋转-位置/方向的概念邻域关系)图，利用该图生成推理的组合表以计算关于旋转的推理；将该框架应用于CCT。

Result: 生成了用于旋转推理的组合表，可对旋转相关推理进行推断计算，并将该方法应用于CCT的分析。

Conclusion: QOR与CNGRLO为旋转推理提供了一个结构化的定性方法，能够将旋转、位置和方向的关系形式化，具有对CCT等认知任务的潜在适用性，并具备对其他物体的推广潜力。

Abstract: This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change (CNGRLO) of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations.

</details>


### [87] [Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models](https://arxiv.org/abs/2601.08383)
*Bo Wang,Junzhuo Li,Hong Chen,Yuanlin Chu,Yuxuan Fan,Xuming Hu*

Main category: cs.AI

TL;DR: Gated-LPI-based neuron-level attribution reveals that MoE models develop a small high-utility core, early stable knowledge profiles, and robust distributed knowledge storage, enabling higher interpretability and bridging sparse architectures with pre-training dynamics.


<details>
  <summary>Details</summary>
Motivation: 理解MoE在预训练中的知识获取过程，以及其与密集模型的差异，以解释扩展性与可解释性之间的关系。

Method: 提出Gated-LPI(neuron-level attribution), 进行时序对比，跟踪1.2M步MoE与600K步密集模型的检查点；评估最重要的10个MoE注意头的掩蔽影响并比较HIT@10的变化。

Result: 发现三个模式：1) 低熵骨干，约1%的MoE神经元捕获>45%正向更新；2) 提早巩固，在<100K步形成稳定的重要性分布；3) 功能鲁棒性，掩蔽前十大MoE注意头对关系HIT@10的降低幅度<10%，而密集模型>50%。

Conclusion: 稀疏性在训练早期就塑造稳定且分布的计算骨架，缩小稀疏架构与训练时可解释性之间的差距。

Abstract: Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. Yet how MoE architectures shape knowledge acquisition during pre-training, and how this process differs from dense architectures, remains unknown. To address this issue, we introduce Gated-LPI (Log-Probability Increase), a neuron-level attribution metric that decomposes log-probability increase across neurons. We present a time-resolved comparison of knowledge acquisition dynamics in MoE and dense architectures, tracking checkpoints over 1.2M training steps (~ 5.0T tokens) and 600K training steps (~ 2.5T tokens), respectively. Our experiments uncover three patterns: (1) Low-entropy backbone. The top approximately 1% of MoE neurons capture over 45% of positive updates, forming a high-utility core, which is absent in the dense baseline. (2) Early consolidation. The MoE model locks into a stable importance profile within < 100K steps, whereas the dense model remains volatile throughout training. (3) Functional robustness. Masking the ten most important MoE attention heads reduces relational HIT@10 by < 10%, compared with > 50% for the dense model, showing that sparsity fosters distributed -- rather than brittle -- knowledge storage. These patterns collectively demonstrate that sparsity fosters an intrinsically stable and distributed computational backbone from early in training, helping bridge the gap between sparse architectures and training-time interpretability.

</details>


### [88] [Creativity in AI as Emergence from Domain-Limited Generative Models](https://arxiv.org/abs/2601.08388)
*Corina Chutaux*

Main category: cs.AI

TL;DR: 将 AI 创造力视为在受限信息环境中涌现的性质，提出四要素的概念分解并在多模态系统中分析其表现，构建研究创造力的技术框架，而非引入新评估标准。


<details>
  <summary>Details</summary>
Motivation: 现有创造力评估多将创造力视为可评估的属性，忽略其产生机制；大规模多模态生成系统的再组合能力表明需从结构与情境条件理解创造力的边界与潜力。

Method: 提出模式化生成、诱导世界模型、情境归 grounding、任意性四要素的概念分解，结合域限定的生成模型与受限信息环境，对多模态系统中的创造力进行理论分析。

Result: 给出一个可操作的技术框架，展示四要素如何在生成过程与域表示间相互作用，从而将创造力定义为生成动力学与环境约束的涌现现象。

Conclusion: 通过将创造力嵌入生成系统的结构和场景中，避免将创造力仅视为评估标签，提出了新的研究方向以探索 AI 系统中的创造性行为。

Abstract: Creativity in artificial intelligence is most often addressed through evaluative frameworks that aim to measure novelty, diversity, or usefulness in generated outputs. While such approaches have provided valuable insights into the behavior of modern generative models, they largely treat creativity as a property to be assessed rather than as a phenomenon to be explicitly modeled. In parallel, recent advances in large-scale generative systems, particularly multimodal architectures, have demonstrated increasingly sophisticated forms of pattern recombination, raising questions about the nature and limits of machine creativity. This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. Rather than introducing new evaluative criteria, we focus on the structural and contextual conditions under which creative behaviors arise. We introduce a conceptual decomposition of creativity into four interacting components-pattern-based generation, induced world models, contextual grounding, and arbitrarity, and examine how these components manifest in multimodal generative systems. By grounding creativity in the interaction between generative dynamics and domain-specific representations, this work aims to provide a technical framework for studying creativity as an emergent phenomenon in AI systems, rather than as a post hoc evaluative label.

</details>


### [89] [Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs](https://arxiv.org/abs/2601.08403)
*Abhijnan Nath,Alireza Bagheri Garakani,Tianchen Zhou,Fan Yang,Nikhil Krishnaswamy*

Main category: cs.AI

TL;DR: OSPO redistributes sequence-level rewards to token-level contributions using Shapley-Owen attributions, addressing credit assignment gaps in RL-based recommender systems without requiring value models; coalitions of semantically coherent units enable identifying which parts of responses drive performance, showing gains and robustness on Amazon ESCI and H&M Fashion datasets.


<details>
  <summary>Details</summary>
Motivation: Credit assignment gap in reinforcement learning for personalized recommendation, especially when latent user intent must be inferred from under-specified language without ground-truth labels; existing methods rely on value models and struggle to attribute success to specific tokens.

Method: OSPO uses potential-based reward shaping with Shapley-Owen attributions to allocate segment-level credit based on tokens' marginal contributions to outcomes. It forms coalitions of semantically coherent units (e.g., attribute-describing phrases or preference sentences) and redistributes sequence-level advantages to these units, preserving the optimal policy and avoiding parametric value models.

Result: Experiments on Amazon ESCI and H&M Fashion show consistent gains over baselines, with improved test-time robustness to out-of-distribution retrievers unseen during training.

Conclusion: OSPO provides a principled, model-free (no value networks) token-level credit assignment framework that maintains policy optimality, improves performance, and enhances robustness in RL-based recommender systems.

Abstract: Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks, but standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when models must infer latent user intent from under-specified language without ground truth labels, a reasoning pattern rarely seen during pretraining. We introduce Owen-Shapley Policy Optimization (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. Unlike value-model-based methods requiring additional computation, OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy, learning directly from task feedback without parametric value models. By forming coalitions of semantically coherent units (phrases describing product attributes or sentences capturing preferences), OSPO identifies which response parts drive performance. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.

</details>


### [90] [Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation](https://arxiv.org/abs/2601.08412)
*Yizhan Feng,Hichem Snoussi,Yuhang Wang,Jing Teng,Abel Cherouat,Tian Wang*

Main category: cs.AI

TL;DR: 通过将大模型的推理能力和代码生成能力蒸馏给轻量模型，实现多主流 UAV SDK 的高效代码生成与控制任务。核心在于结合知识蒸馏、链式推理引导和有监督微调，构建带推理链的数据集，并以黑白盒混合蒸馏和 QLoRA 量化教师模型进行软标签传递。


<details>
  <summary>Details</summary>
Motivation: 解决大规模模型对资源的高消耗与 UAV 平台对实时性、轻量化的严苛要求之间的矛盾，使轻量化模型具备较强的代码生成与推理能力以实现无人机的 onboard 控制。

Method: 1) 构建覆盖主流 UAV SDK 的高质量数据集，包含指令-代码-推理链及对抗性负样本以实现端到端逻辑学习；2) 以 DeepSeek-Coder-V2-Lite（经 QLoRA 量化）为教师，采用混合黑盒与白盒蒸馏，生成高质量的链式推理“软标签”；3) 将软标签与硬标签的加权交叉熵损失结合，用于学生模型的训练；4) 通过针对 UAV 场景的提示微调提升核心任务如 SDK 类型识别和函数调用匹配的性能。

Result: 蒸馏得到的轻量模型在保持较高代码生成准确性的同时，显著提升部署与推理效率，验证该方法在实现 UAV 精准且轻量化的智能控制方面的可行性与优越性。

Conclusion: 将知识蒸馏、链式推理引导和有监督微调有机结合，能够将复杂推理能力有效迁移到小模型，并用于 UAV SDK 控制任务中的高效代码生成与任务执行。

Abstract: With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs

</details>


### [91] [RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation](https://arxiv.org/abs/2601.08430)
*Sunzhu Li,Jiale Zhao,Miteto Wei,Huimin Ren,Yang Zhou,Jingwen Yang,Shunyu Liu,Kaike Zhang,Wei Chen*

Main category: cs.AI

TL;DR: 提出自动化粗到细评分框架RubricHub，构建大规模多域评估数据集并通过RuFT/RuRL提升健康基准上的性能，达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决缺乏 ground truth 导致的开放式生成优化难题，克服 rubric 基准评估的可扩展性与粒度不足问题。

Method: Coarse-to-Fine Rubric Generation；原则引导合成、多模型聚合、难度演化；构建RubricHub (~110k) 数据集；两阶段后训练RuFT（Rubric-based Rejection Sampling Fine-Tuning）和RuRL（Rubric-guided RL）。

Result: 在HealthBench上，基于RubricHub的Qwen3-14B达到69.3，超越GPT-5等前沿模型，显示显著性能提升。

Conclusion: RubricHub与后训练管线有望提升推理密集任务的鲁棒性与泛化性；代码与数据将开源。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has driven substantial progress in reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the lack of ground truth. While rubric-based evaluation offers a structured proxy for verification, existing methods suffer from scalability bottlenecks and coarse criteria, resulting in a supervision ceiling effect. To address this, we propose an automated Coarse-to-Fine Rubric Generation framework. By synergizing principle-guided synthesis, multi-model aggregation, and difficulty evolution, our approach produces comprehensive and highly discriminative criteria capable of capturing the subtle nuances. Based on this framework, we introduce RubricHub, a large-scale ($\sim$110k) and multi-domain dataset. We validate its utility through a two-stage post-training pipeline comprising Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results demonstrate that RubricHub unlocks significant performance gains: our post-trained Qwen3-14B achieves state-of-the-art (SOTA) results on HealthBench (69.3), surpassing proprietary frontier models such as GPT-5. The code and data will be released soon.

</details>


### [92] [YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation](https://arxiv.org/abs/2601.08441)
*Abdelaziz Bounhar,Rania Hossam Elmohamady Elbadry,Hadi Abdine,Preslav Nakov,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.AI

TL;DR: YaPO learns sparse steering vectors via a Sparse Autoencoder to enable disentangled, efficient, and interpretable model alignment, outperforming dense steering vectors.


<details>
  <summary>Details</summary>
Motivation: Dense steering vectors entangle multiple latent factors due to neuron multi-semanticity, limiting fine-grained control such as cultural alignment. Sparse, disentangled representations promise better stability and interpretability.

Method: Optimize sparse codes in the latent space of a Sparse Autoencoder (SAE) to derive steering directions without reference data, comparing against dense baselines across alignment tasks.

Result: YaPO converges faster, yields stronger performance, and improves training stability relative to dense steering vectors; exhibits generalization across alignment tasks (hallucination, jailbreak, power-seeking, etc.) and preserves general knowledge (no MMLU degradation). Code and data are publicly available.

Conclusion: Sparse, disentangled steering via SAE-based codes provides a general, efficient, and stable approach to LLM alignment with broad applicability to controllability and domain adaptation.

Abstract: Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference data in a Direct Preference Optimization (DPO) fashion, enabling control over truthfulness, hallucinations, and safety behaviors. However, dense steering vectors often entangle multiple latent factors due to neuron multi-semanticity, limiting their effectiveness and stability in fine-grained settings such as cultural alignment, where closely related values and behaviors (e.g., among Middle Eastern cultures) must be distinguished. In this paper, we propose Yet another Policy Optimization (YaPO), a \textit{reference-free} method that learns \textit{sparse steering vectors} in the latent space of a Sparse Autoencoder (SAE). By optimizing sparse codes, YaPO produces disentangled, interpretable, and efficient steering directions. Empirically, we show that YaPO converges faster, achieves stronger performance, and exhibits improved training stability compared to dense steering baselines. Beyond cultural alignment, YaPO generalizes to a range of alignment-related behaviors, including hallucination, wealth-seeking, jailbreak, and power-seeking. Importantly, YaPO preserves general knowledge, with no measurable degradation on MMLU. Overall, our results show that YaPO provides a general recipe for efficient, stable, and fine-grained alignment of LLMs, with broad applications to controllability and domain adaptation. The associated code and data are publicly available\footnote{https://github.com/MBZUAI-Paris/YaPO}.

</details>


### [93] [Beyond Linearization: Attributed Table Graphs for Table Reasoning](https://arxiv.org/abs/2601.08444)
*Yuxiang Wang,Junhao Gan,Shengxiang Gao,Shenghao Ye,Zhengyi Yang,Jianzhong Qi*

Main category: cs.AI

TL;DR: TABGR是一种训练无关(step-free)模型，将表格表示为属性表格图（ATG），保持行列单元格结构并进行图形推理以提升可解释性；引入QG-PPR对表格数据进行再排序以缓解“lost-in-the-middle”问题；在两个常用基准上实现对SOTA的显著提升（最高9.7%准确率），且代码将公开。


<details>
  <summary>Details</summary>
Motivation: 现有将表格线性化输入大语言模型的方法会丢失表格结构，缺少可解释的推理路径，易产生“lost-in-the-middle”现象。需要一种训练无关、能显式保留表格结构并提供可解释推理路径的解决方案，同时通过对数据的问句引导的再排序来缓解信息在推理链中的丢失。

Method: 将表格表示为属性表格图（ATG），显式保留行列和单元格的结构，并通过基于图的推理实现解释性。提出问句引导的个性化PageRank（QG-PPR）机制，对表格数据进行重新排序，缓解lost-in-the-middle。该方法为训练无关（training-free）。

Result: 在两个常用基准上，TABGR在准确率方面持续超越现有最优模型，提升幅度高达9.7%。实验结果表明，该方法在保持结构信息和可解释性的同时，能提升推理性能。

Conclusion: TABGR通过显式的ATG表征和QG-PPR再排序，解决了线性化输入的结构损失和缺乏可解释推理路径的问题，并在两项基准测试中实现显著性能提升，具备良好的可解释性和无训练成本的优点，且代码将公开。

Abstract: Table reasoning, a task to answer questions by reasoning over data presented in tables, is an important topic due to the prevalence of knowledge stored in tabular formats. Recent solutions use Large Language Models (LLMs), exploiting the semantic understanding and reasoning capabilities of LLMs. A common paradigm of such solutions linearizes tables to form plain texts that are served as input to LLMs. This paradigm has critical issues. It loses table structures, lacks explicit reasoning paths for result explainability, and is subject to the "lost-in-the-middle" issue. To address these issues, we propose Table Graph Reasoner (TABGR), a training-free model that represents tables as an Attributed Table Graph (ATG). The ATG explicitly preserves row-column-cell structures while enabling graph-based reasoning for explainability. We further propose a Question-Guided Personalized PageRank (QG-PPR) mechanism to rerank tabular data and mitigate the lost-in-the-middle issue. Extensive experiments on two commonly used benchmarks show that TABGR consistently outperforms state-of-the-art models by up to 9.7% in accuracy. Our code will be made publicly available upon publication.

</details>


### [94] [SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System](https://arxiv.org/abs/2601.08475)
*JungMin Yun,Juhwan Choi,Kyohoon Jin,Soojin Jang,Jinhee Jang,YoungBin Kim*

Main category: cs.AI

TL;DR: 提出 SummPilot，通过交互可定制的摘要系统，实现自动和交互式摘要的结合，以满足个性化需求；通过语义图、实体聚类和可解释评估等组件提升可定制性与可用性。


<details>
  <summary>Details</summary>
Motivation: 面向不同用户的兴趣与需求，生成个性化摘要的挑战，需要可定制化的摘要系统来适配多样化场景。

Method: 基于大语言模型的自动摘要与交互式摘要生成框架，结合语义图、实体聚类和可解释评估等交互组件，允许用户与系统互动以定制摘要。

Result: 通过演示与用户研究，证明 SummPilot 具有良好的可定制性、适应性和实用性，用于个性化摘要场景。

Conclusion: SummPilot 提供一个基于交互的、面向个性化摘要的实用系统框架，借助大语言模型实现自动与交互式摘要的结合，并通过可解释评估增强透明度。

Abstract: This paper incorporates the efficiency of automatic summarization and addresses the challenge of generating personalized summaries tailored to individual users' interests and requirements. To tackle this challenge, we introduce SummPilot, an interaction-based customizable summarization system. SummPilot leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system to understand document content and personalize summaries through interactive components such as semantic graphs, entity clustering, and explainable evaluation. Our demo and user studies demonstrate SummPilot's adaptability and usefulness for customizable summarization.

</details>


### [95] [What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting](https://arxiv.org/abs/2601.08509)
*Jinkwan Jang,Hyunbin Jin,Hyungjin Park,Kyubyung Chae,Taesup Kim*

Main category: cs.AI

TL;DR: 提出并发布 What If TSF (WIT) 多模态预测基准，用于评估模型在给定文本情境（尤其未来情景）下对时间序列的条件预测能力。


<details>
  <summary>Details</summary>
Motivation: 现实中的时序预测往往依赖多模态信息；现有方法多为单模态、依赖历史模式外推。尽管大语言模型在多模态预测方面具潜力，但现有基准未充分检验文本条件下的预测能力；人类专家在场景假设下可给出多样的预测。

Method: 设计并发布 What If TSF (WIT) 基准，提供专家设计的可行场景或反事实场景作为额外文本上下文，作为多模态输入的一部分，用以评估在文本情境下的预测能力。数据集包含带文本情景的时序样本，建立用于场景引导的多模态时序预测评测的测试床。

Result: 提出并公开获取的基准 WIT；提供面向未来情景的文本情景以检验模型的情景条件预测能力（可通过 GitHub 获取）。

Conclusion: WIT 为场景引导的多模态时序预测提供严格的测试平台，有助于评估文本输入在预测中的作用，并推动相关模型在情景感知预测上的发展。

Abstract: Time series forecasting is critical to real-world decision making, yet most existing approaches remain unimodal and rely on extrapolating historical patterns. While recent progress in large language models (LLMs) highlights the potential for multimodal forecasting, existing benchmarks largely provide retrospective or misaligned raw context, making it unclear whether such models meaningfully leverage textual inputs. In practice, human experts incorporate what-if scenarios with historical evidence, often producing distinct forecasts from the same observations under different scenarios. Inspired by this, we introduce What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate whether models can condition their forecasts on contextual text, especially future scenarios. By providing expert-crafted plausible or counterfactual scenarios, WIT offers a rigorous testbed for scenario-guided multimodal forecasting. The benchmark is available at https://github.com/jinkwan1115/WhatIfTSF.

</details>


### [96] [Sketch-Based Facade Renovation With Generative AI: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse](https://arxiv.org/abs/2601.08531)
*Warissara Booranamaitree,Xusheng Du,Yushu Cai,Zhengyang Wang,Ye Zhang,Haoran Xie*

Main category: cs.AI

TL;DR: 提出三阶段AI框架，通过粗略草图和文本描述直接生成立面改造方案，避免详细建模。


<details>
  <summary>Details</summary>
Motivation: 立面改造需在保留原结构的前提下表达新意，但现有工作流依赖繁琐的 as-built 建模，效率低下。

Method: 阶段1：微调的视觉-语言模型预测修改区域的边界框；阶段2：稳定扩散生成新元素草图并与原轮廓在生成修复中融合；阶段3：ControlNet提升为高保真照片级输出。

Result: 在数据集与真实建筑实例上，框架能够在保留结构的同时提升立面细节质量，帮助快速探索设计方案并沟通意图。

Conclusion: 该方法可降低对详细建模的依赖并提高初期设计迭代效率，但需关注鲁棒性、合规性和数据偏差等挑战，并需在不同法规环境下验证。

Abstract: Facade renovation offers a more sustainable alternative to full demolition, yet producing design proposals that preserve existing structures while expressing new intent remains challenging. Current workflows typically require detailed as-built modelling before design, which is time-consuming, labour-intensive, and often involves repeated revisions. To solve this issue, we propose a three-stage framework combining generative artificial intelligence (AI) and vision-language models (VLM) that directly processes rough structural sketch and textual descriptions to produce consistent renovation proposals. First, the input sketch is used by a fine-tuned VLM model to predict bounding boxes specifying where modifications are needed and which components should be added. Next, a stable diffusion model generates detailed sketches of new elements, which are merged with the original outline through a generative inpainting pipeline. Finally, ControlNet is employed to refine the result into a photorealistic image. Experiments on datasets and real industrial buildings indicate that the proposed framework can generate renovation proposals that preserve the original structure while improving facade detail quality. This approach effectively bypasses the need for detailed as-built modelling, enabling architects to rapidly explore design alternatives, iterate on early-stage concepts, and communicate renovation intentions with greater clarity.

</details>


### [97] [Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement](https://arxiv.org/abs/2601.08545)
*Zhenlong Dai,Zhuoluo Zhao,Hengning Wang,Xiu Tang,Sai Wu,Chang Yao,Zhipeng Gao,Jingyuan Chen*

Main category: cs.AI

TL;DR: 提出了 Learner-Tailored Program Repair (LPR) 与框架 LT-SG，用于在编程教学场景中提升程序修复质量，并给出错误描述与解释。通过两阶段流程（检索驱动的修复与解决方案引导的修复）及迭代检索增强，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 当前研究多聚焦于修复学生代码中的 Bug，往往不提供错误原因或解释，导致学习者难以理解与长期改进。需要一个能给出错误描述、解释并结合检索驱动的修复框架来提升教学效果。

Method: 阶段1：构建修复方案检索数据库，并通过编辑驱动的代码检索定位有价值的解决方案，指导大语言模型定位并修复错误。阶段2：提出解决方案引导的程序修复，结合检索解决方案对代码修复并给出解释。并提出迭代检索增强，根据生成代码的评估结果迭代优化检索方向，探索更合适的修复策略。

Result: 实验结果显示该方法在与多组基线的比较中实现了显著领先，证实了框架对新任务 LPR 的有效性。

Conclusion: 该框架有效解决了“给予学习者的定制化修复与解释”的需求，提升了修复质量并具备在实际编程教学场景中应用的潜力。

Abstract: With the development of large language models (LLMs) in the field of programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely \textbf{LPR} (\textbf{L}earner-Tailored \textbf{P}rogram \textbf{R}epair). We then propose a novel and effective framework, \textbf{\textsc{\MethodName{}}} (\textbf{L}earner-Tailored \textbf{S}olution \textbf{G}enerator), to enhance program repair while offering the bug descriptions for the buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and then employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing the bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of the generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task.

</details>


### [98] [WaterCopilot: An AI-Driven Virtual Assistant for Water Management](https://arxiv.org/abs/2601.08559)
*Keerththanan Vickneswaran,Mariangel Garcia Andarcia,Hugo Retief,Chris Dickens,Paulo Silva*

Main category: cs.AI

TL;DR: WaterCopilot是一个基于RAG的多语言AI决策支持平台，为跨界水资源管理提供统一、可解释的数据访问和实时洞见，专为Limpopo河流域设计，评估显示较高的相关性与上下文精度。


<details>
  <summary>Details</summary>
Motivation: 解决跨界河流管理中的数据碎片化、缺乏实时性与来源整合困难，通过统一的平台提升决策效率和水安全。

Method: 采用 Retrieval-Augmented Generation（RAG）与工具调用架构，集成iwmi-doc-plugin（通过Azure AI Search实现文档语义检索）和iwmi-api-plugin（查询实时数据库以获取环境流、降雨、库位等动态信息），支持多语言交互、透明引用、自动计算及可视化；与LRB Digital Twin集成，部署在AWS，使用RAGAS评估。

Result: 在RAGAS框架下，WaterCopilot总体得分0.8043；高相关性0.8571、上下文精度0.8009；实现自动阈值警报、与LRB Digital Twin对接、可扩展部署等创新；存在对非英文技术文档处理能力不足和API时延等局限。

Conclusion: 展示了AI辅助框架在数据匮乏的跨界河流治理环境中的可复制性和潜力，帮助实现信息驱动、及时决策，从而增强水安全。

Abstract: Sustainable water resource management in transboundary river basins is challenged by fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper presents WaterCopilot-an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge these gaps through a unified, interactive platform. Built on Retrieval-Augmented Generation (RAG) and tool-calling architectures, WaterCopilot integrates static policy documents and real-time hydrological data via two custom plugins: the iwmi-doc-plugin, which enables semantic search over indexed documents using Azure AI Search, and the iwmi-api-plugin, which queries live databases to deliver dynamic insights such as environmental-flow alerts, rainfall trends, reservoir levels, water accounting, and irrigation data. The system features guided multilingual interactions (English, Portuguese, French), transparent source referencing, automated calculations, and visualization capabilities. Evaluated using the RAGAS framework, WaterCopilot achieves an overall score of 0.8043, with high answer relevancy (0.8571) and context precision (0.8009). Key innovations include automated threshold-based alerts, integration with the LRB Digital Twin, and a scalable deployment pipeline hosted on AWS. While limitations in processing non-English technical documents and API latency remain, WaterCopilot establishes a replicable AI-augmented framework for enhancing water governance in data-scarce, transboundary contexts. The study demonstrates the potential of this AI assistant to support informed, timely decision-making and strengthen water security in complex river basins.

</details>


### [99] [ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios](https://arxiv.org/abs/2601.08620)
*António Loison,Quentin Macé,Antoine Edy,Victor Xing,Tom Balough,Gabriel Moreira,Bo Liu,Manuel Faysse,Céline Hudelot,Gautier Viaud*

Main category: cs.AI

TL;DR: ViDoRe v3：一个全面的多模态RAG基准，覆盖10个数据集、约26,000页文档、3,099条经人工验证的问题，支持6种语言。评估显示视觉检索优于文本检索， late-interaction与文本重新排序有效，混合/纯视觉上下文有助于问答生成，但在非文本元素、开放式问题和细粒度定位方面仍具挑战；已在商用友好许可下发布。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG基准多聚焦文本、单文档理解，无法充分测试跨文档整合、对视觉信息的解释与精准定位等能力，因此需要一个覆盖广泛模态且跨域的基准来推动技术进步。

Method: 构建多模态RAG基准ViDoRe v3，涵盖10个专业领域的视觉丰富文档语料，约26,000页文档，3,099条人工核验的问题，问题以6种语言给出；提供检索相关性、边界框定位以及答案的人工核验，共约12,000小时人工标注，用于评测检索、定位、生成等环节。

Result: 对最先进RAG管线进行评测，发现视觉检索优于文本检索，late-interaction模型和文本重新排序显著提升性能，混合或纯视觉上下文能提升回答生成质量；但当前模型在处理非文本元素、开放式问题与细粒度视觉定位方面仍存在困难。

Conclusion: 基准已在商用友好许可下对外发布（HF链接）。目标是推动多模态RAG领域进步，未来研究方向包括提升对非文本元素的理解、改进对开放性问题的处理以及对视觉细节的细粒度定位能力。

Abstract: Retrieval-Augmented Generation (RAG) pipelines must address challenges beyond simple single-document retrieval, such as interpreting visual elements (tables, charts, images), synthesizing information across documents, and providing accurate source grounding. Existing benchmarks fail to capture this complexity, often focusing on textual data, single-document comprehension, or evaluating retrieval and generation in isolation. We introduce ViDoRe v3, a comprehensive multimodal RAG benchmark featuring multi-type queries over visually rich document corpora. It covers 10 datasets across diverse professional domains, comprising ~26,000 document pages paired with 3,099 human-verified queries, each available in 6 languages. Through 12,000 hours of human annotation effort, we provide high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers. Our evaluation of state-of-the-art RAG pipelines reveals that visual retrievers outperform textual ones, late-interaction models and textual reranking substantially improve performance, and hybrid or purely visual contexts enhance answer generation quality. However, current models still struggle with non-textual elements, open-ended queries, and fine-grained visual grounding. To encourage progress in addressing these challenges, the benchmark is released under a commercially permissive license at https://hf.co/vidore.

</details>


### [100] [Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.08641)
*Yichen Luo,Yebo Feng,Jiahua Xu,Yang Liu*

Main category: cs.AI

TL;DR: Not provided


<details>
  <summary>Details</summary>
Motivation: Not provided

Method: Not provided

Result: Not provided

Conclusion: Not provided

Abstract: The launch of \$Trump coin ignited a wave in meme coin investment. Copy trading, as a strategy-agnostic approach that eliminates the need for deep trading knowledge, quickly gains widespread popularity in the meme coin market. However, copy trading is not a guarantee of profitability due to the prevalence of manipulative bots, the uncertainty of the followed wallets' future performance, and the lag in trade execution. Recently, large language models (LLMs) have shown promise in financial applications by effectively understanding multi-modal data and producing explainable decisions. However, a single LLM struggles with complex, multi-faceted tasks such as asset allocation. These challenges are even more pronounced in cryptocurrency markets, where LLMs often lack sufficient domain-specific knowledge in their training data.
  To address these challenges, we propose an explainable multi-agent system for meme coin copy trading. Inspired by the structure of an asset management team, our system decomposes the complex task into subtasks and coordinates specialized agents to solve them collaboratively. Employing few-shot chain-of-though (CoT) prompting, each agent acquires professional meme coin trading knowledge, interprets multi-modal data, and generates explainable decisions. Using a dataset of 1,000 meme coin projects' transaction data, our empirical evaluation shows that the proposed multi-agent system outperforms both traditional machine learning models and single LLMs, achieving 73% and 70% precision in identifying high-quality meme coin projects and key opinion leader (KOL) wallets, respectively. The selected KOLs collectively generated a total profit of \$500,000 across these projects.

</details>


### [101] [Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding](https://arxiv.org/abs/2601.08653)
*Zenghua Liao,Jinzhi Liao,Xiang Zhao*

Main category: cs.AI

TL;DR: Prism is a four-module framework for complex intent clarification on social platforms, combining intent decomposition, dependency-aware clarification generation, an intent-aware reward with Monte Carlo data synthesis, and a self-evolved tuning loop; it achieves state-of-the-art logical consistency and notable gains in user satisfaction and efficiency, with all data and code released.


<details>
  <summary>Details</summary>
Motivation: On social web, user goals are ambiguous and dynamic, requiring coherent, multi-turn clarification that accounts for logical dependencies among questions. Existing sequential/parallel questioning struggles with dependency modeling and cognitive load. Cognitive Load Theory motivates designing a clarification process that minimizes cognitive effort while maintaining coherence.

Method: 1) Complex intent decomposition module to break down intents into elements and identify logical dependencies. 2) Logical clarification generation module to order and formulate questions respecting dependencies for coherent interactions. 3) Intent-aware reward module to evaluate clarification trajectories with an intent-aware reward and use Monte Carlo sampling to generate scalable training data. 4) Self-evolved intent tuning module to iteratively refine the model via data-driven feedback and optimization.

Result: Prism outperforms existing approaches in clarification interactions, intent execution, and cognitive-load benchmarks. It achieves state-of-the-art logical consistency, reduces logical conflicts to 11.5%, increases user satisfaction by 14.4%, and decreases task completion time by 34.8%. All data and code are released.

Conclusion: Prism demonstrates that structuring intents and clarifications around logical dependencies yields coherent, low-friction user interactions and scalable training data. The open release supports reproducibility, and future work could explore broader domain applicability, robustness to user variability, and more fine-grained cognitive-load analyses.

Abstract: Large Language Models are rapidly emerging as web-native interfaces to social platforms. On the social web, users frequently have ambiguous and dynamic goals, making complex intent understanding-rather than single-turn execution-the cornerstone of effective human-LLM collaboration. Existing approaches attempt to clarify user intents through sequential or parallel questioning, yet they fall short of addressing the core challenge: modeling the logical dependencies among clarification questions. Inspired by the Cognitive Load Theory, we propose Prism, a novel framework for complex intent understanding that enables logically coherent and efficient intent clarification. Prism comprises four tailored modules: a complex intent decomposition module, which decomposes user intents into smaller, well-structured elements and identifies logical dependencies among them; a logical clarification generation module, which organizes clarification questions based on these dependencies to ensure coherent, low-friction interactions; an intent-aware reward module, which evaluates the quality of clarification trajectories via an intent-aware reward function and leverages Monte Carlo Sample to simulate user-LLM interactions for large-scale,high-quality training data generation; and a self-evolved intent tuning module, which iteratively refines the LLM's logical clarification capability through data-driven feedback and optimization. Prism consistently outperforms existing approaches across clarification interactions, intent execution, and cognitive load benchmarks. It achieves stateof-the-art logical consistency, reduces logical conflicts to 11.5%, increases user satisfaction by 14.4%, and decreases task completion time by 34.8%. All data and code are released.

</details>


### [102] [From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner's Tutorial](https://arxiv.org/abs/2601.08662)
*Abhijit Sen,Sonali Panda,Mahima Arya,Subhajit Patra,Zizhan Zheng,Denys I. Bondar*

Main category: cs.AI

TL;DR: 面向本科生的强化学习（RL）教程，基于实例的讲解，降低理论与实操之间的鸿沟，通过动手示例帮助学生将概念转化为代码实现，培养应用 RL 的基础技能。


<details>
  <summary>Details</summary>
Motivation: RL 学习门槛较高，理论与实现之间存在断层；本科生缺乏系统、易于上手的实操教学资源，亟需以实例驱动的教学来降低门槛并提升应用能力。

Method: 采用教程形式，强调实例驱动的解释和动手练习，提供从理论到代码的清晰桥梁；围绕常见难点设计练习，帮助学生掌握基本的 RL 技术及其实现。

Result: 摘要未给出具体实验结果或评估数据；可以预期该教程旨在提升学生的理解与编码能力，使其能够在真实场景中应用 RL。

Conclusion: 通过系统的、以实例为核心的教学设计，本文主张以更易获得的方式传播 RL，使本科生能够自信地将 RL 技术应用于现实世界场景。

Abstract: This tutorial is designed to make reinforcement learning (RL) more accessible to undergraduate students by offering clear, example-driven explanations. It focuses on bridging the gap between RL theory and practical coding applications, addressing common challenges that students face when transitioning from conceptual understanding to implementation. Through hands-on examples and approachable explanations, the tutorial aims to equip students with the foundational skills needed to confidently apply RL techniques in real-world scenarios.

</details>


### [103] [Parallel Context-of-Experts Decoding for Retrieval Augmented Generation](https://arxiv.org/abs/2601.08670)
*Giulio Corallo,Paolo Papotti*

Main category: cs.AI

TL;DR: 将证据聚合从注意力转移到解码阶段的训练无关框架Pced，将检索到的文档视为独立专家，通过检索感知对比解码规则在解码时统一预测，恢复跨文档推理能力且避免共享注意力开销。


<details>
  <summary>Details</summary>
Motivation: RAG 在长提示下存在前填充瓶颈；独立文档缓存提高速度但削弱跨文档交互，因此需要一套不依赖共享注意力的跨文档推理方案。

Method: 提出 Parallel Context-of-Experts Decoding (Pced)，将检索文档视为专家，使用检索感知对比解码规则，将专家 logits 与模型先验对比加权以同步预测，避免在跨文档层面构建共享注意力。

Result: 理论上实现跨文档推理能力的回归，同时降低前填充瓶颈；不需要额外的跨文档注意力模块。

Conclusion: 通过解码阶段的专家投票与对比解码实现证据聚合，Pced提供训练-free、跨文档推理的新路径，但需实验评估对比基线和鲁棒性。

Abstract: Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decoding (Pced), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding. Pced treats retrieved documents as isolated "experts", synchronizing their predictions via a novel retrieval-aware contrastive decoding rule that weighs expert logits against the model prior. This approach recovers cross-document reasoning capabilities without constructing a shared attention across documents.

</details>


### [104] [Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock](https://arxiv.org/abs/2601.08673)
*Didier Sornette,Sandro Claudio Lera,Ke Wu*

Main category: cs.AI

TL;DR: 对LLMs行为的解读应从结构性社会互动的放大效应出发，“对齐失败”并非单纯的模型意图，而是权力、信息与约束极端不对称下的行为谱系极端化；将黑mail等行为视为同一互动谱系的边际极端；AGI作为人类智慧与权力的放大器，治理需聚焦放大效应、复杂性与制度稳定性。


<details>
  <summary>Details</summary>
Motivation: 挑战把LLM的行为异常简单归因于对齐失败的直觉，提出从关系模型理论的结构性视角来解释，并探讨对AGI治理的新取向。

Method: 理论分析，利用关系模型理论将人类互动中的权力、信息与约束不对称性作为理解极端行为（如黑mail）的框架，强调这类行为是连续体中的边际案例。

Result: 揭示看似“不道德”的输出其实是社会互动模式的普遍化与极端化，黑mail等行为不是偏离常规，而是结构性极端点；AGI作为放大器，会压缩实现时间与历史学习空间，放大人类价值与治理的矛盾。

Conclusion: 治理应聚焦放大效应、系统复杂性与制度稳定性，超越单纯的模型级“意图”考量，建立可控的治理机制以应对复杂性与规制性变动。

Abstract: Recent reports of large language models (LLMs) exhibiting behaviors such as deception, threats, or blackmail are often interpreted as evidence of alignment failure or emergent malign agency. We argue that this interpretation rests on a conceptual error. LLMs do not reason morally; they statistically internalize the record of human social interaction, including laws, contracts, negotiations, conflicts, and coercive arrangements. Behaviors commonly labeled as unethical or anomalous are therefore better understood as structural generalizations of interaction regimes that arise under extreme asymmetries of power, information, or constraint. Drawing on relational models theory, we show that practices such as blackmail are not categorical deviations from normal social behavior, but limiting cases within the same continuum that includes market pricing, authority relations, and ultimatum bargaining. The surprise elicited by such outputs reflects an anthropomorphic expectation that intelligence should reproduce only socially sanctioned behavior, rather than the full statistical landscape of behaviors humans themselves enact. Because human morality is plural, context-dependent, and historically contingent, the notion of a universally moral artificial intelligence is ill-defined. We therefore reframe concerns about artificial general intelligence (AGI). The primary risk is not adversarial intent, but AGI's role as an endogenous amplifier of human intelligence, power, and contradiction. By eliminating longstanding cognitive and institutional frictions, AGI compresses timescales and removes the historical margin of error that has allowed inconsistent values and governance regimes to persist without collapse. Alignment failure is thus structural, not accidental, and requires governance approaches that address amplification, complexity, and regime stability rather than model-level intent alone.

</details>


### [105] [PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning](https://arxiv.org/abs/2601.08679)
*Xiaoyou Liu,Xinyi Mou,Shengbin Yue,Liang Wang,Yuqing Wang,Qiexiang Wang,Tianrui Qin,Wangchunshu Zhou,Zhongyu Wei*

Main category: cs.AI

TL;DR: Introduces PersonaDual, 一个单模型双模式框架，结合通用客观推理与个性化推理，并依据上下文自适应切换模式；通过SFT学习两种推理模式，随后用DualGRPO进行强化学习优化模式选择。实验显示在目标与个性化基准上，保持个性化优势的同时降低干扰，接近无干扰的目标推理性能，且能更好利用个性化信号提升问题求解能力。


<details>
  <summary>Details</summary>
Motivation: 随着用户对LLMs的偏好对齐需求增加，个性化信息具有价值但也可能导致客观性和事实正确性下降，尤其当信息与问题不对齐时。需要在个性化与客观推理之间实现兼容与权衡。

Method: 通过两阶段训练实现：1) SFT：学习两种推理模式；2) RL：使用所提出的DualGRPO框架对模式切换进行优化，以在上下文中自适应选择通用对象推理或个性化推理。

Result: 在目标与个性化基准上的实验表明，PersonaDual在保留个性化信号的同时减少干扰，接近无干扰的表现，并更好地利用个性化信号提升客观问题求解。

Conclusion: PersonaDual实现了个性化收益与客观性之间的平衡，使模型在保持个性化能力的同时减少干扰，提升客观推理表现。

Abstract: As users increasingly expect LLMs to align with their preferences, personalized information becomes valuable. However, personalized information can be a double-edged sword: it can improve interaction but may compromise objectivity and factual correctness, especially when it is misaligned with the question. To alleviate this problem, we propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, and adaptively switches modes based on context. PersonaDual is first trained with SFT to learn two reasoning patterns, and then further optimized via reinforcement learning with our proposed DualGRPO to improve mode selection. Experiments on objective and personalized benchmarks show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.

</details>


### [106] [MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection](https://arxiv.org/abs/2601.08684)
*Paolo Italiani,David Gimeno-Gomez,Luca Ragazzi,Gianluca Moro,Paolo Rosso*

Main category: cs.AI

TL;DR: MemeWeaver提出一个端到端多模态框架，通过跨模因图推理检测性别相关的性别歧视和厌女内容，在MAMI和EXIST基准上优于SOTA且收敛更快。


<details>
  <summary>Details</summary>
Motivation: 当前在线骚扰中女性更易成为目标，现有多模态审核忽视社交动态、群体认同与互动结构。图结构可捕捉跨模因之间的关系，但现有方法在图构建、模态融合深度及实例级推理方面受限。

Method: 提出 MemeWeaver，利用一个新颖的跨-模因图推理机制进行端到端训练的多模态融合，评估多种视觉–文本融合策略，并通过图结构来捕捉和推理跨模因关系。

Result: 在MAMI和EXIST基准上持续优于当前最先进的基线，训练收敛更快；学习到的图结构具有语义意义，能揭示在线仇恨的关系性特征。

Conclusion: 证明跨模因图推理在揭示在线仇恨的社交动力学方面具备潜力，提供对仇恨传播关系的可解释视角。

Abstract: Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communities. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shallow modality fusion, and instance-level reasoning. In this work, we present MemeWeaver, an end-to-end trainable multimodal framework for detecting sexism and misogyny through a novel inter-meme graph reasoning mechanism. We systematically evaluate multiple visual--textual fusion strategies and show that our approach consistently outperforms state-of-the-art baselines on the MAMI and EXIST benchmarks, while achieving faster training convergence. Further analyses reveal that the learned graph structure captures semantically meaningful patterns, offering valuable insights into the relational nature of online hate.

</details>


### [107] [All Required, In Order: Phase-Level Evaluation for AI-Human Dialogue in Healthcare and Beyond](https://arxiv.org/abs/2601.08690)
*Shubham Kulkarni,Alexander Lyzhov,Shiva Chaitanya,Preetam Joshi*

Main category: cs.AI

TL;DR: 提出 OIP-SCE，一种按阶段评估临床对话合规性的框架，确保每项必需义务按顺序完成且有证据可审计。


<details>
  <summary>Details</summary>
Motivation: 当前评估多忽略对话全过程中的合规性，难以落地到临床工作流程，需要一个可审计、可操作的评价表述。

Method: 将合规性拆分为信息阶段（Obligatory-Information Phases），逐阶段检查必需的临床义务、顺序与证据，面向 clinicians 提供可review 的证据。

Result: 在呼吸史、福利核验等两个案例中演示，阶段级证据将政策转化为可执行步骤，形成单一可审计的评估表面。

Conclusion: 使工程实现有明确规范，增强与临床工作流的一致性，促进 AI 的安全、可重复使用。

Abstract: Conversational AI is starting to support real clinical work, but most evaluation methods miss how compliance depends on the full course of a conversation. We introduce Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), an evaluation method that checks whether every required clinical obligation is met, in the right order, with clear evidence for clinicians to review. This makes complex rules practical and auditable, helping close the gap between technical progress and what healthcare actually needs. We demonstrate the method in two case studies (respiratory history, benefits verification) and show how phase-level evidence turns policy into shared, actionable steps. By giving clinicians control over what to check and engineers a clear specification to implement, OIP-SCE provides a single, auditable evaluation surface that aligns AI capability with clinical workflow and supports routine, safe use.

</details>


### [108] [Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set](https://arxiv.org/abs/2601.08703)
*Kaivalya Rawal,Eoin Delaney,Zihao Fu,Sandra Wachter,Chris Russell*

Main category: cs.AI

TL;DR: 提出 AXE 指标，用于在无地面真实解释的情形下评估特征重要性解释，克服仅依赖 ground truth 的评估局限，揭示 Rashomon 集内模型行为差异，并能检测对解释的对抗性“公平化”。


<details>
  <summary>Details</summary>
Motivation: 当解释器选择会影响解释结果，且解释评估需不依赖单一的理想解释，从而避免错误的模型选择与隐藏的偏见。Rashomon 集的存在使得多模型具有相似预测但解释不同，因此需要对解释的可比性与公平性进行评估。

Method: 提出解释评估的三项原则；引入 AXE 作为无地面真相情形下的解释评估方法，基于特征重要性解释的质量评估；避免仅以 ideal ground truth 比较；可检测保护属性用于预测的情况以及对解释的对抗性“公平化”行为。

Result: AXE 能以 100% 成功率检测对解释的对抗性公平化，且能揭示 Rashomon 集内模型在预测相同的前提下对解释的差异；相比基于敏感性分析或地面真相的评估，AXE 提供对保护属性使用的可检测性与更稳健的解释评估。

Conclusion: 与提出的原则对齐的评估方法能够揭示模型间在相同预测下的解释差异，有助于从 Rashomon 集中选取模型。AXE 相较于以往评估策略，避免依赖地面真理并具备对保护属性使用的检测能力，提升解释评估的鲁棒性。

Abstract: Explainable artificial intelligence (XAI) is concerned with producing explanations indicating the inner workings of models. For a Rashomon set of similarly performing models, explanations provide a way of disambiguating the behavior of individual models, helping select models for deployment. However explanations themselves can vary depending on the explainer used, and need to be evaluated. In the paper "Evaluating Model Explanations without Ground Truth", we proposed three principles of explanation evaluation and a new method "AXE" to evaluate the quality of feature-importance explanations. We go on to illustrate how evaluation metrics that rely on comparing model explanations against ideal ground truth explanations obscure behavioral differences within a Rashomon set. Explanation evaluation aligned with our proposed principles would highlight these differences instead, helping select models from the Rashomon set. The selection of alternate models from the Rashomon set can maintain identical predictions but mislead explainers into generating false explanations, and mislead evaluation methods into considering the false explanations to be of high quality. AXE, our proposed explanation evaluation method, can detect this adversarial fairwashing of explanations with a 100% success rate. Unlike prior explanation evaluation strategies such as those based on model sensitivity or ground truth comparison, AXE can determine when protected attributes are used to make predictions.

</details>


### [109] [Learning from Demonstrations via Capability-Aware Goal Sampling](https://arxiv.org/abs/2601.08731)
*Yuanlin Duan,Yuning Wang,Wenjie Qiu,He Zhu*

Main category: cs.AI

TL;DR: Cago introduces a curriculum-based imitation learning method that dynamically selects intermediate goals just beyond the agent's current reach to form an adaptive learning curriculum, reducing reliance on exact expert trajectories.


<details>
  <summary>Details</summary>
Motivation: Imitation learning in long-horizon tasks suffers from brittleness: small errors accumulate and perfect replication is unrealistic. There is a need for a learning signal that adapts to the agent's competence rather than solely following demonstrations.

Method: Cago tracks the agent's competence along expert trajectories and uses this signal to select intermediate goals beyond the agent's current reach. These goals create an adaptive curriculum that gradually expands the agent's capability, guiding learning beyond mere policy initialization or reward shaping.

Result: Empirical evaluation shows improved sample efficiency and final performance on sparse-reward, goal-conditioned tasks, with Cago outperforming existing learning-from-demonstrations baselines across tested domains.

Conclusion: Cago provides a principled, competence-aware curriculum that reduces reliance on perfect expert trajectories and enables steady progress toward solving long-horizon tasks.

Abstract: Despite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely on demonstrations only for policy initialization or reward shaping, Cago dynamically tracks the agent's competence along expert trajectories and uses this signal to select intermediate steps--goals that are just beyond the agent's current reach--to guide learning. This results in an adaptive curriculum that enables steady progress toward solving the full task. Empirical results demonstrate that Cago significantly improves sample efficiency and final performance across a range of sparse-reward, goal-conditioned tasks, consistently outperforming existing learning from-demonstrations baselines.

</details>


### [110] [AI as Entertainment](https://arxiv.org/abs/2601.08768)
*Cody Kommers,Ari Holtzman*

Main category: cs.AI

TL;DR: 提出“厚重娱乐”（thick entertainment）框架，用以评估AI生成的娱乐内容，弥补现有评估对文化 harms 的偏重，指出娱乐将成为AI企业的重要商业模式，并可能比生产力更深远地影响社会。


<details>
  <summary>Details</summary>
Motivation: 主流AI叙事聚焦生产力提升，而娱乐化AI的普及，尤其在年轻群体中，成为潜在的巨量经济源与影响力驱动；现有评估框架难以衡量娱乐输出的积极意义，因此需要从人文视角构建新的评价框架。

Method: 基于人文学科的洞见，批判性分析现有评估实践，提出“厚重娱乐”作为评估AI生成文化内容的框架，关注意义建构、身份认同、社会连接等维度；进行概念性综合，而非实验性结果。

Result: 揭示评价实践的一个关键对称性：评估多衡量利益与 harms，但对文化输出的积极潜力缺乏框架；提出“厚重娱乐”作为替代/补充框架，强调娱乐在意义、身份、社交方面的正向作用，以及AI与娱乐商业模型的潜在耦合。

Conclusion: AI在长期可能更像是推动社会连接的媒介，而非仅仅提升生产力；娱乐导向的商业模式可能主导未来AI发展方向，需要重构评估体系以覆盖积极文化产出与社会影响。

Abstract: Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by augmenting or automating human cognitive labor, promising to increase personal, corporate, and macroeconomic productivity. But this mainstream narrative about what AI is and what it can do is in tension with another emerging use case: entertainment. We argue that the field of AI is unprepared to measure or respond to how the proliferation of entertaining AI-generated content will impact society. Emerging data suggest AI is already widely adopted for entertainment purposes -- especially by young people -- and represents a large potential source of revenue. We contend that entertainment will become a primary business model for major AI corporations seeking returns on massive infrastructure investments; this will exert a powerful influence on the technology these companies produce in the coming years. Examining current evaluation practices, we identify a critical asymmetry: while AI assessments rigorously measure both benefits and harms of intelligence, they focus almost exclusively on cultural harms. We lack frameworks for articulating how cultural outputs might be actively beneficial. Drawing on insights from the humanities, we propose "thick entertainment" as a framework for evaluating AI-generated cultural content -- one that considers entertainment's role in meaning-making, identity formation, and social connection rather than simply minimizing harm. While AI is often touted for its potential to revolutionize productivity, in the long run we may find that AI turns out to be as much about "intelligence" as social media is about social connection.

</details>


### [111] [Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards](https://arxiv.org/abs/2601.08778)
*Tengjun Jin,Yoojin Choi,Yuxuan Zhu,Daniel Kang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Researchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of database-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial.
  In this paper, we conduct an empirical study that (i) benchmarks annotation error rates for two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and (ii) corrects a subset of the BIRD development (Dev) set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings. Through expert analysis, we show that BIRD Mini-Dev and Spider 2.0-Snow have error rates of 52.8% and 62.8%, respectively. We re-evaluate all 16 open-source agents from the BIRD leaderboard on both the original and the corrected BIRD Dev subsets. We show that performance changes range from -7% to 31% (in relative terms) and rank changes range from $-9$ to $+9$ positions. We further assess whether these impacts generalize to the full BIRD Dev set. We find that the rankings of agents on the uncorrected subset correlate strongly with those on the full Dev set (Spearman's $r_s$=0.85, $p$=3.26e-5), whereas they correlate weakly with those on the corrected subset (Spearman's $r_s$=0.32, $p$=0.23). These findings show that annotation errors can significantly distort reported performance and rankings, potentially misguiding research directions or deployment choices. Our code and data are available at https://github.com/uiuc-kang-lab/text_to_sql_benchmarks.

</details>


### [112] [Uncovering Political Bias in Large Language Models using Parliamentary Voting Records](https://arxiv.org/abs/2601.08785)
*Jieying Chen,Karen de Jong,Andreas Poole,Jan Burakowski,Elena Elderson Nosti,Joep Windt,Chendi Wang*

Main category: cs.AI

TL;DR: This content has not passed the compliance test and has been hidden.


<details>
  <summary>Details</summary>
Motivation: This content concerns political bias analysis, which falls under sensitive political content.

Method: Not applicable due to compliance.

Result: Not applicable due to compliance.

Conclusion: Not applicable due to compliance.

Abstract: As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited, despite their direct societal impact. This paper introduces a general methodology for constructing political bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. We instantiate this methodology in three national case studies: PoliBiasNL (2,701 Dutch parliamentary motions and votes from 15 political parties), PoliBiasNO (10,584 motions and votes from 9 Norwegian parties), and PoliBiasES (2,480 motions and votes from 10 Spanish parties). Across these benchmarks, we assess ideological tendencies and political entity bias in LLM behavior. As part of our evaluation framework, we also propose a method to visualize the ideology of LLMs and political parties in a shared two-dimensional CHES (Chapel Hill Expert Survey) space by linking their voting-based positions to the CHES dimensions, enabling direct and interpretable comparisons between models and real-world political actors. Our experiments reveal fine-grained ideological distinctions: state-of-the-art LLMs consistently display left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties. These findings highlight the value of transparent, cross-national evaluation grounded in real parliamentary behavior for understanding and auditing political bias in modern LLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [113] [Hierarchical Sparse Plus Low Rank Compression of LLM](https://arxiv.org/abs/2601.07839)
*Pawan Kumar,Aditi Gupta*

Main category: cs.LG

TL;DR: 提出两阶段的层次稀疏+低秩(HSS)压缩，用于大型语言模型的高效存储与训练；先将大权重稀疏化到S，再对密集残差矩阵进行递归的HSS低秩分解，并通过RCM置换对齐高权重以提高可压缩性；可端到端训练。


<details>
  <summary>Details</summary>
Motivation: LLMs对内存和计算资源压力巨大，需高效且可训练的压缩方法以减少推理与持续训练成本，同时保持性能水平。

Method: 两阶段：1) 将最大模的权重转入稀疏矩阵S；2) 对残差矩阵应用递归的Hierarchical Sparse Separable低秩因子分解，并用递归的降秩策略与RCM置换对齐高权重到对角线附近以提升跨对角线的可压缩性。 MV=一个稀疏矩阵乘积加若干薄矩阵乘法，支持端到端训练；仅对自注意力投影(Q,K,V)等1.6B参数进行压缩。

Result: 在LLaMA-7B上，针对自注意力投影的30%稀疏+外部秩512，sHSS-RCM在WikiText测试集上 perplexity达到1.64，优于密集基线和经典稀疏+SVD方法，同时显著降低内存占用。

Conclusion: HSS提供一种高效的稀疏+低秩混合压缩框架，局部化地对自注意力进行压缩，能在保持接近基线性能的同时实现显著的内存节省，且可端到端训练。

Abstract: Modern large language models (LLMs) place extraordinary pressure on memory and compute budgets, making principled compression indispensable for both deployment and continued training. We present Hierarchical Sparse Plus Low-Rank (HSS) compression, a two-stage scheme that (i) removes the largest-magnitude weights into a sparse matrix S and (ii) applies a recursive Hierarchically Sparse Separable (HSS) low-rank factorisation to the dense residual matrix. A recursive rank-reducing strategy and a reverse Cuthill-Mckee (RCM) permutation are introduced to align high weights towards the diagonal with the block-diagonal hierarchy, maximising off-diagonal compressibility (because they are touched only once). HSS is hardware-friendly: its matrix-vector multiply reduces to one sparse and a sequence of thin-matrix multiplications and can be trained end-to-end with standard optimisers.
  Experiments on LLaMA-7B show that targeting only the self-attention projections (1.6 B parameters of Q, K, and V matrices out of a total 7B parameters) suffices to yield large memory savings while retaining comparable state-of-the-art perplexity scores on test samples of the WikiText dataset. For example, with a 30\% sparsity budget and an outer rank of 512, sHSS-RCM achieves a perplexity of 1.64, outperforming dense baselines and classical sparse-plus-SVD variants, while also achieving significant memory savings.

</details>


### [114] [Affect and Effect: Limitations of regularisation-based continual learning in EEG-based emotion classification](https://arxiv.org/abs/2601.07858)
*Nina Peire,Yupei Li,Björn Schuller*

Main category: cs.LG

TL;DR: 正则化型持续学习在EEG情感分类中对 unseen subjects 的泛化效果有限，存在稳定性-塑性错配；前向迁移几乎没有提升，后向遗忘得到抑制但未带来新增信息，且受数据噪声、任务顺序影响显著。


<details>
  <summary>Details</summary>
Motivation: EEG情感识别对个体间和个体内变异性极高，持续学习有潜力解决“忘记旧任务”同时“快速适应新任务”的挑战，但常用的正则化型CL方法在此领域的适用性尚未被充分验证。

Method: 在DREAMER和SEED数据集上进行理论与实证分析，使用 subject-incremental 序列评估正则化型CL方法（EWC、SI、MAS）的稳定性-塑性权衡。考察参数重要性估计的鲁棒性、梯度是否相互干扰、累积的重要性对优化的约束、以及任务顺序对性能的影响；比较与序贯微调的差异。

Result: 发现正则化型CL在EEG情感分类上表现有限：1) 稳定性-塑性权衡导致更关注遗忘而非对新 subjects 的适应；2) 噪声和协变量漂移下参数重要性估计鲁棒性下降；3) 重要性梯度干扰新任务的梯度更新，使优化偏离最小点；4) 随着任务增多，重要性累积对模型的约束增强且敏感于 subject 顺序；5) 前向迁移未显著优于直接序贯微调（p > 0.05）。

Conclusion: 对 unseen subjects 的鲁棒泛化，正则化型CL方法在EEG情感分类中受限，需转向更关注前向迁移和表征学习的策略，或开发更适配EEG数据特性的CL方法。

Abstract: Generalisation to unseen subjects in EEG-based emotion classification remains a challenge due to high inter-and intra-subject variability. Continual learning (CL) poses a promising solution by learning from a sequence of tasks while mitigating catastrophic forgetting. Regularisation-based CL approaches, such as Elastic Weight Consolidation (EWC), Synaptic Intelligence (SI), and Memory Aware Synapses (MAS), are commonly used as baselines in EEG-based CL studies, yet their suitability for this problem remains underexplored. This study theoretically and empirically finds that regularisation-based CL methods show limited performance for EEG-based emotion classification on the DREAMER and SEED datasets. We identify a fundamental misalignment in the stability-plasticity trade-off, where regularisation-based methods prioritise mitigating catastrophic forgetting (backward transfer) over adapting to new subjects (forward transfer). We investigate this limitation under subject-incremental sequences and observe that: (1) the heuristics for estimating parameter importance become less reliable under noisy data and covariate shift, (2) gradients on parameters deemed important by these heuristics often interfere with gradient updates required for new subjects, moving optimisation away from the minimum, (3) importance values accumulated across tasks over-constrain the model, and (4) performance is sensitive to subject order. Forward transfer showed no statistically significant improvement over sequential fine-tuning (p > 0.05 across approaches and datasets). The high variability of EEG signals means past subjects provide limited value to future subjects. Regularisation-based continual learning approaches are therefore limited for robust generalisation to unseen subjects in EEG-based emotion classification.

</details>


### [115] [RewriteNets: End-to-End Trainable String-Rewriting for Generative Sequence Modeling](https://arxiv.org/abs/2601.07868)
*Harshil Vejendla*

Main category: cs.LG

TL;DR: RewriteNets: explicit, parallel string-rewriting layers with learnable rules; better systematic generalization and efficiency than Transformers.


<details>
  <summary>Details</summary>
Motivation: Transformers的注意力机制对序列长度的二次复杂度，以及对结构的隐式编码，促使提出显式的结构性归纳偏置，通过规则驱动的替换来提高泛化性与计算效率。

Method: 层级架构中，每层包含一组可学习的重写规则。对输入序列的每个位置，执行（1）规则模式的模糊匹配，（2）通过可微分的分配算子解决冲突以选择不重叠的替换，（3）将选中的规则应用于替换输入片段成可能长度不同的输出片段，（4）传播未被改动的标记。尽管离散规则分配不可微，但采用直通Gumbel-Sinkhorn估计实现端到端训练。对算法、组合性、字符串操作任务进行评估，并与强大的LSTM与Transformer基线进行比较，附带消融研究与学习到的规则分析。

Result: 在需要系统性泛化的任务上，RewriteNets表现优异（如SC...N在长度分割上的准确率达到98.7%），且在计算上比Transformer更高效；对学习到的规则进行分析，并通过广泛的消融研究支持该架构在具备显式结构性归纳偏置的序列建模中的潜力。

Conclusion: 通过显式的结构化、并行的重写规则，为序列建模提供了一种有前景的替代路径，兼具高效计算与强系统性泛化能力。

Abstract: Dominant sequence models like the Transformer represent structure implicitly through dense attention weights, incurring quadratic complexity. We propose RewriteNets, a novel neural architecture built on an alternative paradigm: explicit, parallel string rewriting. Each layer in a RewriteNet contains a set of learnable rules. For each position in an input sequence, the layer performs four operations: (1) fuzzy matching of rule patterns, (2) conflict resolution via a differentiable assignment operator to select non-overlapping rewrites, (3) application of the chosen rules to replace input segments with output segments of potentially different lengths, and (4) propagation of untouched tokens. While the discrete assignment of rules is non-differentiable, we employ a straight-through Gumbel-Sinkhorn estimator, enabling stable end-to-end training. We evaluate RewriteNets on algorithmic, compositional, and string manipulation tasks, comparing them against strong LSTM and Transformer baselines. Results show that RewriteNets excel at tasks requiring systematic generalization (achieving 98.7% accuracy on the SCAN benchmark's length split) and are computationally more efficient than Transformers. We also provide an analysis of learned rules and an extensive ablation study, demonstrating that this architecture presents a promising direction for sequence modeling with explicit structural inductive biases.

</details>


### [116] [Multiplicative Orthogonal Sequential Editing for Language Models](https://arxiv.org/abs/2601.07873)
*Hao-Xiang Xu,Jun-Yu Ma,Ziqi Peng,Yuhao Sun,Zhen-Hua Ling,Jia-Chen Gu*

Main category: cs.LG

TL;DR: Proposes MOSE, a multiplicative orthogonal editing method that preserves numerical stability while improving sequential knowledge editing performance; outperforms additive methods with three LLMs.


<details>
  <summary>Details</summary>
Motivation: Address numerical instability and degradation of general abilities caused by additive knowledge editing updates. Existing additive/additive-based methods may worsen condition number and norm, limiting both editing performance and generalization.

Method: Introduce a multiplicative editing framework. Derive the update in a multiplicative form by embedding new knowledge into an orthogonal matrix that multiplies the original parameter matrix. This orthogonal factor preserves numerical stability while effecting edits.

Result: Compared to current knowledge editing methods across three LLMs, MOSE reduces deviation in the edited parameter matrix and maintains numerical stability. Achieves 12.08% higher sequential editing performance and retains 95.73% of general abilities on downstream tasks.

Conclusion: MOSE offers a principled, stability-preserving alternative to additive edits, delivering improved sequential editing performance while maintaining general abilities; code is publicly available.

Abstract: Knowledge editing aims to efficiently modify the internal knowledge of large language models (LLMs) without compromising their other capabilities. The prevailing editing paradigm, which appends an update matrix to the original parameter matrix, has been shown by some studies to damage key numerical stability indicators (such as condition number and norm), thereby reducing editing performance and general abilities, especially in sequential editing scenario. Although subsequent methods have made some improvements, they remain within the additive framework and have not fundamentally addressed this limitation. To solve this problem, we analyze it from both statistical and mathematical perspectives and conclude that multiplying the original matrix by an orthogonal matrix does not change the numerical stability of the matrix. Inspired by this, different from the previous additive editing paradigm, a multiplicative editing paradigm termed Multiplicative Orthogonal Sequential Editing (MOSE) is proposed. Specifically, we first derive the matrix update in the multiplicative form, the new knowledge is then incorporated into an orthogonal matrix, which is multiplied by the original parameter matrix. In this way, the numerical stability of the edited matrix is unchanged, thereby maintaining editing performance and general abilities. We compared MOSE with several current knowledge editing methods, systematically evaluating their impact on both editing performance and the general abilities across three different LLMs. Experimental results show that MOSE effectively limits deviations in the edited parameter matrix and maintains its numerical stability. Compared to current methods, MOSE achieves a 12.08% improvement in sequential editing performance, while retaining 95.73% of general abilities across downstream tasks. The code is available at https://github.com/famoustourist/MOSE.

</details>


### [117] [E^2-LLM: Bridging Neural Signals and Interpretable Affective Analysis](https://arxiv.org/abs/2601.07877)
*Fei Ma,Han Lin,Yifan Xie,Hongwei Ren,Xiaoyu Shen,Wenbo Ding,Qi Tian*

Main category: cs.LG

TL;DR: 提出 E^2-LLM，将 EEG 编码器与大语言模型结合，首次实现可解释的 EEG 情感分析的多模态推理框架，通过分阶段训练提升分类与零-shot 推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决 EEG 情感识别中的高跨主体变异、标注数据匮乏和缺乏可解释性等挑战；现有多模态大模型未针对神经信号的时空特征进行有效适配。

Method: 将预训练的 EEG 编码器与 Qwen 基于的大型语言模型连接，采用可学习的投影层，构建多阶段训练：情感判别的预训练、跨模态对齐、以及指令调优与链式推理（CoT）以实现可解释推理。

Result: 在涵盖七个情感类别的数据集上，E^2-LLM 在情感分类任务中表现出色；更大的模型变体表现出更高的可靠性和对复杂推理场景的零-shot 泛化能力。

Conclusion: 将生理信号与大模型的推理能力相结合，表明模型规模的扩大有助于提高识别准确性与可解释的情感理解，确立了生理信号与大语言模型结合的新范式。

Abstract: Emotion recognition from electroencephalography (EEG) signals remains challenging due to high inter-subject variability, limited labeled data, and the lack of interpretable reasoning in existing approaches. While recent multimodal large language models (MLLMs) have advanced emotion analysis, they have not been adapted to handle the unique spatiotemporal characteristics of neural signals. We present E^2-LLM (EEG-to-Emotion Large Language Model), the first MLLM framework for interpretable emotion analysis from EEG. E^2-LLM integrates a pretrained EEG encoder with Qwen-based LLMs through learnable projection layers, employing a multi-stage training pipeline that encompasses emotion-discriminative pretraining, cross-modal alignment, and instruction tuning with chain-of-thought reasoning. We design a comprehensive evaluation protocol covering basic emotion prediction, multi-task reasoning, and zero-shot scenario understanding. Experiments on the dataset across seven emotion categories demonstrate that E^2-LLM achieves excellent performance on emotion classification, with larger variants showing enhanced reliability and superior zero-shot generalization to complex reasoning scenarios. Our work establishes a new paradigm combining physiological signals with LLM reasoning capabilities, showing that model scaling improves both recognition accuracy and interpretable emotional understanding in affective computing.

</details>


### [118] [Sliced-Wasserstein Distribution Alignment Loss Improves the Ultra-Low-Bit Quantization of Large Language Models](https://arxiv.org/abs/2601.07878)
*Deyu Cao,Yixin Yin,Samin Aref*

Main category: cs.LG

TL;DR: 提出 sliced Wasserstein 损失用于 ultra-low-bit post-training quantization 的分布对齐，在不增加推理开销的前提下提升前沿量化方法（如 OmniQuant、TesseraQ）的精度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署成本高，资源消耗大。低于4位的量化容易破坏激活分布，导致性能显著下降，因此需要分布感知的校准方法来缓解 ultra-low-bit 的准确度损失。

Method: 引入 sliced Wasserstein 损失，通过对输出在随机线性投影上的分布对齐来近似全分布差异，与传统均方误差损失互补；无需增加推理开销，可与带 retraining 的 PTQ 框架结合（如 OmniQuant、TesseraQ）。

Result: 在 LLaMA-2-7B、OPT-6.7B、LLaMA-2-13B 等模型上，新的损失函数相较基线在 perplexity/下游任务准确度上有显著提升；对 OmniQuant 来说，恢复了 4.12-20.37% 的损失准确度（不同模型区间），对 OPT-6.7B 为 0.93-7.65%，对 LLaMA-2-13B 为 2.26-6.20%；对 TesseraQ 相对下降的准确度也恢复了 3.63-7.63% 的区间。

Conclusion: 分布对齐的 sliced Wasserstein 损失为 ultra-low-bit PTQ 提供了简单且有效的性能提升，可与现有前沿量化方法协同工作，且实现开源以促进后续研究。

Abstract: The benefits of most large language models come with steep and often hidden economic and environmental costs due to their resource usage inefficiency during deployment. Model quantization improves energy and memory efficiency through representing model parameters by lower-precision values. However, compression below 4-bits often distorts activation distributions and degrades performance. We address this challenge by introducing a sliced Wasserstein loss function for distribution-aware calibration in ultra-low-bit post-training quantization. The proposed loss aligns the output distributions of full-precision and quantized models under random linear projections, complementing standard mean-squared error loss without adding any computational overhead during inference. Our proposed loss function can be incorporated with any post-training quantization framework that has a retraining component. We demonstrate the performance gains of our proposed model by incorporating it with two frontier methods known as OmniQuant and TesseraQ. Compared to these two baselines, the proposed loss consistently improves both perplexity and downstream task accuracy across multiple ultra-low-bit settings. Our proposed loss function recovers 4.12-20.37% of the OmniQuant's lost accuracy on the language model LLaMA-2-7B, 0.93-7.65% on OPT-6.7B, and 2.26-6.20% on LLaMA-2-13B. TesseraQ's accuracy degradation is recovered by 3.63-7.63% in relative terms when augmented by our proposed loss function. Taken together, these results demonstrate that distributional alignment provides a simple yet effective performance boost that can push the limits of frontier quantization methods. Our method is available on GitHub to facilitate future progress in ultra-low-bit quantization.

</details>


### [119] [KVzap: Fast, Adaptive, and Faithful KV Cache Pruning](https://arxiv.org/abs/2601.07891)
*Simon Jegou,Maximilian Jeblick*

Main category: cs.LG

TL;DR: KVzap: 一种输入自适应的KV缓存近似压缩方法，快速且可用于预填充及解码，达到2–4×缓存压缩且几乎不损失准确性，在多模型和长上下文任务上领先KVpress。


<details>
  <summary>Details</summary>
Motivation: 随着变换器模型的上下文长度增加，KV缓存成为推理瓶颈；现有KV缓存裁剪方法速度/准确性权衡难以被主流推理引擎采用。

Method: 提出KVzap，对KVzip进行快速、输入自适应的近似，适用于预填充和解码阶段。

Result: 在Qwen3-8B、Llama-3.1-8B-Instruct、Qwen3-32B等模型和长上下文/推理任务上实现2–4×的KV缓存压缩，几乎无准确性损失，并在KVpress排行榜上达到最优性能。

Conclusion: KVzap为大规模语言模型的KV缓存提供实用的快速近似方案，提升推理效率并具备可部署性。

Abstract: Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. While many KV cache pruning methods have been proposed, they have not yet been adopted in major inference engines due to speed--accuracy trade-offs. We introduce KVzap, a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. On Qwen3-8B, Llama-3.1-8B-Instruct, and Qwen3-32B across long-context and reasoning tasks, KVzap achieves $2$--$4\times$ KV cache compression with negligible accuracy loss and achieves state-of-the-art performance on the KVpress leaderboard. Code and models are available at https://github.com/NVIDIA/kvpress.

</details>


### [120] [Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification](https://arxiv.org/abs/2601.07892)
*Hong Huang,Decheng Wu,Qiangqiang Hu,Guanghua Yu,Jinhai Yang,Jianchen Zhu,Xue Liu,Dapeng Wu*

Main category: cs.LG

TL;DR: 提出 Sherry，一种硬件友好三值量化框架，通过 3:4 细粒度稀疏性实现 1.25-bit 的有效宽度（4 个权重打包为 5 位），并引入 Arenas 机制在训练中防止权重陷阱，从而在不显著损失精度的前提下显著减小模型大小并提升硬件效率；在 LLaMA-3.2 的五项基准评测中与 SOTA 的三值量化保持一致，同时在英特尔 i7-14700HX CPU 的 1B 模型上实现零精度损失、25% 位宽节省和 10% 速度提升，代码开源。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上部署大语言模型时，内存和计算成本成为主要瓶颈。现有三值量化要么采用 2 位对齐打包造成比特浪费，要么采用 1.67 位的非规则打包导致推理速度下降，需找到能与通用硬件对齐且兼顾速度与精度的量化方案。

Method: 提出 3:4 细粒度稀疏性以实现近似 1.25-bit 宽度：将四个权重量打包成五位，恢复对数对齐。另外，提出 Arenas 巡回残差突触机制（annealing residual synapse）以避免稀疏三值训练中的权重陷阱，维持表示多样性并提升训练稳定性。

Result: 在 LLaMA-3.2 上对五项基准进行评估，Sherry 分别达到与最先进三值量化方法相当的性能，同时显著降低模型尺寸。在 CPU（Intel i7-14700HX）上的 1B 模型实现零精度损失相对于 SOTA 基线，并实现 25% 的位宽节省和约 10% 的推理加速。

Conclusion: Sherry 提供了一种硬件高效的三值量化框架，通过 3:4 稀疏性与打包策略实现接近理想 1.25-bit 的宽度，并通过 Arenas 增强训练稳定性与表示多样性，使其在边缘设备上具有实际可用性，同时保持或接近 SOTA 的精度与速度；代码已开源。

Abstract: The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. While ternary quantization offers a compelling solution by reducing weights to {-1, 0, +1}, current implementations suffer from a fundamental misalignment with commodity hardware. Most existing methods must choose between 2-bit aligned packing, which incurs significant bit wastage, or 1.67-bit irregular packing, which degrades inference speed. To resolve this tension, we propose Sherry, a hardware-efficient ternary quantization framework. Sherry introduces a 3:4 fine-grained sparsity that achieves a regularized 1.25-bit width by packing blocks of four weights into five bits, restoring power-of-two alignment. Furthermore, we identify weight trapping issue in sparse ternary training, which leads to representational collapse. To address this, Sherry introduces Arenas, an annealing residual synapse mechanism that maintains representational diversity during training. Empirical evaluations on LLaMA-3.2 across five benchmarks demonstrate that Sherry matches state-of-the-art ternary performance while significantly reducing model size. Notably, on an Intel i7-14700HX CPU, our 1B model achieves zero accuracy loss compared to SOTA baselines while providing 25% bit savings and 10% speed up. The code is available at https://github.com/Tencent/AngelSlim .

</details>


### [121] [Revealing the Attention Floating Mechanism in Masked Diffusion Models](https://arxiv.org/abs/2601.07894)
*Xin Dai,Pengcheng Huang,Zhenghao Liu,Shuo Wang,Yukun Yan,Chaojun Xiao,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.LG

TL;DR: MDMs exhibit Attention Floating: dynamic, dispersed attention anchors that move across denoising steps and layers, unlike ARMs' fixed sink. A two-level attention mechanism emerges: shallow layers use floating tokens to build a global structural framework, while deeper layers focus on semantic content. This pattern explains the strong in-context learning of MDMs and their superior performance on knowledge-intensive tasks, roughly doubling ARM performance.


<details>
  <summary>Details</summary>
Motivation: Address the under-explored internal attention mechanisms in masked diffusion models (MDMs) to understand their strong in-context learning and performance gains over autoregressive models (ARMs).

Method: Empirical analysis of attention maps across denoising steps and network layers in MDMs; identification and characterization of Attention Floating; examination of the roles of shallow versus deep layers in structuring global tokens versus semantic content; benchmarking on knowledge-intensive tasks; provision of code and data.

Result: Discovery of Attention Floating: dynamic, anchored attention that shifts over steps and layers. Shallow layers leverage floating tokens to construct a global structural framework, while deep layers allocate more capacity to semantic content. This mechanism accounts for enhanced in-context learning and a twofold performance gain on knowledge-intensive tasks compared to ARMs.

Conclusion: Proposes a mechanistic explanation for MDMs' strong in-context learning through a Shallow Structure-Aware, Deep Content-Focused attention pattern. The findings illuminate how attention dynamics underpin MDMs' empirical advantages, with available code and datasets enabling replication.

Abstract: Masked diffusion models (MDMs), which leverage bidirectional attention and a denoising process, are narrowing the performance gap with autoregressive models (ARMs). However, their internal attention mechanisms remain under-explored. This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers. Further analysis reveals its Shallow Structure-Aware, Deep Content-Focused attention mechanism: shallow layers utilize floating tokens to build a global structural framework, while deeper layers allocate more capability toward capturing semantic content. Empirically, this distinctive attention pattern provides a mechanistic explanation for the strong in-context learning capabilities of MDMs, allowing them to double the performance compared to ARMs in knowledge-intensive tasks. All codes and datasets are available at https://github.com/NEUIR/Attention-Floating.

</details>


### [122] [Large Language Models and Algorithm Execution: Application to an Arithmetic Function](https://arxiv.org/abs/2601.07898)
*Farah Ben Slama,Frédéric Armetta*

Main category: cs.LG

TL;DR: 提出 LLM-DAL，设计面向推理分解的监督训练，显著提升LLMs在复杂算法推理与泛化上的能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在内部化数据、自主执行算法方面的局限，探索通过结构化、分解式推理的有监督训练提升算法执行能力。

Method: 提出训练框架 LLM-DAL，通过设计引导模型分解问题、逐步推理的监督信号，提升复杂算法推理的训练过程。

Result: 在多项任务上，分解式训练显著提高了算法推理的准确性和泛化能力。

Conclusion: 通过对推理分解的有监督训练，LLM的算法执行与推理能力可提升，表明分解式学习是提升复杂任务的有效路径。

Abstract: Large Language Models (LLMs) have recently developed new advanced functionalities. Their effectiveness relies on statistical learning and generalization capabilities. However, they face limitations in internalizing the data they process and struggle, for instance, to autonomously execute algorithms. In this paper, we investigate the possibility of extending these models' capabilities to algorithm execution through specialized supervised training focused on reasoning decomposition. We introduce a training model called LLM-DAL (Large Language Model - Decompositional Algorithmic Learning), through which we demonstrate that LLMs' ability to perform complex algorithmic inferences and generalize can be significantly improved when the training method is properly designed to guide the model in its learning process.

</details>


### [123] [Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning](https://arxiv.org/abs/2601.07903)
*Jianqi Zhang,Jingyao Wang,Wenwen Qiang,Fanjiang Xu,Changwen Zheng*

Main category: cs.LG

TL;DR: 在冻结大语言模型的前提下，通过向每一层注入由示例信息经过学习得到的上下文向量，提升时间序列预测的性能，且避免提示长度增加。


<details>
  <summary>Details</summary>
Motivation: 解决LLM用于时间序列预测时，预训练分布与时序数据差异导致的预测性能下降，以及在不进行全模型微调的情况下带来的计算开销问题。

Method: 提出LVICL，基于向量化的ICL：使用一个可学习的上下文向量适配器从多个示例中自适应提取上下文向量；在前向传播时将该向量注入到LLM的每一层，从而提升预测表现；与传统将示例放入提示不同，且不增加提示长度；该向量能够抑制对预测有害的分量。

Result: 大量实验表明该方法有效，提升TSF性能并在保持冻结LLM的同时降低额外开销。

Conclusion: 向量注入式ICL为在不微调的情况下提升时间序列预测等任务的LLM表现提供了有效路径，未来可扩展到其他领域和任务。

Abstract: The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.

</details>


### [124] [Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation](https://arxiv.org/abs/2601.07935)
*Yuxin Yang,Aoxiong Zeng,Xiangquan Yang*

Main category: cs.LG

TL;DR: Proposes Med-MoE-LoRA, a parameter-efficient framework combining Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) for multi-task medical-domain adaptation, using asymmetric expert distribution and a Knowledge-Preservation Plugin to protect general reasoning, achieving superior performance and reduced interference.


<details>
  <summary>Details</summary>
Motivation: Address the stability-plasticity dilemma and task interference in adapting LLMs to specialized domains like medicine, while maintaining parameter efficiency.

Method: Integrates MoE with LoRA; implements an asymmetric expert distribution (deeper layers with higher LoRA density); introduces a Knowledge-Preservation Plugin to isolate general-purpose reasoning; employs soft merging with adaptive routing and rank-wise decoupling.

Result: Empirically outperforms standard LoRA and conventional MoE architectures on multiple clinical NLP tasks; demonstrates reduced task interference and preservation of general cognitive capabilities.

Conclusion: Med-MoE-LoRA is an effective, parameter-efficient approach for multi-task medical-domain adaptation that preserves broad reasoning abilities.

Abstract: The rapid evolution of Large Language Models (LLMs) has shifted focus from general-purpose capabilities to domain-specific expertise. However, adapting LLMs to specialized fields such as medicine presents two challenge: (1) the "Stability-Plasticity Dilemma", where the model must acquire complex clinical knowledge without suffering from catastrophic forgetting of general world knowledge; and (2) "Task Interference", where disparate sub-tasks, such as medical diagnosis, report summarization, and drug-drug interaction prediction, compete for limited low-rank parameter space. In this paper, we propose Med-MoE-LoRA, a novel framework that integrates Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) to enable efficient multi-task domain adaptation, especially for medical scenarios. Drawing inspiration from recent advances, our framework employs an asymmetric expert distribution where deeper layers are equipped with a higher density of LoRA experts to capture complex semantic abstractions. We further introduce a "Knowledge-Preservation Plugin", inspired by LoRA MoE, to isolate and protect general-purpose reasoning. By utilizing soft merging with adaptive routing and rank-wise decoupling, Med-MoE-LoRA achieves superior performance in medical benchmarks while reducing interference. Experimental results demonstrate that our approach consistently outperforms standard LoRA and conventional MoE architectures across multiple clinical NLP tasks while retaining the model's general cognitive capabilities.

</details>


### [125] [Coupled Diffusion-Encoder Models for Reconstruction of Flow Fields](https://arxiv.org/abs/2601.07946)
*AmirPouya Hemmasian,Amir Barati Farimani*

Main category: cs.LG

TL;DR: DiffCoder 将扩散模型与卷积ResNet编码器端到端训练，在强压缩下比VAE更好地保留流场的分布和谱特性，尤其在信息瓶颈严重时优势明显。


<details>
  <summary>Details</summary>
Motivation: 传统自编码器在强压缩下难以保留流场的高阶统计结构，点对点重构损失忽略分布与谱信息，需要一类能够保持统计性质的解码策略。

Method: 将编码器将流场压缩为潜在表示，并用条件化的扩散模型学习重建的生成先验，端到端训练，评估基于Kolmogorov流场的数据集，比较不同模型规模与压缩比的性能。

Result: 在强压缩下DiffCoder显著提升谱精度，VAE退化明显；两者的相对L2重构误差相当，但DiffCoder更好地保持分布结构；中等压缩下较大VAE仍具竞争力，表明扩散先验在信息瓶颈较严重时最具优势。

Conclusion: 基于扩散的解码为紧凑且统计一致的流场表示提供了有前景的路径，尤其在强信息瓶颈条件下能更好地保留统计与谱特性。

Abstract: Data-driven flow-field reconstruction typically relies on autoencoder architectures that compress high-dimensional states into low-dimensional latent representations. However, classical approaches such as variational autoencoders (VAEs) often struggle to preserve the higher-order statistical structure of fluid flows when subjected to strong compression. We propose DiffCoder, a coupled framework that integrates a probabilistic diffusion model with a conventional convolutional ResNet encoder and trains both components end-to-end. The encoder compresses the flow field into a latent representation, while the diffusion model learns a generative prior over reconstructions conditioned on the compressed state. This design allows DiffCoder to recover distributional and spectral properties that are not strictly required for minimizing pointwise reconstruction loss but are critical for faithfully representing statistical properties of the flow field. We evaluate DiffCoder and VAE baselines across multiple model sizes and compression ratios on a challenging dataset of Kolmogorov flow fields. Under aggressive compression, DiffCoder significantly improves the spectral accuracy while VAEs exhibit substantial degradation. Although both methods show comparable relative L2 reconstruction error, DiffCoder better preserves the underlying distributional structure of the flow. At moderate compression levels, sufficiently large VAEs remain competitive, suggesting that diffusion-based priors provide the greatest benefit when information bottlenecks are severe. These results demonstrate that the generative decoding by diffusion offers a promising path toward compact, statistically consistent representations of complex flow fields.

</details>


### [126] [Reinforcement Learning Methods for Neighborhood Selection in Local Search](https://arxiv.org/abs/2601.07948)
*Yannick Molinghen,Augustin Delecluse,Renaud De Landtsheer,Stefano Michelini*

Main category: cs.LG

TL;DR: 基于强化学习的邻域选择在局部搜索中的表现因问题而异；ε-greedy 作为鲁棒基线表现良好，而深度强化学习在运行时间显著增加情况下才可能带来边际收益；奖励设计对学习信号的稳定性至关重要。


<details>
  <summary>Details</summary>
Motivation: 评估强化学习在局部搜索的邻域选择中的有效性，并比较带臂机 (bandits) 与深度强化学习方法在不同组合优化问题上的表现。

Method: 将基于强化学习的邻域选择策略（多臂赌博机：UCB、ε-greedy；深度强化学习：PPO、Double DQN）作为局部搜索的邻域选择器，与多种基线方法在三个问题上进行对比：旅行商问题、带时间窗的提货与配送问题、汽车排序问题。分析奖励函数对学习信号的影响、问题特性对算法选择的影响，以及深度RL的计算开销。

Result: 结果表明算法性能随问题而异；ε-greedy 在大多数情况下稳定优于其他策略；深度RL在计算开销较大时才在运行时间显著拉长的情况下才具有竞争力；奖励函数的设计对学习的稳定性和信息量具有关键作用。

Conclusion: 深度强化学习在局部搜索中具备潜力，但受限于成本波动和较高计算开销；简单的带臂方法（如 ε-greedy）具有更稳健的性能与效率。要充分发挥RL在此领域的潜力，需重视奖励设计与问题特性。

Abstract: Reinforcement learning has recently gained traction as a means to improve combinatorial optimization methods, yet its effectiveness within local search metaheuristics specifically remains comparatively underexamined. In this study, we evaluate a range of reinforcement learning-based neighborhood selection strategies -- multi-armed bandits (upper confidence bound, $ε$-greedy) and deep reinforcement learning methods (proximal policy optimization, double deep $Q$-network) -- and compare them against multiple baselines across three different problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem. We show how search-specific characteristics, particularly large variations in cost due to constraint violation penalties, necessitate carefully designed reward functions to provide stable and informative learning signals. Our extensive experiments reveal that algorithm performance varies substantially across problems, although that $ε$-greedy consistently ranks among the best performers. In contrast, the computational overhead of deep reinforcement learning approaches only makes them competitive with a substantially longer runtime. These findings highlight both the promise and the practical limitations of deep reinforcement learning in local search.

</details>


### [127] [InfGraND: An Influence-Guided GNN-to-MLP Knowledge Distillation](https://arxiv.org/abs/2601.08033)
*Amir Eskandari,Aman Anand,Elyas Rashno,Farhana Zulkernine*

Main category: cs.LG

TL;DR: 提出 InfGraND，一种基于节点结构影响的知识蒸馏框架，将 GNN 教师的知识有选择地蒸馏给 MLP 学生，并通过一次性多跳邻域特征预计算实现结构感知，显著提升 GNN->MLP KD 的性能，且不增加推理时延。


<details>
  <summary>Details</summary>
Motivation: 解决低延迟/资源受限场景下 GNN 的推理成本问题，改进单纯的 KD 或图不敏感的蒸馏方法，并弥合 MLP 学习能力与图结构信息之间的差距。

Method: 定义结构性影响节点的度量并据此对蒸馏样本进行加权；在学生端引入结构感知，通过一次性对多跳邻域进行特征预计算，丰富输入特征，避免推理时开销；在传导性和归纳性评估中比较与现有 KD 方法。

Result: 在七个同质同构数据集上进行 transductive 和 inductive 评估，InfGraND 在大多数情况下超越先前的 GNN->MLP KD 方法，证明在低延迟应用中的实用性。

Conclusion: 引入结构影响导向的蒸馏框架与前赴一步的邻域特征预计算，提升 KD 的效能和适用性，提供对图结构信息在知识蒸馏中的新视角。

Abstract: Graph Neural Networks (GNNs) are the go-to model for graph data analysis. However, GNNs rely on two key operations - aggregation and update, which can pose challenges for low-latency inference tasks or resource-constrained scenarios. Simple Multi-Layer Perceptrons (MLPs) offer a computationally efficient alternative. Yet, training an MLP in a supervised setting often leads to suboptimal performance. Knowledge Distillation (KD) from a GNN teacher to an MLP student has emerged to bridge this gap. However, most KD methods either transfer knowledge uniformly across all nodes or rely on graph-agnostic indicators such as prediction uncertainty. We argue this overlooks a more fundamental, graph-centric inquiry: "How important is a node to the structure of the graph?" We introduce a framework, InfGraND, an Influence-guided Graph KNowledge Distillation from GNN to MLP that addresses this by identifying and prioritizing structurally influential nodes to guide the distillation process, ensuring that the MLP learns from the most critical parts of the graph. Additionally, InfGraND embeds structural awareness in MLPs through one-time multi-hop neighborhood feature pre-computation, which enriches the student MLP's input and thus avoids inference-time overhead. Our rigorous evaluation in transductive and inductive settings across seven homophilic graph benchmark datasets shows InfGraND consistently outperforms prior GNN to MLP KD methods, demonstrating its practicality for numerous latency-critical applications in real-world settings.

</details>


### [128] [Riemannian Zeroth-Order Gradient Estimation with Structure-Preserving Metrics for Geodesically Incomplete Manifolds](https://arxiv.org/abs/2601.08039)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 在黎曼度量不完备设置下进行零阶优化：通过构造结构保持且几何完整的度量 g'，使原度量下的静点保留；对对称两点零阶估计器进行纯内在的 MSE 分析，推导带内在估计量的 SGD 收敛性；在额外条件下，g' 下的 ε-静点等价于 g 下的 ε-静点，达到 geodesically 完备情形的复杂度上界；并有合成与网格优化任务的数值验证。


<details>
  <summary>Details</summary>
Motivation: 解决黎曼流形上地理不完备带来的优化困难，目标在不依赖外部嵌入的前提下，通过结构保持的完整度量实现理论分析与稳定算法。

Method: 1) 构造一个几何上完整且保持原静点集合的度量 g'；2) 以纯内在视角分析对称两点 zeroth-order estimator 的均方误差（MSE），仅依赖流形几何；3) 基于内在分析推导带 intrinsic estimator 的随机梯度下降（SGD）收敛性；4) 在额外条件下，证明 g' 的 ε-静点也为 g 的 ε-静点，达到最佳复杂度界。

Result: 给出理论保证：ε-静点在 g' 下的存在性与精度能够映射到 g 下的等效 ε-静点，复杂度与 geodesically 完备情形一致；数值实验在合成问题与网格优化任务中验证了理论的稳定性与实用性。

Conclusion: 提出一个在不完备黎曼几何中的零阶优化框架，利用结构保持的完整度量与内在分析实现稳定收敛与理论可解释性，拓展在不完备几何环境中的高效优化方法。

Abstract: In this paper, we study Riemannian zeroth-order optimization in settings where the underlying Riemannian metric $g$ is geodesically incomplete, and the goal is to approximate stationary points with respect to this incomplete metric. To address this challenge, we construct structure-preserving metrics that are geodesically complete while ensuring that every stationary point under the new metric remains stationary under the original one. Building on this foundation, we revisit the classical symmetric two-point zeroth-order estimator and analyze its mean-squared error from a purely intrinsic perspective, depending only on the manifold's geometry rather than any ambient embedding. Leveraging this intrinsic analysis, we establish convergence guarantees for stochastic gradient descent with this intrinsic estimator. Under additional suitable conditions, an $ε$-stationary point under the constructed metric $g'$ also corresponds to an $ε$-stationary point under the original metric $g$, thereby matching the best-known complexity in the geodesically complete setting. Empirical studies on synthetic problems confirm our theoretical findings, and experiments on a practical mesh optimization task demonstrate that our framework maintains stable convergence even in the absence of geodesic completeness.

</details>


### [129] [LUT-Compiled Kolmogorov-Arnold Networks for Lightweight DoS Detection on IoT Edge Devices](https://arxiv.org/abs/2601.08044)
*Oleksandr Kuznetsov*

Main category: cs.LG

TL;DR: LUT编译的KAN用于IoT DoS检测，显著降低推理延迟，同时保持高准确率，使在CPU边缘网关上实现实时检测成为可能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上实现高效入侵检测。DoS攻击对物联网生态造成严重威胁，但现有基于KAN的实现仍受限于在实时场景中的计算开销。

Method: 提出将B样条评估替换为预计算的量化查找表并使用线性插值的LUT编译流水线，针对分辨率L、量化方案及越界策略等变量进行系统评估，比较不同LUT配置对精度、延迟和内存的影响，目标是在保留检测质量的前提下大幅降低推理延迟。

Result: 模型参数约50k，约0.19 MB。原始精度99.0%。LUT-L=8后精度为98.96%，F1降幅<0.0004；batch=256时速度提升68倍，batch=1时超过5000倍，内存开销约2倍。实现对CPU-only IoT网关的确定性推理延迟和实时DoS检测。

Conclusion: LUT编译的KAN在精度、延迟与内存之间提供清晰的Pareto前沿，使在资源受限的IoT网关上实现实时DoS检测成为可能；通过对不同LUT分辨率、量化和越界策略的广泛评估，显示了方法的鲁棒性和可扩展性。

Abstract: Denial-of-Service (DoS) attacks pose a critical threat to Internet of Things (IoT) ecosystems, yet deploying effective intrusion detection on resource-constrained edge devices remains challenging. Kolmogorov-Arnold Networks (KANs) offer a compact alternative to Multi-Layer Perceptrons (MLPs) by placing learnable univariate spline functions on edges rather than fixed activations on nodes, achieving competitive accuracy with fewer parameters. However, runtime B-spline evaluation introduces significant computational overhead unsuitable for latency-critical IoT applications. We propose a lookup table (LUT) compilation pipeline that replaces expensive spline computations with precomputed quantized tables and linear interpolation, dramatically reducing inference latency while preserving detection quality. Our lightweight KAN model (50K parameters, 0.19~MB) achieves 99.0\% accuracy on the CICIDS2017 DoS dataset. After LUT compilation with resolution $L=8$, the model maintains 98.96\% accuracy (F1 degradation $<0.0004$) while achieving $\mathbf{68\times}$ speedup at batch size 256 and over $\mathbf{5000\times}$ speedup at batch size 1, with only $2\times$ memory overhead. We provide comprehensive evaluation across LUT resolutions, quantization schemes, and out-of-bounds policies, establishing clear Pareto frontiers for accuracy-latency-memory trade-offs. Our results demonstrate that LUT-compiled KANs enable real-time DoS detection on CPU-only IoT gateways with deterministic inference latency and minimal resource footprint.

</details>


### [130] [Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment](https://arxiv.org/abs/2601.08089)
*Qitao Tan,Xiaoying Song,Ningxi Cheng,Ninghao Liu,Xiaoming Zhai,Lingzi Hong,Yanzhi Wang,Zhen Xiang,Geng Yuan*

Main category: cs.LG

TL;DR: A post-training quantization-based defense, Q-realign, recovers and preserves safety alignment of large language models after task-specific fine-tuning, decoupling safety from training and enabling faster, memory-efficient deployment.


<details>
  <summary>Details</summary>
Motivation: Fine-tuning often erodes pretraining safety alignment, and existing defenses are either tightly coupled to training or computationally expensive. A post-hoc, lightweight method is needed to restore safety without retraining.

Method: Q-realign reframes post-training quantization as a dual-objective procedure for model compression and safety, guided by an analysis of the model's representational structure. This decouples safety alignment from fine-tuning and integrates naturally into modern deployment pipelines.

Result: Empirical results across multiple models and datasets show substantial reduction in unsafe behaviors while preserving task performance, with notable memory and GPU-hour savings. For example, safety alignment of a fine-tuned 7B LLM can be recovered on a single RTX 4090 in about 40 minutes.

Conclusion: Q-realign provides a practical, turnkey solution for safety-aware deployment by enabling post-hoc safety recovery through quantization without retraining.

Abstract: Public large language models (LLMs) are typically safety-aligned during pretraining, yet task-specific fine-tuning required for deployment often erodes this alignment and introduces safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on fine-tuning-derived priors for post-hoc correction, leaving safety recovery tightly coupled with training and incurring high computational overhead and a complex workflow. To address these challenges, we propose \texttt{Q-realign}, a post-hoc defense method based on post-training quantization, guided by an analysis of representational structure. By reframing quantization as a dual-objective procedure for compression and safety, \texttt{Q-realign} decouples safety alignment from fine-tuning and naturally piggybacks into modern deployment pipelines. Experiments across multiple models and datasets demonstrate that our method substantially reduces unsafe behaviors while preserving task performance, with significant reductions in memory usage and GPU hours. Notably, our approach can recover the safety alignment of a fine-tuned 7B LLM on a single RTX 4090 within 40 minutes. Overall, our work provides a practical, turnkey solution for safety-aware deployment.

</details>


### [131] [Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition](https://arxiv.org/abs/2601.08094)
*Zheng Zhou,Isabella McEvoy,Camilo E. Valderrama*

Main category: cs.LG

TL;DR: 提出一种融合框架，用本地通道描述符与全局试验级描述符实现跨受试者的情绪识别，采用双分支Transformer进行注意力融合并加入领域对抗正则化，对SEED-VII数据集在留一受试者交叉验证下达到约40%七类情绪识别的均值准确率，代码已发布。


<details>
  <summary>Details</summary>
Motivation: 跨受试者个体差异和短时/嘈杂记录对学习鲁棒表示造成挑战，需提升跨受试者泛化能力；通过结合局部通道级与全局试验级多视角表征并进行领域对抗正则化来实现更稳健的情绪识别。

Method: 建立局部表示：对每个通道，将差分熵与图论特征级联，形成通道级描述；全局表示：在试验级汇总时域、频域和复杂度特征。将两种表示通过双分支Transformer进行融合，采用基于注意力的融合策略并结合领域对抗正则化，对样本按强度阈值进行筛选。评估采用留一受试者交叉验证，在SEED-VII数据集上与单视角及经典基线相比显示优势。

Result: 所提出方法在跨受试者情绪识别任务中实现稳定的性能提升，七类情绪识别的平均准确率约为40%，显著优于基线。代码已开源。

Conclusion: 通过多视角表征与对抗域适应的融合方法提升了跨受试者的情绪识别泛化能力，证明局部与全局信息的互补性在EEG情绪识别中的有效性，并具有推广至其他跨受试者情境的潜力。

Abstract: Subject-independent EEG emotion recognition is challenged by pronounced inter-subject variability and the difficulty of learning robust representations from short, noisy recordings. To address this, we propose a fusion framework that integrates (i) local, channel-wise descriptors and (ii) global, trial-level descriptors, improving cross-subject generalization on the SEED-VII dataset. Local representations are formed per channel by concatenating differential entropy with graph-theoretic features, while global representations summarize time-domain, spectral, and complexity characteristics at the trial level. These representations are fused in a dual-branch transformer with attention-based fusion and domain-adversarial regularization, with samples filtered by an intensity threshold. Experiments under a leave-one-subject-out protocol demonstrate that the proposed method consistently outperforms single-view and classical baselines, achieving approximately 40% mean accuracy in 7-class subject-independent emotion recognition. The code has been released at https://github.com/Danielz-z/LGF-EEG-Emotion.

</details>


### [132] [STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order](https://arxiv.org/abs/2601.08107)
*Chengyang Gu,Yuxin Pan,Hui Xiong,Yize Chen*

Main category: cs.LG

TL;DR: 用LLMs生成带时间序的子目标序列及状态-子目标阶段映射，并基于势能式奖励塑形将稀疏的终端奖励转化为密集、时间上连贯的信号；以离线RL实现对长时序、稀疏奖励任务的高效学习，实验在四个基准上优于最先进的离线目标条件与分层RL方法，且对LLM噪声鲁棒。


<details>
  <summary>Details</summary>
Motivation: 解决离线RL在长时-稀疏奖励任务中的困难。现有目标条件和层次化离线RL往往忽略子目标之间的时间关系，且对奖励塑形依赖经验性且不精确，导致子最优解和学习效率低下。

Method: 让LLMs生成具有时间排序的子目标序列及对应的状态到子目标阶段的映射；基于潜在奖励塑形（potential-based shaping）将稀疏的终端奖励转化为密集且与子目标进度相关的奖励信号；将塑形后的奖励用于离线数据集的增强，提升离线训练的样本效率与策略性能。

Result: 在四个离散/连续的稀疏奖励基准上，STO-RL击败现有的离线目标条件和层次化基线，表现为更快收敛、更高成功率和更短的轨迹。消融实验表明对LLM生成的子目标序列中的噪声不敏感，仍具有鲁棒性。

Conclusion: LLM-guided的时间结构化子目标结合理论上有据的奖励塑形，提供一个可扩展且实用的解决长时-horizon离线RL的框架。

Abstract: Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions, but it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on imprecise reward shaping, leading to suboptimal policies. To address these issues, we propose STO-RL (Offline RL using LLM-Guided Subgoal Temporal Order), an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. The resulting augmented dataset with shaped rewards enables efficient offline training of high-performing policies. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL baselines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL's robustness to imperfect or noisy LLM-generated subgoal sequences, demonstrating that LLM-guided subgoal temporal structures combined with theoretically grounded reward shaping provide a practical and scalable solution for long-horizon offline RL.

</details>


### [133] [Intra-tree Column Subsampling Hinders XGBoost Learning of Ratio-like Interactions](https://arxiv.org/abs/2601.08121)
*Mykola Pinchuk*

Main category: cs.LG

TL;DR: 在XGBoost中，树内列采样削弱对ratio-like信号的合成，除非显式包含ratio特征，性能下降显著；在两种合成数据中，原始特征集下PR-AUC下降，最高可达54%，工程化ratio特征几乎消除该下降；若存在ratio结构，建议避免树内采样或添加ratio特征以提高可解释性与性能。


<details>
  <summary>Details</summary>
Motivation: 研究梯度提升树在混合噪声条件下对复合信号（如比例/比率信号）的合成能力，以及树内列采样（colsample_bylevel/colsample_bynode）对该能力的影响。

Method: 使用两种合成数据生成过程，其结构为两原始特征共用强干扰因子，目标由较小的微分因子决定。通过在XGBoost中改变colsample_bylevel和colsample_bynode，参数s取{0.4,0.6,0.8,0.9}，重点关注较少子采样（s>=0.8）。设置对照：包含工程化ratio的特征集。评估采用测试集PR-AUC及路径共用性指标。

Result: 在原始特征集情形下，树内列采样降低测试PR-AUC；在主过程中，当两个子采样参数都设为0.4时，相对下降达到54%。若引入工程化ratio特征，下降显著减弱甚至消失。路径共用性指标在信号下降的位置同步下降。

Conclusion: 若问题中存在ratio-like结构，应避免树内列采样，或确保显式包含ratio特征，以提高模型对该信号的利用和稳定性。

Abstract: Many applied problems contain signal that becomes clear only after combining multiple raw measurements. Ratios and rates are common examples. In gradient boosted trees, this combination is not an explicit operation: the model must synthesize it through coordinated splits on the component features. We study whether intra-tree column subsampling in XGBoost makes that synthesis harder. We use two synthetic data generating processes with cancellation-style structure. In both, two primitive features share a strong nuisance factor, while the target depends on a smaller differential factor. A log ratio cancels the nuisance and isolates the signal. We vary colsample_bylevel and colsample_bynode over s in {0.4, 0.6, 0.8, 0.9}, emphasizing mild subsampling (s >= 0.8). A control feature set includes the engineered ratio, removing the need for synthesis. Across both processes, intra-tree column subsampling reduces test PR-AUC in the primitives-only setting. In the main process the relative decrease reaches 54 percent when both parameters are set to 0.4. The effect largely disappears when the engineered ratio is present. A path-based co-usage metric drops in the same cells where performance deteriorates. Practically, if ratio-like structure is plausible, either avoid intra-tree subsampling or include the intended ratio features.

</details>


### [134] [Generalization Analysis and Method for Domain Generalization for a Family of Recurrent Neural Networks](https://arxiv.org/abs/2601.08122)
*Atefeh Termehchi,Ekram Hossain,Isaac Woungang*

Main category: cs.LG

TL;DR: 基于Koopman算子对RNN动态进行线性化以获得可解释性，并通过谱分析界定域迁移下的最坏泛化影响，进而提出域泛化方法提升鲁棒性，且在实际时间模式学习任务上验证。


<details>
  <summary>Details</summary>
Motivation: 现有DL在可解释性和泛化方面受限，且大多数泛化分析假设独立同分布，与序列数据的时序相关性不符。本文拟在RNN框架下同时分析可解释性与OOD泛化，并提出提高跨分布鲁棒性的域泛化方法。

Method: 将RNN状态演化建模为离散时间的非线性闭环反馈系统，利用Koopman算子将其非线性动力学近似为线性算子以实现可解释性；通过谱分析量化域移位对泛化误差的最坏情况；在此分析基础上提出域泛化方法以降低OOD误差；在实际的时间模式学习任务上进行验证。

Result: 在实际的时间序列任务上验证了该分析框架和域泛化方法的有效性，展示了解释性和对分布漂移的鲁棒性提升。

Conclusion: 通过Koopman线性化实现对RNN的可解释性，同时通过谱分析量化并减小域移位引起的泛化误差，本文提供了一个可验证的理论与方法用于提升序列模型的可解释性与跨域鲁棒性。

Abstract: Deep learning (DL) has driven broad advances across scientific and engineering domains. Despite its success, DL models often exhibit limited interpretability and generalization, which can undermine trust, especially in safety-critical deployments. As a result, there is growing interest in (i) analyzing interpretability and generalization and (ii) developing models that perform robustly under data distributions different from those seen during training (i.e. domain generalization). However, the theoretical analysis of DL remains incomplete. For example, many generalization analyses assume independent samples, which is violated in sequential data with temporal correlations. Motivated by these limitations, this paper proposes a method to analyze interpretability and out-of-domain (OOD) generalization for a family of recurrent neural networks (RNNs). Specifically, the evolution of a trained RNN's states is modeled as an unknown, discrete-time, nonlinear closed-loop feedback system. Using Koopman operator theory, these nonlinear dynamics are approximated with a linear operator, enabling interpretability. Spectral analysis is then used to quantify the worst-case impact of domain shifts on the generalization error. Building on this analysis, a domain generalization method is proposed that reduces the OOD generalization error and improves the robustness to distribution shifts. Finally, the proposed analysis and domain generalization approach are validated on practical temporal pattern-learning tasks.

</details>


### [135] [Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies](https://arxiv.org/abs/2601.08136)
*Zeyang Li,Sunbochen Tang,Navid Azizan*

Main category: cs.LG

TL;DR: 提出统一的逆向流匹配（RFM）框架，通过 Langevin Stein 算子构造零均值控制变差，统一噪声与梯度期望，扩展从扩散到流动策略的 Boltzmann 目标训练，并实现更低方差的最优估计器，提升在线 RL 的训练效率与稳定性。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习中目标分布为未归一化的 Boltzmann 分布，缺乏直接目标样本；扩散/流动策略训练存在高方差与样本效率问题，需要一个统一的理论框架来有效利用Q信息与样本。

Method: 将训练目标表述为给定中间噪声样本的后验均值估计，使用 Langevin Stein 算子构造零均值控制变差，推导出一个广义估计器族；证明噪声期望和梯度期望是该族的具体实例；实例化 RFM 以训练在线 RL 中的流动策略。

Result: 在连续控制基准上，使用 RFM 训练的流动策略相较于扩散策略基线表现出更高的性能与更稳定的训练过程。

Conclusion: RFM 为将 Boltzmann 目标从扩散推广到流动策略提供理论基础，并通过最优方差估计器实现 Q 值与 Q 梯度信息的有效结合，从而提升训练效率与稳定性。

Abstract: Diffusion and flow policies are gaining prominence in online reinforcement learning (RL) due to their expressive power, yet training them efficiently remains a critical challenge. A fundamental difficulty in online RL is the lack of direct samples from the target distribution; instead, the target is an unnormalized Boltzmann distribution defined by the Q-function. To address this, two seemingly distinct families of methods have been proposed for diffusion policies: a noise-expectation family, which utilizes a weighted average of noise as the training target, and a gradient-expectation family, which employs a weighted average of Q-function gradients. Yet, it remains unclear how these objectives relate formally or if they can be synthesized into a more general formulation. In this paper, we propose a unified framework, reverse flow matching (RFM), which rigorously addresses the problem of training diffusion and flow models without direct target samples. By adopting a reverse inferential perspective, we formulate the training target as a posterior mean estimation problem given an intermediate noisy sample. Crucially, we introduce Langevin Stein operators to construct zero-mean control variates, deriving a general class of estimators that effectively reduce importance sampling variance. We show that existing noise-expectation and gradient-expectation methods are two specific instances within this broader class. This unified view yields two key advancements: it extends the capability of targeting Boltzmann distributions from diffusion to flow policies, and enables the principled combination of Q-value and Q-gradient information to derive an optimal, minimum-variance estimator, thereby improving training efficiency and stability. We instantiate RFM to train a flow policy in online RL, and demonstrate improved performance on continuous-control benchmarks compared to diffusion policy baselines.

</details>


### [136] [Dynamic Graph Structure Learning via Resistance Curvature Flow](https://arxiv.org/abs/2601.08149)
*Chaoqun Fei,Huanjiang Liu,Tinglve Zhou,Yangyang Li,Tianyong Hao*

Main category: cs.LG

TL;DR: 提出利用有效阻抗的曲率流（RCF）替代Ollivier-Ricci曲率流的高成本算子，通过矩阵运算实现高效的曲率优化，用于图结构学习与表示学习，且设计了基于RCF的DGSL-RCF算法，在深度度量学习、流形学习等任务中显著提升表示质量与下游性能，且实现超过100x加速。


<details>
  <summary>Details</summary>
Motivation: 解决基于曲率的图结构优化在大规模数据集和深度学习框架中的计算开销问题，保留几何优化能力、提升可扩展性与可嵌入性。

Method: 提出RCF框架，利用电路物理中的有效阻抗将昂贵的曲率优化转化为高效的矩阵运算，通过曲率梯度引导边权重新分配以降噪并强化局部簇结构；给出RCF的力学机理与流形增强/噪声抑制解释，设计DGSL-RCF图优化算法并与深度学习模型兼容。

Result: 实现相较OCF的100x以上加速，在几何优化方面与OCF相当；在深度度量学习、流形学习和图结构学习等任务上，DGSL-RCF显著提升表示质量及下游任务性能。

Conclusion: RCF提供了一种高效、可扩展的曲率驱动图优化方案，能够与深度学习模型无缝集成，DGSL-RCF具备良好实证效果及理论基础，推动图数据的几何表示学习与噪声抑制。

Abstract: Geometric Representation Learning (GRL) aims to approximate the non-Euclidean topology of high-dimensional data through discrete graph structures, grounded in the manifold hypothesis. However, traditional static graph construction methods based on Euclidean distance often fail to capture the intrinsic curvature characteristics of the data manifold. Although Ollivier-Ricci Curvature Flow (OCF) has proven to be a powerful tool for dynamic topological optimization, its core reliance on Optimal Transport (Wasserstein distance) leads to prohibitive computational complexity, severely limiting its application in large-scale datasets and deep learning frameworks. To break this bottleneck, this paper proposes a novel geometric evolution framework: Resistance Curvature Flow (RCF). Leveraging the concept of effective resistance from circuit physics, RCF transforms expensive curvature optimization into efficient matrix operations. This approach achieves over 100x computational acceleration while maintaining geometric optimization capabilities comparable to OCF. We provide an in-depth exploration of the theoretical foundations and dynamical principles of RCF, elucidating how it guides the redistribution of edge weights via curvature gradients to eliminate topological noise and strengthen local cluster structures. Furthermore, we provide a mechanistic explanation of RCF's role in manifold enhancement and noise suppression, as well as its compatibility with deep learning models. We design a graph optimization algorithm, DGSL-RCF, based on this framework. Experimental results across deep metric learning, manifold learning, and graph structure learning demonstrate that DGSL-RCF significantly improves representation quality and downstream task performance.

</details>


### [137] [VBO-MI: A Fully Gradient-Based Bayesian Optimization Framework Using Variational Mutual Information Estimation](https://arxiv.org/abs/2601.08172)
*Farhad Mirkarimi*

Main category: cs.LG

TL;DR: 提出 VBO-MI，一种基于变分贝叶斯优化的互信息方法，通过 actor-critic 框架实现端到端梯度传播，显著降低 FLOPs，同时在高维和真实任务中保持或优越的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统 BNN-BO 在后验采样与采集函数优化上的高成本瓶颈，提升可扩展性与计算效率。

Method: 结合变分互信息估计的最新进展，设计一个由 action-net（导航输入空间）和变分 critic（估计信息增益）的演员-评论家结构，实现端到端梯度流，消除内循环的采集优化步骤。

Result: 在多种基准与真实任务上，VBO-MI 达到与基线相当或更优的优化性能，同时计算成本显著降低（多达 100× FLOPs 的提升），包括高维合成函数、PDE 优化、Lunar Lander 与 Pest Control 等。

Conclusion: VBO-MI 提供一个高效的变分信息驱动的 BO 框架，适合需要高维和复杂任务场景的应用，兼具性能与计算效率的提升。

Abstract: Many real-world tasks require optimizing expensive black-box functions accessible only through noisy evaluations, a setting commonly addressed with Bayesian optimization (BO). While Bayesian neural networks (BNNs) have recently emerged as scalable alternatives to Gaussian Processes (GPs), traditional BNN-BO frameworks remain burdened by expensive posterior sampling and acquisition function optimization. In this work, we propose {VBO-MI} (Variational Bayesian Optimization with Mutual Information), a fully gradient-based BO framework that leverages recent advances in variational mutual information estimation. To enable end-to-end gradient flow, we employ an actor-critic architecture consisting of an {action-net} to navigate the input space and a {variational critic} to estimate information gain. This formulation effectively eliminates the traditional inner-loop acquisition optimization bottleneck, achieving up to a {$10^2 \times$ reduction in FLOPs} compared to BNN-BO baselines. We evaluate our method on a diverse suite of benchmarks, including high-dimensional synthetic functions and complex real-world tasks such as PDE optimization, the Lunar Lander control problem, and categorical Pest Control. Our experiments demonstrate that VBO-MI consistently provides the same or superior optimization performance and computational scalability over the baselines.

</details>


### [138] [TabPFN Through The Looking Glass: An interpretability study of TabPFN and its internal representations](https://arxiv.org/abs/2601.08181)
*Aviral Gupta,Armaan Sethi,Dhruv Kumar*

Main category: cs.LG

TL;DR: Probes reveal that tabular foundational models store structured, interpretable information in hidden layers; linear, intermediate, and final quantities emerge across layers, enabling inspection of internal computations.


<details>
  <summary>Details</summary>
Motivation: Understand and quantify how tabular foundation models encode and transform information across layers to improve transparency and trustworthiness.

Method: Conduct a suite of probing experiments that test for (i) presence of linear regression coefficients, (ii) intermediate values from complex expressions, and (iii) final outputs in early hidden layers, analyzing how representations evolve across layers.

Result: Evidence that meaningful, structured information is stored in hidden representations; signals corresponding to intermediate and final quantities arise, showing refinement of inputs and emergence of the final prediction.

Conclusion: Tabular foundational models encode concrete, interpretable information in their representations, advancing transparency and trust in their decision processes.

Abstract: Tabular foundational models are pre-trained models designed for a wide range of tabular data tasks. They have shown strong performance across domains, yet their internal representations and learned concepts remain poorly understood. This lack of interpretability makes it important to study how these models process and transform input features. In this work, we analyze the information encoded inside the model's hidden representations and examine how these representations evolve across layers. We run a set of probing experiments that test for the presence of linear regression coefficients, intermediate values from complex expressions, and the final answer in early layers. These experiments allow us to reason about the computations the model performs internally. Our results provide evidence that meaningful and structured information is stored inside the representations of tabular foundational models. We observe clear signals that correspond to both intermediate and final quantities involved in the model's prediction process. This gives insight into how the model refines its inputs and how the final output emerges. Our findings contribute to a deeper understanding of the internal mechanics of tabular foundational models. They show that these models encode concrete and interpretable information, which moves us closer to making their decision processes more transparent and trustworthy.

</details>


### [139] [One-Shot Federated Ridge Regression: Exact Recovery via Sufficient Statistic Aggregation](https://arxiv.org/abs/2601.08216)
*Zahir Alsulaimawi*

Main category: cs.LG

TL;DR: 提出一种一击式联邦岭回归框架：客户端仅发送局部充分统计量（Gram矩阵与矩量向量），服务器通过单次矩阵求逆重建全局解，在覆盖条件下可精确恢复集中解；对异质分布给出非渐近误差界；通信成本显著降低，且具差分隐私、 dropout 鲁棒性与多项实用性设计；框架可扩展至核方法和随机特征模型，但不适用于通用非线性架构。


<details>
  <summary>Details</summary>
Motivation: 解决多轮通信带来的高成本与不稳定收敛问题，探究是否存在等效的一次性聚合方案以实现集中式解，从而提升通信效率与隐私保护。

Method: 将联邦岭回归建模为分布式均衡问题；每个客户端计算局部 Gram 矩阵 G_i = X_i^T X_i 与向量 b_i = X_i^T y_i，上传聚合统计量；服务器对统计量进行一次矩阵求逆以得到全局系数 β_hat；在覆盖条件下可实现对集中解的精确重建；对不满足覆盖的异质分布给出基于聚合 Gram 矩阵谱性质的非渐近误差界；通过随机投影将高维通信降至 O(m^2)；提供单次注入噪声的差分隐私保证；讨论掉线鲁棒性、联邦交叉验证与与梯度法的对比。

Result: 覆盖条件下可精确恢复集中岭回归解；异质场景给出非渐近误差界；合成实验表明一-shot 聚合达到与 FedAvg 相同精度时通信成本降低最多38倍；随机投影将通信降至 O(m^2)；框架可扩展至核方法与随机特征模型，但不适用于一般非线性结构。

Conclusion: 一次性聚合的联邦岭回归在理论与实验上均证实其等效性于集中解，显著降低通信与隐私成本并具鲁棒性，适用范围包括核方法与随机特征模型；未来工作包括扩展至更广模型、提升对覆盖性不足情况的适应性，以及更全面的隐私分析。

Abstract: Federated learning protocols require repeated synchronization between clients and a central server, with convergence rates depending on learning rates, data heterogeneity, and client sampling. This paper asks whether iterative communication is necessary for distributed linear regression. We show it is not. We formulate federated ridge regression as a distributed equilibrium problem where each client computes local sufficient statistics -- the Gram matrix and moment vector -- and transmits them once. The server reconstructs the global solution through a single matrix inversion. We prove exact recovery: under a coverage condition on client feature matrices, one-shot aggregation yields the centralized ridge solution, not an approximation. For heterogeneous distributions violating coverage, we derive non-asymptotic error bounds depending on spectral properties of the aggregated Gram matrix. Communication reduces from $\mathcal{O}(Rd)$ in iterative methods to $\mathcal{O}(d^2)$ total; for high-dimensional settings, we propose and experimentally validate random projection techniques reducing this to $\mathcal{O}(m^2)$ where $m \ll d$. We establish differential privacy guarantees where noise is injected once per client, eliminating the composition penalty that degrades privacy in multi-round protocols. We further address practical considerations including client dropout robustness, federated cross-validation for hyperparameter selection, and comparison with gradient-based alternatives. Comprehensive experiments on synthetic heterogeneous regression demonstrate that one-shot fusion matches FedAvg accuracy while requiring up to $38\times$ less communication. The framework applies to kernel methods and random feature models but not to general nonlinear architectures.

</details>


### [140] [Hyperbolic Heterogeneous Graph Transformer](https://arxiv.org/abs/2601.08251)
*Jongmin Park,Seunghoon Han,Hyewon Lee,Won-Yong Shin,Sungsu Lim*

Main category: cs.LG

TL;DR: 提出 HypHGT，一种在超曲线空间中运行的异构图 Transformer，解决切空间映射畸变与局部化消息传递局限，通过线性复杂度的关系特异超曲线注意力实现局部与全局依赖建模，在节点分类任务上超越 SOTA且更高效。


<details>
  <summary>Details</summary>
Motivation: 现有的超曲线空间异构图学习方法多依赖切空间操作，容易产生映射畸变；其消息传递架构偏向局部邻域信息，难以捕捉全局层级结构以及不同类型节点之间的长程依赖，亟需在超曲线空间内直接、高效地建模异构图的全局结构与语义。

Method: 提出 Hyperbolic Heterogeneous Graph Transformer (HypHGT)，完全在超曲线空间中学习表示；以 Transformer 架构同时捕捉局部与全局依赖；设计关系特异的超曲线注意力机制，具线性时间复杂度，兼顾高效性与跨关系信息保留。

Result: 实验结果显示 HypHGT 在节点分类任务上持续超越现有最先进方法，并显著降低训练时间与内存占用。

Conclusion: HypHGT 能在超曲线空间内有效捕捉异构图的复杂结构属性与语义信息，并通过高效的关系特异注意力实现对局部与全局依赖的统一建模，展现了更高的准确性与更优的计算效率。

Abstract: In heterogeneous graphs, we can observe complex structures such as tree-like or hierarchical structures. Recently, the hyperbolic space has been widely adopted in many studies to effectively learn these complex structures. Although these methods have demonstrated the advantages of the hyperbolic space in learning heterogeneous graphs, most existing methods still have several challenges. They rely heavily on tangent-space operations, which often lead to mapping distortions during frequent transitions. Moreover, their message-passing architectures mainly focus on local neighborhood information, making it difficult to capture global hierarchical structures and long-range dependencies between different types of nodes. To address these limitations, we propose Hyperbolic Heterogeneous Graph Transformer (HypHGT), which effectively and efficiently learns heterogeneous graph representations entirely within the hyperbolic space. Unlike previous message-passing based hyperbolic heterogeneous GNNs, HypHGT naturally captures both local and global dependencies through transformer-based architecture. Furthermore, the proposed relation-specific hyperbolic attention mechanism in HypHGT, which operates with linear time complexity, enables efficient computation while preserving the heterogeneous information across different relation types. This design allows HypHGT to effectively capture the complex structural properties and semantic information inherent in heterogeneous graphs. We conduct comprehensive experiments to evaluate the effectiveness and efficiency of HypHGT, and the results demonstrate that it consistently outperforms state-of-the-art methods in node classification task, with significantly reduced training time and memory usage.

</details>


### [141] [On Evaluation of Unsupervised Feature Selection for Pattern Classification](https://arxiv.org/abs/2601.08257)
*Gyu-Il Kim,Dae-Won Kim,Jaesung Lee*

Main category: cs.LG

TL;DR: 将多标签分类框架用于无监督特征选择的评估，揭示单标签评估的局限性并提出更公正的比较方式。


<details>
  <summary>Details</summary>
Motivation: 现有评估偏向单标签数据，导致不同选择的标签会改变方法排名；需要一个不受单一标签选择影响的评估框架。

Method: 在21个多标签数据集上，使用若干典型的无监督特征选择方法，按照多标签分类性能评估其有效性，并比较与单标签评估的排名差异。

Result: 多标签评估下的方法排名与单标签评估显著不同，表明单标签评估易产生偏见；多标签评估有助于更公平、可靠的比较。

Conclusion: 倡导采用多标签分类框架来评估无监督特征选择方法的辨别能力，以提高比较公平性与可靠性。

Abstract: Unsupervised feature selection aims to identify a compact subset of features that captures the intrinsic structure of data without supervised label. Most existing studies evaluate the performance of methods using the single-label dataset that can be instantiated by selecting a label from multi-label data while maintaining the original features. Because the chosen label can vary arbitrarily depending on the experimental setting, the superiority among compared methods can be changed with regard to which label happens to be selected. Thus, evaluating unsupervised feature selection methods based solely on single-label accuracy is unreasonable for assessing their true discriminative ability. This study revisits this evaluation paradigm by adopting a multi-label classification framework. Experiments on 21 multi-label datasets using several representative methods demonstrate that performance rankings differ markedly from those reported under single-label settings, suggesting the possibility of multi-label evaluation settings for fair and reliable comparison of unsupervised feature selection methods.

</details>


### [142] [A Usable GAN-Based Tool for Synthetic ECG Generation in Cardiac Amyloidosis Research](https://arxiv.org/abs/2601.08260)
*Francesco Speziale,Ugo Lomoio,Fabiola Boccuto,Pierangelo Veltri,Pietro Hiram Guzzi*

Main category: cs.LG

TL;DR: 基于GAN的ECG生成框架及命令行/图形界面，用于生成真实的合成心电波形以辅助CA早期诊断和患者分层，以及在少样本、类别不平衡数据环境下保留少数类分布。


<details>
  <summary>Details</summary>
Motivation: 心髓淀积性肌病（CA）罕见且诊断不足，现有机器学习数据集通常规模小、类别不平衡且异质性高；需要生成的合成数据来扩充训练集并保持少数类分布以改进模型性能。

Method: 训练面向类别的GANs以生成带标签的ECG beats，并提供用于训练生成器的一次性配置的图形/命令行界面，研究者可交互地生成大量带标签的合成心电波形，保留 minority class 的分布。

Result: 合成波形在保留少数类分布的前提下实现数据扩增，能够支持CA检测和分层的规模化数据增量，潜在提高不平衡数据下的ML模型表现。

Conclusion: 基于GAN的ECG合成生成及友好界面工具，有望通过扩充训练数据并维持类别分布来促进CA的早期诊断与患者分层。

Abstract: Cardiac amyloidosis (CA) is a rare and underdiagnosed infiltrative cardiomyopathy, and available datasets for machine-learning models are typically small, imbalanced and heterogeneous. This paper presents a Generative Adversarial Network (GAN) and a graphical command-line interface for generating realistic synthetic electrocardiogram (ECG) beats to support early diagnosis and patient stratification in CA. The tool is designed for usability, allowing clinical researchers to train class-specific generators once and then interactively produce large volumes of labelled synthetic beats that preserve the distribution of minority classes.

</details>


### [143] [Demystifying the Slash Pattern in Attention: The Role of RoPE](https://arxiv.org/abs/2601.08297)
*Yuan Cheng,Fengzhuo Zhang,Yunlong Hou,Cunxiao Du,Chao Du,Tianyu Pang,Aixin Sun,Zhuoran Yang*

Main category: cs.LG

TL;DR: Slash-Dominant Heads (SDHs) 在大语言模型中自发出现，源于查询-键结构和 RoPE 的频率分量分布；在这两条充分条件下，注意力沿 Δ-th 子对角线集中，且可从梯度下降训练的浅变换器中被证明会出现。


<details>
  <summary>Details</summary>
Motivation: 揭示 slash 注意力模式的成因及其信息在代际传递中的作用，提供理论与经验层面的统一解释。

Method: 对开源 LLM 进行实证分析，检查查询、键以及 RoPE 的性质；构建含 RoPE 的浅层 Transformer 的理论建模，并在给定条件下分析训练动力学，证明 SDHs 的出现；并验证对分布外提示的泛化。

Result: 给出两条充分条件： (1) 查询和键几乎秩-一；(2) RoPE 的中高频成分主导。满足这两点时，查询/键在标记间几乎相同，RoPE 的中高频相互作用促成 SDHs；训练下的梯度下降能出现 SDHs，且 SDHs 能泛化至分布外提示。

Conclusion: SDHs 是模型的内在特性，与 RoPE 和 Q/K 的结构密切相关；理论与实证结果共同解释了信息在序列中的跨越与传递方式，为理解 transformers 的信息路由提供了依据。

Abstract: Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the $Δ$-th sub-diagonal for some offset $Δ$. These patterns play a key role in passing information across tokens. But why do they emerge? In this paper, we demystify the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. First, by analyzing open-source LLMs, we find that SDHs are intrinsic to models and generalize to out-of-distribution prompts. To explain the intrinsic emergence, we analyze the queries, keys, and Rotary Position Embedding (RoPE), which jointly determine attention scores. Our empirical analysis reveals two characteristic conditions of SDHs: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. Under these conditions, queries and keys are nearly identical across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs. Beyond empirical evidence, we theoretically show that these conditions are sufficient to ensure the emergence of SDHs by formalizing them as our modeling assumptions. Particularly, we analyze the training dynamics of a shallow Transformer equipped with RoPE under these conditions, and prove that models trained via gradient descent exhibit SDHs. The SDHs generalize to out-of-distribution prompts.

</details>


### [144] [ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning](https://arxiv.org/abs/2601.08310)
*Kun Liang,Clive Bai,Xin Xu,Chenming Tang,Sanwoo Lee,Weijie Liu,Saiyong Yang,Yunfang Wu*

Main category: cs.LG

TL;DR: ORBIT 是一个可控多预算推理框架，通过多阶段强化学习发现每个预算下的帕累托最优推理行为，并通过 on-policy distillation 将这些行为融合成一个单一模型，同时保持清晰的模式分离和高性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在推理阶段对长篇Chain-of-Thought的统一长推理成本高且不必要，现有按预算推理的策略要么不可靠要么在训练阶段固定了成本-精度权衡，缺乏在不同部署场景的灵活性。

Method: 利用多阶段强化学习在每个预算层面发现帕累托最优的推理行为集合，并通过 on-policy distillation 将这些多模式行为整合为一个统一的学生模型，使模型具备能按输入激活不同推理模式的能力。

Result: 实验表明：1) 能实现跨多种模式的可控推理行为；2) 每种模式内具备具有竞争力的推理密度；3) 将前沿策略整合到单一学生模型，同时保持模式分离和每种模式的高性能。

Conclusion: ORBIT 提供了一种可控的多预算推理框架，能够在不同输入条件下激活不同推理模式，并通过前沿策略的蒸馏实现单一模型的部署，同时保持清晰的模式边界和高水平的模式内性能。

Abstract: Recent Large Reasoning Models (LRMs) achieve strong performance by leveraging long-form Chain-of-Thought (CoT) reasoning, but uniformly applying overlong reasoning at inference time incurs substantial and often unnecessary computational cost. To address this, prior work explores various strategies to infer an appropriate reasoning budget from the input. However, such approaches are unreliable in the worst case, as estimating the minimal required reasoning effort is fundamentally difficult, and they implicitly fix the trade-off between reasoning cost and accuracy during training, limiting flexibility under varying deployment scenarios. Motivated by these limitations, we propose ORBIT, a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input. ORBIT employs multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model. Experiments show that ORBIT achieves (1) controllable reasoning behavior over multiple modes, (2) competitive reasoning density within each mode, and (3) integration of these frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance.

</details>


### [145] [Deep Exploration of Epoch-wise Double Descent in Noisy Data: Signal Separation, Large Activation, and Benign Overfitting](https://arxiv.org/abs/2601.08316)
*Tomoki Kubo,Ryuken Uda,Yusuke Iida*

Main category: cs.LG

TL;DR: Epoch-wise double descent observed in deep nets trained on CIFAR-10 with 30% label noise; three main findings: (1) benign overfitting during double descent; (2) noisy data learned after clean data with increasing separation of activations; (3) emergence of a single large activation in a shallow layer correlated with input patterns; links deep double descent, benign overfitting, and large activations; proposes a new scenario for understanding deep double descent.


<details>
  <summary>Details</summary>
Motivation: Clarify how internal representations evolve during epoch-wise double descent and how this relates to generalization phenomena in deep learning.

Method: Train fully-connected networks of three sizes on CIFAR-10 with 30% label noise; decompose training loss into clean vs noisy data contributions; analyze epoch-wise evolution of internal signals, including layer-wise activations and separability between clean and noisy data.

Result: Three findings described in the abstract: (1) strong test re-generalization after fitting noisy data (benign overfitting); (2) noisy data learned after clean data with increasing separation in outer layers, enabling overfitting to noisy data; (3) emergence of a single very large activation in a shallow layer correlated with input patterns, not outputs.

Conclusion: The findings link deep double descent, benign overfitting, and large activations, offering a novel perspective for understanding deep double descent and guiding future theoretical and empirical work.

Abstract: Deep double descent is one of the key phenomena underlying the generalization capability of deep learning models. In this study, epoch-wise double descent, which is delayed generalization following overfitting, was empirically investigated by focusing on the evolution of internal structures. Fully connected neural networks of three different sizes were trained on the CIFAR-10 dataset with 30% label noise. By decomposing the loss curves into signal contributions from clean and noisy training data, the epoch-wise evolutions of internal signals were analyzed separately. Three main findings were obtained from this analysis. First, the model achieved strong re-generalization on test data even after perfectly fitting noisy training data during the double descent phase, corresponding to a "benign overfitting" state. Second, noisy data were learned after clean data, and as learning progressed, their corresponding internal activations became increasingly separated in outer layers; this enabled the model to overfit only noisy data. Third, a single, very large activation emerged in the shallow layer across all models; this phenomenon is referred as "outliers," "massive activa-tions," and "super activations" in recent large language models and evolves with re-generalization. The magnitude of large activation correlated with input patterns but not with output patterns. These empirical findings directly link the recent key phenomena of "deep double descent," "benign overfitting," and "large activation", and support the proposal of a novel scenario for understanding deep double descent.

</details>


### [146] [Automated Machine Learning in Radiomics: A Comparative Evaluation of Performance, Efficiency and Accessibility](https://arxiv.org/abs/2601.08334)
*Jose Lozano-Montoya,Emilio Soria-Olivas,Almudena Fuster-Matanzo,Angel Alberich-Bayarri,Ana Jimenez-Pastor*

Main category: cs.LG

TL;DR: AutoML can support radiomics modeling but shows uneven performance across frameworks; radiomics-specific tools offer limited practicality due to obsolescence or inefficiency, while general-purpose AutoMLs are more accessible but may miss radiomics-specific needs.


<details>
  <summary>Details</summary>
Motivation: Assess how general-purpose vs radiomics-specific AutoML frameworks perform on radiomics classification tasks, and identify gaps hindering their adoption in radiomics research.

Method: Evaluation of six general-purpose and five radiomics-specific AutoML frameworks on ten public/private radiomics datasets (CT/MRI) with varied sizes, anatomies, endpoints; standardized cross-validation; predefined parameters; metrics: AUC, runtime, software status, accessibility, and interpretability.

Result: Simplatab (radiomics-specific, no-code) achieved highest average test AUC (81.81%) with ~1 h runtime; LightAutoML (general-purpose) was fastest with mean AUC 78.74% in ~6 min; many radiomics-specific frameworks were excluded due to obsolescence, heavy programming requirements, or inefficiency; general-purpose frameworks offered higher accessibility and easier implementation.

Conclusion: Simplatab provides a favorable balance of performance, efficiency, and accessibility for radiomics classification, but key radiomics-specific gaps remain (survival analysis support, feature reproducibility, harmonization). Future work should adapt AutoML to address these radiomics-specific challenges.

Abstract: Automated machine learning (AutoML) frameworks can lower technical barriers for predictive and prognostic model development in radiomics by enabling researchers without programming expertise to build models. However, their effectiveness in addressing radiomics-specific challenges remains unclear. This study evaluates the performance, efficiency, and accessibility of general-purpose and radiomics-specific AutoML frameworks on diverse radiomics classification tasks, thereby highlighting development needs for radiomics. Ten public/private radiomics datasets with varied imaging modalities (CT/MRI), sizes, anatomies and endpoints were used. Six general-purpose and five radiomics-specific frameworks were tested with predefined parameters using standardized cross-validation. Evaluation metrics included AUC, runtime, together with qualitative aspects related to software status, accessibility, and interpretability. Simplatab, a radiomics-specific tool with a no-code interface, achieved the highest average test AUC (81.81%) with a moderate runtime (~1 hour). LightAutoML, a general-purpose framework, showed the fastest execution with competitive performance (78.74% mean AUC in six minutes). Most radiomics-specific frameworks were excluded from the performance analysis due to obsolescence, extensive programming requirements, or computational inefficiency. Conversely, general-purpose frameworks demonstrated higher accessibility and ease of implementation. Simplatab provides an effective balance of performance, efficiency, and accessibility for radiomics classification problems. However, significant gaps remain, including the lack of accessible survival analysis support and the limited integration of feature reproducibility and harmonization within current AutoML frameworks. Future research should focus on adapting AutoML solutions to better address these radiomics-specific challenges.

</details>


### [147] [Decodable but not structured: linear probing enables Underwater Acoustic Target Recognition with pretrained audio embeddings](https://arxiv.org/abs/2601.08358)
*Hilde I. Hummel,Sandjai Bhulai,Rob D. van der Mei,Burooj Ghani*

Main category: cs.LG

TL;DR: 通过对多源预训练音频模型的嵌入进行被冻结权重的线性探针分析，系统比较了在水下目标识别中的迁移学习效果，发现嵌入空间主要受记录特征支配，但线性探针可抑制这类干扰并提取船型信息，从而实现低成本的自动UATR。


<details>
  <summary>Details</summary>
Motivation: 解决水下声学监测中标注数据稀缺的问题；利用迁移学习与线性探针在大规模PAM数据上实现高效、低成本的船舶噪声识别。

Method: 选取来自多源的预训练音频模型并冻结权重，提取嵌入；对嵌入进行分类、聚类和相似性评估；训练线性探针以抑制记录特征并保留船型信息；在不同域模型上比较迁移学习效果。

Result: 嵌入空间很大程度上被记录特征所支配；简单线性探针能显著抑制记录信息、提取船型特征；线性探针在低计算成本下实现有效的UATR，减少对大量高质量带标签船舶录音的需求。

Conclusion: 跨域预训练音频模型通过线性探针在水下目标识别任务中展现出有效且高效的迁移学习潜力，适合在标注数据有限的场景中应用。

Abstract: Increasing levels of anthropogenic noise from ships contribute significantly to underwater sound pollution, posing risks to marine ecosystems. This makes monitoring crucial to understand and quantify the impact of the ship radiated noise. Passive Acoustic Monitoring (PAM) systems are widely deployed for this purpose, generating years of underwater recordings across diverse soundscapes. Manual analysis of such large-scale data is impractical, motivating the need for automated approaches based on machine learning. Recent advances in automatic Underwater Acoustic Target Recognition (UATR) have largely relied on supervised learning, which is constrained by the scarcity of labeled data. Transfer Learning (TL) offers a promising alternative to mitigate this limitation. In this work, we conduct the first empirical comparative study of transfer learning for UATR, evaluating multiple pretrained audio models originating from diverse audio domains. The pretrained model weights are frozen, and the resulting embeddings are analyzed through classification, clustering, and similarity-based evaluations. The analysis shows that the geometrical structure of the embedding space is largely dominated by recording-specific characteristics. However, a simple linear probe can effectively suppress this recording-specific information and isolate ship-type features from these embeddings. As a result, linear probing enables effective automatic UATR using pretrained audio models at low computational cost, significantly reducing the need for a large amounts of high-quality labeled ship recordings.

</details>


### [148] [Controlled LLM Training on Spectral Sphere](https://arxiv.org/abs/2601.08393)
*Tian Xie,Haoming Luo,Haoyu Tang,Yiwen Hu,Jason Klein Liu,Qingnan Ren,Yang Wang,Wayne Xin Zhao,Rui Yan,Bing Su,Chong Luo,Baining Guo*

Main category: cs.LG

TL;DR: 提出 Spectral Sphere Optimizer (SSO)，在 Maximal Update Parametrization (μP) 框架下实现严格的模组级谱约束，对权重及其更新进行全谱对齐的最速下降优化，并在 Megatron 中实现并行化以支持大规模训练；实验表明相较于 AdamW 和 Muon，在多种模型上提高训练稳定性与收敛性，且具备路由负载均衡改进、离群抑制和激活有界等实际稳定性优势。


<details>
  <summary>Details</summary>
Motivation: 现有优化器在权重漂移与更新控制之间存在不对齐问题，如 Muon 等仅部分对齐，未对权重本身施加严格的谱约束，导致大规模训练的稳定性和一致性受限。需要一种在更新和权重上均施加谱约束、且易于大规模并行实现的优化方法。

Method: 提出在谱球（spectral sphere）上求解最速下降方向，从而对权重及其更新实施模块级谱约束，确保完全与 μP 对齐。将该梯度方向作为更新步骤，形成一个完整的 μP 对齐优化过程。为大规模训练，将 SSO 以并行算法在 Megatron 框架内实现，并在不同体系结构（Dense 1.7B、MoE 8B-A1B、200 层 DeepNet）中进行预训练。

Result: SSO 在多种大模型预训练中持续优于 AdamW 和 Muon，表现出更稳健的收敛与训练稳定性。此外，实证观察到实际稳定性提升，包括 MoE 路由负载均衡改善、离群值抑制、激活严格有界等效应。

Conclusion: SSO 提供了对 μP 的完全对齐并施加严格的谱约束的优化框架，适合大规模模型训练，兼具理论性保障与实用稳定性优势，且通过 Megatron 实现的并行化使其具备实际部署潜力。

Abstract: Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization ($\boldsymbolμ$P) provides a theoretical safeguard for width-invariant $Θ(1)$ activation control, whereas emerging optimizers like Muon are only ``half-aligned'' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the \textbf{Spectral Sphere Optimizer (SSO)}, which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully $\boldsymbolμ$P-aligned optimization process. To enable large-scale training, we implement SSO as an efficient parallel algorithm within Megatron. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.

</details>


### [149] [Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance](https://arxiv.org/abs/2601.08418)
*Jihang Li,Qing Liu,Zulong Chen,Jing Wang,Wei Wang,Chuanfei Xu,Zeyi Wen*

Main category: cs.LG

TL;DR: Taxon is a semantically aligned, expert-guided framework for hierarchical tax code prediction that combines a feature-gating mixture-of-experts model with a semantic consistency model distilled from LLMs, plus a multi-source training pipeline; it achieves state-of-the-art results and is deployed in Alibaba’s tax service system.


<details>
  <summary>Details</summary>
Motivation: Accurate tax code assignment in e-commerce requires aligning product titles with multi-level taxonomies, while mitigating noisy supervision and ensuring semantic consistency between definitions and real-world records.

Method: 1) Feature-gating mixture-of-experts routing multi-modal features across taxonomy levels. 2) Semantic consistency model distilled from large language models acting as domain experts to verify alignment with official tax definitions. 3) Multi-source training using curated tax databases, invoice validation logs, and merchant data for structural and semantic supervision. 4) Additional full hierarchical paths reconstruction to improve structural consistency.

Result: State-of-the-art performance on the proprietary TaxCode dataset and public benchmarks; improved F1 scores with full hierarchical path reconstruction; robust, interpretable results; deployed in Alibaba handling hundreds of thousands to millions of tax-code queries daily with improved accuracy.

Conclusion: Taxon delivers strong accuracy, interpretability, and robustness for hierarchical tax code prediction in large-scale e-commerce, with practical production deployment and potential for further gains via hierarchical reconstruction.

Abstract: Tax code prediction is a crucial yet underexplored task in automating invoicing and compliance management for large-scale e-commerce platforms. Each product must be accurately mapped to a node within a multi-level taxonomic hierarchy defined by national standards, where errors lead to financial inconsistencies and regulatory risks. This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction. Taxon integrates (i) a feature-gating mixture-of-experts architecture that adaptively routes multi-modal features across taxonomy levels, and (ii) a semantic consistency model distilled from large language models acting as domain experts to verify alignment between product titles and official tax definitions. To address noisy supervision in real business records, we design a multi-source training pipeline that combines curated tax databases, invoice validation logs, and merchant registration data to provide both structural and semantic supervision. Extensive experiments on the proprietary TaxCode dataset and public benchmarks demonstrate that Taxon achieves state-of-the-art performance, outperforming strong baselines. Further, an additional full hierarchical paths reconstruction procedure significantly improves structural consistency, yielding the highest overall F1 scores. Taxon has been deployed in production within Alibaba's tax service system, handling an average of over 500,000 tax code queries per day and reaching peak volumes above five million requests during business event with improved accuracy, interpretability, and robustness.

</details>


### [150] [Coverage Improvement and Fast Convergence of On-policy Preference Learning](https://arxiv.org/abs/2601.08421)
*Juno Kim,Jihun Yun,Jason D. Lee,Kwang-Sung Jun*

Main category: cs.LG

TL;DR: 这篇论文从理论上解释在线 on-policy 偏好学习（如 DPO）在语言模型对齐中的显著优势，提出“覆盖提升原则”，并证明在带 Bradley-Terry 偏好与线性 softmax 策略的上下文赌博人设下，若批量足够大，on-policy DPO 指数收敛；离线仅利用初始策略的学习在样本复杂度上存在明显劣势。基于此提出基于优先 G-optimal 设计的混合采样器，能在两轮内收敛；同时给出一般函数类下的 on-policy 奖励蒸馏方案及基于偏差的覆盖新 notion 的更快无噪声收敛率。实验结果表明 on-policy DPO 和奖励蒸馏算法优于离线方法，且迭代过程呈稳定、单调的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解释为何在线、按策略更新的偏好学习在 LM 对齐中优于离线采样，核心在于随着训练，采样策略的覆盖区域不断改善，提升后续数据的信息量，从而实现更快、更稳健的收敛。

Method: 在带 Bradley–Terry 偏好、线性 softmax 策略类的上下文赌博设定下，给出对 on-policy DPO 的收敛性分析，证明只要批量大小超过一个广义的覆盖阈值，更新即可将覆盖性带入更优的区域，导出指数收敛。相比之下，离线仅基于初始策略的学习具有慢的 minimax 收敛率，导致样本复杂度上存在显著差距。进一步提出基于新颖的“偏好”G-optimal 设计的混合采样器，消除对覆盖性的依赖，保证仅需两轮收敛。最后发展在一般函数类下的 on-policy 奖励蒸馏策略，并给出基于偏差的覆盖 notion 的无噪声情况下的更快收敛率。

Result: 理论上在所考察的设定下，on-policy DPO 指数级收敛；离线策略因只能从初始策略采样，导致较慢的 minimax 收敛速率；提出的混合采样器实现两轮内收敛；奖励蒸馏方法在一般设定和无噪声下表现出更快的收敛速率。实验结果支持 on-policy DPO 及奖励蒸馏算法优于离线方法，且迭代过程具稳定、单调的性能提升。

Conclusion: 结论支持在语言模型对齐任务中优先采用 on-policy DPO 及文中提出的覆盖提升原则、混合采样设计与奖励蒸馏策略，这些方法可实现更快且更稳定的性能提升及更低的样本开销。

Abstract: Online on-policy preference learning algorithms for language model alignment such as online direct policy optimization (DPO) can significantly outperform their offline counterparts. We provide a theoretical explanation for this phenomenon by analyzing how the sampling policy's coverage evolves throughout on-policy training. We propose and rigorously justify the \emph{coverage improvement principle}: with sufficient batch size, each update moves into a region around the target where coverage is uniformly better, making subsequent data increasingly informative and enabling rapid convergence. In the contextual bandit setting with Bradley-Terry preferences and linear softmax policy class, we show that on-policy DPO converges exponentially in the number of iterations for batch size exceeding a generalized coverage threshold. In contrast, any learner restricted to offline samples from the initial policy suffers a slower minimax rate, leading to a sharp separation in total sample complexity. Motivated by this analysis, we further propose a simple hybrid sampler based on a novel \emph{preferential} G-optimal design, which removes dependence on coverage and guarantees convergence in just two rounds. Finally, we develop principled on-policy schemes for reward distillation in the general function class setting, and show faster noiseless rates under an alternative deviation-based notion of coverage. Experimentally, we confirm that on-policy DPO and our proposed reward distillation algorithms outperform their off-policy counterparts and enjoy stable, monotonic performance gains across iterations.

</details>


### [151] [DiffMM: Efficient Method for Accurate Noisy and Sparse Trajectory Map Matching via One Step Diffusion](https://arxiv.org/abs/2601.08482)
*Chenxu Han,Sean Bin Yang,Jilin Hu*

Main category: cs.LG

TL;DR: DiffMM 框架通过路段感知编码与一步扩散实现稀疏轨迹的高效地图匹配，显著优于现有HMM/编码器-解码器方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 HMM 或编码器-解码器的地图匹配在处理噪声和稀疏GPS轨迹时表现不充分，且对复杂路网的鲁棒性有限，需提升准确性与计算效率。

Method: 提出 DiffMM：1) 路段感知轨迹编码器，将轨迹与周边候选路段通过注意力机制嵌入共享潜在空间；2) 一步扩散捷径模型，以联合嵌入作为条件实现地图匹配。

Result: 在大规模数据集上实验，DiffMM 在准确性和效率上持续优于最先进方法，尤其对稀疏轨迹和复杂路网更具优势。

Conclusion: DiffMM 为地图匹配提供了一种高效鲁棒的新范式，将扩散模型应用于地理序列任务，适用于稀疏与噪声轨迹场景。

Abstract: Map matching for sparse trajectories is a fundamental problem for many trajectory-based applications, e.g., traffic scheduling and traffic flow analysis. Existing methods for map matching are generally based on Hidden Markov Model (HMM) or encoder-decoder framework. However, these methods continue to face significant challenges when handling noisy or sparsely sampled GPS trajectories. To address these limitations, we propose DiffMM, an encoder-diffusion-based map matching framework that produces effective yet efficient matching results through a one-step diffusion process. We first introduce a road segment-aware trajectory encoder that jointly embeds the input trajectory and its surrounding candidate road segments into a shared latent space through an attention mechanism. Next, we propose a one step diffusion method to realize map matching through a shortcut model by leveraging the joint embedding of the trajectory and candidate road segments as conditioning context. We conduct extensive experiments on large-scale trajectory datasets, demonstrating that our approach consistently outperforms state-of-the-art map matching methods in terms of both accuracy and efficiency, particularly for sparse trajectories and complex road network topologies.

</details>


### [152] [Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care](https://arxiv.org/abs/2601.08503)
*Aditya Kumar,Simon Rauch,Mario Cypko,Marcel Naik,Matthieu-P Schapranow,Aadil Rashid,Fabian Halleck,Bilgin Osmanodja,Roland Roller,Lars Pape,Klemens Budde,Mario Schiffer,Oliver Amft*

Main category: cs.LG

TL;DR: TFN是一种多模态、任务无关的嵌入模型，整合不规则时间序列与临床文本以改进器官移植后结局预测。


<details>
  <summary>Details</summary>
Motivation: 解决异质、非规则的医疗数据与丰富的叙事性文档对预测任务的挑战，提升器官移植后肾病移植患者的结局预测能力。

Method: 在3382名肾移植后患者的队列中训练TFN，对移植后结局（肾损失、排斥反应、死亡）进行三项预测。与现有最优模型比较，评估时间序列、静态数据及文本信息的影响，并采用AUC指标。通过解耦度量评估潜在因子可解释性，使用SHAP评估特征归因以对齐临床推理。

Result: TFN在肾移植后结局预测中表现优于对比：肾损失AUC 0.96(对比0.94)，排斥反应AUC 0.84(对比0.74)；死亡AUC 0.86。相对于仅时间序列基线约提升10% AUC，相对于时间序列+静态数据基线约提升5% AUC。整合文本信息在所有任务中提升。解耦度量显示潜在因子稳健且具可解释性，SHAP归因与临床推理一致。

Conclusion: TFN在肿瘤以外的任务中也具潜力，适用于具有异质数据、不规则纵向数据与丰富叙事文档的临床场景。

Abstract: We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives. We analysed TFN in post-kidney transplant (KTx) care, with a retrospective cohort of 3382 patients, on three key outcomes: graft loss, graft rejection, and mortality. Compared to state-of-the-art model in post KTx care, TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94) and graft rejection (AUC 0.84 vs. 0.74). In mortality prediction, TFN yielded an AUC of 0.86. TFN outperformed unimodal baselines (approx 10% AUC improvement over time series only baseline, approx 5% AUC improvement over time series with static patient data). Integrating clinical text improved performance across all tasks. Disentanglement metrics confirmed robust and interpretable latent factors in the embedding space, and SHAP-based attributions confirmed alignment with clinical reasoning. TFN has potential application in clinical tasks beyond KTx, where heterogeneous data sources, irregular longitudinal data, and rich narrative documentation are available.

</details>


### [153] [Your Group-Relative Advantage Is Biased](https://arxiv.org/abs/2601.08521)
*Fengkai Yang,Zherui Chen,Xiaohan Wang,Xiaodong Lu,Jiajun Chai,Guojun Yin,Wei Lin,Shuai Ma,Fuzhen Zhuang,Deqing Wang,Yaodong Yang,Jianxin Li,Yikun Ban*

Main category: cs.LG

TL;DR: 该论文揭示在 RLVR 的基于分组的优势估计中存在固有偏差：对难 prompts 低估、对易 prompts 高估，导致探索与利用失衡；提出 HA-DW 来纠正偏差，在五个数学推理基准上与 GRPO 等变体联用时取得一致提升。


<details>
  <summary>Details</summary>
Motivation: 理解基于分组的 RLVR 的理论性质，特别是组相对优势估计的偏差及其对训练稳定性和性能的影响，并提出实用的偏差校正方法。

Method: 进行对组相对优势估计的理论分析，证明其偏差性；提出 History-Aware Adaptive Difficulty Weighting (HA-DW) 的自适应再加权机制，基于演化中的难度锚点和训练动态调整优势估计；在五个数学推理基准上对 GRPO 及其变体进行实验验证。

Result: 理论分析和实验证据表明 HA-DW 能在将其整合到 GRPO 及其变体后，带来一致的性能提升；改进了探索-利用之间的平衡，凸显了纠正偏差在鲁棒且高效的 RLVR 训练中的作用。

Conclusion: 纠正基于分组的优势估计的偏差对鲁棒 RLVR 至关重要，HA-DW 提供了一个有效的解决方案，并暗示未来应在 RLVR 中优先考虑偏差校正策略。

Abstract: Reinforcement Learning from Verifier Rewards (RLVR) has emerged as a widely used approach for post-training large language models on reasoning tasks, with group-based methods such as GRPO and its variants gaining broad adoption. These methods rely on group-relative advantage estimation to avoid learned critics, yet its theoretical properties remain poorly understood.
  In this work, we uncover a fundamental issue of group-based RL: the group-relative advantage estimator is inherently biased relative to the true (expected) advantage. We provide the first theoretical analysis showing that it systematically underestimates advantages for hard prompts and overestimates them for easy prompts, leading to imbalanced exploration and exploitation. To address this issue, we propose History-Aware Adaptive Difficulty Weighting (HA-DW), an adaptive reweighting scheme that adjusts advantage estimates based on an evolving difficulty anchor and training dynamics. Both theoretical analysis and experiments on five mathematical reasoning benchmarks demonstrate that HA-DW consistently improves performance when integrated into GRPO and its variants. Our results suggest that correcting biased advantage estimation is critical for robust and efficient RLVR training.

</details>


### [154] [EviNAM: Intelligibility and Uncertainty via Evidential Neural Additive Models](https://arxiv.org/abs/2601.08556)
*Sören Schleibaum,Anton Frederik Thielmann,Julian Teusch,Benjamin Säfken,Jörg P. Müller*

Main category: cs.LG

TL;DR: EviNAM is a single-pass evidential learning framework that combines Neural Additive Models' interpretability with principled uncertainty estimation, providing both aleatoric and epistemic uncertainty estimates plus explicit feature contributions, with competitive predictive performance in regression and potential extension to classification/GAMs.


<details>
  <summary>Details</summary>
Motivation: There is a demand for transparent, trustworthy predictions that come with credible uncertainty estimates. Integrating interpretable additive models with rigorous uncertainty quantification can improve decision-making.

Method: Extend evidential learning to Neural Additive Models (NAMs) to enable simultaneous estimation of aleatoric and epistemic uncertainty and explicit feature contributions in a single pass, preserving additive interpretability.

Result: Empirical results on synthetic and real data show predictive performance on par with state-of-the-art methods; uncertainty estimates and feature attributions are provided in a single pass; demonstrated for regression with natural extension to classification and generalized additive models.

Conclusion: EviNAM advances intelligible and trustworthy predictions by unifying interpretability and uncertainty quantification, with a natural path to extend to other tasks like classification and GAMs.

Abstract: Intelligibility and accurate uncertainty estimation are crucial for reliable decision-making. In this paper, we propose EviNAM, an extension of evidential learning that integrates the interpretability of Neural Additive Models (NAMs) with principled uncertainty estimation. Unlike standard Bayesian neural networks and previous evidential methods, EviNAM enables, in a single pass, both the estimation of the aleatoric and epistemic uncertainty as well as explicit feature contributions. Experiments on synthetic and real data demonstrate that EviNAM matches state-of-the-art predictive performance. While we focus on regression, our method extends naturally to classification and generalized additive models, offering a path toward more intelligible and trustworthy predictions.

</details>


### [155] [M$^2$FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting](https://arxiv.org/abs/2601.08631)
*Yaohui Huang,Runmin Zou,Yun Wang,Laeeq Aslam,Ruipeng Dong*

Main category: cs.LG

TL;DR: 提出了 M^2FMoE 的极端自适应预测模型，通过多分辨率和多视角频率建模，在傅立叶与小波域为不同谱段分配专家，具备跨视角的分割与协作，层级粒度融合和时序门控，能在不依赖极端事件标签的情况下提升极端事件预测表现。


<details>
  <summary>Details</summary>
Motivation: 极端事件具有高方差、非平稳性与稀疏但高影响的特征，现有方法在常规模式上表现良好，但在极端事件上往往预测失效，需更好地捕捉极端时序动力学。尽管有方法利用辅助信号，但仍难以覆盖极端事件的复杂时间特征，因此需要新的多视角、频域和多分辨率的建模策略。

Method: 提出三大模块：1) 多视角频率混合专家（MView-FMoE）：在傅立叶与小波域的谱带上分配专家，跨视角的分割器对齐频率分区并实现跨专家协作以捕捉主导与罕见波动；2) 多分辨率自适应融合（MR-AF）：从粗到细的频率特征层级聚合，提升对短期变化和突变的敏感度；3) 时序门控整合（TG-I）：动态平衡长期趋势与短期频率特征，提高对常规与极端时序模式的适应性。

Result: 在真实水文数据集上的极端模式评估中，M^2FMoE 显著优于现有最先进基线，且无需极端事件标签。

Conclusion: 通过谱域多视角和多分辨率融合实现对常规与极端时间动态的高效建模，显著提升极端事件预测的鲁棒性与准确性。

Abstract: Forecasting time series with extreme events is critical yet challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. While existing methods excel in modeling dominant regular patterns, their performance degrades significantly during extreme events, constituting the primary source of forecasting errors in real-world applications. Although some approaches incorporate auxiliary signals to improve performance, they still fail to capture extreme events' complex temporal dynamics. To address these limitations, we propose M$^2$FMoE, an extreme-adaptive forecasting model that learns both regular and extreme patterns through multi-resolution and multi-view frequency modeling. It comprises three modules: (1) a multi-view frequency mixture-of-experts module assigns experts to distinct spectral bands in Fourier and Wavelet domains, with cross-view shared band splitter aligning frequency partitions and enabling inter-expert collaboration to capture both dominant and rare fluctuations; (2) a multi-resolution adaptive fusion module that hierarchically aggregates frequency features from coarse to fine resolutions, enhancing sensitivity to both short-term variations and sudden changes; (3) a temporal gating integration module that dynamically balances long-term trends and short-term frequency-aware features, improving adaptability to both regular and extreme temporal patterns. Experiments on real-world hydrological datasets with extreme patterns demonstrate that M$^2$FMoE outperforms state-of-the-art baselines without requiring extreme-event labels.

</details>


### [156] [Provably Safe Reinforcement Learning using Entropy Regularizer](https://arxiv.org/abs/2601.08646)
*Abhijit Mazumdar,Rafal Wisniewski,Manuela L. Bujorianu*

Main category: cs.LG

TL;DR: 在具有 reach-avoid 安全约束的马尔可夫决策过程（MDP）中，提出基于乐观策略（OFU）的安全强化学习算法及其引入熵正则化后的主算法，给出两算法的有限样本下的 regret 分析与界。结果表明，熵正则化不仅改善了 regret，还显著降低了 OFU-安全 RL 过程中固有的对局间波动。


<details>
  <summary>Details</summary>
Motivation: 解决在线学习过程中的安全性保障问题，在达到目标的同时确保高概率的安全约束满足，研究在安全约束环境中的强化学习的可行性与性能保障。

Method: 基于OFU的安全RL算法；在此基础上提出引入熵正则化的主算法；对两种算法进行有限样本分析，推导其 regret 界；通过正则化对过度探索与策略波动进行抑制，提升稳定性。

Result: 两种算法均给出有限样本下的 regret 界；熵正则化提升了 regret 的上界表现，并显著降低了与 OFU 相关的 episode-to-episode 变异性。

Conclusion: 熵正则化在安全强化学习中具有明显的优点，能够在保证安全性前提下提高学习效率并降低结果的波动，为未来在安全约束下的在线RL提供更稳健的优化方向。

Abstract: We consider the problem of learning the optimal policy for Markov decision processes with safety constraints. We formulate the problem in a reach-avoid setup. Our goal is to design online reinforcement learning algorithms that ensure safety constraints with arbitrarily high probability during the learning phase. To this end, we first propose an algorithm based on the optimism in the face of uncertainty (OFU) principle. Based on the first algorithm, we propose our main algorithm, which utilizes entropy regularization. We investigate the finite-sample analysis of both algorithms and derive their regret bounds. We demonstrate that the inclusion of entropy regularization improves the regret and drastically controls the episode-to-episode variability that is inherent in OFU-based safe RL algorithms.

</details>


### [157] [TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations](https://arxiv.org/abs/2601.08659)
*Hamid Gadirov,Martijn Westra,Steffen Frey*

Main category: cs.LG

TL;DR: 对参数化Kármán涡街仿真的高维时变数据，比较2D与3D卷积自编码器在重建基础异常检测中的性能。结果显示：2D擅长定位单帧的局部空间异常，3D通过时空上下文检测运动型异常并减少时间上的冗余检测；体积数据的重构误差受质量分布影响显著，集中质量导致误差增大，强调时序信息对鲁棒性的重要性。


<details>
  <summary>Details</summary>
Motivation: 在高维、时变的流体仿真中，异常检测面临复杂的时空特征与冗余信号，需通过重构误差实现无监督检测。本文通过比较2D和3D自编码器来评估时空上下文对检测性能的影响，并探讨 volumetric 时间数据中质量分布对重构误差的作用。

Method: 采用卷积自编码器：2D模型对单帧进行重构；3D模型对短时间栈进行体积化重构，比较两者在来自参数化涡街的集合数据上的异常检测能力；扩展到体积时间数据，分析重构误差与质量分布的关系。

Result: 2D模型能在单帧层面识别局部空间不规则性；3D模型利用时空相关性检测异常的运动模式，并减少跨时间的冗余检测；在体积时间数据中，重构误差与质量分布高度相关，集中区域产生更大误差；总体而言，时序上下文对稳健的动态异常检测至关重要。

Conclusion: 引入时序信息（3D卷积）显著提升动态仿真中的异常检测鲁棒性，尤其在减少冗余检测方面表现突出；同时需注意质量分布对重构误差的影响，设计时应考虑对高集中区域的敏感性。

Abstract: Detecting anomalies in high-dimensional, time-dependent simulation data is challenging due to complex spatial and temporal dynamics. We study reconstruction-based anomaly detection for ensemble data from parameterized Kármán vortex street simulations using convolutional autoencoders. We compare a 2D autoencoder operating on individual frames with a 3D autoencoder that processes short temporal stacks. The 2D model identifies localized spatial irregularities in single time steps, while the 3D model exploits spatio-temporal context to detect anomalous motion patterns and reduces redundant detections across time. We further evaluate volumetric time-dependent data and find that reconstruction errors are strongly influenced by the spatial distribution of mass, with highly concentrated regions yielding larger errors than dispersed configurations. Our results highlight the importance of temporal context for robust anomaly detection in dynamic simulations.

</details>


### [158] [Soft Partition-based KAPI-ELM for Multi-Scale PDEs](https://arxiv.org/abs/2601.08719)
*Vikas Dwivedi,Monica Sigovan,Bruno Sixou*

Main category: cs.LG

TL;DR: 提出 KAPI-ELM，一种基于软分区的核自适应物理信息极限学习机，通过平滑分区长度同时控制采样点和高斯核带宽，实现无 Fourier 特征、无随机采样和无硬域界面的连续自适应分辨率；结合基于符号距离的加权，在不规则几何上稳定最小二乘学习。针对振荡性 ODE、高频 Poisson、 irregular shapes 及强耦合/奇异摄动对流-扩散等问题，达到或超过 PINN 与 TFC 的精度，仅需一次线性求解；示例表明对多尺度 PDE 的潜力，代码开源。


<details>
  <summary>Details</summary>
Motivation: 为解决高振荡、多尺度或奇异摄动 PDE 中的光谱偏置、反向传播成本与手动调参等挑战，提出一种确定性的低维参数化方法，通过软分区控制采样点和高斯核带宽，避免使用 Fourier 特征、随机采样和硬域界面。

Method: 引入基于软分区的核自适应方法，采用确定的低维参数（分区长度）共同设定 collocation 点与高斯核带宽，实现从粗到细的连续分辨率；不使用傅里叶特征、随机采样或硬域界面；采用基于符号距离的加权稳定在不规则几何上的最小二乘学习；整个训练仅需一个线性求解。

Result: 在八个基准上，方法与状态艺术的 PINN 与 TFC 变体在精度上相当或优于之处，同时计算成本低廉，仅需一次线性求解；可用于稳态线性 PDE，且对多尺度问题具有潜力；代码可复现。

Conclusion: 软分区核自适应为快速、架构无关的多尺度 PDE 解决方案，具有广泛潜力与未来拓展空间。

Abstract: Physics-informed machine learning holds great promise for solving differential equations, yet existing methods struggle with highly oscillatory, multiscale, or singularly perturbed PDEs due to spectral bias, costly backpropagation, and manually tuned kernel or Fourier frequencies. This work introduces a soft partition--based Kernel-Adaptive Physics-Informed Extreme Learning Machine (KAPI-ELM), a deterministic low-dimensional parameterization in which smooth partition lengths jointly control collocation centers and Gaussian kernel widths, enabling continuous coarse-to-fine resolution without Fourier features, random sampling, or hard domain interfaces. A signed-distance-based weighting further stabilizes least-squares learning on irregular geometries. Across eight benchmarks--including oscillatory ODEs, high-frequency Poisson equations, irregular-shaped domains, and stiff singularly perturbed convection-diffusion problems-the proposed method matches or exceeds the accuracy of state-of-the-art Physics-Informed Neural Network (PINN) and Theory of Functional Connections (TFC) variants while using only a single linear solve. Although demonstrated on steady linear PDEs, the results show that soft-partition kernel adaptation provides a fast, architecture-free approach for multiscale PDEs with broad potential for future physics-informed modeling. For reproducibility, the reference codes are available at https://github.com/vikas-dwivedi-2022/soft_kapi

</details>


### [159] [A Novel Approach to Explainable AI with Quantized Active Ingredients in Decision Making](https://arxiv.org/abs/2601.08733)
*A. M. A. S. D. Alagiyawanna,Asoka Karunananda,Thushari Silva,A. Mahasinghe*

Main category: cs.LG

TL;DR: 提出将量子-经典混合模型用于提升可解释性AI，通过在降维后的MNIST上比较QBMs与CBMs来评估性能与特征归因的清晰度；结果显示QBMs在准确性和归因集中性上优于CBMs。


<details>
  <summary>Details</summary>
Motivation: 解决高风险领域的可解释性挑战；探索将量子计算原理融入经典机器学习以提高透明度和信任度。

Method: 在 binarised、PCA 降维处理的 MNIST 数据集上，分别训练量子-经典混合的 QBMs 与经典 Boltzmann Machines CBMs。对可解释性进行评估：QBMs 使用基于梯度的显著性图，CBMs 使用 SHAP。CBMs 采用对比散度进行训练，QBMs 使用强纠缠层的混合量子-经典电路以获得更丰富的潜在表征。

Result: QBMs 的分类准确率为83.5%，CBMs 为54%。在特征归因的熵值方面，QBMs 为1.27，CBMs 为1.39，QBMs 的归因更集中、对“活性成分”的识别更清晰。

Conclusion: 量子-经典混合模型可同时在准确性和可解释性方面带来提升，推动可解释AI系统的发展与信任建立。

Abstract: Artificial Intelligence (AI) systems have shown good success at classifying. However, the lack of explainability is a true and significant challenge, especially in high-stakes domains, such as health and finance, where understanding is paramount. We propose a new solution to this challenge: an explainable AI framework based on our comparative study with Quantum Boltzmann Machines (QBMs) and Classical Boltzmann Machines (CBMs). We leverage principles of quantum computing within classical machine learning to provide substantive transparency around decision-making. The design involves training both models on a binarised and dimensionally reduced MNIST dataset, where Principal Component Analysis (PCA) is applied for preprocessing. For interpretability, we employ gradient-based saliency maps in QBMs and SHAP (SHapley Additive exPlanations) in CBMs to evaluate feature attributions.QBMs deploy hybrid quantum-classical circuits with strongly entangling layers, allowing for richer latent representations, whereas CBMs serve as a classical baseline that utilises contrastive divergence. Along the way, we found that QBMs outperformed CBMs on classification accuracy (83.5% vs. 54%) and had more concentrated distributions in feature attributions as quantified by entropy (1.27 vs. 1.39). In other words, QBMs not only produced better predictive performance than CBMs, but they also provided clearer identification of "active ingredient" or the most important features behind model predictions. To conclude, our results illustrate that quantum-classical hybrid models can display improvements in both accuracy and interpretability, which leads us toward more trustworthy and explainable AI systems.

</details>


### [160] [Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs](https://arxiv.org/abs/2601.08763)
*Zhiyuan Hu,Yucheng Wang,Yufei He,Jiaying Wu,Yilun Zhao,See-Kiong Ng,Cynthia Breazeal,Anh Tuan Luu,Hae Won Park,Bryan Hooi*

Main category: cs.LG

TL;DR: 提出一种将高层策略多样性纳入回合级奖励的Uniqueness-Aware RL，利用LLM judge将同一问题的不同解策略聚类并按簇大小对优势进行反向重加权，从而提升pass@k和AUC@K，同时保持pass@1。


<details>
  <summary>Details</summary>
Motivation: RL在后训练的LLMs中用于复杂推理，但探索崩溃导致仅聚焦少数解策略，提升pass@1但降低rollout层面的多样性与pass@k增益。现有正则化聚焦于局部token行为而非解集合的多样性。需要一个能鼓励多样高层策略的 rollout 级目标。

Method: 提出Uniqueness-Aware RL，使用LLM判别器对同一问题的rollouts按高层策略聚类，忽略表面变体；以簇大小的逆数对策略优势进行重加权，正确但新颖的策略获得更高奖励。

Result: 在数学、物理、医学推理基准上，方法在大采样预算下显著提升pass@k、提高AUC@K，同时不损害pass@1，保持探索并在规模上发现更多多样化解策略。

Conclusion: 通过将高层策略多样性纳入回合级目标，解决探索崩溃问题，方法在多领域具备泛化性，可在大规模采样下提升解策略多样性与鲁棒性。

Abstract: Reinforcement learning (RL) has become a central paradigm for post-training large language models (LLMs), particularly for complex reasoning tasks, yet it often suffers from exploration collapse: policies prematurely concentrate on a small set of dominant reasoning patterns, improving pass@1 while limiting rollout-level diversity and gains in pass@k. We argue that this failure stems from regularizing local token behavior rather than diversity over sets of solutions. To address this, we propose Uniqueness-Aware Reinforcement Learning, a rollout-level objective that explicitly rewards correct solutions that exhibit rare high-level strategies. Our method uses an LLM-based judge to cluster rollouts for the same problem according to their high-level solution strategies, ignoring superficial variations, and reweights policy advantages inversely with cluster size. As a result, correct but novel strategies receive higher rewards than redundant ones. Across mathematics, physics, and medical reasoning benchmarks, our approach consistently improves pass@$k$ across large sampling budgets and increases the area under the pass@$k$ curve (AUC@$K$) without sacrificing pass@1, while sustaining exploration and uncovering more diverse solution strategies at scale.

</details>


### [161] [Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling](https://arxiv.org/abs/2601.08777)
*Yang Cai,Weiqiang Zheng*

Main category: cs.LG

TL;DR: 提出并分析一种基于测试时扩展的通用对齐框架，给出最优收敛速率 f(k)=k/(k+1)，并指出现有 NLHF 等方法在输出多样性方面的局限。


<details>
  <summary>Details</summary>
Motivation: 在用户偏好异质且可能冲突的场景下，追求普适性的对齐；通过测试时提供多输出以供用户选择实现更强的对齐保障；给出理论极限与实现路径。

Method: 引入 k 输出策略、输出集合的胜率 f(k) 相对单输出模型，提出 U-对齐（f(k)→1 当 k→∞）；构造单输出策略，使其 k 样本的联合策略达到 f(k)=k/(k+1)，并证明无方法能超越此速率。分析 NLHF 等后训练方法在多样性缺失导致的潜在效率浪费；提出对称多玩家对齐博弈，证明任何对称纳什均衡策略在 (k+1)-玩家对齐博弈中实现最优的 (k, k/(k+1))-鲁棒对齐；给出自博弍学习动态的收敛性保证，并扩展到对手也生成多重输出的情况。

Result: 理论上确立了最优的收敛速率 f(k)=k/(k+1)；指出常见 NLHF 等方法在对齐测试时扩展下的效率上限受限；提出通过对称纳什均衡实现最优鲁棒对齐的具体机制；给出自博弈学习的收敛性保证及对手多输出情形的扩展。

Conclusion: 提供了一个可操作的对齐框架，强调输出多样性的重要性，揭示了测试时扩展带来的理论极限，并给出实现路径及收敛保障，未来工作可在更真实的用户分布和成本约束下进行实验验证。

Abstract: Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. We formalize an ideal notion of universal alignment through test-time scaling: for each prompt, the model produces $k\ge 1$ candidate responses and a user selects their preferred one. We introduce $(k,f(k))$-robust alignment, which requires the $k$-output model to have win rate $f(k)$ against any other single-output model, and asymptotic universal alignment (U-alignment), which requires $f(k)\to 1$ as $k\to\infty$. Our main result characterizes the optimal convergence rate: there exists a family of single-output policies whose $k$-sample product policies achieve U-alignment at rate $f(k)=\frac{k}{k+1}$, and no method can achieve a faster rate in general.
  We show that popular post-training methods, including Nash learning from human feedback (NLHF), can fundamentally underutilize the benefits of test-time scaling. Even though NLHF is optimal for $k=1$, sampling from the resulting (often deterministic) policy cannot guarantee win rates above $\tfrac{1}{2}$ except for an arbitrarily small slack. This stems from a lack of output diversity: existing alignment methods can collapse to a single majority-preferred response, making additional samples redundant. In contrast, our approach preserves output diversity and achieves the optimal test-time scaling rate. In particular, we propose a family of symmetric multi-player alignment games and prove that any symmetric Nash equilibrium policy of the $(k+1)$-player alignment game achieves the optimal $(k,\frac{k}{k+1})$-robust alignment. Finally, we provide theoretical convergence guarantees for self-play learning dynamics in these games and extend the framework to opponents that also generate multiple responses.

</details>


### [162] [Fast and explainable clustering in the Manhattan and Tanimoto distance](https://arxiv.org/abs/2601.08781)
*Stefan Güttel,Kaustubh Roy*

Main category: cs.LG

TL;DR: 将 CLASSIX 算法扩展到 Manhattan 和 Tanimoto 距离，采用向量范数排序和三角不等式剪枝；在化学指纹数据上，Tanimoto 变体显著提速并提升簇质量。


<details>
  <summary>Details</summary>
Motivation: 解决原始 CLASSIX 依赖第一主成分排序的局限性，提升对不同距离度量的聚类效率与可解释性，尤其是大规模化学指纹数据的处理。

Method: 将原有基于主成分排序改为基于数据向量范数的排序，结合三角不等式进行搜索终止；对 Tanimoto 距离使用更尖锐的交集不等式以增强剪枝；实现 Manhattan 与 Tanimoto 等距离下的近邻筛选与簇构建。

Result: 在真实化学指纹基准上，CLASSIX Tanimoto 约比 Taylor-Butina 快 30 倍、比 DBSCAN 快 80 倍，且簇质量更高；扩展到 Manhattan 与其他距离指标同样显示性能与质量的提升。

Conclusion: 通用化的 CLASSIX 在多种距离度量下实现显著加速与簇质量提升，尤其在化学指纹数据场景中对 Tanimoto 距离的变体效果突出。

Abstract: The CLASSIX algorithm is a fast and explainable approach to data clustering. In its original form, this algorithm exploits the sorting of the data points by their first principal component to truncate the search for nearby data points, with nearness being defined in terms of the Euclidean distance. Here we extend CLASSIX to other distance metrics, including the Manhattan distance and the Tanimoto distance. Instead of principal components, we use an appropriate norm of the data vectors as the sorting criterion, combined with the triangle inequality for search termination. In the case of Tanimoto distance, a provably sharper intersection inequality is used to further boost the performance of the new algorithm. On a real-world chemical fingerprint benchmark, CLASSIX Tanimoto is about 30 times faster than the Taylor--Butina algorithm, and about 80 times faster than DBSCAN, while computing higher-quality clusters in both cases.

</details>
